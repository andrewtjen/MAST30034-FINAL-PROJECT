{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error, r2_score\n",
    "import statistics\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adamax\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../df.csv\")\n",
    "doc2vec50 = pd.read_csv(\"../dataset/doc2vec_50.csv\")\n",
    "df_train= df[[\"essay_set\", \"essay\",\"total_score\", \"word_count\",\"Mistakes\",\"reading_ease\"]]\n",
    "df_train = doc2vec50\n",
    "df_train = pd.concat([df_train, df[[\"essay_set\", \"word_count\",\"Mistakes\",\"reading_ease\"]]], axis = 1, join = \"inner\").drop(['Unnamed: 0'], axis = 1)\n",
    "y = df[\"total_score\"]\n",
    "X = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../df.csv\")\n",
    "doc2vec300 = pd.read_csv(\"../dataset/doc2vec_300.csv\")\n",
    "df_train= df[[\"essay_set\", \"essay\",\"total_score\", \"word_count\",\"Mistakes\",\"reading_ease\"]]\n",
    "df_train = doc2vec300\n",
    "df_train = pd.concat([df_train, df[[\"essay_set\", \"word_count\",\"Mistakes\",\"reading_ease\"]]], axis = 1, join = \"inner\").drop(['Unnamed: 0'], axis = 1)\n",
    "y = df[\"total_score\"].values\n",
    "X = df_train.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(neuron = 50, dropout = 0.1, rec_dropout = 0.1):\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neuron, dropout= dropout, recurrent_dropout=dropout, input_shape=[1, 54], return_sequences=True))\n",
    "    model.add(LSTM(neuron, recurrent_dropout=dropout))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<tensorflow.python.keras.engine.sequential.Sequential object at 0x00000254C8465D60>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'dropout': [0.2, 0.4, 0.8], 'neuron': [50, 100, 200],\n",
       "                         'rec_dropout': [0.2, 0.4, 0.8]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropouts = [0.2, 0.4, 0.8]\n",
    "rec_dropouts = [0.2, 0.4, 0.8]\n",
    "neurons = [50,100,200]\n",
    "param_grid = dict(neuron=neurons, dropout = dropouts, rec_dropout = rec_dropouts)\n",
    "param_grid\n",
    "\n",
    "model = get_model()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########Set-1###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_38 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_42 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_44 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_46 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_50 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_58 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_62 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_66 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_68 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_70 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_72 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_73 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_74 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_76 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_78 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_80 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_82 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_84 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_85 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_86 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_88 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_89 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_90 (LSTM)               (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_92 (LSTM)               (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_94 (LSTM)               (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_95 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_96 (LSTM)               (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_98 (LSTM)               (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_100 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_101 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_102 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_103 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_104 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_105 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_106 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_107 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_108 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_109 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_110 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_111 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_112 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_113 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_114 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_115 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_116 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_117 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_118 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_119 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_120 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_121 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_122 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_123 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_124 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_125 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_126 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_127 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_128 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_129 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_130 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_131 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_132 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_133 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_134 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_135 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_136 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_137 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_138 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_139 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_140 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_141 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_142 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_143 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_144 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_145 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_146 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_147 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_148 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_149 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_150 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_151 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_152 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_153 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_154 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_155 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_156 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_157 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_158 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_159 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_160 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_161 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_162 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_163 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_164 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_165 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_166 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_167 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_168 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_169 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_170 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_171 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_172 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_173 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_174 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_175 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_176 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_177 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_178 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_179 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_180 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_181 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_182 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_183 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_184 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_185 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_186 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_187 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_188 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_189 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_190 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_191 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_192 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_193 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_194 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_195 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_196 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_197 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_198 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_199 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_200 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_201 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_202 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_203 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_204 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_205 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_206 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_207 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_208 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_209 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_210 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_211 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_212 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_213 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_214 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_215 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_216 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_217 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_218 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_219 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_220 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_221 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_222 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_223 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_224 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_225 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_226 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_227 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_228 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_229 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_230 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_231 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_232 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_233 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_234 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_235 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_236 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_237 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_238 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_239 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_240 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_241 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_242 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_243 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_244 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_245 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_246 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_247 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_248 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_249 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_250 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_251 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_252 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_253 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_254 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_255 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_256 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_257 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_258 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_259 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_260 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_261 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_262 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_263 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_264 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_265 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_266 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_267 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_268 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_269 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_270 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_271 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "###########Set-2###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_272 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_273 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_274 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_275 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_276 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_277 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_278 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_279 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_280 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_281 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_282 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_283 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_284 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_285 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_286 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_287 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_288 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_289 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_290 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_291 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_292 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_293 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_294 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_295 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_296 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_297 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_298 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_299 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_300 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_301 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_302 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_303 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_304 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_305 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_306 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_307 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_308 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_309 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_310 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_311 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_312 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_313 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_314 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_315 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_316 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_317 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_318 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_319 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_320 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_321 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_322 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_323 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_324 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_325 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_326 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_327 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_328 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_329 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_330 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_331 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_332 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_333 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_334 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_335 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_336 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_337 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_338 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_339 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_340 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_341 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_342 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_343 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_344 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_345 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_346 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_347 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_348 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_349 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_350 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_351 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_352 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_353 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_354 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_355 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_356 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_357 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_358 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_359 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_360 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_361 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_362 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_363 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_364 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_365 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_366 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_367 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_368 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_369 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_370 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_371 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_372 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_373 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_374 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_375 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_376 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_377 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_188 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_378 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_379 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_380 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_381 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_382 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_383 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_384 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_385 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_386 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_387 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_388 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_389 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_194 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_390 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_391 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_195 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_392 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_393 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_394 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_395 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_396 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_397 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_398 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_399 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_400 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_401 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_402 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_403 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_404 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_405 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_406 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_407 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_203 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_408 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_409 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_204 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_410 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_411 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_205 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_412 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_413 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_206 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_414 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_415 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_207 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_416 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_417 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_208 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_418 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_419 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_209 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_420 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_421 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_210 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_422 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_423 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_211 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_424 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_425 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_212 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_426 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_427 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_213 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_428 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_429 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_214 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_430 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_431 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_215 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_432 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_433 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_216 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_434 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_435 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_436 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_437 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_438 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_439 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_440 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_441 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_442 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_443 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_221 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_444 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_445 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_222 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_446 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_447 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_223 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_448 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_449 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_224 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_450 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_451 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_452 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_453 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_226 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_454 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_455 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_227 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_456 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_457 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_228 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_458 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_459 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_229 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_460 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_461 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_230 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_462 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_463 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_231 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_464 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_465 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_232 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_466 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_467 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_233 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_468 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_469 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_234 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_470 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_471 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_235 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_472 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_473 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_236 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_474 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_475 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_237 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_476 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_477 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_238 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_478 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_479 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_239 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_480 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_481 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_240 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_482 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_483 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_241 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_484 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_485 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_242 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_486 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_487 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_243 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_488 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_489 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_244 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_490 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_491 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_245 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_492 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_493 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_246 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_494 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_495 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_247 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_496 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_497 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_248 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_498 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_499 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_249 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_500 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_501 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_250 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_502 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_503 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_251 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_504 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_505 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_252 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_506 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_507 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_253 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_508 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_509 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_254 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_510 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_511 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_255 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_512 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_513 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_256 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_514 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_515 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_257 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_516 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_517 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_258 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_518 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_519 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_259 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_520 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_521 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_260 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_522 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_523 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_261 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_524 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_525 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_262 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_263\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_526 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_527 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_263 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_528 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_529 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_264 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_265\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_530 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_531 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_265 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_266\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_532 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_533 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_266 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_267\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_534 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_535 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_267 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_268\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_536 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_537 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_268 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_269\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_538 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_539 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_269 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_270\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_540 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_541 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_270 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########Set-3###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_271\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_542 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_543 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_271 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_272\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_544 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_545 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_272 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_273\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_546 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_547 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_273 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_274\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_548 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_549 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_274 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_275\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_550 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_551 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_275 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_276\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_552 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_553 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_276 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_277\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_554 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_555 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_277 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_278\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_556 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_557 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_278 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_279\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_558 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_559 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_279 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_280\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_560 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_561 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_280 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_281\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_562 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_563 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_281 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_282\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_564 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_565 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_282 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_283\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_566 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_567 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_283 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_284\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_568 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_569 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_284 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_285\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_570 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_571 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_285 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_286\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_572 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_573 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_286 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_287\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_574 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_575 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_287 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_288\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_576 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_577 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_288 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_289\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_578 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_579 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_289 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_290\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_580 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_581 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_290 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_291\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_582 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_583 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_291 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_292\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_584 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_585 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_292 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_293\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_586 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_587 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_293 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_294\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_588 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_589 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_294 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_295\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_590 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_591 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_295 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_296\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_592 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_593 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_296 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_297\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_594 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_595 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_297 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_298\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_596 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_597 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_298 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_299\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_598 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_599 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_299 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_300\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_600 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_601 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_300 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_301\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_602 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_603 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_301 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_302\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_604 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_605 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_302 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_303\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_606 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_607 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_303 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_304\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_608 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_609 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_304 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_305\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_610 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_611 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_305 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_306\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_612 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_613 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_306 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_307\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_614 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_615 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_307 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_308\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_616 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_617 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_308 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_309\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_618 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_619 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_309 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_310\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_620 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_621 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_310 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_311\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_622 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_623 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_311 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_312\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_624 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_625 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_312 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_313\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_626 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_627 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_313 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_314\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_628 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_629 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_314 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_315\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_630 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_631 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_315 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_316\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_632 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_633 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_316 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_317\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_634 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_635 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_317 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_318\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_636 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_637 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_318 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_319\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_638 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_639 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_319 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_320\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_640 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_641 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_320 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_321\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_642 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_643 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_321 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_322\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_644 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_645 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_322 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_323\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_646 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_647 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_323 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_324\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_648 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_649 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_324 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_325\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_650 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_651 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_325 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_326\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_652 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_653 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_327\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_654 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_655 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_328\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_656 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_657 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_328 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_329\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_658 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_659 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_329 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_330\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_660 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_661 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_330 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_331\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_662 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_663 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_331 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_332\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_664 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_665 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_332 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_333\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_666 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_667 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_333 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_334\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_668 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_669 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_334 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_335\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_670 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_671 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_335 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_336\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_672 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_673 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_336 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_337\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_674 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_675 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_337 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_338\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_676 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_677 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_338 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_339\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_678 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_679 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_339 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_340\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_680 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_681 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_340 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_341\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_682 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_683 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_341 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_342\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_684 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_685 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_342 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_343\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_686 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_687 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_343 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_344\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_688 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_689 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_344 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_345\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_690 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_691 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_345 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_346\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_692 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_693 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_346 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_347\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_694 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_695 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_347 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_348\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_696 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_697 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_348 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_349\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_698 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_699 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_349 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_350\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_700 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_701 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_350 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_351\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_702 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_703 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_351 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_352\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_704 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_705 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_352 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_353\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_706 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_707 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_353 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_354\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_708 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_709 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_354 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_355\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_710 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_711 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_355 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_356\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_712 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_713 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_356 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_357\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_714 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_715 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_357 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_358\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_716 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_717 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_358 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_359\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_718 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_719 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_359 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_360\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_720 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_721 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_360 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_360 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_361\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_722 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_723 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_361 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_361 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_362\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_724 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_725 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_362 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_363\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_726 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_727 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_364\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_728 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_729 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_364 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_364 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_365\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_730 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_731 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_365 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_365 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_366\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_732 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_733 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_366 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_366 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_367\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_734 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_735 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_367 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_367 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_368\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_736 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_737 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_368 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_368 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_369\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_738 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_739 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_369 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_369 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_370\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_740 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_741 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_370 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_370 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_371\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_742 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_743 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_371 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_372\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_744 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_745 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_372 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_372 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_373\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_746 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_747 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_373 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_373 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_374\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_748 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_749 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_374 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_375\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_750 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_751 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_375 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_375 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_376\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_752 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_753 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_376 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_376 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_377\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_754 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_755 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_377 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_378\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_756 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_757 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_378 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_378 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_379\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_758 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_759 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_379 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_380\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_760 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_761 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_380 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_380 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_381\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_762 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_763 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_381 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_381 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_382\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_764 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_765 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_382 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_383\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_766 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_767 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_383 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_384\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_768 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_769 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_384 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_384 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_385\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_770 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_771 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_385 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_386\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_772 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_773 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_386 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_387\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_774 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_775 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_387 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_387 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_388\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_776 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_777 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_388 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_388 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_389\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_778 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_779 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_389 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_390\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_780 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_781 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_390 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_390 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_391\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_782 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_783 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_391 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_392\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_784 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_785 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_392 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_392 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_393\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_786 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_787 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_393 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_393 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_394\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_788 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_789 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_394 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_395\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_790 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_791 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_395 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_396\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_792 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_793 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_396 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_396 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_397\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_794 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_795 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_397 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_398\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_796 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_797 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_398 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_399\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_798 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_799 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_399 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_400\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_800 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_801 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_400 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_400 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_401\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_802 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_803 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_401 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_402\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_804 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_805 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_402 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_402 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_403\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_806 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_807 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_403 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_404\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_808 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_809 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_404 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_405\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_810 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_811 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_405 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_405 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "###########Set-4###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_406\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_812 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_813 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_406 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_407\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_814 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_815 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_407 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_408\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_816 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_817 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_408 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_408 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_409\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_818 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_819 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_409 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_410\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_820 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_821 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_410 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_411\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_822 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_823 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_411 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_412\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_824 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_825 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_412 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_412 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_413\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_826 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_827 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_413 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_414\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_828 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_829 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_414 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_414 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_415\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_830 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_831 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_415 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_416\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_832 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_833 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_416 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_416 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_417\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_834 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_835 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_417 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_417 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_418\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_836 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_837 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_418 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_419\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_838 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_839 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_419 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_420\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_840 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_841 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_420 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_420 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_421\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_842 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_843 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_421 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_422\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_844 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_845 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_422 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_423\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_846 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_847 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_423 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_424\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_848 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_849 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_424 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_425\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_850 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_851 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_425 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_425 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_426\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_852 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_853 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_426 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_427\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_854 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_855 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_427 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_428\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_856 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_857 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_428 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_428 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_429\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_858 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_859 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_429 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_429 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_430\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_860 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_861 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_430 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_431\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_862 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_863 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_431 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_431 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_432\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_864 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_865 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_432 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_432 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_433\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_866 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_867 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_433 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_434\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_868 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_869 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_434 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_435\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_870 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_871 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_435 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_435 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_436\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_872 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_873 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_436 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_437\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_874 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_875 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_437 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_437 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_438\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_876 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_877 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_438 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_438 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_439\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_878 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_879 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_439 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_440\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_880 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_881 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_440 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_440 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_441\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_882 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_883 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_441 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_441 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_442\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_884 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_885 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_442 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_443\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_886 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_887 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_443 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_444\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_888 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_889 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_444 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_444 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_445\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_890 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_891 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_445 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_445 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_446\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_892 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_893 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_446 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_446 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_447\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_894 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_895 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_447 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_447 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_448\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_896 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_897 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_448 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_448 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_449\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_898 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_899 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_449 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_449 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_450\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_900 (LSTM)              (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_901 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_450 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_450 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_451\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_902 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_903 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_451 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_451 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_452\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_904 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_905 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_452 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_452 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_453\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_906 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_907 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_453 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_453 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_454\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_908 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_909 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_454 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_454 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_455\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_910 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_911 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_455 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_455 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_456\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_912 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_913 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_456 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_456 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_457\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_914 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_915 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_457 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_457 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_458\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_916 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_917 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_458 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_458 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_459\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_918 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_919 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_459 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_459 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_460\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_920 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_921 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_460 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_460 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_461\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_922 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_923 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_461 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_461 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_462\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_924 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_925 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_462 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_462 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_463\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_926 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_927 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_463 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_463 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_464\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_928 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_929 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_464 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_464 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_465\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_930 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_931 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_465 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_465 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_466\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_932 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_933 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_466 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_466 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_467\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_934 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_935 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_467 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_467 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_468\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_936 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_937 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_468 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_468 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_469\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_938 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_939 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_469 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_469 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_470\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_940 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_941 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_470 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_470 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_471\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_942 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_943 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_471 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_471 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_472\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_944 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_945 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_472 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_472 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_473\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_946 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_947 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_473 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_473 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_474\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_948 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_949 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_474 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_474 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_475\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_950 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_951 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_475 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_475 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_476\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_952 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_953 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_476 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_476 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_477\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_954 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_955 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_477 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_477 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_478\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_956 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_957 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_478 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_479\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_958 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_959 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_479 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_479 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_480\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_960 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_961 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_480 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_480 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_481\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_962 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_963 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_481 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_481 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_482\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_964 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_965 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_482 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_482 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_483\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_966 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_967 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_483 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_483 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_484\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_968 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_969 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_484 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_484 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_485\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_970 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_971 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_485 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_485 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_486\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_972 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_973 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_486 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_486 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_487\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_974 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_975 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_487 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_487 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_488\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_976 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_977 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_488 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_488 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_489\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_978 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_979 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_489 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_489 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_490\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_980 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_981 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_490 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_490 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_491\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_982 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_983 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_491 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_491 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_492\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_984 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_985 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_492 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_492 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_493\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_986 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_987 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_493 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_493 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_494\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_988 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_989 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_494 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_494 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_495\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_990 (LSTM)              (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_991 (LSTM)              (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_495 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_495 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_496\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_992 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_993 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_496 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_496 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_497\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_994 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_995 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_497 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_497 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_498\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_996 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_997 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_498 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_498 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_499\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_998 (LSTM)              (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_999 (LSTM)              (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_499 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_499 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_500\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1000 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1001 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_500 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_500 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_501\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1002 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1003 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_501 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_501 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_502\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1004 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1005 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_502 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_502 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_503\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1006 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1007 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_503 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_503 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_504\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1008 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1009 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_504 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_504 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_505\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1010 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1011 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_505 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_505 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_506\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1012 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1013 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_506 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_506 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_507\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1014 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1015 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_507 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_507 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_508\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1016 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1017 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_508 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_508 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_509\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1018 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1019 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_509 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_509 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_510\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1020 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1021 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_510 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_510 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_511\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1022 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1023 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_511 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_511 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_512\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1024 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1025 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_512 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_512 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_513\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1026 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1027 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_513 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_513 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_514\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1028 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1029 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_514 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_514 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_515\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1030 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1031 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_515 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_515 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_516\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1032 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1033 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_516 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_516 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_517\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1034 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1035 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_517 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_517 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_518\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1036 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1037 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_518 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_518 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_519\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1038 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1039 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_519 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_519 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_520\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1040 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1041 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_520 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_520 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_521\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1042 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1043 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_521 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_521 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_522\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1044 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1045 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_522 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_522 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_523\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1046 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1047 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_523 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_523 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_524\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1048 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1049 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_524 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_524 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_525\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1050 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1051 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_525 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_525 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_526\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1052 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1053 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_526 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_526 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_527\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1054 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1055 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_527 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_527 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_528\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1056 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1057 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_528 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_528 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_529\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1058 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1059 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_529 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_529 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_530\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1060 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1061 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_530 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_530 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_531\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1062 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1063 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_531 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_531 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_532\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1064 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1065 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_532 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_532 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_533\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1066 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1067 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_533 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_533 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_534\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1068 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1069 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_534 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_534 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_535\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1070 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1071 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_535 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_535 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_536\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1072 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1073 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_536 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_536 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_537\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1074 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1075 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_537 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_537 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_538\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1076 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1077 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_538 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_538 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_539\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1078 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1079 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_539 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_539 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_540\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1080 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1081 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_540 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_540 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########Set-5###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_541\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1082 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1083 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_541 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_541 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_542\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1084 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1085 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_542 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_542 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_543\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1086 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1087 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_543 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_543 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_544\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1088 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1089 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_544 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_544 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_545\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1090 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1091 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_545 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_545 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_546\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1092 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1093 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_546 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_546 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_547\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1094 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1095 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_547 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_547 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_548\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1096 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1097 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_548 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_548 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_549\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1098 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1099 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_549 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_549 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_550\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1100 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1101 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_550 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_550 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_551\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1102 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1103 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_551 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_551 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_552\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1104 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1105 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_552 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_552 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_553\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1106 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1107 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_553 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_553 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_554\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1108 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1109 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_554 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_554 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_555\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1110 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1111 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_555 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_555 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_556\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1112 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1113 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_556 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_556 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_557\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1114 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1115 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_557 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_557 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_558\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1116 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1117 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_558 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_558 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_559\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1118 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1119 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_559 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_559 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_560\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1120 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1121 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_560 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_560 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_561\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1122 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1123 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_561 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_561 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_562\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1124 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1125 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_562 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_562 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_563\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1126 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1127 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_563 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_563 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_564\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1128 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1129 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_564 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_564 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_565\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1130 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1131 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_565 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_565 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_566\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1132 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1133 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_566 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_566 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_567\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1134 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1135 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_567 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_567 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_568\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1136 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1137 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_568 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_568 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_569\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1138 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1139 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_569 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_569 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_570\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1140 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1141 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_570 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_570 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_571\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1142 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1143 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_571 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_571 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_572\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1144 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1145 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_572 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_572 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_573\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1146 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1147 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_573 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_573 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_574\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1148 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1149 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_574 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_574 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_575\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1150 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1151 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_575 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_575 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_576\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1152 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1153 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_576 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_576 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_577\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1154 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1155 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_577 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_577 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_578\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1156 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1157 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_578 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_578 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_579\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1158 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1159 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_579 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_579 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_580\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1160 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1161 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_580 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_580 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_581\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1162 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1163 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_581 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_581 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_582\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1164 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1165 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_582 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_582 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_583\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1166 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1167 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_583 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_583 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_584\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1168 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1169 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_584 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_584 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_585\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1170 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1171 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_585 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_585 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_586\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1172 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1173 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_586 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_586 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_587\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1174 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1175 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_587 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_587 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_588\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1176 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1177 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_588 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_588 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_589\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1178 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1179 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_589 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_589 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_590\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1180 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1181 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_590 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_590 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_591\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1182 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1183 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_591 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_591 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_592\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1184 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1185 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_592 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_592 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_593\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1186 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1187 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_593 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_593 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_594\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1188 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1189 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_594 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_594 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_595\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1190 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1191 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_595 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_595 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_596\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1192 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1193 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_596 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_596 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_597\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1194 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1195 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_597 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_597 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_598\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1196 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1197 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_598 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_598 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_599\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1198 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1199 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_599 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_599 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_600\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1200 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1201 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_600 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_600 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_601\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1202 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1203 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_601 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_601 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_602\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1204 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1205 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_602 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_602 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_603\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1206 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1207 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_603 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_603 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_604\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1208 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1209 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_604 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_605\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1210 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1211 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_605 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_605 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_606\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1212 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1213 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_606 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_606 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_607\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1214 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1215 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_607 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_607 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_608\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1216 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1217 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_608 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_608 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_609\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1218 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1219 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_609 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_609 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_610\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1220 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1221 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_610 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_610 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_611\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1222 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1223 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_611 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_611 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_612\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1224 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1225 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_612 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_612 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_613\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1226 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1227 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_613 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_613 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_614\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1228 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1229 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_614 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_614 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_615\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1230 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1231 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_615 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_615 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_616\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1232 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1233 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_616 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_616 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_617\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1234 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1235 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_617 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_617 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_618\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1236 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1237 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_618 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_618 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_619\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1238 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1239 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_619 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_619 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_620\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1240 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1241 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_620 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_620 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_621\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1242 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1243 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_621 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_621 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_622\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1244 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1245 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_622 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_623\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1246 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1247 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_623 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_623 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_624\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1248 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1249 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_624 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_624 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_625\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1250 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1251 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_625 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_625 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_626\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1252 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1253 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_626 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_626 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_627\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1254 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1255 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_627 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_627 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_628\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1256 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1257 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_628 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_628 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_629\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1258 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1259 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_629 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_629 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_630\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1260 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1261 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_630 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_630 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_631\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1262 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1263 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_631 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_631 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_632\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1264 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1265 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_632 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_632 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_633\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1266 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1267 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_633 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_633 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_634\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1268 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1269 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_634 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_635\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1270 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1271 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_635 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_635 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_636\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1272 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1273 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_636 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_636 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_637\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1274 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1275 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_637 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_637 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_638\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1276 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1277 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_638 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_638 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_639\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1278 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1279 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_639 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_639 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_640\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1280 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1281 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_640 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_640 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_641\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1282 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1283 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_641 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_641 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_642\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1284 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1285 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_642 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_642 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_643\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1286 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1287 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_643 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_643 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_644\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1288 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1289 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_644 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_644 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_645\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1290 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1291 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_645 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_645 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_646\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1292 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1293 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_646 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_646 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_647\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1294 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1295 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_647 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_647 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_648\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1296 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1297 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_648 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_648 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_649\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1298 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1299 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_649 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_649 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_650\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1300 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1301 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_650 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_650 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_651\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1302 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1303 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_651 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_651 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_652\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1304 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1305 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_652 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_652 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_653\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1306 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1307 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_653 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_653 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_654\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1308 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1309 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_654 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_654 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_655\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1310 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1311 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_655 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_655 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_656\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1312 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1313 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_656 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_656 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_657\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1314 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1315 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_657 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_657 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_658\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1316 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1317 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_658 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_658 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_659\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1318 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1319 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_659 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_659 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_660\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1320 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1321 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_660 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_660 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_661\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1322 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1323 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_661 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_661 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_662\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1324 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1325 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_662 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_662 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_663\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1326 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1327 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_663 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_663 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_664\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1328 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1329 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_664 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_664 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_665\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1330 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1331 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_665 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_665 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_666\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1332 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1333 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_666 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_666 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_667\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1334 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1335 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_667 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_667 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_668\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1336 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1337 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_668 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_668 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_669\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1338 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1339 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_669 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_669 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_670\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1340 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1341 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_670 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_670 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_671\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1342 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1343 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_671 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_671 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_672\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1344 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1345 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_672 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_672 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_673\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1346 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1347 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_673 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_674\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1348 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1349 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_674 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_674 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_675\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1350 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1351 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_675 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_675 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "###########Set-6###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_676\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1352 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1353 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_676 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_677\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1354 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1355 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_677 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_677 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_678\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1356 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1357 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_678 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_678 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_679\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1358 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1359 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_679 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_679 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_680\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1360 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1361 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_680 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_680 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_681\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1362 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1363 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_681 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_681 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_682\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1364 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1365 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_682 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_682 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_683\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1366 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1367 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_683 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_683 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_684\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1368 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1369 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_684 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_684 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_685\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1370 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1371 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_685 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_685 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_686\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1372 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1373 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_686 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_686 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_687\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1374 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1375 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_687 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_687 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_688\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1376 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1377 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_688 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_688 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_689\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1378 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1379 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_689 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_689 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_690\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1380 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1381 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_690 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_690 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_691\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1382 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1383 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_691 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_691 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_692\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1384 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1385 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_692 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_692 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_693\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1386 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1387 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_693 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_693 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_694\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1388 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1389 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_694 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_694 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_695\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1390 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1391 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_695 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_695 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_696\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1392 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1393 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_696 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_696 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_697\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1394 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1395 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_697 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_697 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_698\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1396 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1397 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_698 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_698 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_699\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1398 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1399 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_699 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_699 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_700\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1400 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1401 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_700 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_700 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_701\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1402 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1403 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_701 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_702\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1404 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1405 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_702 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_702 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_703\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1406 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1407 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_703 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_704\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1408 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1409 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_704 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_705\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1410 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1411 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_705 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_705 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_706\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1412 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1413 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_706 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_706 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_707\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1414 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1415 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_707 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_707 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_708\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1416 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1417 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_708 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_708 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_709\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1418 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1419 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_709 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_709 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_710\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1420 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1421 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_710 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_710 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_711\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1422 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1423 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_711 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_711 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_712\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1424 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1425 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_712 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_712 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_713\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1426 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1427 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_713 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_713 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_714\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1428 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1429 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_714 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_714 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_715\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1430 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1431 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_715 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_715 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_716\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1432 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1433 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_716 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_716 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_717\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1434 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1435 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_717 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_717 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_718\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1436 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1437 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_718 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_718 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_719\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1438 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1439 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_719 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_719 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_720\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1440 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1441 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_720 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_720 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_721\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1442 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1443 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_721 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_721 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_722\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1444 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1445 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_722 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_722 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_723\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1446 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1447 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_723 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_723 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_724\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1448 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1449 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_724 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_724 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_725\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1450 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1451 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_725 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_725 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_726\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1452 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1453 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_726 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_726 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_727\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1454 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1455 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_727 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_727 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_728\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1456 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1457 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_728 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_728 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_729\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1458 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1459 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_729 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_729 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_730\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1460 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1461 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_730 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_730 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_731\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1462 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1463 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_731 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_731 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_732\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1464 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1465 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_732 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_732 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_733\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1466 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1467 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_733 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_733 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_734\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1468 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1469 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_734 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_734 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_735\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1470 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1471 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_735 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_735 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_736\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1472 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1473 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_736 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_736 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_737\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1474 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1475 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_737 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_737 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_738\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1476 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1477 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_738 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_738 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_739\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1478 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1479 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_739 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_739 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_740\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1480 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1481 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_740 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_740 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_741\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1482 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1483 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_741 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_741 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_742\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1484 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1485 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_742 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_742 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_743\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1486 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1487 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_743 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_743 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_744\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1488 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1489 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_744 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_744 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_745\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1490 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1491 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_745 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_745 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_746\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1492 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1493 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_746 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_746 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_747\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1494 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1495 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_747 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_747 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_748\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1496 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1497 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_748 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_748 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_749\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1498 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1499 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_749 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_749 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_750\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1500 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1501 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_750 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_750 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_751\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1502 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1503 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_751 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_751 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_752\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1504 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1505 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_752 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_752 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_753\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1506 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1507 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_753 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_753 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_754\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1508 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1509 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_754 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_754 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_755\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1510 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1511 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_755 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_755 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_756\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1512 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1513 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_756 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_756 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_757\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1514 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1515 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_757 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_757 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_758\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1516 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1517 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_758 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_758 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_759\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1518 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1519 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_759 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_759 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_760\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1520 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1521 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_760 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_760 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_761\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1522 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1523 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_761 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_761 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_762\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1524 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1525 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_762 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_762 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_763\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1526 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1527 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_763 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_763 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_764\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1528 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1529 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_764 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_764 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_765\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1530 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1531 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_765 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_765 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_766\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1532 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1533 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_766 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_766 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_767\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1534 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1535 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_767 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_767 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_768\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1536 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1537 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_768 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_768 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_769\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1538 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1539 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_769 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_769 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_770\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1540 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1541 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_770 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_770 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_771\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1542 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1543 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_771 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_771 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_772\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1544 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1545 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_772 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_772 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_773\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1546 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1547 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_773 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_773 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_774\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1548 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1549 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_774 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_774 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_775\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1550 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1551 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_775 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_775 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_776\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1552 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1553 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_776 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_776 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_777\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1554 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1555 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_777 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_777 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_778\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1556 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1557 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_778 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_778 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_779\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1558 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1559 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_779 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_779 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_780\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1560 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1561 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_780 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_780 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_781\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1562 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1563 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_781 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_781 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_782\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1564 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1565 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_782 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_782 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_783\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1566 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1567 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_783 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_783 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_784\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1568 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1569 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_784 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_784 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_785\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1570 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1571 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_785 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_785 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_786\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1572 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1573 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_786 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_786 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_787\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1574 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1575 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_787 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_787 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_788\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1576 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1577 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_788 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_788 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_789\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1578 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1579 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_789 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_789 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_790\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1580 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1581 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_790 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_790 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_791\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1582 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1583 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_791 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_791 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_792\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1584 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1585 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_792 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_792 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_793\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1586 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1587 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_793 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_793 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_794\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1588 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1589 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_794 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_794 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_795\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1590 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1591 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_795 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_795 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_796\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1592 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1593 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_796 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_796 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_797\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1594 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1595 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_797 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_797 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_798\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1596 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1597 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_798 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_798 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_799\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1598 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1599 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_799 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_799 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_800\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1600 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1601 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_800 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_800 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_801\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1602 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1603 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_801 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_801 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_802\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1604 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1605 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_802 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_802 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_803\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1606 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1607 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_803 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_803 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_804\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1608 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1609 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_804 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_804 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_805\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1610 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1611 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_805 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_805 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_806\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1612 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1613 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_806 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_806 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_807\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1614 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1615 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_807 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_807 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_808\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1616 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1617 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_808 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_808 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_809\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1618 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1619 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_809 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_809 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_810\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1620 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1621 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_810 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_810 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########Set-7###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_811\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1622 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1623 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_811 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_811 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_812\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1624 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1625 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_812 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_812 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_813\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1626 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1627 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_813 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_813 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_814\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1628 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1629 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_814 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_814 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_815\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1630 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1631 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_815 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_815 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_816\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1632 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1633 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_816 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_816 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_817\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1634 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1635 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_817 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_817 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_818\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1636 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1637 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_818 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_818 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_819\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1638 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1639 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_819 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_819 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_820\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1640 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1641 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_820 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_820 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_821\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1642 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1643 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_821 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_821 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_822\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1644 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1645 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_822 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_822 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_823\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1646 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1647 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_823 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_823 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_824\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1648 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1649 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_824 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_824 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_825\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1650 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1651 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_825 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_825 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_826\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1652 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1653 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_826 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_826 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_827\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1654 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1655 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_827 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_827 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_828\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1656 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1657 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_828 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_828 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_829\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1658 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1659 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_829 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_829 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_830\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1660 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1661 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_830 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_830 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_831\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1662 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1663 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_831 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_831 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_832\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1664 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1665 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_832 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_832 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_833\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1666 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1667 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_833 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_834\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1668 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1669 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_834 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_835\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1670 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1671 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_835 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_836\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1672 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1673 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_836 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_836 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_837\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1674 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1675 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_837 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_837 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_838\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1676 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1677 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_838 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_838 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_839\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1678 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1679 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_839 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_839 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_840\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1680 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1681 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_840 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_840 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_841\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1682 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1683 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_841 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_841 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_842\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1684 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1685 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_842 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_842 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_843\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1686 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1687 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_843 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_843 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_844\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1688 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1689 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_844 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_844 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_845\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1690 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1691 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_845 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_845 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_846\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1692 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1693 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_846 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_846 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_847\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1694 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1695 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_847 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_847 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_848\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1696 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1697 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_848 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_848 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_849\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1698 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1699 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_849 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_849 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_850\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1700 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1701 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_850 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_850 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_851\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1702 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1703 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_851 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_851 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_852\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1704 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1705 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_852 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_852 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_853\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1706 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1707 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_853 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_853 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_854\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1708 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1709 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_854 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_854 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_855\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1710 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1711 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_855 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_855 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_856\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1712 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1713 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_856 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_856 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_857\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1714 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1715 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_857 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_857 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_858\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1716 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1717 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_858 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_858 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_859\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1718 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1719 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_859 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_859 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_860\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1720 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1721 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_860 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_860 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_861\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1722 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1723 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_861 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_861 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_862\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1724 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1725 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_862 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_862 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_863\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1726 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1727 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_863 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_863 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_864\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1728 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1729 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_864 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_864 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_865\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1730 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1731 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_865 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_865 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_866\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1732 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1733 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_866 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_866 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_867\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1734 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1735 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_867 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_867 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_868\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1736 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1737 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_868 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_868 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_869\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1738 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1739 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_869 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_869 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_870\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1740 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1741 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_870 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_870 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_871\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1742 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1743 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_871 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_871 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_872\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1744 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1745 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_872 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_872 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_873\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1746 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1747 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_873 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_873 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_874\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1748 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1749 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_874 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_874 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_875\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1750 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1751 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_875 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_875 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_876\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1752 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1753 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_876 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_876 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_877\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1754 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1755 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_877 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_877 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_878\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1756 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1757 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_878 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_878 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_879\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1758 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1759 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_879 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_879 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_880\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1760 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1761 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_880 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_880 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_881\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1762 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1763 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_881 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_881 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_882\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1764 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1765 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_882 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_882 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_883\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1766 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1767 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_883 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_883 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_884\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1768 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1769 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_884 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_884 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_885\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1770 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1771 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_885 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_885 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_886\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1772 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1773 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_886 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_886 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_887\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1774 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1775 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_887 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_887 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_888\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1776 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1777 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_888 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_888 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_889\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1778 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1779 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_889 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_889 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_890\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1780 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1781 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_890 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_890 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_891\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1782 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1783 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_891 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_891 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_892\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1784 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1785 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_892 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_892 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_893\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1786 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1787 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_893 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_893 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_894\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1788 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1789 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_894 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_894 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_895\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1790 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1791 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_895 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_895 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_896\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1792 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1793 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_896 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_896 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_897\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1794 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1795 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_897 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_897 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_898\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1796 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1797 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_898 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_898 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_899\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1798 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1799 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_899 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_899 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_900\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1800 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1801 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_900 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_900 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_901\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1802 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1803 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_901 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_901 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_902\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1804 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1805 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_902 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_902 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_903\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1806 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1807 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_903 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_903 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_904\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1808 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1809 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_904 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_904 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_905\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1810 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1811 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_905 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_905 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_906\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1812 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1813 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_906 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_906 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_907\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1814 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1815 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_907 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_907 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_908\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1816 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1817 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_908 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_908 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_909\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1818 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1819 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_909 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_909 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_910\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1820 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1821 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_910 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_910 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_911\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1822 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1823 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_911 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_911 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_912\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1824 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1825 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_912 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_912 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_913\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1826 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1827 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_913 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_913 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_914\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1828 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1829 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_914 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_914 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_915\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1830 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1831 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_915 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_915 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_916\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1832 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1833 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_916 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_916 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_917\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1834 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1835 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_917 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_917 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_918\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1836 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1837 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_918 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_918 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_919\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1838 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1839 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_919 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_920\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1840 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1841 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_920 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_920 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_921\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1842 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1843 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_921 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_921 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_922\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1844 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1845 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_922 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_922 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_923\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1846 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1847 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_923 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_923 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_924\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1848 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1849 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_924 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_924 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_925\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1850 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1851 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_925 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_925 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_926\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1852 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1853 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_926 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_926 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_927\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1854 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1855 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_927 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_927 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_928\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1856 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1857 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_928 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_928 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_929\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1858 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1859 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_929 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_929 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_930\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1860 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1861 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_930 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_930 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_931\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1862 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1863 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_931 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_931 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_932\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1864 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1865 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_932 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_932 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_933\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1866 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1867 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_933 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_933 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_934\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1868 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1869 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_934 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_934 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_935\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1870 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1871 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_935 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_935 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_936\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1872 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1873 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_936 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_936 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_937\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1874 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1875 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_937 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_937 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_938\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1876 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1877 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_938 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_938 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_939\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1878 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1879 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_939 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_939 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_940\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1880 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1881 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_940 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_940 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_941\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1882 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1883 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_941 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_941 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_942\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1884 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1885 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_942 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_942 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_943\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1886 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1887 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_943 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_943 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_944\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1888 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1889 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_944 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_944 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_945\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1890 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_1891 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_945 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_945 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "###########Set-8###########\n",
      "\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_946\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1892 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1893 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_946 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_946 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_947\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1894 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1895 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_947 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_947 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_948\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1896 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1897 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_948 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_948 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_949\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1898 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1899 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_949 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_949 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_950\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1900 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1901 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_950 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_950 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_951\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1902 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1903 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_951 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_951 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_952\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1904 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1905 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_952 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_952 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_953\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1906 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1907 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_953 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_953 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_954\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1908 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1909 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_954 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_954 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_955\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1910 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1911 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_955 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_955 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_956\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1912 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1913 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_956 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_956 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_957\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1914 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1915 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_957 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_957 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_958\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1916 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1917 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_958 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_958 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_959\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1918 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1919 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_959 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_959 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_960\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1920 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1921 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_960 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_960 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_961\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1922 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1923 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_961 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_961 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_962\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1924 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1925 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_962 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_962 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_963\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1926 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1927 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_963 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_963 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_964\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1928 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1929 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_964 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_964 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_965\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1930 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1931 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_965 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_965 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_966\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1932 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1933 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_966 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_966 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_967\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1934 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1935 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_967 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_967 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_968\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1936 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1937 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_968 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_968 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_969\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1938 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1939 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_969 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_969 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_970\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1940 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1941 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_970 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_970 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_971\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1942 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1943 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_971 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_971 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_972\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1944 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1945 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_972 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_972 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_973\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1946 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1947 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_973 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_973 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_974\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1948 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1949 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_974 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_974 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_975\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1950 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1951 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_975 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_975 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_976\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1952 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1953 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_976 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_976 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_977\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1954 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1955 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_977 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_977 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_978\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1956 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1957 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_978 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_978 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_979\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1958 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1959 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_979 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_979 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_980\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1960 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1961 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_980 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_980 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_981\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1962 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1963 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_981 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_981 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_982\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1964 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1965 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_982 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_982 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_983\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1966 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1967 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_983 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_983 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_984\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1968 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1969 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_984 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_984 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_985\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1970 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1971 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_985 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_985 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_986\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1972 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1973 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_986 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_986 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_987\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1974 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1975 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_987 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_987 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_988\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1976 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1977 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_988 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_988 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_989\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1978 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1979 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_989 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_989 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_990\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1980 (LSTM)             (None, 1, 50)             21000     \n",
      "_________________________________________________________________\n",
      "lstm_1981 (LSTM)             (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_990 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_990 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 41,251\n",
      "Trainable params: 41,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_991\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1982 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1983 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_991 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_991 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_992\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1984 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1985 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_992 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_992 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_993\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1986 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1987 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_993 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_993 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_994\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1988 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1989 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_994 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_994 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_995\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1990 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1991 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_995 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_995 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_996\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1992 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1993 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_996 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_996 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_997\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1994 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1995 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_997 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_997 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_998\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1996 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1997 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_998 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_998 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_999\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1998 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_1999 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_999 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_999 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1000\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2000 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2001 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1000 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1000 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_1001\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2002 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2003 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1001 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1001 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1002\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2004 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2005 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1002 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1002 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1003\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2006 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2007 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1003 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1003 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1004\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2008 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2009 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1004 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1004 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1005\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2010 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2011 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1005 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1005 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_1006\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2012 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2013 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1006 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1006 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1007\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2014 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2015 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1007 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1007 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1008\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2016 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2017 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1008 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1008 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1009\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2018 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2019 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1009 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1009 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1010\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2020 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2021 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1010 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1010 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_1011\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2022 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2023 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1011 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1011 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1012\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2024 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2025 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1012 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1012 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1013\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2026 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2027 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1013 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1013 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1014\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2028 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2029 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1014 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1014 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1015\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2030 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2031 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1015 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1015 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_1016\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2032 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2033 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1016 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1016 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1017\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2034 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2035 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1017 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1017 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1018\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2036 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2037 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1018 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1018 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1019\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2038 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2039 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1019 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1019 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1020\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2040 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2041 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1020 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1020 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_1021\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2042 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2043 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1021 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1021 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1022\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2044 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2045 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1022 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1022 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1023\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2046 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2047 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1023 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1023 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1024\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2048 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2049 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1024 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1024 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1025\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2050 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2051 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1025 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1025 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_1026\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2052 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2053 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1026 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1026 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1027\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2054 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2055 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1027 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1027 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1028\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2056 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2057 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1028 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1028 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1029\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2058 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2059 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1029 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1029 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1030\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2060 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2061 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1030 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1030 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_1031\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2062 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2063 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1031 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1031 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1032\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2064 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2065 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1032 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1032 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1033\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2066 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2067 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1033 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1033 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1034\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2068 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2069 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1034 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1034 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1035\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2070 (LSTM)             (None, 1, 100)            62000     \n",
      "_________________________________________________________________\n",
      "lstm_2071 (LSTM)             (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1035 (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1035 (Dense)           (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 142,501\n",
      "Trainable params: 142,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_1036\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2072 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2073 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1036 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1036 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1037\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2074 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2075 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1037 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1037 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1038\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2076 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2077 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1038 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1038 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1039\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2078 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2079 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1039 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1039 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1040\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2080 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2081 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1040 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1040 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_1041\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2082 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2083 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1041 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1041 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1042\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2084 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2085 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1042 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1042 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1043\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2086 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2087 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1043 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1043 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1044\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2088 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2089 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1044 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1044 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1045\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2090 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2091 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1045 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1045 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_1046\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2092 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2093 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1046 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1046 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1047\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2094 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2095 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1047 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1047 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1048\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2096 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2097 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1048 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1048 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1049\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2098 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2099 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1049 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1049 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1050\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2100 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2101 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1050 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1050 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_1051\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2102 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2103 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1051 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1051 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1052\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2104 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2105 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1052 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1052 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1053\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2106 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2107 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1053 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1053 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1054\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2108 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2109 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1054 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1054 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1055\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2110 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2111 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1055 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1055 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_1056\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2112 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2113 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1056 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1056 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1057\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2114 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2115 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1057 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1057 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1058\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2116 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2117 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1058 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1058 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1059\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2118 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2119 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1059 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1059 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1060\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2120 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2121 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1060 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1060 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_1061\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2122 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2123 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1061 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1061 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1062\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2124 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2125 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1062 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1062 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1063\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2126 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2127 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1063 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1063 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1064\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2128 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2129 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1064 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1064 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1065\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2130 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2131 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1065 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1065 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.2\n",
      "Model: \"sequential_1066\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2132 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2133 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1066 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1066 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1067\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2134 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2135 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1067 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1067 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1068\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2136 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2137 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1068 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1068 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1069\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2138 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2139 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1069 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1069 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1070\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2140 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2141 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1070 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1070 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REC DROP OUT NUMBER: 0.4\n",
      "Model: \"sequential_1071\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2142 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2143 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1071 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1071 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1072\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2144 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2145 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1072 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1072 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1073\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2146 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2147 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1073 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1073 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1074\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2148 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2149 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1074 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1074 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1075\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2150 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2151 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1075 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1075 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " REC DROP OUT NUMBER: 0.8\n",
      "Model: \"sequential_1076\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2152 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2153 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1076 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1076 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1077\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2154 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2155 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1077 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1077 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1078\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2156 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2157 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1078 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1078 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1079\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2158 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2159 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1079 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1079 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1080\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2160 (LSTM)             (None, 1, 200)            204000    \n",
      "_________________________________________________________________\n",
      "lstm_2161 (LSTM)             (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1080 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1080 (Dense)           (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 525,001\n",
      "Trainable params: 525,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 5, shuffle = True)\n",
    "results = []\n",
    "r2s = []\n",
    "mses = []\n",
    "y_pred_list = []\n",
    "count = 1\n",
    "resultsdf = pd.DataFrame(columns=['essay_set', 'UserName', 'Action'])\n",
    "d = {}\n",
    "\n",
    "for num in range(1,9):\n",
    "    d[str(num)] = {}\n",
    "    essay_set = pd.read_csv(\"../dataset/cleandata_set_{}.csv\".format(num))\n",
    "    train_corpus = essay_set['essay']\n",
    "    test_corpus = train_corpus.copy()\n",
    "    vocab = CountVectorizer(stop_words='english', lowercase= True).fit(train_corpus)\n",
    "\n",
    "    # generate counts for a new set of documents\n",
    "    doc_emb = vocab.transform(train_corpus)\n",
    "    \n",
    "    vec_size = 50\n",
    "    window=2\n",
    "    min_count=1\n",
    "    workers=8\n",
    "    epochs=40\n",
    "    essays = [TaggedDocument(gensim.utils.simple_preprocess(doc), [i]) for i, doc in enumerate(train_corpus)]\n",
    "    \n",
    "    model = Doc2Vec(essays, vector_size=vec_size, window=window, min_count=min_count, workers=workers, epochs=epochs)\n",
    "    #might not need this line\n",
    "    model.train(essays, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    doc = [gensim.utils.simple_preprocess(doc) for i, doc in enumerate(test_corpus)]\n",
    "\n",
    "    doc_emb = np.zeros((len(doc), vec_size))\n",
    "    for i in range(len(doc)):\n",
    "        doc_emb[i,:] = model.infer_vector(doc[i])\n",
    "        \n",
    "    df_train = pd.DataFrame(doc_emb)\n",
    "    df_train = pd.concat([df_train, df[[\"essay_set\", \"word_count\",\"Mistakes\",\"reading_ease\"]]], axis = 1, join = \"inner\")\n",
    "    \n",
    "    y = df[\"total_score\"]\n",
    "    X = df_train\n",
    "    print(\"\\n###########Set-{}###########\\n\".format(num))\n",
    "    \n",
    "    for neuron in neurons:\n",
    "        d[str(num)][str(neuron)] = {}\n",
    "        #print(\" NEURON NUMBER: {}\".format(neuron))\n",
    "        for dropout in dropouts:\n",
    "            d[str(num)][str(neuron)][str(dropout)] = {}\n",
    "            #print(\" DROP OUT NUMBER: {}\".format(neuron))\n",
    "            for rec_dropout in dropouts:\n",
    "                d[str(num)][str(neuron)][str(dropout)][str(rec_dropout)]= {}\n",
    "                #print(\" REC DROP OUT NUMBER: {}\".format(rec_dropout))\n",
    "                count = 1\n",
    "                result_for_set = []\n",
    "                for traincv, testcv in cv.split(X):\n",
    "                    #print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "\n",
    "                    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "                    X_train = X_train.to_numpy()\n",
    "                    X_test = X_test.to_numpy()\n",
    "\n",
    "                    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "                    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "                    early_stop = EarlyStopping(monitor=\"val_loss\", patience=100)\n",
    "\n",
    "                    lstm_model = get_model(neuron, dropout, rec_dropout)\n",
    "                    lstm_model.fit(X_train, y_train, validation_split=0.2, epochs=1000, batch_size=32, verbose=0,callbacks=[early_stop])\n",
    "                    y_pred_temp = lstm_model.predict(X_test)\n",
    "                    y_pred = []\n",
    "                    for i in y_pred_temp:\n",
    "                        y_pred.append(int(round(i[0])))\n",
    "                    y_pred_temp = np.around(y_pred_temp)\n",
    "\n",
    "                    y_test_new = []\n",
    "                    for  i in list(y_test.array):\n",
    "                        y_test_new.append(int(i))\n",
    "                    result = cohen_kappa_score(y_test_new,y_pred,weights='quadratic')\n",
    "                    #print(\"Kappa Score: {}\".format(result))\n",
    "                    result_for_set.append(result)\n",
    "                    count += 1\n",
    "                d[str(num)][str(neuron)][str(dropout)][str(rec_dropout)] = result_for_set\n",
    "                #print(\"===================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'50': {'0.2': {'0.2': [0.7822229273018805,\n",
       "     0.831578071015277,\n",
       "     0.7679183888840032,\n",
       "     0.7736123893933575,\n",
       "     0.7774992523496382],\n",
       "    '0.4': [0.8072263015450674,\n",
       "     0.8127656386224935,\n",
       "     0.8018044847401917,\n",
       "     0.7855830049342649,\n",
       "     0.7963817660049989],\n",
       "    '0.8': [0.7753845525299777,\n",
       "     0.831038718631846,\n",
       "     0.8038468723557789,\n",
       "     0.7457837020860105,\n",
       "     0.8293238167507517]},\n",
       "   '0.4': {'0.2': [0.6412645947145328,\n",
       "     0.7513163555901575,\n",
       "     0.7353803647269683,\n",
       "     0.8251764184287984,\n",
       "     0.6709744393716301],\n",
       "    '0.4': [0.7671747709109399,\n",
       "     0.7413726977525121,\n",
       "     0.7443229704545185,\n",
       "     0.7649705103075166,\n",
       "     0.7184655488234466],\n",
       "    '0.8': [0.80612211166573,\n",
       "     0.7314726255687911,\n",
       "     0.524859609628182,\n",
       "     0.7595900041936996,\n",
       "     0.7430979627443937]},\n",
       "   '0.8': {'0.2': [0.5408971578586919,\n",
       "     0.02651742049691108,\n",
       "     0.19118869492934332,\n",
       "     0.3064607537546047,\n",
       "     0.04702358667165851],\n",
       "    '0.4': [0.22328883642612873,\n",
       "     0.19190706036091143,\n",
       "     0.22589009522654213,\n",
       "     0.26280448953585267,\n",
       "     0.2599294757155991],\n",
       "    '0.8': [0.22084864760300849,\n",
       "     0.25483810020782915,\n",
       "     0.14279047799514122,\n",
       "     0.1885199191835466,\n",
       "     0.16168561577047957]}},\n",
       "  '100': {'0.2': {'0.2': [0.7738246821408828,\n",
       "     0.822141191385918,\n",
       "     0.7984072087534864,\n",
       "     0.8357220412595006,\n",
       "     0.7878838266267597],\n",
       "    '0.4': [0.7475956157959249,\n",
       "     0.7756644569729261,\n",
       "     0.7871603849680112,\n",
       "     0.7424277947921398,\n",
       "     0.799564065057135],\n",
       "    '0.8': [0.8255477633820674,\n",
       "     0.780478332632124,\n",
       "     0.8231413023081253,\n",
       "     0.7776727741338576,\n",
       "     0.8129972353228168]},\n",
       "   '0.4': {'0.2': [0.8053395061728394,\n",
       "     0.757915095317649,\n",
       "     0.7714273253024659,\n",
       "     0.6301645344016368,\n",
       "     0.8193884386534092],\n",
       "    '0.4': [0.8076464752434602,\n",
       "     0.8134397623909412,\n",
       "     0.6011953679491968,\n",
       "     0.6686024077789783,\n",
       "     0.7719888094189458],\n",
       "    '0.8': [0.7812953269849278,\n",
       "     0.7955212307310567,\n",
       "     0.7067690969705755,\n",
       "     0.6062983061996382,\n",
       "     0.6574515910289576]},\n",
       "   '0.8': {'0.2': [0.2711190890530153,\n",
       "     0.2216542039094701,\n",
       "     0.41482329420869335,\n",
       "     0.31499318291771117,\n",
       "     0.32018028128224163],\n",
       "    '0.4': [0.23496614894464363,\n",
       "     0.28010969022158516,\n",
       "     0.22959216339074207,\n",
       "     0.20193780168975373,\n",
       "     0.3708926440231728],\n",
       "    '0.8': [0.1006053514500973,\n",
       "     0.3860645759666107,\n",
       "     0.3050918266431284,\n",
       "     0.02050568525255747,\n",
       "     0.3214010399876659]}},\n",
       "  '200': {'0.2': {'0.2': [0.7713318114542307,\n",
       "     0.8292270275986042,\n",
       "     0.7241026390818042,\n",
       "     0.8259999695711047,\n",
       "     0.7980655736337436],\n",
       "    '0.4': [0.8246235606731621,\n",
       "     0.7939966378027451,\n",
       "     0.7871448632312974,\n",
       "     0.850986489080798,\n",
       "     0.8183243595053548],\n",
       "    '0.8': [0.8290200639720849,\n",
       "     0.8104074679775378,\n",
       "     0.69253775749082,\n",
       "     0.7836987794635358,\n",
       "     0.8061997226074896]},\n",
       "   '0.4': {'0.2': [0.7562549443030938,\n",
       "     0.5691949434464405,\n",
       "     0.8180208146127077,\n",
       "     0.8020480070469059,\n",
       "     0.7350998653013339],\n",
       "    '0.4': [0.7261272612726127,\n",
       "     0.7728285077951003,\n",
       "     0.8006119326874044,\n",
       "     0.8222333187691155,\n",
       "     0.6448732856528457],\n",
       "    '0.8': [0.7902206395842639,\n",
       "     0.7582764811490126,\n",
       "     0.6705461437713629,\n",
       "     0.7217842688089937,\n",
       "     0.7196284946651903]},\n",
       "   '0.8': {'0.2': [0.5190056598074877,\n",
       "     0.1999000161512371,\n",
       "     0.5154181708784598,\n",
       "     0.2665707358658259,\n",
       "     0.3031592548119123],\n",
       "    '0.4': [0.13731050002347867,\n",
       "     0.5285082363157751,\n",
       "     0.4088244296376522,\n",
       "     0.14601842501485585,\n",
       "     0.3674561222529721],\n",
       "    '0.8': [0.34623813002191384,\n",
       "     0.4391243846602726,\n",
       "     0.19376315315949655,\n",
       "     0.167132325714478,\n",
       "     0.24231478289542707]}}},\n",
       " '2': {'50': {'0.2': {'0.2': [0.7844917454841828,\n",
       "     0.7090318753707346,\n",
       "     0.6034743202416919,\n",
       "     0.7589087012665879,\n",
       "     0.6372834848225004],\n",
       "    '0.4': [0.7124243255980154,\n",
       "     0.7388268367516587,\n",
       "     0.7372402430598615,\n",
       "     0.6504394861392833,\n",
       "     0.6313728757080973],\n",
       "    '0.8': [0.7125542543608222,\n",
       "     0.667452292252718,\n",
       "     0.7592795063284101,\n",
       "     0.7311460634957554,\n",
       "     0.693261531920924]},\n",
       "   '0.4': {'0.2': [0.7290671910672315,\n",
       "     0.7006915588706006,\n",
       "     0.6458445469225063,\n",
       "     0.7597793380140421,\n",
       "     0.6966677047648708],\n",
       "    '0.4': [0.6992741777283724,\n",
       "     0.7135873074439627,\n",
       "     0.6836443553362122,\n",
       "     0.7497261312884469,\n",
       "     0.6290076335877863],\n",
       "    '0.8': [0.583419689119171,\n",
       "     0.6398448164379624,\n",
       "     0.7248288105503424,\n",
       "     0.6413904859153365,\n",
       "     0.7357286536727474]},\n",
       "   '0.8': {'0.2': [0.0019238545712990662,\n",
       "     0.0,\n",
       "     0.12392241379310331,\n",
       "     0.09090909090909094,\n",
       "     0.1625357554700254],\n",
       "    '0.4': [0.00981637185451778,\n",
       "     0.02364737688648577,\n",
       "     0.08192771084337358,\n",
       "     0.11201186356895698,\n",
       "     0.32402919085921267],\n",
       "    '0.8': [0.022228039696327806,\n",
       "     0.0,\n",
       "     0.0764097108037528,\n",
       "     0.27277494398627067,\n",
       "     0.0]}},\n",
       "  '100': {'0.2': {'0.2': [0.7443368737663314,\n",
       "     0.6512185920169018,\n",
       "     0.7419058251789584,\n",
       "     0.7540761279045236,\n",
       "     0.7163398692810458],\n",
       "    '0.4': [0.7506292434273145,\n",
       "     0.6815814786560085,\n",
       "     0.7015548623222225,\n",
       "     0.7555281472997974,\n",
       "     0.6937106918238993],\n",
       "    '0.8': [0.6811069442648391,\n",
       "     0.7524807056229328,\n",
       "     0.6921122079953084,\n",
       "     0.697307444125066,\n",
       "     0.6868921377925582]},\n",
       "   '0.4': {'0.2': [0.661548280522601,\n",
       "     0.6465734183882483,\n",
       "     0.5800652325852295,\n",
       "     0.7694744251525105,\n",
       "     0.6701617353652842],\n",
       "    '0.4': [0.6600420100177735,\n",
       "     0.6083053767340647,\n",
       "     0.7059086723456584,\n",
       "     0.6758389261744966,\n",
       "     0.7080706917019177],\n",
       "    '0.8': [0.6670373665480427,\n",
       "     0.7419430446501816,\n",
       "     0.6776801087449025,\n",
       "     0.691099077110823,\n",
       "     0.7343008970915947]},\n",
       "   '0.8': {'0.2': [0.20743293713716615,\n",
       "     0.17214543150223782,\n",
       "     0.202207931695512,\n",
       "     0.14714682043192073,\n",
       "     0.1480947914954509],\n",
       "    '0.4': [0.2881130401723482,\n",
       "     0.24933372816108967,\n",
       "     0.08426808126009455,\n",
       "     0.19601542416452433,\n",
       "     0.16772583909993888],\n",
       "    '0.8': [0.030761797390884138,\n",
       "     0.2780476234116993,\n",
       "     0.2764046618656779,\n",
       "     0.15130434782608693,\n",
       "     0.20485720710591415]}},\n",
       "  '200': {'0.2': {'0.2': [0.6919569237934574,\n",
       "     0.7380056413665791,\n",
       "     0.6332872059378538,\n",
       "     0.6793416127668237,\n",
       "     0.7442349249578165],\n",
       "    '0.4': [0.7471691847916321,\n",
       "     0.5888926725071975,\n",
       "     0.782893561260349,\n",
       "     0.6213020305116199,\n",
       "     0.6972919961600353],\n",
       "    '0.8': [0.6921734070410241,\n",
       "     0.7789681073759389,\n",
       "     0.7215978635807277,\n",
       "     0.6793461861464465,\n",
       "     0.7673927949786381]},\n",
       "   '0.4': {'0.2': [0.6426102217731213,\n",
       "     0.7515329138867495,\n",
       "     0.6280978487384181,\n",
       "     0.7242850695441678,\n",
       "     0.7458567465680348],\n",
       "    '0.4': [0.7764900662251655,\n",
       "     0.5196122951857007,\n",
       "     0.6502357479639949,\n",
       "     0.698028980289803,\n",
       "     0.6908286582804044],\n",
       "    '0.8': [0.5823282642894598,\n",
       "     0.6296537063882623,\n",
       "     0.7823303889611377,\n",
       "     0.6845298281092013,\n",
       "     0.6860587018596583]},\n",
       "   '0.8': {'0.2': [0.2938832436740386,\n",
       "     0.33913104097317837,\n",
       "     0.3557105492589363,\n",
       "     0.23268870867124136,\n",
       "     0.2795531405555344],\n",
       "    '0.4': [0.26470588235294124,\n",
       "     0.24867520023229361,\n",
       "     0.20856673263341496,\n",
       "     0.27277742024455276,\n",
       "     0.23375081217932914],\n",
       "    '0.8': [0.23236026563364687,\n",
       "     0.23843726606843363,\n",
       "     0.3426395653592198,\n",
       "     0.3967479361160404,\n",
       "     0.3030192465565995]}}},\n",
       " '3': {'50': {'0.2': {'0.2': [0.7316312398887082,\n",
       "     0.746903653008409,\n",
       "     0.7941351973403802,\n",
       "     0.8066612779611839,\n",
       "     0.7750109217999126],\n",
       "    '0.4': [0.7824431242534504,\n",
       "     0.7684732134509302,\n",
       "     0.7587826897600707,\n",
       "     0.7550861133892431,\n",
       "     0.761807606198777],\n",
       "    '0.8': [0.7558426720879047,\n",
       "     0.6888068880688807,\n",
       "     0.7561837455830389,\n",
       "     0.79445808181842,\n",
       "     0.7359839771465424]},\n",
       "   '0.4': {'0.2': [0.7483202959088462,\n",
       "     0.7107762866891526,\n",
       "     0.5589672891339766,\n",
       "     0.741139846743295,\n",
       "     0.6500837345967092],\n",
       "    '0.4': [0.7035239116171846,\n",
       "     0.7648668443431733,\n",
       "     0.5312841788228571,\n",
       "     0.6971515879078904,\n",
       "     0.7692532877416889],\n",
       "    '0.8': [0.7559222034979212,\n",
       "     0.6598711312981937,\n",
       "     0.7174773070668159,\n",
       "     0.4738362872425015,\n",
       "     0.7257876312718786]},\n",
       "   '0.8': {'0.2': [0.0029436370960246316,\n",
       "     0.13754707712461112,\n",
       "     0.07003694145033146,\n",
       "     0.016953689658249393,\n",
       "     0.22101945222338037],\n",
       "    '0.4': [0.2653734059528676,\n",
       "     0.11501899269814397,\n",
       "     0.09969539100976454,\n",
       "     0.0,\n",
       "     0.2600536193029491],\n",
       "    '0.8': [0.14574418653036603,\n",
       "     0.2288705879540539,\n",
       "     0.15665275004538037,\n",
       "     0.10651555168081228,\n",
       "     0.031987222224202805]}},\n",
       "  '100': {'0.2': {'0.2': [0.748702696485203,\n",
       "     0.7576104506091296,\n",
       "     0.7941062512739245,\n",
       "     0.7689833405824221,\n",
       "     0.7489047598923777],\n",
       "    '0.4': [0.7280076790043774,\n",
       "     0.7787389537268354,\n",
       "     0.7562596704975623,\n",
       "     0.7094671073482139,\n",
       "     0.7393335895165378],\n",
       "    '0.8': [0.7815515521979007,\n",
       "     0.7629019227661981,\n",
       "     0.7645298472200346,\n",
       "     0.7585808754067388,\n",
       "     0.7920522215917829]},\n",
       "   '0.4': {'0.2': [0.734212603052538,\n",
       "     0.7433305113799352,\n",
       "     0.7933189137226628,\n",
       "     0.6623474315110043,\n",
       "     0.7090052883057427],\n",
       "    '0.4': [0.7534685799109352,\n",
       "     0.7587472840338653,\n",
       "     0.7139877964007106,\n",
       "     0.7819946267607402,\n",
       "     0.6478048695241881],\n",
       "    '0.8': [0.7526815978996773,\n",
       "     0.6873743658466545,\n",
       "     0.7079294059159831,\n",
       "     0.6975797067721666,\n",
       "     0.7624150741197047]},\n",
       "   '0.8': {'0.2': [0.16106876569318362,\n",
       "     0.22118505988731485,\n",
       "     0.3391389556201795,\n",
       "     0.3721572173534672,\n",
       "     0.020428712682674655],\n",
       "    '0.4': [0.2073453786933377,\n",
       "     0.29856415288054494,\n",
       "     0.1299891354546331,\n",
       "     0.12360048924073597,\n",
       "     0.1675685873439844],\n",
       "    '0.8': [0.43787096184117413,\n",
       "     0.3902985303592795,\n",
       "     0.10060714163207896,\n",
       "     0.47247153943633946,\n",
       "     0.3452644533518895]}},\n",
       "  '200': {'0.2': {'0.2': [0.7865008543763052,\n",
       "     0.6703267801959366,\n",
       "     0.7189071326587622,\n",
       "     0.7359465536625442,\n",
       "     0.7921949478349458],\n",
       "    '0.4': [0.7480282902054608,\n",
       "     0.778311077317873,\n",
       "     0.7006877373613178,\n",
       "     0.7452340302351822,\n",
       "     0.763088501895292],\n",
       "    '0.8': [0.7238522347217999,\n",
       "     0.8119301337435499,\n",
       "     0.7437330352866038,\n",
       "     0.7146958729173365,\n",
       "     0.7915021573099009]},\n",
       "   '0.4': {'0.2': [0.7804737637991916,\n",
       "     0.7587041461988904,\n",
       "     0.7272499646441579,\n",
       "     0.749487102648625,\n",
       "     0.7281703608995089],\n",
       "    '0.4': [0.7589591359358573,\n",
       "     0.7800406322778851,\n",
       "     0.6353748403230571,\n",
       "     0.6896000881348463,\n",
       "     0.7618660312324141],\n",
       "    '0.8': [0.6583943718759208,\n",
       "     0.6994005227816995,\n",
       "     0.7207738814993954,\n",
       "     0.7027898155518214,\n",
       "     0.7454347765479941]},\n",
       "   '0.8': {'0.2': [0.35631191421888,\n",
       "     0.062364804153216435,\n",
       "     0.4481645406228293,\n",
       "     0.35154920962593417,\n",
       "     0.28681695988927636],\n",
       "    '0.4': [0.18786524440728913,\n",
       "     0.37564863777242785,\n",
       "     0.17709134111398417,\n",
       "     0.26447182268332936,\n",
       "     0.3962325544582318],\n",
       "    '0.8': [0.23113427843982104,\n",
       "     0.2677448155513169,\n",
       "     0.27795350308397904,\n",
       "     0.21331864999676098,\n",
       "     0.35940658686049964]}}},\n",
       " '4': {'50': {'0.2': {'0.2': [0.7651359796409936,\n",
       "     0.6433286960920703,\n",
       "     0.7596400556532417,\n",
       "     0.7758841948565269,\n",
       "     0.7695149789377074],\n",
       "    '0.4': [0.7775413602778476,\n",
       "     0.7828987265009096,\n",
       "     0.770162545092721,\n",
       "     0.670537961409396,\n",
       "     0.7718844873745259],\n",
       "    '0.8': [0.7869941458104219,\n",
       "     0.7866512254496467,\n",
       "     0.7802547424885713,\n",
       "     0.6908904363771311,\n",
       "     0.7785307710667352]},\n",
       "   '0.4': {'0.2': [0.7323591929238287,\n",
       "     0.7169241880981247,\n",
       "     0.7347981784877997,\n",
       "     0.692776571783356,\n",
       "     0.672456383464018],\n",
       "    '0.4': [0.696250016169299,\n",
       "     0.6246616931819315,\n",
       "     0.652796508349067,\n",
       "     0.7190712066876956,\n",
       "     0.7114574597401129],\n",
       "    '0.8': [0.7150066215490931,\n",
       "     0.7635029553638155,\n",
       "     0.7132163999308019,\n",
       "     0.6884151903595948,\n",
       "     0.7596105816789258]},\n",
       "   '0.8': {'0.2': [0.4072351986579873,\n",
       "     0.28090284884910965,\n",
       "     0.090479017142446,\n",
       "     0.0060933061542940425,\n",
       "     0.0],\n",
       "    '0.4': [0.0416198110300503,\n",
       "     0.2676079023810449,\n",
       "     0.281488567634416,\n",
       "     0.001295359462250678,\n",
       "     0.1727384718241416],\n",
       "    '0.8': [0.12638451673079165,\n",
       "     0.20928295600817748,\n",
       "     0.038891828558470065,\n",
       "     0.31894906523873934,\n",
       "     0.01111563754874001]}},\n",
       "  '100': {'0.2': {'0.2': [0.780314585158155,\n",
       "     0.7569546864669684,\n",
       "     0.7762418567421887,\n",
       "     0.7466035585940924,\n",
       "     0.781198607034113],\n",
       "    '0.4': [0.7283788227556725,\n",
       "     0.780691847066667,\n",
       "     0.7544585095172671,\n",
       "     0.7723515475160769,\n",
       "     0.7611057775349773],\n",
       "    '0.8': [0.7961206985210935,\n",
       "     0.7614081117122196,\n",
       "     0.7749755667326166,\n",
       "     0.7917647058823529,\n",
       "     0.7644671510245606]},\n",
       "   '0.4': {'0.2': [0.7538190020921236,\n",
       "     0.6505905959206997,\n",
       "     0.5711004706195979,\n",
       "     0.7974348284572186,\n",
       "     0.7111080885968675],\n",
       "    '0.4': [0.7039434311441751,\n",
       "     0.708871856527402,\n",
       "     0.7351824847713898,\n",
       "     0.709301690252204,\n",
       "     0.5566573168100416],\n",
       "    '0.8': [0.7842877480886696,\n",
       "     0.7389040416563353,\n",
       "     0.785383971021921,\n",
       "     0.7605508245947404,\n",
       "     0.7735666070772351]},\n",
       "   '0.8': {'0.2': [0.3832160785936629,\n",
       "     0.4445839086230702,\n",
       "     0.22695289942420793,\n",
       "     0.35752376305162903,\n",
       "     0.22397875300366754],\n",
       "    '0.4': [0.13781425994773067,\n",
       "     0.2495764947651976,\n",
       "     0.12036430554255961,\n",
       "     0.1809558325323417,\n",
       "     0.44077299087197996],\n",
       "    '0.8': [0.2810333091681838,\n",
       "     0.31389492817296727,\n",
       "     0.3316856817717604,\n",
       "     0.019252555907252722,\n",
       "     0.27763292143747875]}},\n",
       "  '200': {'0.2': {'0.2': [0.7557026137750009,\n",
       "     0.6904893382040609,\n",
       "     0.7890591686863349,\n",
       "     0.7223520450320182,\n",
       "     0.7380398494481893],\n",
       "    '0.4': [0.7631802796434457,\n",
       "     0.6919001334095674,\n",
       "     0.7721910262580887,\n",
       "     0.7699674233414344,\n",
       "     0.6037505451373746],\n",
       "    '0.8': [0.7382210014789774,\n",
       "     0.8252385596193983,\n",
       "     0.6917656349664368,\n",
       "     0.6666759587061765,\n",
       "     0.7207865994679358]},\n",
       "   '0.4': {'0.2': [0.7493057646625849,\n",
       "     0.4862666958261447,\n",
       "     0.7176115701094334,\n",
       "     0.734366515837104,\n",
       "     0.7119332430812934],\n",
       "    '0.4': [0.6774979312595424,\n",
       "     0.7698033173933052,\n",
       "     0.7831974631517346,\n",
       "     0.7565137644727576,\n",
       "     0.5825458994093105],\n",
       "    '0.8': [0.8180801809435744,\n",
       "     0.693866961845792,\n",
       "     0.5582984604752945,\n",
       "     0.644019620931865,\n",
       "     0.6676416422922761]},\n",
       "   '0.8': {'0.2': [0.35736466285906443,\n",
       "     0.5013192612137203,\n",
       "     0.4332451621885006,\n",
       "     0.30969309693096936,\n",
       "     0.4301727983243798],\n",
       "    '0.4': [0.34453290154275185,\n",
       "     0.3128647564499537,\n",
       "     0.2708114199849736,\n",
       "     0.27918338059670167,\n",
       "     0.48916240446969617],\n",
       "    '0.8': [0.25371359380743363,\n",
       "     0.29819322333628073,\n",
       "     0.28043462192327595,\n",
       "     0.42124819283619996,\n",
       "     0.35685194058457115]}}},\n",
       " '5': {'50': {'0.2': {'0.2': [0.603519241947039,\n",
       "     0.7172475197150852,\n",
       "     0.6804530877857585,\n",
       "     0.5491963963058926,\n",
       "     0.7477150581090256],\n",
       "    '0.4': [0.760762579007415,\n",
       "     0.6671483833041445,\n",
       "     0.7339881978234789,\n",
       "     0.6874871006948425,\n",
       "     0.6029078413135134],\n",
       "    '0.8': [0.7237894847931191,\n",
       "     0.6930447537358277,\n",
       "     0.7552566833963263,\n",
       "     0.6485993051402965,\n",
       "     0.772498887887671]},\n",
       "   '0.4': {'0.2': [0.7320348788145474,\n",
       "     0.7289018122802272,\n",
       "     0.720938670873595,\n",
       "     0.6751958055537576,\n",
       "     0.7313842811804245],\n",
       "    '0.4': [0.7117257806921438,\n",
       "     0.6412754327139594,\n",
       "     0.7207318716529499,\n",
       "     0.741803002154678,\n",
       "     0.7130268999386954],\n",
       "    '0.8': [0.5070126227208975,\n",
       "     0.6342600097260496,\n",
       "     0.6724305777078454,\n",
       "     0.6415734588548683,\n",
       "     0.7174597620713785]},\n",
       "   '0.8': {'0.2': [0.022256114782805092,\n",
       "     0.13925263655602949,\n",
       "     0.30389951340952803,\n",
       "     0.23193114522086067,\n",
       "     0.11203240815810522],\n",
       "    '0.4': [0.0,\n",
       "     0.21332786165661932,\n",
       "     0.29876558681621657,\n",
       "     0.36648705586841146,\n",
       "     0.4114684555951086],\n",
       "    '0.8': [-0.0011745172795474268,\n",
       "     0.09632167434007088,\n",
       "     0.005633058065282026,\n",
       "     0.25992882353085256,\n",
       "     0.15704189847778582]}},\n",
       "  '100': {'0.2': {'0.2': [0.6927931920928996,\n",
       "     0.6926798376296419,\n",
       "     0.6420034674609227,\n",
       "     0.7335191794978679,\n",
       "     0.7021058885661473],\n",
       "    '0.4': [0.5762211515425772,\n",
       "     0.6756283539736263,\n",
       "     0.7270022044004825,\n",
       "     0.6709327640312602,\n",
       "     0.6206139028293013],\n",
       "    '0.8': [0.7482830536652476,\n",
       "     0.7525343273788332,\n",
       "     0.7136613530975838,\n",
       "     0.6627400570376927,\n",
       "     0.6768956892601832]},\n",
       "   '0.4': {'0.2': [0.6900152412127771,\n",
       "     0.7062619989880998,\n",
       "     0.6762474222270387,\n",
       "     0.6879062818172508,\n",
       "     0.7294612425914012],\n",
       "    '0.4': [0.709519603179996,\n",
       "     0.662092893476133,\n",
       "     0.7381368387190372,\n",
       "     0.71616815896827,\n",
       "     0.5937068054313359],\n",
       "    '0.8': [0.6057032941904416,\n",
       "     0.706861550954121,\n",
       "     0.5585165049047593,\n",
       "     0.7074630439724238,\n",
       "     0.6057830326428589]},\n",
       "   '0.8': {'0.2': [0.16527084567013517,\n",
       "     0.25900976895144456,\n",
       "     0.35951453973831193,\n",
       "     0.3343545664723486,\n",
       "     0.16009847813484046],\n",
       "    '0.4': [0.20594461149898824,\n",
       "     0.08889220059995384,\n",
       "     0.17720060742525012,\n",
       "     0.406694823194486,\n",
       "     0.22732706496659116],\n",
       "    '0.8': [0.23913071416637754,\n",
       "     0.37037134297525187,\n",
       "     0.4360360451602612,\n",
       "     0.18180079750535105,\n",
       "     0.2356367267129842]}},\n",
       "  '200': {'0.2': {'0.2': [0.6395425215408987,\n",
       "     0.7046931118315585,\n",
       "     0.6701174504433407,\n",
       "     0.6327672010006626,\n",
       "     0.6684192597375034],\n",
       "    '0.4': [0.5260410466834251,\n",
       "     0.718027210417436,\n",
       "     0.6782864008529803,\n",
       "     0.6945815752907225,\n",
       "     0.7339702886206991],\n",
       "    '0.8': [0.6352427149978489,\n",
       "     0.6629381590196637,\n",
       "     0.6526832844827142,\n",
       "     0.6992522999563333,\n",
       "     0.770342118850343]},\n",
       "   '0.4': {'0.2': [0.5015069884162393,\n",
       "     0.6174744093533208,\n",
       "     0.7669951651556534,\n",
       "     0.6867013353542217,\n",
       "     0.6876159440632299],\n",
       "    '0.4': [0.7126388954218332,\n",
       "     0.506222265248063,\n",
       "     0.5403218155095302,\n",
       "     0.7342156404277663,\n",
       "     0.7420302126535037],\n",
       "    '0.8': [0.6580878784734889,\n",
       "     0.6083878684812994,\n",
       "     0.7606392038542021,\n",
       "     0.6936781504218608,\n",
       "     0.759314894539598]},\n",
       "   '0.8': {'0.2': [0.21576646683379463,\n",
       "     0.2596828596906138,\n",
       "     0.32352063175903645,\n",
       "     0.3049343754100865,\n",
       "     0.30861128881160305],\n",
       "    '0.4': [0.30520356269843507,\n",
       "     0.30212743614588955,\n",
       "     0.2687065402580888,\n",
       "     0.28874520960195615,\n",
       "     0.10748417634432283],\n",
       "    '0.8': [0.3400252341020865,\n",
       "     0.24642614023144993,\n",
       "     0.12447213246859923,\n",
       "     0.1864003246165955,\n",
       "     0.32328164776672075]}}},\n",
       " '6': {'50': {'0.2': {'0.2': [0.7597292724196277,\n",
       "     0.6981361968775942,\n",
       "     0.7519527126873549,\n",
       "     0.7067694749971651,\n",
       "     0.7548331353277892],\n",
       "    '0.4': [0.7206966250842197,\n",
       "     0.6756109247724006,\n",
       "     0.6631502890173411,\n",
       "     0.7581539826935877,\n",
       "     0.7413793103448276],\n",
       "    '0.8': [0.7278992312472508,\n",
       "     0.7638145726804276,\n",
       "     0.6625596625596626,\n",
       "     0.7368333610234259,\n",
       "     0.721385203507983]},\n",
       "   '0.4': {'0.2': [0.6860435556308787,\n",
       "     0.7137561961851895,\n",
       "     0.6122419405181254,\n",
       "     0.6449449264660636,\n",
       "     0.6664482575044024],\n",
       "    '0.4': [0.6523125996810207,\n",
       "     0.7073024740622507,\n",
       "     0.6172922641490086,\n",
       "     0.5914844649021864,\n",
       "     0.6519702166820045],\n",
       "    '0.8': [0.6907020069438563,\n",
       "     0.701151631477927,\n",
       "     0.6962382583386009,\n",
       "     0.6341934860345994,\n",
       "     0.6834264432029795]},\n",
       "   '0.8': {'0.2': [0.12138872511224996,\n",
       "     0.121344537815126,\n",
       "     0.3347944893544347,\n",
       "     0.11301482005725205,\n",
       "     0.2565409244209369],\n",
       "    '0.4': [0.025087357763641238,\n",
       "     0.0,\n",
       "     0.3090519550080343,\n",
       "     0.09233686955491027,\n",
       "     0.026721479958890182],\n",
       "    '0.8': [0.1812130958949134,\n",
       "     0.4055218026609244,\n",
       "     0.06782431052093973,\n",
       "     0.01758923952405589,\n",
       "     0.018138671295635067]}},\n",
       "  '100': {'0.2': {'0.2': [0.6828446922570854,\n",
       "     0.7490414778668526,\n",
       "     0.7439328348419257,\n",
       "     0.7134925290598834,\n",
       "     0.7694230947309937],\n",
       "    '0.4': [0.6824824485121004,\n",
       "     0.7211239449133717,\n",
       "     0.7734759396653255,\n",
       "     0.7082501608459673,\n",
       "     0.7278880866425992],\n",
       "    '0.8': [0.7067520238847104,\n",
       "     0.7386088980395668,\n",
       "     0.7348536209553158,\n",
       "     0.4877784741610164,\n",
       "     0.7398324078171618]},\n",
       "   '0.4': {'0.2': [0.7024784144609908,\n",
       "     0.6168556208168283,\n",
       "     0.7161606268364349,\n",
       "     0.6982515091141575,\n",
       "     0.6850095887492009],\n",
       "    '0.4': [0.7041205300417499,\n",
       "     0.6982117217073489,\n",
       "     0.5794522024295237,\n",
       "     0.7303170318861796,\n",
       "     0.681723472177088],\n",
       "    '0.8': [0.7022673906662753,\n",
       "     0.7093007205366756,\n",
       "     0.7280843101073369,\n",
       "     0.6989556438152723,\n",
       "     0.6765396961975048]},\n",
       "   '0.8': {'0.2': [0.25960655763540585,\n",
       "     0.12989123640455058,\n",
       "     0.32750455373406195,\n",
       "     0.16665103101487888,\n",
       "     0.17327898232420835],\n",
       "    '0.4': [0.2987040133779264,\n",
       "     0.13520582215146681,\n",
       "     0.04370633038880378,\n",
       "     0.24680450284791677,\n",
       "     0.1608680675163624],\n",
       "    '0.8': [0.04070638320237563,\n",
       "     0.2778321465933249,\n",
       "     0.18811762232301088,\n",
       "     0.3571428571428572,\n",
       "     0.07741360394953378]}},\n",
       "  '200': {'0.2': {'0.2': [0.737781954887218,\n",
       "     0.7153343120245563,\n",
       "     0.75957976968146,\n",
       "     0.7312506465294301,\n",
       "     0.7223267363985251],\n",
       "    '0.4': [0.7177262721740256,\n",
       "     0.6383296047725577,\n",
       "     0.8114111388447671,\n",
       "     0.740605481415748,\n",
       "     0.737307624270299],\n",
       "    '0.8': [0.7055787476280835,\n",
       "     0.648247541515075,\n",
       "     0.6998213222156044,\n",
       "     0.7336124060508039,\n",
       "     0.772281288450011]},\n",
       "   '0.4': {'0.2': [0.7080247291424374,\n",
       "     0.5832305795314426,\n",
       "     0.7002190466256388,\n",
       "     0.734475877450405,\n",
       "     0.6086509929239898],\n",
       "    '0.4': [0.6340808834870593,\n",
       "     0.7394074393427703,\n",
       "     0.7273220924242214,\n",
       "     0.683727948003714,\n",
       "     0.6524793166433868],\n",
       "    '0.8': [0.6506528204869688,\n",
       "     0.6219549294456275,\n",
       "     0.661859168585626,\n",
       "     0.7403688150447325,\n",
       "     0.7560396693532574]},\n",
       "   '0.8': {'0.2': [0.22046271081718127,\n",
       "     0.363048656005444,\n",
       "     0.2659896668448245,\n",
       "     0.29856764564275395,\n",
       "     0.2072927072927072],\n",
       "    '0.4': [0.3050705749274578,\n",
       "     0.15108159010409006,\n",
       "     0.367428727570817,\n",
       "     0.30559154272684874,\n",
       "     0.303921568627451],\n",
       "    '0.8': [0.35598485170843785,\n",
       "     0.27322280263456733,\n",
       "     0.3534347142108023,\n",
       "     0.2650052127289877,\n",
       "     0.2158354604358924]}}},\n",
       " '7': {'50': {'0.2': {'0.2': [0.7441791277044686,\n",
       "     0.8165466394833208,\n",
       "     0.6848039186826256,\n",
       "     0.6190403003078528,\n",
       "     0.7060480841472576],\n",
       "    '0.4': [0.7339903913135317,\n",
       "     0.6593354479932354,\n",
       "     0.6889736115581466,\n",
       "     0.7201918992011108,\n",
       "     0.7608563921641889],\n",
       "    '0.8': [0.7456213511259383,\n",
       "     0.7059507462765091,\n",
       "     0.7276605333906307,\n",
       "     0.724673052716916,\n",
       "     0.7609639708440845]},\n",
       "   '0.4': {'0.2': [0.7328757834172404,\n",
       "     0.7201043370338622,\n",
       "     0.711880095794204,\n",
       "     0.6212520801900486,\n",
       "     0.7543267249931522],\n",
       "    '0.4': [0.7584782759337537,\n",
       "     0.6909234675785725,\n",
       "     0.6351279347912344,\n",
       "     0.7349099144642388,\n",
       "     0.7740258355864369],\n",
       "    '0.8': [0.6797076579814441,\n",
       "     0.6463947610612921,\n",
       "     0.770699221323512,\n",
       "     0.7250050826517367,\n",
       "     0.6145196520022214]},\n",
       "   '0.8': {'0.2': [0.1799234069215081,\n",
       "     0.09880059309717104,\n",
       "     0.07103599556429752,\n",
       "     0.0,\n",
       "     0.2506378721857754],\n",
       "    '0.4': [0.0, 0.0, 0.0, 0.2515397117898709, 0.2054093201175704],\n",
       "    '0.8': [0.07352378092270728,\n",
       "     0.36263564681083615,\n",
       "     0.011108426033473284,\n",
       "     0.036742946898891904,\n",
       "     0.20632857447261876]}},\n",
       "  '100': {'0.2': {'0.2': [0.7386111875827532,\n",
       "     0.7705819538535366,\n",
       "     0.7515350505346343,\n",
       "     0.7161788654325968,\n",
       "     0.69430308468034],\n",
       "    '0.4': [0.7407221692328655,\n",
       "     0.7417740686270244,\n",
       "     0.7801743879193401,\n",
       "     0.755067807137233,\n",
       "     0.686821949534761],\n",
       "    '0.8': [0.6570159182120546,\n",
       "     0.7707085966083321,\n",
       "     0.7346981078511334,\n",
       "     0.6936691808904736,\n",
       "     0.7477798973819234]},\n",
       "   '0.4': {'0.2': [0.7565629757060963,\n",
       "     0.7720229429140253,\n",
       "     0.689847074998475,\n",
       "     0.7111903498240317,\n",
       "     0.7333398674577983],\n",
       "    '0.4': [0.7625088158758725,\n",
       "     0.7384359949735315,\n",
       "     0.68647980714597,\n",
       "     0.6684686206605288,\n",
       "     0.7460087216185338],\n",
       "    '0.8': [0.7118877548562978,\n",
       "     0.7823497255810903,\n",
       "     0.6569304593220524,\n",
       "     0.7504136935618304,\n",
       "     0.7963299477914181]},\n",
       "   '0.8': {'0.2': [0.362933435543631,\n",
       "     0.17458648440975433,\n",
       "     0.3133170625619215,\n",
       "     0.2942945759282952,\n",
       "     0.2420517662060595],\n",
       "    '0.4': [0.2384376521777627,\n",
       "     0.060448658490501184,\n",
       "     0.3708975337888547,\n",
       "     0.20659957244277294,\n",
       "     0.24702425263487837],\n",
       "    '0.8': [0.32921518684782525,\n",
       "     0.22863401658582372,\n",
       "     0.1658528134083661,\n",
       "     0.24968010331918866,\n",
       "     0.40612501224824293]}},\n",
       "  '200': {'0.2': {'0.2': [0.7830965646265495,\n",
       "     0.7705790322196368,\n",
       "     0.6315941475892586,\n",
       "     0.65614854681474,\n",
       "     0.7537714423908178],\n",
       "    '0.4': [0.7620946395527861,\n",
       "     0.5574450949416101,\n",
       "     0.739798472720158,\n",
       "     0.7664904578442792,\n",
       "     0.6534330671850203],\n",
       "    '0.8': [0.6760367778505543,\n",
       "     0.7714856762158561,\n",
       "     0.720459011602195,\n",
       "     0.7153528174631953,\n",
       "     0.7401542226129654]},\n",
       "   '0.4': {'0.2': [0.6001599032780172,\n",
       "     0.6661304188263211,\n",
       "     0.8047322918246625,\n",
       "     0.5975673961916108,\n",
       "     0.6420892458402363],\n",
       "    '0.4': [0.5179715584092603,\n",
       "     0.6518755114431276,\n",
       "     0.7993642075017166,\n",
       "     0.7546226165572627,\n",
       "     0.7878118029251137],\n",
       "    '0.8': [0.7174604780147762,\n",
       "     0.6681593189180155,\n",
       "     0.661529352743642,\n",
       "     0.7611686373006659,\n",
       "     0.7152391801285922]},\n",
       "   '0.8': {'0.2': [0.34350701440780207,\n",
       "     0.23225270407575915,\n",
       "     0.17234567343782625,\n",
       "     0.3601620190060757,\n",
       "     0.1830759430257224],\n",
       "    '0.4': [0.2806171606945891,\n",
       "     0.27303413217138706,\n",
       "     0.45835060673557293,\n",
       "     0.15251707090028777,\n",
       "     0.19405299516890906],\n",
       "    '0.8': [0.19863634144621567,\n",
       "     0.373577800913948,\n",
       "     0.2788557551744246,\n",
       "     0.3541343916633304,\n",
       "     0.2346991817744265]}}},\n",
       " '8': {'50': {'0.2': {'0.2': [0.7531169330477289,\n",
       "     0.6917106893628122,\n",
       "     0.7025458498439527,\n",
       "     0.7963355834136934,\n",
       "     0.7676514772158237],\n",
       "    '0.4': [0.7621562106776919,\n",
       "     0.700716338176373,\n",
       "     0.815028300906196,\n",
       "     0.7347809228383094,\n",
       "     0.7055990367248646],\n",
       "    '0.8': [0.7809619015883594,\n",
       "     0.7534708097339133,\n",
       "     0.6682838816612999,\n",
       "     0.7632450331125828,\n",
       "     0.7022376486227013]},\n",
       "   '0.4': {'0.2': [0.6600732600732601,\n",
       "     0.6880934847486531,\n",
       "     0.6632940786200033,\n",
       "     0.7445339470655926,\n",
       "     0.7806165678159421],\n",
       "    '0.4': [0.7332502522105513,\n",
       "     0.6905718913637805,\n",
       "     0.798074120453834,\n",
       "     0.7658716159214664,\n",
       "     0.7118577075098814],\n",
       "    '0.8': [0.721293261485473,\n",
       "     0.7055055999865162,\n",
       "     0.8017006391351673,\n",
       "     0.6871867960093789,\n",
       "     0.67891544773457]},\n",
       "   '0.8': {'0.2': [0.19194802370467023,\n",
       "     0.30210864623344047,\n",
       "     -0.0014416468300533225,\n",
       "     0.3995433789954338,\n",
       "     0.2387403881362139],\n",
       "    '0.4': [0.26792804274300286,\n",
       "     -0.2470978198969085,\n",
       "     0.0,\n",
       "     0.28268809349890434,\n",
       "     0.34412027009810164],\n",
       "    '0.8': [0.20159470437791482,\n",
       "     0.0,\n",
       "     0.3710631008951265,\n",
       "     0.0,\n",
       "     0.002991944764096588]}},\n",
       "  '100': {'0.2': {'0.2': [0.7663220785346487,\n",
       "     0.6136656639449936,\n",
       "     0.6962425488963797,\n",
       "     0.8229416776392224,\n",
       "     0.7521085441877521],\n",
       "    '0.4': [0.7244734432234432,\n",
       "     0.8016632926629097,\n",
       "     0.6722107998076943,\n",
       "     0.6786459540922791,\n",
       "     0.7860768958325135],\n",
       "    '0.8': [0.7435504409753337,\n",
       "     0.7673227128605676,\n",
       "     0.7495416830035924,\n",
       "     0.6594684385382059,\n",
       "     0.7198739771213498]},\n",
       "   '0.4': {'0.2': [0.7861900645751767,\n",
       "     0.7502191060473269,\n",
       "     0.7505444250871081,\n",
       "     0.6799262381454162,\n",
       "     0.717379171782565],\n",
       "    '0.4': [0.8190899754712657,\n",
       "     0.7211139074744747,\n",
       "     0.7417123557036112,\n",
       "     0.8117256407595725,\n",
       "     0.5847331490537955],\n",
       "    '0.8': [0.8117737218286178,\n",
       "     0.7819495118824573,\n",
       "     0.786790253891146,\n",
       "     0.778626787468617,\n",
       "     0.574763757643135]},\n",
       "   '0.8': {'0.2': [0.22569269521410584,\n",
       "     0.07639969599363039,\n",
       "     0.3796221421745204,\n",
       "     -0.07690887268026958,\n",
       "     0.15135279935708545],\n",
       "    '0.4': [0.22308380554727114,\n",
       "     0.08390456929107071,\n",
       "     0.2603985907346058,\n",
       "     0.1505402393526818,\n",
       "     0.13952403173121797],\n",
       "    '0.8': [0.10045265327567376,\n",
       "     0.52023149206502,\n",
       "     0.302229801008685,\n",
       "     0.3053173241852487,\n",
       "     0.23312806334045488]}},\n",
       "  '200': {'0.2': {'0.2': [0.7802834477226135,\n",
       "     0.7811614374591249,\n",
       "     0.6715127787797475,\n",
       "     0.8023458946843025,\n",
       "     0.7564886261148411],\n",
       "    '0.4': [0.7502331449887542,\n",
       "     0.5474619132794671,\n",
       "     0.7571131571131571,\n",
       "     0.7438588123062246,\n",
       "     0.7683690469351411],\n",
       "    '0.8': [0.7239311065866946,\n",
       "     0.6714727085478888,\n",
       "     0.7748701090303498,\n",
       "     0.637060489918347,\n",
       "     0.7483462350457424]},\n",
       "   '0.4': {'0.2': [0.7028395061728394,\n",
       "     0.8552207290524283,\n",
       "     0.7816900822665303,\n",
       "     0.599576966558477,\n",
       "     0.7174939390072732],\n",
       "    '0.4': [0.7533216168717047,\n",
       "     0.53323766677009,\n",
       "     0.6879823345838826,\n",
       "     0.7811807944211469,\n",
       "     0.7275878778842212],\n",
       "    '0.8': [0.7486543198613265,\n",
       "     0.6295169728677454,\n",
       "     0.6737210124039946,\n",
       "     0.6014658726523134,\n",
       "     0.6831424398493351]},\n",
       "   '0.8': {'0.2': [0.3441551914765302,\n",
       "     0.10288785872761053,\n",
       "     0.20186474949449562,\n",
       "     0.2849083215796897,\n",
       "     0.24152264897645415],\n",
       "    '0.4': [0.13395904436860073,\n",
       "     0.21439471363171814,\n",
       "     0.1917964842075175,\n",
       "     0.2081902245706737,\n",
       "     0.2831242221399981],\n",
       "    '0.8': [0.20520439661887313,\n",
       "     0.43796706874631774,\n",
       "     0.1929127052722558,\n",
       "     0.022570024335544225,\n",
       "     0.3171780663303283]}}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'j' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8b255b5ebb03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"essay_set\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"total_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"essay_set\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'j' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'1': {'50': {'0.2': {'0.2': [0.7822229273018805,\n",
    "     0.831578071015277,\n",
    "     0.7679183888840032,\n",
    "     0.7736123893933575,\n",
    "     0.7774992523496382],\n",
    "    '0.4': [0.8072263015450674,\n",
    "     0.8127656386224935,\n",
    "     0.8018044847401917,\n",
    "     0.7855830049342649,\n",
    "     0.7963817660049989],\n",
    "    '0.8': [0.7753845525299777,\n",
    "     0.831038718631846,\n",
    "     0.8038468723557789,\n",
    "     0.7457837020860105,\n",
    "     0.8293238167507517]},\n",
    "   '0.4': {'0.2': [0.6412645947145328,\n",
    "     0.7513163555901575,\n",
    "     0.7353803647269683,\n",
    "     0.8251764184287984,\n",
    "     0.6709744393716301],\n",
    "    '0.4': [0.7671747709109399,\n",
    "     0.7413726977525121,\n",
    "     0.7443229704545185,\n",
    "     0.7649705103075166,\n",
    "     0.7184655488234466],\n",
    "    '0.8': [0.80612211166573,\n",
    "     0.7314726255687911,\n",
    "     0.524859609628182,\n",
    "     0.7595900041936996,\n",
    "     0.7430979627443937]},\n",
    "   '0.8': {'0.2': [0.5408971578586919,\n",
    "     0.02651742049691108,\n",
    "     0.19118869492934332,\n",
    "     0.3064607537546047,\n",
    "     0.04702358667165851],\n",
    "    '0.4': [0.22328883642612873,\n",
    "     0.19190706036091143,\n",
    "     0.22589009522654213,\n",
    "     0.26280448953585267,\n",
    "     0.2599294757155991],\n",
    "    '0.8': [0.22084864760300849,\n",
    "     0.25483810020782915,\n",
    "     0.14279047799514122,\n",
    "     0.1885199191835466,\n",
    "     0.16168561577047957]}},\n",
    "  '100': {'0.2': {'0.2': [0.7738246821408828,\n",
    "     0.822141191385918,\n",
    "     0.7984072087534864,\n",
    "     0.8357220412595006,\n",
    "     0.7878838266267597],\n",
    "    '0.4': [0.7475956157959249,\n",
    "     0.7756644569729261,\n",
    "     0.7871603849680112,\n",
    "     0.7424277947921398,\n",
    "     0.799564065057135],\n",
    "    '0.8': [0.8255477633820674,\n",
    "     0.780478332632124,\n",
    "     0.8231413023081253,\n",
    "     0.7776727741338576,\n",
    "     0.8129972353228168]},\n",
    "   '0.4': {'0.2': [0.8053395061728394,\n",
    "     0.757915095317649,\n",
    "     0.7714273253024659,\n",
    "     0.6301645344016368,\n",
    "     0.8193884386534092],\n",
    "    '0.4': [0.8076464752434602,\n",
    "     0.8134397623909412,\n",
    "     0.6011953679491968,\n",
    "     0.6686024077789783,\n",
    "     0.7719888094189458],\n",
    "    '0.8': [0.7812953269849278,\n",
    "     0.7955212307310567,\n",
    "     0.7067690969705755,\n",
    "     0.6062983061996382,\n",
    "     0.6574515910289576]},\n",
    "   '0.8': {'0.2': [0.2711190890530153,\n",
    "     0.2216542039094701,\n",
    "     0.41482329420869335,\n",
    "     0.31499318291771117,\n",
    "     0.32018028128224163],\n",
    "    '0.4': [0.23496614894464363,\n",
    "     0.28010969022158516,\n",
    "     0.22959216339074207,\n",
    "     0.20193780168975373,\n",
    "     0.3708926440231728],\n",
    "    '0.8': [0.1006053514500973,\n",
    "     0.3860645759666107,\n",
    "     0.3050918266431284,\n",
    "     0.02050568525255747,\n",
    "     0.3214010399876659]}},\n",
    "  '200': {'0.2': {'0.2': [0.7713318114542307,\n",
    "     0.8292270275986042,\n",
    "     0.7241026390818042,\n",
    "     0.8259999695711047,\n",
    "     0.7980655736337436],\n",
    "    '0.4': [0.8246235606731621,\n",
    "     0.7939966378027451,\n",
    "     0.7871448632312974,\n",
    "     0.850986489080798,\n",
    "     0.8183243595053548],\n",
    "    '0.8': [0.8290200639720849,\n",
    "     0.8104074679775378,\n",
    "     0.69253775749082,\n",
    "     0.7836987794635358,\n",
    "     0.8061997226074896]},\n",
    "   '0.4': {'0.2': [0.7562549443030938,\n",
    "     0.5691949434464405,\n",
    "     0.8180208146127077,\n",
    "     0.8020480070469059,\n",
    "     0.7350998653013339],\n",
    "    '0.4': [0.7261272612726127,\n",
    "     0.7728285077951003,\n",
    "     0.8006119326874044,\n",
    "     0.8222333187691155,\n",
    "     0.6448732856528457],\n",
    "    '0.8': [0.7902206395842639,\n",
    "     0.7582764811490126,\n",
    "     0.6705461437713629,\n",
    "     0.7217842688089937,\n",
    "     0.7196284946651903]},\n",
    "   '0.8': {'0.2': [0.5190056598074877,\n",
    "     0.1999000161512371,\n",
    "     0.5154181708784598,\n",
    "     0.2665707358658259,\n",
    "     0.3031592548119123],\n",
    "    '0.4': [0.13731050002347867,\n",
    "     0.5285082363157751,\n",
    "     0.4088244296376522,\n",
    "     0.14601842501485585,\n",
    "     0.3674561222529721],\n",
    "    '0.8': [0.34623813002191384,\n",
    "     0.4391243846602726,\n",
    "     0.19376315315949655,\n",
    "     0.167132325714478,\n",
    "     0.24231478289542707]}}},\n",
    " '2': {'50': {'0.2': {'0.2': [0.7844917454841828,\n",
    "     0.7090318753707346,\n",
    "     0.6034743202416919,\n",
    "     0.7589087012665879,\n",
    "     0.6372834848225004],\n",
    "    '0.4': [0.7124243255980154,\n",
    "     0.7388268367516587,\n",
    "     0.7372402430598615,\n",
    "     0.6504394861392833,\n",
    "     0.6313728757080973],\n",
    "    '0.8': [0.7125542543608222,\n",
    "     0.667452292252718,\n",
    "     0.7592795063284101,\n",
    "     0.7311460634957554,\n",
    "     0.693261531920924]},\n",
    "   '0.4': {'0.2': [0.7290671910672315,\n",
    "     0.7006915588706006,\n",
    "     0.6458445469225063,\n",
    "     0.7597793380140421,\n",
    "     0.6966677047648708],\n",
    "    '0.4': [0.6992741777283724,\n",
    "     0.7135873074439627,\n",
    "     0.6836443553362122,\n",
    "     0.7497261312884469,\n",
    "     0.6290076335877863],\n",
    "    '0.8': [0.583419689119171,\n",
    "     0.6398448164379624,\n",
    "     0.7248288105503424,\n",
    "     0.6413904859153365,\n",
    "     0.7357286536727474]},\n",
    "   '0.8': {'0.2': [0.0019238545712990662,\n",
    "     0.0,\n",
    "     0.12392241379310331,\n",
    "     0.09090909090909094,\n",
    "     0.1625357554700254],\n",
    "    '0.4': [0.00981637185451778,\n",
    "     0.02364737688648577,\n",
    "     0.08192771084337358,\n",
    "     0.11201186356895698,\n",
    "     0.32402919085921267],\n",
    "    '0.8': [0.022228039696327806,\n",
    "     0.0,\n",
    "     0.0764097108037528,\n",
    "     0.27277494398627067,\n",
    "     0.0]}},\n",
    "  '100': {'0.2': {'0.2': [0.7443368737663314,\n",
    "     0.6512185920169018,\n",
    "     0.7419058251789584,\n",
    "     0.7540761279045236,\n",
    "     0.7163398692810458],\n",
    "    '0.4': [0.7506292434273145,\n",
    "     0.6815814786560085,\n",
    "     0.7015548623222225,\n",
    "     0.7555281472997974,\n",
    "     0.6937106918238993],\n",
    "    '0.8': [0.6811069442648391,\n",
    "     0.7524807056229328,\n",
    "     0.6921122079953084,\n",
    "     0.697307444125066,\n",
    "     0.6868921377925582]},\n",
    "   '0.4': {'0.2': [0.661548280522601,\n",
    "     0.6465734183882483,\n",
    "     0.5800652325852295,\n",
    "     0.7694744251525105,\n",
    "     0.6701617353652842],\n",
    "    '0.4': [0.6600420100177735,\n",
    "     0.6083053767340647,\n",
    "     0.7059086723456584,\n",
    "     0.6758389261744966,\n",
    "     0.7080706917019177],\n",
    "    '0.8': [0.6670373665480427,\n",
    "     0.7419430446501816,\n",
    "     0.6776801087449025,\n",
    "     0.691099077110823,\n",
    "     0.7343008970915947]},\n",
    "   '0.8': {'0.2': [0.20743293713716615,\n",
    "     0.17214543150223782,\n",
    "     0.202207931695512,\n",
    "     0.14714682043192073,\n",
    "     0.1480947914954509],\n",
    "    '0.4': [0.2881130401723482,\n",
    "     0.24933372816108967,\n",
    "     0.08426808126009455,\n",
    "     0.19601542416452433,\n",
    "     0.16772583909993888],\n",
    "    '0.8': [0.030761797390884138,\n",
    "     0.2780476234116993,\n",
    "     0.2764046618656779,\n",
    "     0.15130434782608693,\n",
    "     0.20485720710591415]}},\n",
    "  '200': {'0.2': {'0.2': [0.6919569237934574,\n",
    "     0.7380056413665791,\n",
    "     0.6332872059378538,\n",
    "     0.6793416127668237,\n",
    "     0.7442349249578165],\n",
    "    '0.4': [0.7471691847916321,\n",
    "     0.5888926725071975,\n",
    "     0.782893561260349,\n",
    "     0.6213020305116199,\n",
    "     0.6972919961600353],\n",
    "    '0.8': [0.6921734070410241,\n",
    "     0.7789681073759389,\n",
    "     0.7215978635807277,\n",
    "     0.6793461861464465,\n",
    "     0.7673927949786381]},\n",
    "   '0.4': {'0.2': [0.6426102217731213,\n",
    "     0.7515329138867495,\n",
    "     0.6280978487384181,\n",
    "     0.7242850695441678,\n",
    "     0.7458567465680348],\n",
    "    '0.4': [0.7764900662251655,\n",
    "     0.5196122951857007,\n",
    "     0.6502357479639949,\n",
    "     0.698028980289803,\n",
    "     0.6908286582804044],\n",
    "    '0.8': [0.5823282642894598,\n",
    "     0.6296537063882623,\n",
    "     0.7823303889611377,\n",
    "     0.6845298281092013,\n",
    "     0.6860587018596583]},\n",
    "   '0.8': {'0.2': [0.2938832436740386,\n",
    "     0.33913104097317837,\n",
    "     0.3557105492589363,\n",
    "     0.23268870867124136,\n",
    "     0.2795531405555344],\n",
    "    '0.4': [0.26470588235294124,\n",
    "     0.24867520023229361,\n",
    "     0.20856673263341496,\n",
    "     0.27277742024455276,\n",
    "     0.23375081217932914],\n",
    "    '0.8': [0.23236026563364687,\n",
    "     0.23843726606843363,\n",
    "     0.3426395653592198,\n",
    "     0.3967479361160404,\n",
    "     0.3030192465565995]}}},\n",
    " '3': {'50': {'0.2': {'0.2': [0.7316312398887082,\n",
    "     0.746903653008409,\n",
    "     0.7941351973403802,\n",
    "     0.8066612779611839,\n",
    "     0.7750109217999126],\n",
    "    '0.4': [0.7824431242534504,\n",
    "     0.7684732134509302,\n",
    "     0.7587826897600707,\n",
    "     0.7550861133892431,\n",
    "     0.761807606198777],\n",
    "    '0.8': [0.7558426720879047,\n",
    "     0.6888068880688807,\n",
    "     0.7561837455830389,\n",
    "     0.79445808181842,\n",
    "     0.7359839771465424]},\n",
    "   '0.4': {'0.2': [0.7483202959088462,\n",
    "     0.7107762866891526,\n",
    "     0.5589672891339766,\n",
    "     0.741139846743295,\n",
    "     0.6500837345967092],\n",
    "    '0.4': [0.7035239116171846,\n",
    "     0.7648668443431733,\n",
    "     0.5312841788228571,\n",
    "     0.6971515879078904,\n",
    "     0.7692532877416889],\n",
    "    '0.8': [0.7559222034979212,\n",
    "     0.6598711312981937,\n",
    "     0.7174773070668159,\n",
    "     0.4738362872425015,\n",
    "     0.7257876312718786]},\n",
    "   '0.8': {'0.2': [0.0029436370960246316,\n",
    "     0.13754707712461112,\n",
    "     0.07003694145033146,\n",
    "     0.016953689658249393,\n",
    "     0.22101945222338037],\n",
    "    '0.4': [0.2653734059528676,\n",
    "     0.11501899269814397,\n",
    "     0.09969539100976454,\n",
    "     0.0,\n",
    "     0.2600536193029491],\n",
    "    '0.8': [0.14574418653036603,\n",
    "     0.2288705879540539,\n",
    "     0.15665275004538037,\n",
    "     0.10651555168081228,\n",
    "     0.031987222224202805]}},\n",
    "  '100': {'0.2': {'0.2': [0.748702696485203,\n",
    "     0.7576104506091296,\n",
    "     0.7941062512739245,\n",
    "     0.7689833405824221,\n",
    "     0.7489047598923777],\n",
    "    '0.4': [0.7280076790043774,\n",
    "     0.7787389537268354,\n",
    "     0.7562596704975623,\n",
    "     0.7094671073482139,\n",
    "     0.7393335895165378],\n",
    "    '0.8': [0.7815515521979007,\n",
    "     0.7629019227661981,\n",
    "     0.7645298472200346,\n",
    "     0.7585808754067388,\n",
    "     0.7920522215917829]},\n",
    "   '0.4': {'0.2': [0.734212603052538,\n",
    "     0.7433305113799352,\n",
    "     0.7933189137226628,\n",
    "     0.6623474315110043,\n",
    "     0.7090052883057427],\n",
    "    '0.4': [0.7534685799109352,\n",
    "     0.7587472840338653,\n",
    "     0.7139877964007106,\n",
    "     0.7819946267607402,\n",
    "     0.6478048695241881],\n",
    "    '0.8': [0.7526815978996773,\n",
    "     0.6873743658466545,\n",
    "     0.7079294059159831,\n",
    "     0.6975797067721666,\n",
    "     0.7624150741197047]},\n",
    "   '0.8': {'0.2': [0.16106876569318362,\n",
    "     0.22118505988731485,\n",
    "     0.3391389556201795,\n",
    "     0.3721572173534672,\n",
    "     0.020428712682674655],\n",
    "    '0.4': [0.2073453786933377,\n",
    "     0.29856415288054494,\n",
    "     0.1299891354546331,\n",
    "     0.12360048924073597,\n",
    "     0.1675685873439844],\n",
    "    '0.8': [0.43787096184117413,\n",
    "     0.3902985303592795,\n",
    "     0.10060714163207896,\n",
    "     0.47247153943633946,\n",
    "     0.3452644533518895]}},\n",
    "  '200': {'0.2': {'0.2': [0.7865008543763052,\n",
    "     0.6703267801959366,\n",
    "     0.7189071326587622,\n",
    "     0.7359465536625442,\n",
    "     0.7921949478349458],\n",
    "    '0.4': [0.7480282902054608,\n",
    "     0.778311077317873,\n",
    "     0.7006877373613178,\n",
    "     0.7452340302351822,\n",
    "     0.763088501895292],\n",
    "    '0.8': [0.7238522347217999,\n",
    "     0.8119301337435499,\n",
    "     0.7437330352866038,\n",
    "     0.7146958729173365,\n",
    "     0.7915021573099009]},\n",
    "   '0.4': {'0.2': [0.7804737637991916,\n",
    "     0.7587041461988904,\n",
    "     0.7272499646441579,\n",
    "     0.749487102648625,\n",
    "     0.7281703608995089],\n",
    "    '0.4': [0.7589591359358573,\n",
    "     0.7800406322778851,\n",
    "     0.6353748403230571,\n",
    "     0.6896000881348463,\n",
    "     0.7618660312324141],\n",
    "    '0.8': [0.6583943718759208,\n",
    "     0.6994005227816995,\n",
    "     0.7207738814993954,\n",
    "     0.7027898155518214,\n",
    "     0.7454347765479941]},\n",
    "   '0.8': {'0.2': [0.35631191421888,\n",
    "     0.062364804153216435,\n",
    "     0.4481645406228293,\n",
    "     0.35154920962593417,\n",
    "     0.28681695988927636],\n",
    "    '0.4': [0.18786524440728913,\n",
    "     0.37564863777242785,\n",
    "     0.17709134111398417,\n",
    "     0.26447182268332936,\n",
    "     0.3962325544582318],\n",
    "    '0.8': [0.23113427843982104,\n",
    "     0.2677448155513169,\n",
    "     0.27795350308397904,\n",
    "     0.21331864999676098,\n",
    "     0.35940658686049964]}}},\n",
    " '4': {'50': {'0.2': {'0.2': [0.7651359796409936,\n",
    "     0.6433286960920703,\n",
    "     0.7596400556532417,\n",
    "     0.7758841948565269,\n",
    "     0.7695149789377074],\n",
    "    '0.4': [0.7775413602778476,\n",
    "     0.7828987265009096,\n",
    "     0.770162545092721,\n",
    "     0.670537961409396,\n",
    "     0.7718844873745259],\n",
    "    '0.8': [0.7869941458104219,\n",
    "     0.7866512254496467,\n",
    "     0.7802547424885713,\n",
    "     0.6908904363771311,\n",
    "     0.7785307710667352]},\n",
    "   '0.4': {'0.2': [0.7323591929238287,\n",
    "     0.7169241880981247,\n",
    "     0.7347981784877997,\n",
    "     0.692776571783356,\n",
    "     0.672456383464018],\n",
    "    '0.4': [0.696250016169299,\n",
    "     0.6246616931819315,\n",
    "     0.652796508349067,\n",
    "     0.7190712066876956,\n",
    "     0.7114574597401129],\n",
    "    '0.8': [0.7150066215490931,\n",
    "     0.7635029553638155,\n",
    "     0.7132163999308019,\n",
    "     0.6884151903595948,\n",
    "     0.7596105816789258]},\n",
    "   '0.8': {'0.2': [0.4072351986579873,\n",
    "     0.28090284884910965,\n",
    "     0.090479017142446,\n",
    "     0.0060933061542940425,\n",
    "     0.0],\n",
    "    '0.4': [0.0416198110300503,\n",
    "     0.2676079023810449,\n",
    "     0.281488567634416,\n",
    "     0.001295359462250678,\n",
    "     0.1727384718241416],\n",
    "    '0.8': [0.12638451673079165,\n",
    "     0.20928295600817748,\n",
    "     0.038891828558470065,\n",
    "     0.31894906523873934,\n",
    "     0.01111563754874001]}},\n",
    "  '100': {'0.2': {'0.2': [0.780314585158155,\n",
    "     0.7569546864669684,\n",
    "     0.7762418567421887,\n",
    "     0.7466035585940924,\n",
    "     0.781198607034113],\n",
    "    '0.4': [0.7283788227556725,\n",
    "     0.780691847066667,\n",
    "     0.7544585095172671,\n",
    "     0.7723515475160769,\n",
    "     0.7611057775349773],\n",
    "    '0.8': [0.7961206985210935,\n",
    "     0.7614081117122196,\n",
    "     0.7749755667326166,\n",
    "     0.7917647058823529,\n",
    "     0.7644671510245606]},\n",
    "   '0.4': {'0.2': [0.7538190020921236,\n",
    "     0.6505905959206997,\n",
    "     0.5711004706195979,\n",
    "     0.7974348284572186,\n",
    "     0.7111080885968675],\n",
    "    '0.4': [0.7039434311441751,\n",
    "     0.708871856527402,\n",
    "     0.7351824847713898,\n",
    "     0.709301690252204,\n",
    "     0.5566573168100416],\n",
    "    '0.8': [0.7842877480886696,\n",
    "     0.7389040416563353,\n",
    "     0.785383971021921,\n",
    "     0.7605508245947404,\n",
    "     0.7735666070772351]},\n",
    "   '0.8': {'0.2': [0.3832160785936629,\n",
    "     0.4445839086230702,\n",
    "     0.22695289942420793,\n",
    "     0.35752376305162903,\n",
    "     0.22397875300366754],\n",
    "    '0.4': [0.13781425994773067,\n",
    "     0.2495764947651976,\n",
    "     0.12036430554255961,\n",
    "     0.1809558325323417,\n",
    "     0.44077299087197996],\n",
    "    '0.8': [0.2810333091681838,\n",
    "     0.31389492817296727,\n",
    "     0.3316856817717604,\n",
    "     0.019252555907252722,\n",
    "     0.27763292143747875]}},\n",
    "  '200': {'0.2': {'0.2': [0.7557026137750009,\n",
    "     0.6904893382040609,\n",
    "     0.7890591686863349,\n",
    "     0.7223520450320182,\n",
    "     0.7380398494481893],\n",
    "    '0.4': [0.7631802796434457,\n",
    "     0.6919001334095674,\n",
    "     0.7721910262580887,\n",
    "     0.7699674233414344,\n",
    "     0.6037505451373746],\n",
    "    '0.8': [0.7382210014789774,\n",
    "     0.8252385596193983,\n",
    "     0.6917656349664368,\n",
    "     0.6666759587061765,\n",
    "     0.7207865994679358]},\n",
    "   '0.4': {'0.2': [0.7493057646625849,\n",
    "     0.4862666958261447,\n",
    "     0.7176115701094334,\n",
    "     0.734366515837104,\n",
    "     0.7119332430812934],\n",
    "    '0.4': [0.6774979312595424,\n",
    "     0.7698033173933052,\n",
    "     0.7831974631517346,\n",
    "     0.7565137644727576,\n",
    "     0.5825458994093105],\n",
    "    '0.8': [0.8180801809435744,\n",
    "     0.693866961845792,\n",
    "     0.5582984604752945,\n",
    "     0.644019620931865,\n",
    "     0.6676416422922761]},\n",
    "   '0.8': {'0.2': [0.35736466285906443,\n",
    "     0.5013192612137203,\n",
    "     0.4332451621885006,\n",
    "     0.30969309693096936,\n",
    "     0.4301727983243798],\n",
    "    '0.4': [0.34453290154275185,\n",
    "     0.3128647564499537,\n",
    "     0.2708114199849736,\n",
    "     0.27918338059670167,\n",
    "     0.48916240446969617],\n",
    "    '0.8': [0.25371359380743363,\n",
    "     0.29819322333628073,\n",
    "     0.28043462192327595,\n",
    "     0.42124819283619996,\n",
    "     0.35685194058457115]}}},\n",
    " '5': {'50': {'0.2': {'0.2': [0.603519241947039,\n",
    "     0.7172475197150852,\n",
    "     0.6804530877857585,\n",
    "     0.5491963963058926,\n",
    "     0.7477150581090256],\n",
    "    '0.4': [0.760762579007415,\n",
    "     0.6671483833041445,\n",
    "     0.7339881978234789,\n",
    "     0.6874871006948425,\n",
    "     0.6029078413135134],\n",
    "    '0.8': [0.7237894847931191,\n",
    "     0.6930447537358277,\n",
    "     0.7552566833963263,\n",
    "     0.6485993051402965,\n",
    "     0.772498887887671]},\n",
    "   '0.4': {'0.2': [0.7320348788145474,\n",
    "     0.7289018122802272,\n",
    "     0.720938670873595,\n",
    "     0.6751958055537576,\n",
    "     0.7313842811804245],\n",
    "    '0.4': [0.7117257806921438,\n",
    "     0.6412754327139594,\n",
    "     0.7207318716529499,\n",
    "     0.741803002154678,\n",
    "     0.7130268999386954],\n",
    "    '0.8': [0.5070126227208975,\n",
    "     0.6342600097260496,\n",
    "     0.6724305777078454,\n",
    "     0.6415734588548683,\n",
    "     0.7174597620713785]},\n",
    "   '0.8': {'0.2': [0.022256114782805092,\n",
    "     0.13925263655602949,\n",
    "     0.30389951340952803,\n",
    "     0.23193114522086067,\n",
    "     0.11203240815810522],\n",
    "    '0.4': [0.0,\n",
    "     0.21332786165661932,\n",
    "     0.29876558681621657,\n",
    "     0.36648705586841146,\n",
    "     0.4114684555951086],\n",
    "    '0.8': [-0.0011745172795474268,\n",
    "     0.09632167434007088,\n",
    "     0.005633058065282026,\n",
    "     0.25992882353085256,\n",
    "     0.15704189847778582]}},\n",
    "  '100': {'0.2': {'0.2': [0.6927931920928996,\n",
    "     0.6926798376296419,\n",
    "     0.6420034674609227,\n",
    "     0.7335191794978679,\n",
    "     0.7021058885661473],\n",
    "    '0.4': [0.5762211515425772,\n",
    "     0.6756283539736263,\n",
    "     0.7270022044004825,\n",
    "     0.6709327640312602,\n",
    "     0.6206139028293013],\n",
    "    '0.8': [0.7482830536652476,\n",
    "     0.7525343273788332,\n",
    "     0.7136613530975838,\n",
    "     0.6627400570376927,\n",
    "     0.6768956892601832]},\n",
    "   '0.4': {'0.2': [0.6900152412127771,\n",
    "     0.7062619989880998,\n",
    "     0.6762474222270387,\n",
    "     0.6879062818172508,\n",
    "     0.7294612425914012],\n",
    "    '0.4': [0.709519603179996,\n",
    "     0.662092893476133,\n",
    "     0.7381368387190372,\n",
    "     0.71616815896827,\n",
    "     0.5937068054313359],\n",
    "    '0.8': [0.6057032941904416,\n",
    "     0.706861550954121,\n",
    "     0.5585165049047593,\n",
    "     0.7074630439724238,\n",
    "     0.6057830326428589]},\n",
    "   '0.8': {'0.2': [0.16527084567013517,\n",
    "     0.25900976895144456,\n",
    "     0.35951453973831193,\n",
    "     0.3343545664723486,\n",
    "     0.16009847813484046],\n",
    "    '0.4': [0.20594461149898824,\n",
    "     0.08889220059995384,\n",
    "     0.17720060742525012,\n",
    "     0.406694823194486,\n",
    "     0.22732706496659116],\n",
    "    '0.8': [0.23913071416637754,\n",
    "     0.37037134297525187,\n",
    "     0.4360360451602612,\n",
    "     0.18180079750535105,\n",
    "     0.2356367267129842]}},\n",
    "  '200': {'0.2': {'0.2': [0.6395425215408987,\n",
    "     0.7046931118315585,\n",
    "     0.6701174504433407,\n",
    "     0.6327672010006626,\n",
    "     0.6684192597375034],\n",
    "    '0.4': [0.5260410466834251,\n",
    "     0.718027210417436,\n",
    "     0.6782864008529803,\n",
    "     0.6945815752907225,\n",
    "     0.7339702886206991],\n",
    "    '0.8': [0.6352427149978489,\n",
    "     0.6629381590196637,\n",
    "     0.6526832844827142,\n",
    "     0.6992522999563333,\n",
    "     0.770342118850343]},\n",
    "   '0.4': {'0.2': [0.5015069884162393,\n",
    "     0.6174744093533208,\n",
    "     0.7669951651556534,\n",
    "     0.6867013353542217,\n",
    "     0.6876159440632299],\n",
    "    '0.4': [0.7126388954218332,\n",
    "     0.506222265248063,\n",
    "     0.5403218155095302,\n",
    "     0.7342156404277663,\n",
    "     0.7420302126535037],\n",
    "    '0.8': [0.6580878784734889,\n",
    "     0.6083878684812994,\n",
    "     0.7606392038542021,\n",
    "     0.6936781504218608,\n",
    "     0.759314894539598]},\n",
    "   '0.8': {'0.2': [0.21576646683379463,\n",
    "     0.2596828596906138,\n",
    "     0.32352063175903645,\n",
    "     0.3049343754100865,\n",
    "     0.30861128881160305],\n",
    "    '0.4': [0.30520356269843507,\n",
    "     0.30212743614588955,\n",
    "     0.2687065402580888,\n",
    "     0.28874520960195615,\n",
    "     0.10748417634432283],\n",
    "    '0.8': [0.3400252341020865,\n",
    "     0.24642614023144993,\n",
    "     0.12447213246859923,\n",
    "     0.1864003246165955,\n",
    "     0.32328164776672075]}}},\n",
    " '6': {'50': {'0.2': {'0.2': [0.7597292724196277,\n",
    "     0.6981361968775942,\n",
    "     0.7519527126873549,\n",
    "     0.7067694749971651,\n",
    "     0.7548331353277892],\n",
    "    '0.4': [0.7206966250842197,\n",
    "     0.6756109247724006,\n",
    "     0.6631502890173411,\n",
    "     0.7581539826935877,\n",
    "     0.7413793103448276],\n",
    "    '0.8': [0.7278992312472508,\n",
    "     0.7638145726804276,\n",
    "     0.6625596625596626,\n",
    "     0.7368333610234259,\n",
    "     0.721385203507983]},\n",
    "   '0.4': {'0.2': [0.6860435556308787,\n",
    "     0.7137561961851895,\n",
    "     0.6122419405181254,\n",
    "     0.6449449264660636,\n",
    "     0.6664482575044024],\n",
    "    '0.4': [0.6523125996810207,\n",
    "     0.7073024740622507,\n",
    "     0.6172922641490086,\n",
    "     0.5914844649021864,\n",
    "     0.6519702166820045],\n",
    "    '0.8': [0.6907020069438563,\n",
    "     0.701151631477927,\n",
    "     0.6962382583386009,\n",
    "     0.6341934860345994,\n",
    "     0.6834264432029795]},\n",
    "   '0.8': {'0.2': [0.12138872511224996,\n",
    "     0.121344537815126,\n",
    "     0.3347944893544347,\n",
    "     0.11301482005725205,\n",
    "     0.2565409244209369],\n",
    "    '0.4': [0.025087357763641238,\n",
    "     0.0,\n",
    "     0.3090519550080343,\n",
    "     0.09233686955491027,\n",
    "     0.026721479958890182],\n",
    "    '0.8': [0.1812130958949134,\n",
    "     0.4055218026609244,\n",
    "     0.06782431052093973,\n",
    "     0.01758923952405589,\n",
    "     0.018138671295635067]}},\n",
    "  '100': {'0.2': {'0.2': [0.6828446922570854,\n",
    "     0.7490414778668526,\n",
    "     0.7439328348419257,\n",
    "     0.7134925290598834,\n",
    "     0.7694230947309937],\n",
    "    '0.4': [0.6824824485121004,\n",
    "     0.7211239449133717,\n",
    "     0.7734759396653255,\n",
    "     0.7082501608459673,\n",
    "     0.7278880866425992],\n",
    "    '0.8': [0.7067520238847104,\n",
    "     0.7386088980395668,\n",
    "     0.7348536209553158,\n",
    "     0.4877784741610164,\n",
    "     0.7398324078171618]},\n",
    "   '0.4': {'0.2': [0.7024784144609908,\n",
    "     0.6168556208168283,\n",
    "     0.7161606268364349,\n",
    "     0.6982515091141575,\n",
    "     0.6850095887492009],\n",
    "    '0.4': [0.7041205300417499,\n",
    "     0.6982117217073489,\n",
    "     0.5794522024295237,\n",
    "     0.7303170318861796,\n",
    "     0.681723472177088],\n",
    "    '0.8': [0.7022673906662753,\n",
    "     0.7093007205366756,\n",
    "     0.7280843101073369,\n",
    "     0.6989556438152723,\n",
    "     0.6765396961975048]},\n",
    "   '0.8': {'0.2': [0.25960655763540585,\n",
    "     0.12989123640455058,\n",
    "     0.32750455373406195,\n",
    "     0.16665103101487888,\n",
    "     0.17327898232420835],\n",
    "    '0.4': [0.2987040133779264,\n",
    "     0.13520582215146681,\n",
    "     0.04370633038880378,\n",
    "     0.24680450284791677,\n",
    "     0.1608680675163624],\n",
    "    '0.8': [0.04070638320237563,\n",
    "     0.2778321465933249,\n",
    "     0.18811762232301088,\n",
    "     0.3571428571428572,\n",
    "     0.07741360394953378]}},\n",
    "  '200': {'0.2': {'0.2': [0.737781954887218,\n",
    "     0.7153343120245563,\n",
    "     0.75957976968146,\n",
    "     0.7312506465294301,\n",
    "     0.7223267363985251],\n",
    "    '0.4': [0.7177262721740256,\n",
    "     0.6383296047725577,\n",
    "     0.8114111388447671,\n",
    "     0.740605481415748,\n",
    "     0.737307624270299],\n",
    "    '0.8': [0.7055787476280835,\n",
    "     0.648247541515075,\n",
    "     0.6998213222156044,\n",
    "     0.7336124060508039,\n",
    "     0.772281288450011]},\n",
    "   '0.4': {'0.2': [0.7080247291424374,\n",
    "     0.5832305795314426,\n",
    "     0.7002190466256388,\n",
    "     0.734475877450405,\n",
    "     0.6086509929239898],\n",
    "    '0.4': [0.6340808834870593,\n",
    "     0.7394074393427703,\n",
    "     0.7273220924242214,\n",
    "     0.683727948003714,\n",
    "     0.6524793166433868],\n",
    "    '0.8': [0.6506528204869688,\n",
    "     0.6219549294456275,\n",
    "     0.661859168585626,\n",
    "     0.7403688150447325,\n",
    "     0.7560396693532574]},\n",
    "   '0.8': {'0.2': [0.22046271081718127,\n",
    "     0.363048656005444,\n",
    "     0.2659896668448245,\n",
    "     0.29856764564275395,\n",
    "     0.2072927072927072],\n",
    "    '0.4': [0.3050705749274578,\n",
    "     0.15108159010409006,\n",
    "     0.367428727570817,\n",
    "     0.30559154272684874,\n",
    "     0.303921568627451],\n",
    "    '0.8': [0.35598485170843785,\n",
    "     0.27322280263456733,\n",
    "     0.3534347142108023,\n",
    "     0.2650052127289877,\n",
    "     0.2158354604358924]}}},\n",
    " '7': {'50': {'0.2': {'0.2': [0.7441791277044686,\n",
    "     0.8165466394833208,\n",
    "     0.6848039186826256,\n",
    "     0.6190403003078528,\n",
    "     0.7060480841472576],\n",
    "    '0.4': [0.7339903913135317,\n",
    "     0.6593354479932354,\n",
    "     0.6889736115581466,\n",
    "     0.7201918992011108,\n",
    "     0.7608563921641889],\n",
    "    '0.8': [0.7456213511259383,\n",
    "     0.7059507462765091,\n",
    "     0.7276605333906307,\n",
    "     0.724673052716916,\n",
    "     0.7609639708440845]},\n",
    "   '0.4': {'0.2': [0.7328757834172404,\n",
    "     0.7201043370338622,\n",
    "     0.711880095794204,\n",
    "     0.6212520801900486,\n",
    "     0.7543267249931522],\n",
    "    '0.4': [0.7584782759337537,\n",
    "     0.6909234675785725,\n",
    "     0.6351279347912344,\n",
    "     0.7349099144642388,\n",
    "     0.7740258355864369],\n",
    "    '0.8': [0.6797076579814441,\n",
    "     0.6463947610612921,\n",
    "     0.770699221323512,\n",
    "     0.7250050826517367,\n",
    "     0.6145196520022214]},\n",
    "   '0.8': {'0.2': [0.1799234069215081,\n",
    "     0.09880059309717104,\n",
    "     0.07103599556429752,\n",
    "     0.0,\n",
    "     0.2506378721857754],\n",
    "    '0.4': [0.0, 0.0, 0.0, 0.2515397117898709, 0.2054093201175704],\n",
    "    '0.8': [0.07352378092270728,\n",
    "     0.36263564681083615,\n",
    "     0.011108426033473284,\n",
    "     0.036742946898891904,\n",
    "     0.20632857447261876]}},\n",
    "  '100': {'0.2': {'0.2': [0.7386111875827532,\n",
    "     0.7705819538535366,\n",
    "     0.7515350505346343,\n",
    "     0.7161788654325968,\n",
    "     0.69430308468034],\n",
    "    '0.4': [0.7407221692328655,\n",
    "     0.7417740686270244,\n",
    "     0.7801743879193401,\n",
    "     0.755067807137233,\n",
    "     0.686821949534761],\n",
    "    '0.8': [0.6570159182120546,\n",
    "     0.7707085966083321,\n",
    "     0.7346981078511334,\n",
    "     0.6936691808904736,\n",
    "     0.7477798973819234]},\n",
    "   '0.4': {'0.2': [0.7565629757060963,\n",
    "     0.7720229429140253,\n",
    "     0.689847074998475,\n",
    "     0.7111903498240317,\n",
    "     0.7333398674577983],\n",
    "    '0.4': [0.7625088158758725,\n",
    "     0.7384359949735315,\n",
    "     0.68647980714597,\n",
    "     0.6684686206605288,\n",
    "     0.7460087216185338],\n",
    "    '0.8': [0.7118877548562978,\n",
    "     0.7823497255810903,\n",
    "     0.6569304593220524,\n",
    "     0.7504136935618304,\n",
    "     0.7963299477914181]},\n",
    "   '0.8': {'0.2': [0.362933435543631,\n",
    "     0.17458648440975433,\n",
    "     0.3133170625619215,\n",
    "     0.2942945759282952,\n",
    "     0.2420517662060595],\n",
    "    '0.4': [0.2384376521777627,\n",
    "     0.060448658490501184,\n",
    "     0.3708975337888547,\n",
    "     0.20659957244277294,\n",
    "     0.24702425263487837],\n",
    "    '0.8': [0.32921518684782525,\n",
    "     0.22863401658582372,\n",
    "     0.1658528134083661,\n",
    "     0.24968010331918866,\n",
    "     0.40612501224824293]}},\n",
    "  '200': {'0.2': {'0.2': [0.7830965646265495,\n",
    "     0.7705790322196368,\n",
    "     0.6315941475892586,\n",
    "     0.65614854681474,\n",
    "     0.7537714423908178],\n",
    "    '0.4': [0.7620946395527861,\n",
    "     0.5574450949416101,\n",
    "     0.739798472720158,\n",
    "     0.7664904578442792,\n",
    "     0.6534330671850203],\n",
    "    '0.8': [0.6760367778505543,\n",
    "     0.7714856762158561,\n",
    "     0.720459011602195,\n",
    "     0.7153528174631953,\n",
    "     0.7401542226129654]},\n",
    "   '0.4': {'0.2': [0.6001599032780172,\n",
    "     0.6661304188263211,\n",
    "     0.8047322918246625,\n",
    "     0.5975673961916108,\n",
    "     0.6420892458402363],\n",
    "    '0.4': [0.5179715584092603,\n",
    "     0.6518755114431276,\n",
    "     0.7993642075017166,\n",
    "     0.7546226165572627,\n",
    "     0.7878118029251137],\n",
    "    '0.8': [0.7174604780147762,\n",
    "     0.6681593189180155,\n",
    "     0.661529352743642,\n",
    "     0.7611686373006659,\n",
    "     0.7152391801285922]},\n",
    "   '0.8': {'0.2': [0.34350701440780207,\n",
    "     0.23225270407575915,\n",
    "     0.17234567343782625,\n",
    "     0.3601620190060757,\n",
    "     0.1830759430257224],\n",
    "    '0.4': [0.2806171606945891,\n",
    "     0.27303413217138706,\n",
    "     0.45835060673557293,\n",
    "     0.15251707090028777,\n",
    "     0.19405299516890906],\n",
    "    '0.8': [0.19863634144621567,\n",
    "     0.373577800913948,\n",
    "     0.2788557551744246,\n",
    "     0.3541343916633304,\n",
    "     0.2346991817744265]}}},\n",
    " '8': {'50': {'0.2': {'0.2': [0.7531169330477289,\n",
    "     0.6917106893628122,\n",
    "     0.7025458498439527,\n",
    "     0.7963355834136934,\n",
    "     0.7676514772158237],\n",
    "    '0.4': [0.7621562106776919,\n",
    "     0.700716338176373,\n",
    "     0.815028300906196,\n",
    "     0.7347809228383094,\n",
    "     0.7055990367248646],\n",
    "    '0.8': [0.7809619015883594,\n",
    "     0.7534708097339133,\n",
    "     0.6682838816612999,\n",
    "     0.7632450331125828,\n",
    "     0.7022376486227013]},\n",
    "   '0.4': {'0.2': [0.6600732600732601,\n",
    "     0.6880934847486531,\n",
    "     0.6632940786200033,\n",
    "     0.7445339470655926,\n",
    "     0.7806165678159421],\n",
    "    '0.4': [0.7332502522105513,\n",
    "     0.6905718913637805,\n",
    "     0.798074120453834,\n",
    "     0.7658716159214664,\n",
    "     0.7118577075098814],\n",
    "    '0.8': [0.721293261485473,\n",
    "     0.7055055999865162,\n",
    "     0.8017006391351673,\n",
    "     0.6871867960093789,\n",
    "     0.67891544773457]},\n",
    "   '0.8': {'0.2': [0.19194802370467023,\n",
    "     0.30210864623344047,\n",
    "     -0.0014416468300533225,\n",
    "     0.3995433789954338,\n",
    "     0.2387403881362139],\n",
    "    '0.4': [0.26792804274300286,\n",
    "     -0.2470978198969085,\n",
    "     0.0,\n",
    "     0.28268809349890434,\n",
    "     0.34412027009810164],\n",
    "    '0.8': [0.20159470437791482,\n",
    "     0.0,\n",
    "     0.3710631008951265,\n",
    "     0.0,\n",
    "     0.002991944764096588]}},\n",
    "  '100': {'0.2': {'0.2': [0.7663220785346487,\n",
    "     0.6136656639449936,\n",
    "     0.6962425488963797,\n",
    "     0.8229416776392224,\n",
    "     0.7521085441877521],\n",
    "    '0.4': [0.7244734432234432,\n",
    "     0.8016632926629097,\n",
    "     0.6722107998076943,\n",
    "     0.6786459540922791,\n",
    "     0.7860768958325135],\n",
    "    '0.8': [0.7435504409753337,\n",
    "     0.7673227128605676,\n",
    "     0.7495416830035924,\n",
    "     0.6594684385382059,\n",
    "     0.7198739771213498]},\n",
    "   '0.4': {'0.2': [0.7861900645751767,\n",
    "     0.7502191060473269,\n",
    "     0.7505444250871081,\n",
    "     0.6799262381454162,\n",
    "     0.717379171782565],\n",
    "    '0.4': [0.8190899754712657,\n",
    "     0.7211139074744747,\n",
    "     0.7417123557036112,\n",
    "     0.8117256407595725,\n",
    "     0.5847331490537955],\n",
    "    '0.8': [0.8117737218286178,\n",
    "     0.7819495118824573,\n",
    "     0.786790253891146,\n",
    "     0.778626787468617,\n",
    "     0.574763757643135]},\n",
    "   '0.8': {'0.2': [0.22569269521410584,\n",
    "     0.07639969599363039,\n",
    "     0.3796221421745204,\n",
    "     -0.07690887268026958,\n",
    "     0.15135279935708545],\n",
    "    '0.4': [0.22308380554727114,\n",
    "     0.08390456929107071,\n",
    "     0.2603985907346058,\n",
    "     0.1505402393526818,\n",
    "     0.13952403173121797],\n",
    "    '0.8': [0.10045265327567376,\n",
    "     0.52023149206502,\n",
    "     0.302229801008685,\n",
    "     0.3053173241852487,\n",
    "     0.23312806334045488]}},\n",
    "  '200': {'0.2': {'0.2': [0.7802834477226135,\n",
    "     0.7811614374591249,\n",
    "     0.6715127787797475,\n",
    "     0.8023458946843025,\n",
    "     0.7564886261148411],\n",
    "    '0.4': [0.7502331449887542,\n",
    "     0.5474619132794671,\n",
    "     0.7571131571131571,\n",
    "     0.7438588123062246,\n",
    "     0.7683690469351411],\n",
    "    '0.8': [0.7239311065866946,\n",
    "     0.6714727085478888,\n",
    "     0.7748701090303498,\n",
    "     0.637060489918347,\n",
    "     0.7483462350457424]},\n",
    "   '0.4': {'0.2': [0.7028395061728394,\n",
    "     0.8552207290524283,\n",
    "     0.7816900822665303,\n",
    "     0.599576966558477,\n",
    "     0.7174939390072732],\n",
    "    '0.4': [0.7533216168717047,\n",
    "     0.53323766677009,\n",
    "     0.6879823345838826,\n",
    "     0.7811807944211469,\n",
    "     0.7275878778842212],\n",
    "    '0.8': [0.7486543198613265,\n",
    "     0.6295169728677454,\n",
    "     0.6737210124039946,\n",
    "     0.6014658726523134,\n",
    "     0.6831424398493351]},\n",
    "   '0.8': {'0.2': [0.3441551914765302,\n",
    "     0.10288785872761053,\n",
    "     0.20186474949449562,\n",
    "     0.2849083215796897,\n",
    "     0.24152264897645415],\n",
    "    '0.4': [0.13395904436860073,\n",
    "     0.21439471363171814,\n",
    "     0.1917964842075175,\n",
    "     0.2081902245706737,\n",
    "     0.2831242221399981],\n",
    "    '0.8': [0.20520439661887313,\n",
    "     0.43796706874631774,\n",
    "     0.1929127052722558,\n",
    "     0.022570024335544225,\n",
    "     0.3171780663303283]}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,9):\n",
    "    for neuron in neurons:\n",
    "        for dropout in dropouts:\n",
    "            temp = []\n",
    "            for rec_dropout in rec_dropouts:\n",
    "                array = d[str(i)][str(neuron)][str(dropout)][str(rec_dropout)]\n",
    "                d[str(i)][str(neuron)][str(dropout)][str(rec_dropout)]= np.mean(array)\n",
    "                temp.append(np.mean(array))\n",
    "            d[str(i)][str(neuron)][str(dropout)] = np.mean(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_d = {}\n",
    "result = []\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "for i in range(1,9):\n",
    "    new_d[str(i)] = {}\n",
    "    result_array = []\n",
    "    for dropout in dropouts:\n",
    "        new_d[str(i)][str(dropout)] = []\n",
    "        for neuron in neurons:\n",
    "            new_d[str(i)][str(dropout)].append(d[str(i)][str(neuron)][str(dropout)])\n",
    "        new_d[str(i)][str(dropout)] = np.mean(new_d[str(i)][str(dropout)])\n",
    "        result_array.append(np.mean(new_d[str(i)][str(dropout)]))\n",
    "    result.append(result_array)\n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "legends = []\n",
    "for i in range(1,9):\n",
    "    ax.plot(dropouts, result[i-1])\n",
    "    string = \"essay \" + str(i)\n",
    "    legends.append(string)\n",
    "ax.legend(legends)\n",
    "ax.set_xlabel(\"drop out rate\")\n",
    "ax.set_ylabel(\"Quadratic kappa score\")\n",
    "ax.set_title(\"LSTM dropout Hyper Parameter Tuning\")\n",
    "fig.savefig(\"lstm_dropout_hyper_parameter_tuning.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_d = {}\n",
    "result = []\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "for i in range(1,9):\n",
    "    new_d[str(i)] = {}\n",
    "    result_array = []\n",
    "    for neuron in neurons:\n",
    "        new_d[str(i)][str(neuron)] = []\n",
    "        for dropout in dropouts:\n",
    "            new_d[str(i)][str(neuron)].append(d[str(i)][str(neuron)][str(dropout)])\n",
    "        new_d[str(i)][str(neuron)] = np.mean(new_d[str(i)][str(neuron)])\n",
    "        result_array.append(np.mean(new_d[str(i)][str(neuron)]))\n",
    "    result.append(result_array)\n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "legends = []\n",
    "for i in range(1,9):\n",
    "    ax.plot(neurons, result[i-1])\n",
    "    string = \"essay \" + str(i)\n",
    "    legends.append(string)\n",
    "ax.legend(legends)\n",
    "ax.set_xlabel(\"Number of Neurons\")\n",
    "ax.set_ylabel(\"Quadratic kappa score\")\n",
    "ax.set_title(\"LSTM dropout Hyper Parameter Tuning\")\n",
    "fig.savefig(\"lstm_neurons_hyperparameter_tuning.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay set 1\n",
      "0.7963777815429541\n",
      "Essay set 2\n",
      "0.7042569408784093\n",
      "Essay set 3\n",
      "0.7483292893148542\n",
      "Essay set 4\n",
      "0.7292880118116293\n",
      "Essay set 5\n",
      "0.672460309581742\n",
      "Essay set 6\n",
      "0.7247463231238779\n",
      "Essay set 7\n",
      "0.7131959981086414\n",
      "Essay set 8\n",
      "0.7276339272341596\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    print(\"Essay set \" + str(i))\n",
    "    print(d[str(i)][\"200\"][\"0.2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOMS SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(length):\n",
    "    model = Sequential([\n",
    "        #tune these layers\n",
    "        Dense(128, activation=tf.nn.relu, input_shape=[length]),\n",
    "        Dense(128, activation=tf.nn.relu),\n",
    "        Dense(128, activation=tf.nn.relu),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    optimizer =  tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "    model.compile(loss=\"mse\",\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=[\"mae\",\"mse\"])\n",
    "    \n",
    "    return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########Set-1###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 183.9047 - mae: 5.8832 - mse: 183.9047 - val_loss: 5.8881 - val_mae: 2.2037 - val_mse: 5.8881\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 57.7236 - mae: 5.8763 - mse: 57.7236 - val_loss: 12.3643 - val_mae: 2.9653 - val_mse: 12.3643\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 23.3152 - mae: 4.1832 - mse: 23.3152 - val_loss: 20.9764 - val_mae: 4.0151 - val_mse: 20.9764\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 14.4565 - mae: 3.1036 - mse: 14.4565 - val_loss: 1.5786 - val_mae: 0.9400 - val_mse: 1.5786\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 7.7410 - mae: 2.0343 - mse: 7.7410 - val_loss: 8.3589 - val_mae: 2.4571 - val_mse: 8.3589\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 5.6345 - mae: 1.7586 - mse: 5.6345 - val_loss: 1.1537 - val_mae: 0.8291 - val_mse: 1.1537\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.1638 - mae: 1.6050 - mse: 4.1638 - val_loss: 1.9176 - val_mae: 1.1506 - val_mse: 1.9176\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3753 - mae: 1.2106 - mse: 2.3753 - val_loss: 1.4847 - val_mae: 0.9811 - val_mse: 1.4847\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5560 - mae: 1.2665 - mse: 2.5560 - val_loss: 2.2264 - val_mae: 1.2577 - val_mse: 2.2264\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1172 - mae: 1.1511 - mse: 2.1172 - val_loss: 2.7817 - val_mae: 1.4732 - val_mse: 2.7817\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6873 - mae: 1.0125 - mse: 1.6873 - val_loss: 0.8397 - val_mae: 0.7084 - val_mse: 0.8397\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9196 - mae: 1.0695 - mse: 1.9196 - val_loss: 1.2772 - val_mae: 0.9165 - val_mse: 1.2772\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7552 - mae: 1.0542 - mse: 1.7552 - val_loss: 1.5386 - val_mae: 0.9968 - val_mse: 1.5386\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8367 - mae: 1.0708 - mse: 1.8367 - val_loss: 1.2981 - val_mae: 0.9347 - val_mse: 1.2981\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4097 - mae: 0.9415 - mse: 1.4097 - val_loss: 0.8245 - val_mae: 0.7011 - val_mse: 0.8245\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5368 - mae: 0.9761 - mse: 1.5368 - val_loss: 1.0476 - val_mae: 0.7774 - val_mse: 1.0476\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3578 - mae: 0.8938 - mse: 1.3578 - val_loss: 0.7149 - val_mae: 0.6606 - val_mse: 0.7149\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3379 - mae: 0.9202 - mse: 1.3379 - val_loss: 0.6873 - val_mae: 0.6432 - val_mse: 0.6873\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2832 - mae: 0.8862 - mse: 1.2832 - val_loss: 3.5887 - val_mae: 1.7329 - val_mse: 3.5887\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3372 - mae: 0.8982 - mse: 1.3372 - val_loss: 3.2647 - val_mae: 1.6306 - val_mse: 3.2647\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4143 - mae: 0.9384 - mse: 1.4143 - val_loss: 1.0565 - val_mae: 0.8110 - val_mse: 1.0565\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1948 - mae: 0.8591 - mse: 1.1948 - val_loss: 1.0189 - val_mae: 0.7954 - val_mse: 1.0189\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2439 - mae: 0.8856 - mse: 1.2439 - val_loss: 1.6978 - val_mae: 1.1019 - val_mse: 1.6978\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1771 - mae: 0.8551 - mse: 1.1771 - val_loss: 0.8897 - val_mae: 0.7346 - val_mse: 0.8897\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2153 - mae: 0.8672 - mse: 1.2153 - val_loss: 0.6941 - val_mae: 0.6540 - val_mse: 0.6941\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1793 - mae: 0.8486 - mse: 1.1793 - val_loss: 0.8448 - val_mae: 0.7139 - val_mse: 0.8448\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0859 - mae: 0.8203 - mse: 1.0859 - val_loss: 0.7262 - val_mae: 0.6510 - val_mse: 0.7262\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1153 - mae: 0.8203 - mse: 1.1153 - val_loss: 0.6463 - val_mae: 0.6193 - val_mse: 0.6463\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0583 - mae: 0.8047 - mse: 1.0583 - val_loss: 1.1727 - val_mae: 0.8793 - val_mse: 1.1727\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1699 - mae: 0.8581 - mse: 1.1699 - val_loss: 1.1238 - val_mae: 0.8488 - val_mse: 1.1238\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1216 - mae: 0.8441 - mse: 1.1216 - val_loss: 0.7013 - val_mae: 0.6367 - val_mse: 0.7013\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0612 - mae: 0.8201 - mse: 1.0612 - val_loss: 0.7478 - val_mae: 0.6762 - val_mse: 0.7478\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1189 - mae: 0.8433 - mse: 1.1189 - val_loss: 0.6475 - val_mae: 0.6205 - val_mse: 0.6475\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0424 - mae: 0.7920 - mse: 1.0424 - val_loss: 0.7414 - val_mae: 0.6569 - val_mse: 0.7414\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0844 - mae: 0.8285 - mse: 1.0844 - val_loss: 1.4066 - val_mae: 0.9861 - val_mse: 1.4066\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0005 - mae: 0.7902 - mse: 1.0005 - val_loss: 0.6336 - val_mae: 0.6178 - val_mse: 0.6336\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0071 - mae: 0.7901 - mse: 1.0071 - val_loss: 0.6395 - val_mae: 0.6171 - val_mse: 0.6395\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0058 - mae: 0.7915 - mse: 1.0058 - val_loss: 0.6577 - val_mae: 0.6258 - val_mse: 0.6577\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9361 - mae: 0.7630 - mse: 0.9361 - val_loss: 1.6691 - val_mae: 1.0376 - val_mse: 1.6691\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9835 - mae: 0.7848 - mse: 0.9835 - val_loss: 0.6502 - val_mae: 0.6252 - val_mse: 0.6502\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0037 - mae: 0.7855 - mse: 1.0037 - val_loss: 0.6856 - val_mae: 0.6411 - val_mse: 0.6856\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9779 - mae: 0.7762 - mse: 0.9779 - val_loss: 0.6292 - val_mae: 0.6137 - val_mse: 0.6292\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9696 - mae: 0.7775 - mse: 0.9696 - val_loss: 0.7882 - val_mae: 0.6778 - val_mse: 0.7882\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9305 - mae: 0.7742 - mse: 0.9305 - val_loss: 0.6996 - val_mae: 0.6431 - val_mse: 0.6996\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9635 - mae: 0.7686 - mse: 0.9635 - val_loss: 1.3652 - val_mae: 0.9601 - val_mse: 1.3652\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9581 - mae: 0.7744 - mse: 0.9581 - val_loss: 1.7400 - val_mae: 1.1238 - val_mse: 1.7400\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9004 - mae: 0.7456 - mse: 0.9004 - val_loss: 1.3143 - val_mae: 0.9308 - val_mse: 1.3143\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.8413 - mae: 0.7324 - mse: 0.841 - 0s 1ms/step - loss: 0.9879 - mae: 0.7673 - mse: 0.9879 - val_loss: 0.8501 - val_mae: 0.7186 - val_mse: 0.8501\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9587 - mae: 0.7771 - mse: 0.9587 - val_loss: 0.7486 - val_mae: 0.6620 - val_mse: 0.7486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8962 - mae: 0.7345 - mse: 0.8962 - val_loss: 0.7973 - val_mae: 0.6794 - val_mse: 0.7973\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9324 - mae: 0.7663 - mse: 0.9324 - val_loss: 0.8548 - val_mae: 0.7171 - val_mse: 0.8548\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8407 - mae: 0.7233 - mse: 0.8407 - val_loss: 0.6786 - val_mae: 0.6312 - val_mse: 0.6786\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8871 - mae: 0.7295 - mse: 0.8871 - val_loss: 0.6621 - val_mae: 0.6205 - val_mse: 0.6621\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8846 - mae: 0.7336 - mse: 0.8846 - val_loss: 1.0040 - val_mae: 0.8046 - val_mse: 1.0040\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8690 - mae: 0.7356 - mse: 0.8690 - val_loss: 2.1189 - val_mae: 1.2535 - val_mse: 2.1189\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9289 - mae: 0.7580 - mse: 0.9289 - val_loss: 0.9539 - val_mae: 0.7645 - val_mse: 0.9539\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8531 - mae: 0.7316 - mse: 0.8531 - val_loss: 0.6339 - val_mae: 0.6056 - val_mse: 0.6339\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8680 - mae: 0.7298 - mse: 0.8680 - val_loss: 0.8876 - val_mae: 0.7267 - val_mse: 0.8876\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8806 - mae: 0.7482 - mse: 0.8806 - val_loss: 0.8468 - val_mae: 0.7014 - val_mse: 0.8468\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8484 - mae: 0.7301 - mse: 0.8484 - val_loss: 0.9609 - val_mae: 0.7700 - val_mse: 0.9609\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8585 - mae: 0.7345 - mse: 0.8585 - val_loss: 0.6521 - val_mae: 0.6262 - val_mse: 0.6521\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8025 - mae: 0.6995 - mse: 0.8025 - val_loss: 0.7953 - val_mae: 0.7087 - val_mse: 0.7953\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8520 - mae: 0.7271 - mse: 0.8520 - val_loss: 0.6593 - val_mae: 0.6195 - val_mse: 0.6593\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8121 - mae: 0.7068 - mse: 0.8121 - val_loss: 0.6631 - val_mae: 0.6268 - val_mse: 0.6631\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8063 - mae: 0.7146 - mse: 0.8063 - val_loss: 0.6569 - val_mae: 0.6122 - val_mse: 0.6569\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8475 - mae: 0.7279 - mse: 0.8475 - val_loss: 0.6243 - val_mae: 0.5972 - val_mse: 0.6243\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7701 - mae: 0.6929 - mse: 0.7701 - val_loss: 0.7365 - val_mae: 0.6797 - val_mse: 0.7365\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7782 - mae: 0.6850 - mse: 0.7782 - val_loss: 0.6410 - val_mae: 0.6229 - val_mse: 0.6410\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7882 - mae: 0.6903 - mse: 0.7882 - val_loss: 0.6523 - val_mae: 0.6278 - val_mse: 0.6523\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8070 - mae: 0.7100 - mse: 0.8070 - val_loss: 0.8087 - val_mae: 0.6971 - val_mse: 0.8087\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7504 - mae: 0.6789 - mse: 0.7504 - val_loss: 0.7176 - val_mae: 0.6425 - val_mse: 0.7176\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7906 - mae: 0.6887 - mse: 0.7906 - val_loss: 0.7429 - val_mae: 0.6639 - val_mse: 0.7429\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7775 - mae: 0.6939 - mse: 0.7775 - val_loss: 0.7931 - val_mae: 0.7098 - val_mse: 0.7931\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7453 - mae: 0.6826 - mse: 0.7453 - val_loss: 0.8772 - val_mae: 0.7673 - val_mse: 0.8772\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7592 - mae: 0.6798 - mse: 0.7592 - val_loss: 0.9423 - val_mae: 0.7512 - val_mse: 0.9423\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.7598 - mae: 0.6858 - mse: 0.7598 - val_loss: 0.7329 - val_mae: 0.6700 - val_mse: 0.7329\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6754 - mae: 0.6406 - mse: 0.6754 - val_loss: 1.0130 - val_mae: 0.7912 - val_mse: 1.0130\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8042 - mae: 0.6996 - mse: 0.8042 - val_loss: 1.9775 - val_mae: 1.1861 - val_mse: 1.9775\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7664 - mae: 0.6838 - mse: 0.7664 - val_loss: 0.7156 - val_mae: 0.6441 - val_mse: 0.7156\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7031 - mae: 0.6515 - mse: 0.7031 - val_loss: 1.6843 - val_mae: 1.0909 - val_mse: 1.6843\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7647 - mae: 0.6827 - mse: 0.7647 - val_loss: 1.3897 - val_mae: 0.9511 - val_mse: 1.3897\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7041 - mae: 0.6573 - mse: 0.7041 - val_loss: 0.6507 - val_mae: 0.6304 - val_mse: 0.6507\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7640 - mae: 0.6842 - mse: 0.7640 - val_loss: 1.0767 - val_mae: 0.8195 - val_mse: 1.0767\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7081 - mae: 0.6689 - mse: 0.7081 - val_loss: 0.7853 - val_mae: 0.6699 - val_mse: 0.7853\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7075 - mae: 0.6508 - mse: 0.7075 - val_loss: 0.7801 - val_mae: 0.7074 - val_mse: 0.7801\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7539 - mae: 0.6857 - mse: 0.7539 - val_loss: 0.7631 - val_mae: 0.7093 - val_mse: 0.7631\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6942 - mae: 0.6379 - mse: 0.6942 - val_loss: 1.1539 - val_mae: 0.8652 - val_mse: 1.1539\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6976 - mae: 0.6464 - mse: 0.6976 - val_loss: 0.6778 - val_mae: 0.6350 - val_mse: 0.6778\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7482 - mae: 0.6708 - mse: 0.7482 - val_loss: 1.3056 - val_mae: 0.9259 - val_mse: 1.3056\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6887 - mae: 0.6562 - mse: 0.6887 - val_loss: 0.6736 - val_mae: 0.6500 - val_mse: 0.6736\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7398 - mae: 0.6687 - mse: 0.7398 - val_loss: 0.9050 - val_mae: 0.7353 - val_mse: 0.9050\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6818 - mae: 0.6482 - mse: 0.6818 - val_loss: 0.8240 - val_mae: 0.7420 - val_mse: 0.8240\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7263 - mae: 0.6671 - mse: 0.7263 - val_loss: 1.2238 - val_mae: 0.8795 - val_mse: 1.2238\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6627 - mae: 0.6377 - mse: 0.6627 - val_loss: 0.7398 - val_mae: 0.6608 - val_mse: 0.7398\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6927 - mae: 0.6494 - mse: 0.6927 - val_loss: 0.6544 - val_mae: 0.6289 - val_mse: 0.6544\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6553 - mae: 0.6252 - mse: 0.6553 - val_loss: 0.7456 - val_mae: 0.6567 - val_mse: 0.7456\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7372 - mae: 0.6724 - mse: 0.7372 - val_loss: 0.8916 - val_mae: 0.7319 - val_mse: 0.8916\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6757 - mae: 0.6328 - mse: 0.6757 - val_loss: 0.6974 - val_mae: 0.6373 - val_mse: 0.6974\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6692 - mae: 0.6376 - mse: 0.6692 - val_loss: 0.6582 - val_mae: 0.6296 - val_mse: 0.6582\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6653 - mae: 0.6398 - mse: 0.6653 - val_loss: 0.7256 - val_mae: 0.6734 - val_mse: 0.7256\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6681 - mae: 0.6427 - mse: 0.6681 - val_loss: 0.7258 - val_mae: 0.6522 - val_mse: 0.7258\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6832 - mae: 0.6399 - mse: 0.6832 - val_loss: 0.6655 - val_mae: 0.6261 - val_mse: 0.6655\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6774 - mae: 0.6518 - mse: 0.6774 - val_loss: 0.6827 - val_mae: 0.6353 - val_mse: 0.6827\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6455 - mae: 0.6166 - mse: 0.6455 - val_loss: 0.7010 - val_mae: 0.6531 - val_mse: 0.7010\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6591 - mae: 0.6203 - mse: 0.6591 - val_loss: 0.7491 - val_mae: 0.6605 - val_mse: 0.7491\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6562 - mae: 0.6411 - mse: 0.6562 - val_loss: 0.6970 - val_mae: 0.6414 - val_mse: 0.6970\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6685 - mae: 0.6301 - mse: 0.6685 - val_loss: 0.9304 - val_mae: 0.7491 - val_mse: 0.9304\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6880 - mae: 0.6399 - mse: 0.6880 - val_loss: 0.7424 - val_mae: 0.6571 - val_mse: 0.7424\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6485 - mae: 0.6298 - mse: 0.6485 - val_loss: 0.8401 - val_mae: 0.6991 - val_mse: 0.8401\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6392 - mae: 0.6265 - mse: 0.6392 - val_loss: 0.7090 - val_mae: 0.6554 - val_mse: 0.7090\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6271 - mae: 0.6137 - mse: 0.6271 - val_loss: 0.6770 - val_mae: 0.6347 - val_mse: 0.6770\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6712 - mae: 0.6288 - mse: 0.6712 - val_loss: 0.6984 - val_mae: 0.6319 - val_mse: 0.6984\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6206 - mae: 0.6121 - mse: 0.6206 - val_loss: 0.7629 - val_mae: 0.6875 - val_mse: 0.7629\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6466 - mae: 0.6210 - mse: 0.6466 - val_loss: 0.7188 - val_mae: 0.6665 - val_mse: 0.7188\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6117 - mae: 0.6084 - mse: 0.6117 - val_loss: 0.7692 - val_mae: 0.6965 - val_mse: 0.7692\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6395 - mae: 0.6134 - mse: 0.6395 - val_loss: 0.8835 - val_mae: 0.7280 - val_mse: 0.8835\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5824 - mae: 0.5881 - mse: 0.5824 - val_loss: 0.7012 - val_mae: 0.6555 - val_mse: 0.7012\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6447 - mae: 0.6182 - mse: 0.6447 - val_loss: 0.7492 - val_mae: 0.6819 - val_mse: 0.7492\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5688 - mae: 0.5796 - mse: 0.5688 - val_loss: 0.7994 - val_mae: 0.7113 - val_mse: 0.7994\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6147 - mae: 0.6125 - mse: 0.6147 - val_loss: 0.6994 - val_mae: 0.6492 - val_mse: 0.6994\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6428 - mae: 0.6225 - mse: 0.6428 - val_loss: 0.6853 - val_mae: 0.6400 - val_mse: 0.6853\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5671 - mae: 0.5744 - mse: 0.5671 - val_loss: 0.7855 - val_mae: 0.7060 - val_mse: 0.7855\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5829 - mae: 0.5851 - mse: 0.5829 - val_loss: 0.8451 - val_mae: 0.7473 - val_mse: 0.8451\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6391 - mae: 0.6185 - mse: 0.6391 - val_loss: 0.7597 - val_mae: 0.6802 - val_mse: 0.7597\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6172 - mae: 0.6008 - mse: 0.6172 - val_loss: 0.7207 - val_mae: 0.6683 - val_mse: 0.7207\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6074 - mae: 0.6050 - mse: 0.6074 - val_loss: 0.7225 - val_mae: 0.6529 - val_mse: 0.7225\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5814 - mae: 0.5877 - mse: 0.5814 - val_loss: 0.8402 - val_mae: 0.6989 - val_mse: 0.8402\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6007 - mae: 0.5958 - mse: 0.6007 - val_loss: 0.6841 - val_mae: 0.6395 - val_mse: 0.6841\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5749 - mae: 0.5841 - mse: 0.5749 - val_loss: 0.7845 - val_mae: 0.6797 - val_mse: 0.7845\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5860 - mae: 0.5933 - mse: 0.5860 - val_loss: 1.3510 - val_mae: 0.9161 - val_mse: 1.3510\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5934 - mae: 0.5884 - mse: 0.5934 - val_loss: 1.4698 - val_mae: 0.9951 - val_mse: 1.4698\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5823 - mae: 0.5907 - mse: 0.5823 - val_loss: 1.0354 - val_mae: 0.7801 - val_mse: 1.0354\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6067 - mae: 0.6065 - mse: 0.6067 - val_loss: 1.1365 - val_mae: 0.8370 - val_mse: 1.1365\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6211 - mae: 0.6099 - mse: 0.6211 - val_loss: 1.3604 - val_mae: 0.9165 - val_mse: 1.3604\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5666 - mae: 0.5863 - mse: 0.5666 - val_loss: 0.7381 - val_mae: 0.6620 - val_mse: 0.7381\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5703 - mae: 0.5801 - mse: 0.5703 - val_loss: 0.6906 - val_mae: 0.6458 - val_mse: 0.6906\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5593 - mae: 0.5711 - mse: 0.5593 - val_loss: 0.8475 - val_mae: 0.6935 - val_mse: 0.8475\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5522 - mae: 0.5695 - mse: 0.5522 - val_loss: 0.7505 - val_mae: 0.6840 - val_mse: 0.7505\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5752 - mae: 0.5725 - mse: 0.5752 - val_loss: 0.7101 - val_mae: 0.6490 - val_mse: 0.7101\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5863 - mae: 0.5730 - mse: 0.5863 - val_loss: 0.7225 - val_mae: 0.6605 - val_mse: 0.7225\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5816 - mae: 0.5926 - mse: 0.5816 - val_loss: 0.7001 - val_mae: 0.6436 - val_mse: 0.7001\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5168 - mae: 0.5506 - mse: 0.5168 - val_loss: 0.8478 - val_mae: 0.7255 - val_mse: 0.8478\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5488 - mae: 0.5667 - mse: 0.5488 - val_loss: 1.1662 - val_mae: 0.8500 - val_mse: 1.1662\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5912 - mae: 0.5992 - mse: 0.5912 - val_loss: 0.7736 - val_mae: 0.6745 - val_mse: 0.7736\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5402 - mae: 0.5716 - mse: 0.5402 - val_loss: 0.7280 - val_mae: 0.6565 - val_mse: 0.7280\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5256 - mae: 0.5666 - mse: 0.5256 - val_loss: 1.4677 - val_mae: 0.9681 - val_mse: 1.4677\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5809 - mae: 0.5879 - mse: 0.5809 - val_loss: 0.6845 - val_mae: 0.6322 - val_mse: 0.6845\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5648 - mae: 0.5807 - mse: 0.5648 - val_loss: 0.7739 - val_mae: 0.6708 - val_mse: 0.7739\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5191 - mae: 0.5548 - mse: 0.5191 - val_loss: 0.8249 - val_mae: 0.7003 - val_mse: 0.8249\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5497 - mae: 0.5661 - mse: 0.5497 - val_loss: 0.8299 - val_mae: 0.7108 - val_mse: 0.8299\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5228 - mae: 0.5528 - mse: 0.5228 - val_loss: 1.0581 - val_mae: 0.8388 - val_mse: 1.0581\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5564 - mae: 0.5799 - mse: 0.5564 - val_loss: 0.7547 - val_mae: 0.6593 - val_mse: 0.7547\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5341 - mae: 0.5724 - mse: 0.5341 - val_loss: 0.8815 - val_mae: 0.7227 - val_mse: 0.8815\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5146 - mae: 0.5530 - mse: 0.5146 - val_loss: 0.7470 - val_mae: 0.6646 - val_mse: 0.7470\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4989 - mae: 0.5464 - mse: 0.4989 - val_loss: 1.0343 - val_mae: 0.7815 - val_mse: 1.0343\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5374 - mae: 0.5594 - mse: 0.5374 - val_loss: 0.7583 - val_mae: 0.6803 - val_mse: 0.7583\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5096 - mae: 0.5587 - mse: 0.5096 - val_loss: 0.7406 - val_mae: 0.6679 - val_mse: 0.7406\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5487 - mae: 0.5764 - mse: 0.5487 - val_loss: 0.7557 - val_mae: 0.6792 - val_mse: 0.7557\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5057 - mae: 0.5425 - mse: 0.5057 - val_loss: 1.1379 - val_mae: 0.8715 - val_mse: 1.1379\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5597 - mae: 0.5796 - mse: 0.5597 - val_loss: 0.7613 - val_mae: 0.6794 - val_mse: 0.7613\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5174 - mae: 0.5559 - mse: 0.5174 - val_loss: 0.7702 - val_mae: 0.6828 - val_mse: 0.7702\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5290 - mae: 0.5638 - mse: 0.5290 - val_loss: 0.7735 - val_mae: 0.6736 - val_mse: 0.7735\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4991 - mae: 0.5403 - mse: 0.4991 - val_loss: 0.9523 - val_mae: 0.7899 - val_mse: 0.9523\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4851 - mae: 0.5287 - mse: 0.4851 - val_loss: 0.8004 - val_mae: 0.6884 - val_mse: 0.8004\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5315 - mae: 0.5555 - mse: 0.5315 - val_loss: 1.0442 - val_mae: 0.7855 - val_mse: 1.0442\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5084 - mae: 0.5445 - mse: 0.5084 - val_loss: 0.7738 - val_mae: 0.6847 - val_mse: 0.7738\n",
      "Kappa Score: 0.8185692817100775\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 147.1227 - mae: 5.9860 - mse: 147.1227 - val_loss: 112.7006 - val_mae: 10.2184 - val_mse: 112.7006\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 35.2739 - mae: 4.2427 - mse: 35.2739 - val_loss: 123.9065 - val_mae: 10.2820 - val_mse: 123.9065\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 20.0410 - mae: 3.6028 - mse: 20.0410 - val_loss: 15.1252 - val_mae: 3.3873 - val_mse: 15.1252\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 7.5889 - mae: 2.1820 - mse: 7.5889 - val_loss: 1.2257 - val_mae: 0.8631 - val_mse: 1.2257\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.8899 - mae: 1.8038 - mse: 4.8899 - val_loss: 6.1082 - val_mae: 2.0163 - val_mse: 6.1082\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.7585 - mae: 1.5589 - mse: 3.7585 - val_loss: 4.6564 - val_mae: 1.9533 - val_mse: 4.6564\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 3.1701 - mae: 1.4046 - mse: 3.1701 - val_loss: 2.0431 - val_mae: 1.1785 - val_mse: 2.0431\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 2.5229 - mae: 1.2599 - mse: 2.5229 - val_loss: 2.8374 - val_mae: 1.3574 - val_mse: 2.8374\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2024 - mae: 1.1975 - mse: 2.2024 - val_loss: 0.9484 - val_mae: 0.7667 - val_mse: 0.9484\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 2.3453 - mae: 1.1841 - mse: 2.3453 - val_loss: 1.0408 - val_mae: 0.7891 - val_mse: 1.0408\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8630 - mae: 1.0963 - mse: 1.8630 - val_loss: 5.0640 - val_mae: 2.0614 - val_mse: 5.0640\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7115 - mae: 1.0300 - mse: 1.7115 - val_loss: 2.0213 - val_mae: 1.1701 - val_mse: 2.0213\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5778 - mae: 0.9728 - mse: 1.5778 - val_loss: 0.8187 - val_mae: 0.7124 - val_mse: 0.8187\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5910 - mae: 0.9834 - mse: 1.5910 - val_loss: 3.0583 - val_mae: 1.5530 - val_mse: 3.0583\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3692 - mae: 0.9321 - mse: 1.3692 - val_loss: 1.6861 - val_mae: 1.0680 - val_mse: 1.6861\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4533 - mae: 0.9461 - mse: 1.4533 - val_loss: 0.7390 - val_mae: 0.6783 - val_mse: 0.7390\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3779 - mae: 0.9170 - mse: 1.3779 - val_loss: 2.8878 - val_mae: 1.4899 - val_mse: 2.8878\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3268 - mae: 0.8896 - mse: 1.3268 - val_loss: 1.1956 - val_mae: 0.8703 - val_mse: 1.1956\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2563 - mae: 0.8770 - mse: 1.2563 - val_loss: 0.9037 - val_mae: 0.7559 - val_mse: 0.9037\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1843 - mae: 0.8528 - mse: 1.1843 - val_loss: 1.3172 - val_mae: 0.9232 - val_mse: 1.3172\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3182 - mae: 0.9027 - mse: 1.3182 - val_loss: 0.7720 - val_mae: 0.6797 - val_mse: 0.7720\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1447 - mae: 0.8359 - mse: 1.1447 - val_loss: 0.9760 - val_mae: 0.7747 - val_mse: 0.9760\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1716 - mae: 0.8489 - mse: 1.1716 - val_loss: 0.7857 - val_mae: 0.6829 - val_mse: 0.7857\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2137 - mae: 0.8588 - mse: 1.2137 - val_loss: 0.9945 - val_mae: 0.7847 - val_mse: 0.9945\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1753 - mae: 0.8478 - mse: 1.1753 - val_loss: 0.7754 - val_mae: 0.6786 - val_mse: 0.7754\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0908 - mae: 0.8239 - mse: 1.0908 - val_loss: 0.7288 - val_mae: 0.6683 - val_mse: 0.7288\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1009 - mae: 0.8287 - mse: 1.1009 - val_loss: 0.7188 - val_mae: 0.6548 - val_mse: 0.7188\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1182 - mae: 0.8291 - mse: 1.1182 - val_loss: 1.4461 - val_mae: 0.9805 - val_mse: 1.4461\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1055 - mae: 0.8158 - mse: 1.1055 - val_loss: 0.6776 - val_mae: 0.6441 - val_mse: 0.6776\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0857 - mae: 0.8217 - mse: 1.0857 - val_loss: 1.0172 - val_mae: 0.7939 - val_mse: 1.0172\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9947 - mae: 0.7828 - mse: 0.9947 - val_loss: 1.0246 - val_mae: 0.8093 - val_mse: 1.0246\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0613 - mae: 0.8166 - mse: 1.0613 - val_loss: 1.2753 - val_mae: 0.9106 - val_mse: 1.2753\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0648 - mae: 0.8156 - mse: 1.0648 - val_loss: 0.6548 - val_mae: 0.6386 - val_mse: 0.6548\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9748 - mae: 0.7796 - mse: 0.9748 - val_loss: 1.2795 - val_mae: 0.9204 - val_mse: 1.2795\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0250 - mae: 0.8029 - mse: 1.0250 - val_loss: 0.6771 - val_mae: 0.6381 - val_mse: 0.6771\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0837 - mae: 0.8107 - mse: 1.0837 - val_loss: 0.6421 - val_mae: 0.6300 - val_mse: 0.6421\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9480 - mae: 0.7605 - mse: 0.9480 - val_loss: 0.9620 - val_mae: 0.7847 - val_mse: 0.9620\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0489 - mae: 0.7975 - mse: 1.0489 - val_loss: 1.1046 - val_mae: 0.8381 - val_mse: 1.1046\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9920 - mae: 0.7838 - mse: 0.9920 - val_loss: 0.6802 - val_mae: 0.6463 - val_mse: 0.6802\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9396 - mae: 0.7623 - mse: 0.9396 - val_loss: 0.6767 - val_mae: 0.6529 - val_mse: 0.6767\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0679 - mae: 0.8192 - mse: 1.0679 - val_loss: 0.9035 - val_mae: 0.7478 - val_mse: 0.9035\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9563 - mae: 0.7759 - mse: 0.9563 - val_loss: 0.6806 - val_mae: 0.6398 - val_mse: 0.6806\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.0481 - mae: 0.7985 - mse: 1.0481 - val_loss: 0.7300 - val_mae: 0.6799 - val_mse: 0.7300\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9374 - mae: 0.7615 - mse: 0.9374 - val_loss: 0.6819 - val_mae: 0.6539 - val_mse: 0.6819\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9315 - mae: 0.7554 - mse: 0.9315 - val_loss: 0.6338 - val_mae: 0.6272 - val_mse: 0.6338\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8738 - mae: 0.7309 - mse: 0.8738 - val_loss: 1.2225 - val_mae: 0.8899 - val_mse: 1.2225\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.9992 - mae: 0.7882 - mse: 0.9992 - val_loss: 1.1935 - val_mae: 0.8804 - val_mse: 1.1935\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1000us/step - loss: 0.9070 - mae: 0.7458 - mse: 0.9070 - val_loss: 1.2918 - val_mae: 0.9236 - val_mse: 1.2918\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9589 - mae: 0.7679 - mse: 0.9589 - val_loss: 0.6635 - val_mae: 0.6420 - val_mse: 0.6635\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8481 - mae: 0.7145 - mse: 0.8481 - val_loss: 1.2794 - val_mae: 0.9173 - val_mse: 1.2794\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0053 - mae: 0.7963 - mse: 1.0053 - val_loss: 1.0342 - val_mae: 0.8127 - val_mse: 1.0342\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8801 - mae: 0.7359 - mse: 0.8801 - val_loss: 0.7487 - val_mae: 0.6673 - val_mse: 0.7487\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8953 - mae: 0.7509 - mse: 0.8953 - val_loss: 0.6619 - val_mae: 0.6357 - val_mse: 0.6619\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8664 - mae: 0.7483 - mse: 0.8664 - val_loss: 0.7456 - val_mae: 0.6743 - val_mse: 0.7456\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8906 - mae: 0.7380 - mse: 0.8906 - val_loss: 1.3283 - val_mae: 0.9402 - val_mse: 1.3283\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9229 - mae: 0.7532 - mse: 0.9229 - val_loss: 0.7330 - val_mae: 0.6746 - val_mse: 0.7330\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9328 - mae: 0.7602 - mse: 0.9328 - val_loss: 0.8021 - val_mae: 0.7007 - val_mse: 0.8021\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8307 - mae: 0.7174 - mse: 0.8307 - val_loss: 0.7080 - val_mae: 0.6602 - val_mse: 0.7080\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9435 - mae: 0.7608 - mse: 0.9435 - val_loss: 0.6530 - val_mae: 0.6395 - val_mse: 0.6530\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8452 - mae: 0.7115 - mse: 0.8452 - val_loss: 0.6156 - val_mae: 0.6238 - val_mse: 0.6156\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9107 - mae: 0.7514 - mse: 0.9107 - val_loss: 0.7655 - val_mae: 0.6977 - val_mse: 0.7655\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8445 - mae: 0.7214 - mse: 0.8445 - val_loss: 0.8903 - val_mae: 0.7566 - val_mse: 0.8903\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9080 - mae: 0.7540 - mse: 0.9080 - val_loss: 0.6141 - val_mae: 0.6141 - val_mse: 0.6141\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8808 - mae: 0.7240 - mse: 0.8808 - val_loss: 0.6584 - val_mae: 0.6308 - val_mse: 0.6584\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8279 - mae: 0.7143 - mse: 0.8279 - val_loss: 0.6268 - val_mae: 0.6241 - val_mse: 0.6268\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8741 - mae: 0.7407 - mse: 0.8741 - val_loss: 0.6941 - val_mae: 0.6511 - val_mse: 0.6941\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8342 - mae: 0.7149 - mse: 0.8342 - val_loss: 0.6945 - val_mae: 0.6451 - val_mse: 0.6945\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8556 - mae: 0.7165 - mse: 0.8556 - val_loss: 0.7310 - val_mae: 0.6670 - val_mse: 0.7310\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8799 - mae: 0.7355 - mse: 0.8799 - val_loss: 0.8824 - val_mae: 0.7425 - val_mse: 0.8824\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8351 - mae: 0.7103 - mse: 0.8351 - val_loss: 1.7777 - val_mae: 1.1185 - val_mse: 1.7777\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8707 - mae: 0.7310 - mse: 0.8707 - val_loss: 0.9357 - val_mae: 0.7637 - val_mse: 0.9357\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 983us/step - loss: 0.8560 - mae: 0.7269 - mse: 0.8560 - val_loss: 0.7823 - val_mae: 0.7045 - val_mse: 0.7823\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8209 - mae: 0.7149 - mse: 0.8209 - val_loss: 0.8030 - val_mae: 0.7145 - val_mse: 0.8030\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8775 - mae: 0.7350 - mse: 0.8775 - val_loss: 1.2285 - val_mae: 0.8958 - val_mse: 1.2285\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8052 - mae: 0.7091 - mse: 0.8052 - val_loss: 0.6208 - val_mae: 0.6306 - val_mse: 0.6208\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8168 - mae: 0.7074 - mse: 0.8168 - val_loss: 0.7169 - val_mae: 0.6744 - val_mse: 0.7169\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8036 - mae: 0.7074 - mse: 0.8036 - val_loss: 0.6285 - val_mae: 0.6231 - val_mse: 0.6285\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8179 - mae: 0.7025 - mse: 0.8179 - val_loss: 0.6687 - val_mae: 0.6342 - val_mse: 0.6687\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8103 - mae: 0.7107 - mse: 0.8103 - val_loss: 0.9093 - val_mae: 0.7527 - val_mse: 0.9093\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7835 - mae: 0.6932 - mse: 0.7835 - val_loss: 0.6134 - val_mae: 0.6157 - val_mse: 0.6134\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7663 - mae: 0.6843 - mse: 0.7663 - val_loss: 0.8679 - val_mae: 0.7352 - val_mse: 0.8679\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7729 - mae: 0.6896 - mse: 0.7729 - val_loss: 1.0182 - val_mae: 0.8037 - val_mse: 1.0182\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8276 - mae: 0.7047 - mse: 0.8276 - val_loss: 0.6073 - val_mae: 0.6220 - val_mse: 0.6073\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7856 - mae: 0.6931 - mse: 0.7856 - val_loss: 0.6855 - val_mae: 0.6480 - val_mse: 0.6855\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8078 - mae: 0.7004 - mse: 0.8078 - val_loss: 0.6366 - val_mae: 0.6260 - val_mse: 0.6366\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8372 - mae: 0.7216 - mse: 0.8372 - val_loss: 0.7400 - val_mae: 0.6695 - val_mse: 0.7400\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8079 - mae: 0.7085 - mse: 0.8079 - val_loss: 1.3756 - val_mae: 0.9615 - val_mse: 1.3756\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7966 - mae: 0.6959 - mse: 0.7966 - val_loss: 0.6827 - val_mae: 0.6456 - val_mse: 0.6827\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8507 - mae: 0.7294 - mse: 0.8507 - val_loss: 1.8911 - val_mae: 1.1635 - val_mse: 1.8911\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7792 - mae: 0.6933 - mse: 0.7792 - val_loss: 0.7241 - val_mae: 0.6691 - val_mse: 0.7241\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7747 - mae: 0.6855 - mse: 0.7747 - val_loss: 0.6442 - val_mae: 0.6281 - val_mse: 0.6442\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7472 - mae: 0.6810 - mse: 0.7472 - val_loss: 0.6533 - val_mae: 0.6371 - val_mse: 0.6533\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7687 - mae: 0.6761 - mse: 0.7687 - val_loss: 0.7986 - val_mae: 0.6828 - val_mse: 0.7986\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7552 - mae: 0.6846 - mse: 0.7552 - val_loss: 0.9276 - val_mae: 0.7710 - val_mse: 0.9276\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7187 - mae: 0.6736 - mse: 0.7187 - val_loss: 0.7752 - val_mae: 0.6822 - val_mse: 0.7752\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7536 - mae: 0.6792 - mse: 0.7536 - val_loss: 0.6692 - val_mae: 0.6579 - val_mse: 0.6692\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7573 - mae: 0.6872 - mse: 0.7573 - val_loss: 1.7651 - val_mae: 1.1169 - val_mse: 1.7651\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7699 - mae: 0.6856 - mse: 0.7699 - val_loss: 0.6147 - val_mae: 0.6259 - val_mse: 0.6147\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7053 - mae: 0.6567 - mse: 0.7053 - val_loss: 1.0208 - val_mae: 0.8100 - val_mse: 1.0208\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7524 - mae: 0.6732 - mse: 0.7524 - val_loss: 0.7922 - val_mae: 0.6959 - val_mse: 0.7922\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7150 - mae: 0.6598 - mse: 0.7150 - val_loss: 0.8897 - val_mae: 0.7391 - val_mse: 0.8897\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7753 - mae: 0.6938 - mse: 0.7753 - val_loss: 0.6105 - val_mae: 0.6205 - val_mse: 0.6105\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7632 - mae: 0.6825 - mse: 0.7632 - val_loss: 1.1827 - val_mae: 0.8750 - val_mse: 1.1827\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7592 - mae: 0.6833 - mse: 0.7592 - val_loss: 0.6621 - val_mae: 0.6429 - val_mse: 0.6621\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7004 - mae: 0.6511 - mse: 0.7004 - val_loss: 0.6697 - val_mae: 0.6354 - val_mse: 0.6697\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7741 - mae: 0.6818 - mse: 0.7741 - val_loss: 0.6269 - val_mae: 0.6192 - val_mse: 0.6269\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7541 - mae: 0.6745 - mse: 0.7541 - val_loss: 0.8086 - val_mae: 0.7256 - val_mse: 0.8086\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6970 - mae: 0.6618 - mse: 0.6970 - val_loss: 0.6307 - val_mae: 0.6260 - val_mse: 0.6307\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7335 - mae: 0.6736 - mse: 0.7335 - val_loss: 0.7137 - val_mae: 0.6791 - val_mse: 0.7137\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7578 - mae: 0.6791 - mse: 0.7578 - val_loss: 0.6721 - val_mae: 0.6577 - val_mse: 0.6721\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7554 - mae: 0.6774 - mse: 0.7554 - val_loss: 0.6244 - val_mae: 0.6201 - val_mse: 0.6244\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7080 - mae: 0.6512 - mse: 0.7080 - val_loss: 1.0962 - val_mae: 0.8433 - val_mse: 1.0962\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7109 - mae: 0.6575 - mse: 0.7109 - val_loss: 0.7660 - val_mae: 0.6886 - val_mse: 0.7660\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7181 - mae: 0.6607 - mse: 0.7181 - val_loss: 0.7153 - val_mae: 0.6625 - val_mse: 0.7153\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6762 - mae: 0.6361 - mse: 0.6762 - val_loss: 0.7607 - val_mae: 0.6767 - val_mse: 0.7607\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7110 - mae: 0.6567 - mse: 0.7110 - val_loss: 0.8086 - val_mae: 0.7182 - val_mse: 0.8086\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6949 - mae: 0.6478 - mse: 0.6949 - val_loss: 0.7293 - val_mae: 0.6677 - val_mse: 0.7293\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7618 - mae: 0.6776 - mse: 0.7618 - val_loss: 0.8008 - val_mae: 0.6970 - val_mse: 0.8008\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6439 - mae: 0.6281 - mse: 0.6439 - val_loss: 0.8345 - val_mae: 0.7170 - val_mse: 0.8345\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6979 - mae: 0.6496 - mse: 0.6979 - val_loss: 0.6222 - val_mae: 0.6264 - val_mse: 0.6222\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6744 - mae: 0.6403 - mse: 0.6744 - val_loss: 0.7792 - val_mae: 0.6865 - val_mse: 0.7792\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6639 - mae: 0.6287 - mse: 0.6639 - val_loss: 1.1021 - val_mae: 0.8421 - val_mse: 1.1021\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6201 - mae: 0.6191 - mse: 0.6201 - val_loss: 0.7417 - val_mae: 0.6924 - val_mse: 0.7417\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7001 - mae: 0.6505 - mse: 0.7001 - val_loss: 0.7067 - val_mae: 0.6745 - val_mse: 0.7067\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6713 - mae: 0.6309 - mse: 0.6713 - val_loss: 0.8157 - val_mae: 0.7272 - val_mse: 0.8157\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6926 - mae: 0.6532 - mse: 0.6926 - val_loss: 0.7406 - val_mae: 0.6842 - val_mse: 0.7406\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6602 - mae: 0.6361 - mse: 0.6602 - val_loss: 0.6850 - val_mae: 0.6593 - val_mse: 0.6850\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7022 - mae: 0.6560 - mse: 0.7022 - val_loss: 0.9785 - val_mae: 0.7909 - val_mse: 0.9785\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.6387 - mae: 0.6237 - mse: 0.6387 - val_loss: 0.6586 - val_mae: 0.6511 - val_mse: 0.6586\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6391 - mae: 0.6186 - mse: 0.6391 - val_loss: 0.6930 - val_mae: 0.6564 - val_mse: 0.6930\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6710 - mae: 0.6368 - mse: 0.6710 - val_loss: 0.6306 - val_mae: 0.6200 - val_mse: 0.6306\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6569 - mae: 0.6360 - mse: 0.6569 - val_loss: 0.8225 - val_mae: 0.7125 - val_mse: 0.8225\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6330 - mae: 0.6172 - mse: 0.6330 - val_loss: 1.0137 - val_mae: 0.8048 - val_mse: 1.0137\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6644 - mae: 0.6356 - mse: 0.6644 - val_loss: 1.5159 - val_mae: 1.0050 - val_mse: 1.5159\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6589 - mae: 0.6274 - mse: 0.6589 - val_loss: 0.8895 - val_mae: 0.7667 - val_mse: 0.8895\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6389 - mae: 0.6159 - mse: 0.6389 - val_loss: 0.6922 - val_mae: 0.6552 - val_mse: 0.6922\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6480 - mae: 0.6206 - mse: 0.6480 - val_loss: 0.6942 - val_mae: 0.6669 - val_mse: 0.6942\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6374 - mae: 0.6177 - mse: 0.6374 - val_loss: 0.6812 - val_mae: 0.6422 - val_mse: 0.6812\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6391 - mae: 0.6215 - mse: 0.6391 - val_loss: 1.2788 - val_mae: 0.9257 - val_mse: 1.2788\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6509 - mae: 0.6304 - mse: 0.6509 - val_loss: 0.7460 - val_mae: 0.6961 - val_mse: 0.7460\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6329 - mae: 0.6201 - mse: 0.6329 - val_loss: 0.9058 - val_mae: 0.7671 - val_mse: 0.9058\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5957 - mae: 0.6010 - mse: 0.5957 - val_loss: 0.6663 - val_mae: 0.6357 - val_mse: 0.6663\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6194 - mae: 0.6051 - mse: 0.6194 - val_loss: 0.6561 - val_mae: 0.6426 - val_mse: 0.6561\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6182 - mae: 0.6021 - mse: 0.6182 - val_loss: 0.7934 - val_mae: 0.7179 - val_mse: 0.7934\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6028 - mae: 0.6049 - mse: 0.6028 - val_loss: 1.0583 - val_mae: 0.8296 - val_mse: 1.0583\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6219 - mae: 0.6092 - mse: 0.6219 - val_loss: 1.0820 - val_mae: 0.8382 - val_mse: 1.0820\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6368 - mae: 0.6211 - mse: 0.6368 - val_loss: 0.7599 - val_mae: 0.6768 - val_mse: 0.7599\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5994 - mae: 0.6011 - mse: 0.5994 - val_loss: 0.8137 - val_mae: 0.7164 - val_mse: 0.8137\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6135 - mae: 0.6031 - mse: 0.6135 - val_loss: 0.6257 - val_mae: 0.6268 - val_mse: 0.6257\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5642 - mae: 0.5780 - mse: 0.5642 - val_loss: 0.7185 - val_mae: 0.6629 - val_mse: 0.7185\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6017 - mae: 0.5973 - mse: 0.6017 - val_loss: 0.6564 - val_mae: 0.6369 - val_mse: 0.6564\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6501 - mae: 0.6247 - mse: 0.6501 - val_loss: 0.8080 - val_mae: 0.7048 - val_mse: 0.8080\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5885 - mae: 0.5934 - mse: 0.5885 - val_loss: 0.9139 - val_mae: 0.7629 - val_mse: 0.9139\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6243 - mae: 0.6126 - mse: 0.6243 - val_loss: 0.7514 - val_mae: 0.6990 - val_mse: 0.7514\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5810 - mae: 0.5894 - mse: 0.5810 - val_loss: 0.6874 - val_mae: 0.6576 - val_mse: 0.6874\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5414 - mae: 0.5654 - mse: 0.5414 - val_loss: 1.1631 - val_mae: 0.8665 - val_mse: 1.1631\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 988us/step - loss: 0.6517 - mae: 0.6240 - mse: 0.6517 - val_loss: 1.1755 - val_mae: 0.8730 - val_mse: 1.1755\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5908 - mae: 0.5995 - mse: 0.5908 - val_loss: 0.6330 - val_mae: 0.6234 - val_mse: 0.6330\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5367 - mae: 0.5604 - mse: 0.5367 - val_loss: 0.6773 - val_mae: 0.6397 - val_mse: 0.6773\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5950 - mae: 0.5950 - mse: 0.5950 - val_loss: 0.6996 - val_mae: 0.6520 - val_mse: 0.6996\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5750 - mae: 0.5834 - mse: 0.5750 - val_loss: 0.6744 - val_mae: 0.6419 - val_mse: 0.6744\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.5352 - mae: 0.5971 - mse: 0.535 - 0s 1ms/step - loss: 0.5701 - mae: 0.5778 - mse: 0.5701 - val_loss: 1.2992 - val_mae: 0.9280 - val_mse: 1.2992\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5672 - mae: 0.5790 - mse: 0.5672 - val_loss: 1.3028 - val_mae: 0.9177 - val_mse: 1.3028\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5683 - mae: 0.5767 - mse: 0.5683 - val_loss: 0.8587 - val_mae: 0.7354 - val_mse: 0.8587\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.5694 - mae: 0.5825 - mse: 0.5694 - val_loss: 0.7450 - val_mae: 0.6704 - val_mse: 0.7450\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5698 - mae: 0.5733 - mse: 0.5698 - val_loss: 0.6892 - val_mae: 0.6476 - val_mse: 0.6892\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6020 - mae: 0.6006 - mse: 0.6020 - val_loss: 0.6935 - val_mae: 0.6487 - val_mse: 0.6935\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5342 - mae: 0.5646 - mse: 0.5342 - val_loss: 0.7839 - val_mae: 0.7004 - val_mse: 0.7839\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5478 - mae: 0.5751 - mse: 0.5478 - val_loss: 0.7318 - val_mae: 0.6793 - val_mse: 0.7318\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5634 - mae: 0.5807 - mse: 0.5634 - val_loss: 0.7199 - val_mae: 0.6543 - val_mse: 0.7199\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5703 - mae: 0.5855 - mse: 0.5703 - val_loss: 0.9006 - val_mae: 0.7489 - val_mse: 0.9006\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5259 - mae: 0.5617 - mse: 0.5259 - val_loss: 0.8428 - val_mae: 0.7194 - val_mse: 0.8428\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5510 - mae: 0.5704 - mse: 0.5510 - val_loss: 0.7470 - val_mae: 0.6951 - val_mse: 0.7470\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5603 - mae: 0.5853 - mse: 0.5603 - val_loss: 0.9500 - val_mae: 0.7739 - val_mse: 0.9500\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5208 - mae: 0.5469 - mse: 0.5208 - val_loss: 0.7458 - val_mae: 0.6857 - val_mse: 0.7458\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5601 - mae: 0.5739 - mse: 0.5601 - val_loss: 0.8891 - val_mae: 0.7523 - val_mse: 0.8891\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5410 - mae: 0.5734 - mse: 0.5410 - val_loss: 0.7310 - val_mae: 0.6824 - val_mse: 0.7310\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5412 - mae: 0.5685 - mse: 0.5412 - val_loss: 0.7432 - val_mae: 0.6763 - val_mse: 0.7432\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5214 - mae: 0.5583 - mse: 0.5214 - val_loss: 0.8663 - val_mae: 0.7604 - val_mse: 0.8663\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5466 - mae: 0.5730 - mse: 0.5466 - val_loss: 0.7009 - val_mae: 0.6533 - val_mse: 0.7009\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5279 - mae: 0.5673 - mse: 0.5279 - val_loss: 0.7028 - val_mae: 0.6670 - val_mse: 0.7028\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4940 - mae: 0.5415 - mse: 0.4940 - val_loss: 0.7160 - val_mae: 0.6546 - val_mse: 0.7160\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5187 - mae: 0.5578 - mse: 0.5187 - val_loss: 0.7552 - val_mae: 0.6820 - val_mse: 0.7552\n",
      "Kappa Score: 0.8461184024732828\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      " 1/36 [..............................] - ETA: 0s - loss: 231.5640 - mae: 14.7474 - mse: 231.5640WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 102.9527 - mae: 5.2595 - mse: 102.9527 - val_loss: 60.7332 - val_mae: 7.1013 - val_mse: 60.7332\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 21.0623 - mae: 3.9628 - mse: 21.0623 - val_loss: 17.2818 - val_mae: 3.5930 - val_mse: 17.2818\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 11.4309 - mae: 2.8089 - mse: 11.4309 - val_loss: 4.4193 - val_mae: 1.8933 - val_mse: 4.4193\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.7658 - mae: 1.9530 - mse: 6.7658 - val_loss: 5.4816 - val_mae: 2.1009 - val_mse: 5.4816\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.1204 - mae: 1.6685 - mse: 4.1204 - val_loss: 1.4186 - val_mae: 0.8877 - val_mse: 1.4186\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.1503 - mae: 1.4088 - mse: 3.1503 - val_loss: 1.1946 - val_mae: 0.8212 - val_mse: 1.1946\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2982 - mae: 1.2086 - mse: 2.2982 - val_loss: 1.5452 - val_mae: 0.9774 - val_mse: 1.5452\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2222 - mae: 1.1582 - mse: 2.2222 - val_loss: 1.9531 - val_mae: 1.1316 - val_mse: 1.9531\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0027 - mae: 1.1063 - mse: 2.0027 - val_loss: 1.0385 - val_mae: 0.7942 - val_mse: 1.0385\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9696 - mae: 1.1027 - mse: 1.9696 - val_loss: 0.9829 - val_mae: 0.7883 - val_mse: 0.9829\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7363 - mae: 1.0476 - mse: 1.7363 - val_loss: 2.3497 - val_mae: 1.2272 - val_mse: 2.3497\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7199 - mae: 1.0462 - mse: 1.7199 - val_loss: 0.9678 - val_mae: 0.7649 - val_mse: 0.9678\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6267 - mae: 1.0071 - mse: 1.6267 - val_loss: 1.5139 - val_mae: 0.9773 - val_mse: 1.5139\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6454 - mae: 1.0170 - mse: 1.6454 - val_loss: 0.9801 - val_mae: 0.7756 - val_mse: 0.9801\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4621 - mae: 0.9492 - mse: 1.4621 - val_loss: 3.2672 - val_mae: 1.6084 - val_mse: 3.2672\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4452 - mae: 0.9510 - mse: 1.4452 - val_loss: 2.1294 - val_mae: 1.2237 - val_mse: 2.1294\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5573 - mae: 0.9798 - mse: 1.5573 - val_loss: 0.9152 - val_mae: 0.7432 - val_mse: 0.9152\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4574 - mae: 0.9384 - mse: 1.4574 - val_loss: 0.7953 - val_mae: 0.6919 - val_mse: 0.7953\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2947 - mae: 0.9052 - mse: 1.2947 - val_loss: 1.0225 - val_mae: 0.7961 - val_mse: 1.0225\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3316 - mae: 0.9001 - mse: 1.3316 - val_loss: 0.9338 - val_mae: 0.7543 - val_mse: 0.9338\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2711 - mae: 0.8802 - mse: 1.2711 - val_loss: 1.1510 - val_mae: 0.8546 - val_mse: 1.1510\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3112 - mae: 0.9007 - mse: 1.3112 - val_loss: 1.5385 - val_mae: 0.9977 - val_mse: 1.5385\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 1.2276 - mae: 0.8809 - mse: 1.2276 - val_loss: 0.8430 - val_mae: 0.7180 - val_mse: 0.8430\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1933 - mae: 0.8402 - mse: 1.1933 - val_loss: 1.1293 - val_mae: 0.8402 - val_mse: 1.1293\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2033 - mae: 0.8684 - mse: 1.2033 - val_loss: 1.4941 - val_mae: 0.9974 - val_mse: 1.4941\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.2491 - mae: 0.8792 - mse: 1.2491 - val_loss: 0.9963 - val_mae: 0.7869 - val_mse: 0.9963\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2436 - mae: 0.8816 - mse: 1.2436 - val_loss: 1.4944 - val_mae: 0.9987 - val_mse: 1.4944\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1136 - mae: 0.8175 - mse: 1.1136 - val_loss: 0.8798 - val_mae: 0.7336 - val_mse: 0.8798\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0826 - mae: 0.8245 - mse: 1.0826 - val_loss: 1.5631 - val_mae: 1.0097 - val_mse: 1.5631\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1422 - mae: 0.8388 - mse: 1.1422 - val_loss: 1.5620 - val_mae: 1.0017 - val_mse: 1.5620\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1002 - mae: 0.8223 - mse: 1.1002 - val_loss: 1.6651 - val_mae: 1.0620 - val_mse: 1.6651\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0618 - mae: 0.8013 - mse: 1.0618 - val_loss: 1.9161 - val_mae: 1.1555 - val_mse: 1.9161\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1872 - mae: 0.8514 - mse: 1.1872 - val_loss: 0.6887 - val_mae: 0.6549 - val_mse: 0.6887\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1408 - mae: 0.8399 - mse: 1.1408 - val_loss: 2.1327 - val_mae: 1.2450 - val_mse: 2.1327\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1177 - mae: 0.8348 - mse: 1.1177 - val_loss: 1.1112 - val_mae: 0.8310 - val_mse: 1.1112\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9606 - mae: 0.7491 - mse: 0.9606 - val_loss: 1.0647 - val_mae: 0.8144 - val_mse: 1.0647\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0951 - mae: 0.8204 - mse: 1.0951 - val_loss: 1.5311 - val_mae: 1.0153 - val_mse: 1.5311\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1007 - mae: 0.8292 - mse: 1.1007 - val_loss: 0.6795 - val_mae: 0.6466 - val_mse: 0.6795\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0741 - mae: 0.8059 - mse: 1.0741 - val_loss: 0.8590 - val_mae: 0.7273 - val_mse: 0.8590\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0534 - mae: 0.8031 - mse: 1.0534 - val_loss: 1.0619 - val_mae: 0.8349 - val_mse: 1.0619\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0302 - mae: 0.7971 - mse: 1.0302 - val_loss: 0.6740 - val_mae: 0.6491 - val_mse: 0.6740\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0398 - mae: 0.7956 - mse: 1.0398 - val_loss: 0.6839 - val_mae: 0.6477 - val_mse: 0.6839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1000us/step - loss: 0.9411 - mae: 0.7659 - mse: 0.9411 - val_loss: 1.4912 - val_mae: 0.9977 - val_mse: 1.4912\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9299 - mae: 0.7554 - mse: 0.9299 - val_loss: 1.6022 - val_mae: 1.0455 - val_mse: 1.6022\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9496 - mae: 0.7580 - mse: 0.9496 - val_loss: 0.8371 - val_mae: 0.7366 - val_mse: 0.8371\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0464 - mae: 0.8146 - mse: 1.0464 - val_loss: 0.8429 - val_mae: 0.7295 - val_mse: 0.8429\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9443 - mae: 0.7608 - mse: 0.9443 - val_loss: 0.7676 - val_mae: 0.7046 - val_mse: 0.7676\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9234 - mae: 0.7493 - mse: 0.9234 - val_loss: 0.7698 - val_mae: 0.7050 - val_mse: 0.7698\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9878 - mae: 0.7882 - mse: 0.9878 - val_loss: 0.6750 - val_mae: 0.6552 - val_mse: 0.6750\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9417 - mae: 0.7467 - mse: 0.9417 - val_loss: 3.1557 - val_mae: 1.5596 - val_mse: 3.1557\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1611 - mae: 0.8474 - mse: 1.1611 - val_loss: 0.7704 - val_mae: 0.6856 - val_mse: 0.7704\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8941 - mae: 0.7354 - mse: 0.8941 - val_loss: 0.6673 - val_mae: 0.6486 - val_mse: 0.6673\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9976 - mae: 0.7862 - mse: 0.9976 - val_loss: 0.8411 - val_mae: 0.7099 - val_mse: 0.8411\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9507 - mae: 0.7692 - mse: 0.9507 - val_loss: 0.6655 - val_mae: 0.6476 - val_mse: 0.6655\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8551 - mae: 0.7287 - mse: 0.8551 - val_loss: 1.9826 - val_mae: 1.1858 - val_mse: 1.9826\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9552 - mae: 0.7676 - mse: 0.9552 - val_loss: 0.6985 - val_mae: 0.6513 - val_mse: 0.6985\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8985 - mae: 0.7418 - mse: 0.8985 - val_loss: 1.2741 - val_mae: 0.9245 - val_mse: 1.2741\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0208 - mae: 0.7788 - mse: 1.0208 - val_loss: 0.8850 - val_mae: 0.7591 - val_mse: 0.8850\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9241 - mae: 0.7514 - mse: 0.9241 - val_loss: 0.7838 - val_mae: 0.6822 - val_mse: 0.7838\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9276 - mae: 0.7613 - mse: 0.9276 - val_loss: 0.6841 - val_mae: 0.6507 - val_mse: 0.6841\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8023 - mae: 0.6988 - mse: 0.8023 - val_loss: 0.7079 - val_mae: 0.6724 - val_mse: 0.7079\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9311 - mae: 0.7574 - mse: 0.9311 - val_loss: 0.6720 - val_mae: 0.6482 - val_mse: 0.6720\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8351 - mae: 0.7166 - mse: 0.8351 - val_loss: 1.3496 - val_mae: 0.9355 - val_mse: 1.3496\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9391 - mae: 0.7595 - mse: 0.9391 - val_loss: 0.7500 - val_mae: 0.6931 - val_mse: 0.7500\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8160 - mae: 0.6992 - mse: 0.8160 - val_loss: 1.0730 - val_mae: 0.8167 - val_mse: 1.0730\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9088 - mae: 0.7474 - mse: 0.9088 - val_loss: 0.7959 - val_mae: 0.6955 - val_mse: 0.7959\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8334 - mae: 0.7142 - mse: 0.8334 - val_loss: 0.7276 - val_mae: 0.6770 - val_mse: 0.7276\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8719 - mae: 0.7332 - mse: 0.8719 - val_loss: 0.9892 - val_mae: 0.7740 - val_mse: 0.9892\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8843 - mae: 0.7368 - mse: 0.8843 - val_loss: 0.8739 - val_mae: 0.7521 - val_mse: 0.8739\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8927 - mae: 0.7524 - mse: 0.8927 - val_loss: 1.3406 - val_mae: 0.9262 - val_mse: 1.3406\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7485 - mae: 0.6755 - mse: 0.7485 - val_loss: 0.6619 - val_mae: 0.6383 - val_mse: 0.6619\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8997 - mae: 0.7386 - mse: 0.8997 - val_loss: 1.1051 - val_mae: 0.8496 - val_mse: 1.1051\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8368 - mae: 0.7204 - mse: 0.8368 - val_loss: 1.4830 - val_mae: 0.9935 - val_mse: 1.4830\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8112 - mae: 0.7040 - mse: 0.8112 - val_loss: 1.1773 - val_mae: 0.8684 - val_mse: 1.1773\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8757 - mae: 0.7304 - mse: 0.8757 - val_loss: 0.7088 - val_mae: 0.6695 - val_mse: 0.7088\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8072 - mae: 0.7037 - mse: 0.8072 - val_loss: 0.7441 - val_mae: 0.6638 - val_mse: 0.7441\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8139 - mae: 0.7071 - mse: 0.8139 - val_loss: 0.7908 - val_mae: 0.7102 - val_mse: 0.7908\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7760 - mae: 0.6836 - mse: 0.7760 - val_loss: 0.6814 - val_mae: 0.6411 - val_mse: 0.6814\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8556 - mae: 0.7239 - mse: 0.8556 - val_loss: 0.6854 - val_mae: 0.6407 - val_mse: 0.6854\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8461 - mae: 0.7218 - mse: 0.8461 - val_loss: 1.1115 - val_mae: 0.8337 - val_mse: 1.1115\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7491 - mae: 0.6676 - mse: 0.7491 - val_loss: 1.1020 - val_mae: 0.8434 - val_mse: 1.1020\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8345 - mae: 0.7160 - mse: 0.8345 - val_loss: 0.7669 - val_mae: 0.6727 - val_mse: 0.7669\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7828 - mae: 0.6982 - mse: 0.7828 - val_loss: 0.6536 - val_mae: 0.6351 - val_mse: 0.6536\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7234 - mae: 0.6678 - mse: 0.7234 - val_loss: 1.1694 - val_mae: 0.8749 - val_mse: 1.1694\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7911 - mae: 0.6860 - mse: 0.7911 - val_loss: 0.6976 - val_mae: 0.6465 - val_mse: 0.6976\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8196 - mae: 0.7024 - mse: 0.8196 - val_loss: 1.3092 - val_mae: 0.9179 - val_mse: 1.3092\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7209 - mae: 0.6588 - mse: 0.7209 - val_loss: 0.6982 - val_mae: 0.6477 - val_mse: 0.6982\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8416 - mae: 0.7200 - mse: 0.8416 - val_loss: 1.1896 - val_mae: 0.8640 - val_mse: 1.1896\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7328 - mae: 0.6687 - mse: 0.7328 - val_loss: 1.0263 - val_mae: 0.7884 - val_mse: 1.0263\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7704 - mae: 0.6871 - mse: 0.7704 - val_loss: 1.5781 - val_mae: 1.0389 - val_mse: 1.5781\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8070 - mae: 0.6971 - mse: 0.8070 - val_loss: 0.8234 - val_mae: 0.6976 - val_mse: 0.8234\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8185 - mae: 0.7044 - mse: 0.8185 - val_loss: 0.8646 - val_mae: 0.7116 - val_mse: 0.8646\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7130 - mae: 0.6582 - mse: 0.7130 - val_loss: 0.6811 - val_mae: 0.6546 - val_mse: 0.6811\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7724 - mae: 0.6793 - mse: 0.7724 - val_loss: 0.6904 - val_mae: 0.6515 - val_mse: 0.6904\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7281 - mae: 0.6583 - mse: 0.7281 - val_loss: 0.7684 - val_mae: 0.6706 - val_mse: 0.7684\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7153 - mae: 0.6577 - mse: 0.7153 - val_loss: 0.7819 - val_mae: 0.6777 - val_mse: 0.7819\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7344 - mae: 0.6655 - mse: 0.7344 - val_loss: 0.7136 - val_mae: 0.6736 - val_mse: 0.7136\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7535 - mae: 0.6792 - mse: 0.7535 - val_loss: 0.6704 - val_mae: 0.6378 - val_mse: 0.6704\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7306 - mae: 0.6493 - mse: 0.7306 - val_loss: 0.8039 - val_mae: 0.7054 - val_mse: 0.8039\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6606 - mae: 0.6298 - mse: 0.6606 - val_loss: 0.8840 - val_mae: 0.7267 - val_mse: 0.8840\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7686 - mae: 0.6953 - mse: 0.7686 - val_loss: 0.6910 - val_mae: 0.6442 - val_mse: 0.6910\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6726 - mae: 0.6421 - mse: 0.6726 - val_loss: 1.4498 - val_mae: 0.9822 - val_mse: 1.4498\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7220 - mae: 0.6574 - mse: 0.7220 - val_loss: 0.8457 - val_mae: 0.7387 - val_mse: 0.8457\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7198 - mae: 0.6689 - mse: 0.7198 - val_loss: 1.4118 - val_mae: 0.9785 - val_mse: 1.4118\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7480 - mae: 0.6794 - mse: 0.7480 - val_loss: 0.8438 - val_mae: 0.7064 - val_mse: 0.8438\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7197 - mae: 0.6599 - mse: 0.7197 - val_loss: 0.9197 - val_mae: 0.7645 - val_mse: 0.9197\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7202 - mae: 0.6677 - mse: 0.7202 - val_loss: 0.8803 - val_mae: 0.7163 - val_mse: 0.8803\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6542 - mae: 0.6311 - mse: 0.6542 - val_loss: 0.8572 - val_mae: 0.7087 - val_mse: 0.8572\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7034 - mae: 0.6429 - mse: 0.7034 - val_loss: 1.1836 - val_mae: 0.8817 - val_mse: 1.1836\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6737 - mae: 0.6397 - mse: 0.6737 - val_loss: 0.6926 - val_mae: 0.6520 - val_mse: 0.6926\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6807 - mae: 0.6482 - mse: 0.6807 - val_loss: 0.7095 - val_mae: 0.6468 - val_mse: 0.7095\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7269 - mae: 0.6496 - mse: 0.7269 - val_loss: 0.7883 - val_mae: 0.6760 - val_mse: 0.7883\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.6534 - mae: 0.6274 - mse: 0.6534 - val_loss: 0.7856 - val_mae: 0.6800 - val_mse: 0.7856\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6922 - mae: 0.6502 - mse: 0.6922 - val_loss: 0.7384 - val_mae: 0.6545 - val_mse: 0.7384\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.6577 - mae: 0.6314 - mse: 0.6577 - val_loss: 0.8628 - val_mae: 0.7468 - val_mse: 0.8628\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 984us/step - loss: 0.6790 - mae: 0.6472 - mse: 0.6790 - val_loss: 1.4534 - val_mae: 0.9713 - val_mse: 1.4534\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6584 - mae: 0.6240 - mse: 0.6584 - val_loss: 0.8059 - val_mae: 0.7098 - val_mse: 0.8059\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6588 - mae: 0.6181 - mse: 0.6588 - val_loss: 0.8208 - val_mae: 0.7320 - val_mse: 0.8208\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6530 - mae: 0.6295 - mse: 0.6530 - val_loss: 0.8356 - val_mae: 0.6978 - val_mse: 0.8356\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6561 - mae: 0.6297 - mse: 0.6561 - val_loss: 0.6749 - val_mae: 0.6432 - val_mse: 0.6749\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6382 - mae: 0.6123 - mse: 0.6382 - val_loss: 0.9020 - val_mae: 0.7702 - val_mse: 0.9020\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6709 - mae: 0.6374 - mse: 0.6709 - val_loss: 0.7452 - val_mae: 0.6897 - val_mse: 0.7452\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6129 - mae: 0.5991 - mse: 0.6129 - val_loss: 0.7349 - val_mae: 0.6540 - val_mse: 0.7349\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6497 - mae: 0.6214 - mse: 0.6497 - val_loss: 0.9432 - val_mae: 0.7929 - val_mse: 0.9432\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6184 - mae: 0.6077 - mse: 0.6184 - val_loss: 1.3233 - val_mae: 0.9176 - val_mse: 1.3233\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.6281 - mae: 0.6117 - mse: 0.6281 - val_loss: 0.8297 - val_mae: 0.7400 - val_mse: 0.8297\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6117 - mae: 0.5992 - mse: 0.6117 - val_loss: 1.0671 - val_mae: 0.8012 - val_mse: 1.0671\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6074 - mae: 0.6061 - mse: 0.6074 - val_loss: 0.7109 - val_mae: 0.6425 - val_mse: 0.7109\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6020 - mae: 0.6005 - mse: 0.6020 - val_loss: 0.6776 - val_mae: 0.6376 - val_mse: 0.6776\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6046 - mae: 0.6024 - mse: 0.6046 - val_loss: 1.1569 - val_mae: 0.8379 - val_mse: 1.1569\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6482 - mae: 0.6276 - mse: 0.6482 - val_loss: 0.6986 - val_mae: 0.6648 - val_mse: 0.6986\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5977 - mae: 0.5965 - mse: 0.5977 - val_loss: 0.9621 - val_mae: 0.7521 - val_mse: 0.9621\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6075 - mae: 0.6031 - mse: 0.6075 - val_loss: 0.7414 - val_mae: 0.6608 - val_mse: 0.7414\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5890 - mae: 0.5972 - mse: 0.5890 - val_loss: 0.9177 - val_mae: 0.7410 - val_mse: 0.9177\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6369 - mae: 0.6258 - mse: 0.6369 - val_loss: 0.7493 - val_mae: 0.6757 - val_mse: 0.7493\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6469 - mae: 0.6109 - mse: 0.6469 - val_loss: 0.8140 - val_mae: 0.6912 - val_mse: 0.8140\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5844 - mae: 0.5918 - mse: 0.5844 - val_loss: 1.3217 - val_mae: 0.9177 - val_mse: 1.3217\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6007 - mae: 0.5993 - mse: 0.6007 - val_loss: 0.9430 - val_mae: 0.7423 - val_mse: 0.9430\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5788 - mae: 0.5781 - mse: 0.5788 - val_loss: 0.7466 - val_mae: 0.6922 - val_mse: 0.7466\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5637 - mae: 0.5842 - mse: 0.5637 - val_loss: 0.6957 - val_mae: 0.6592 - val_mse: 0.6957\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5415 - mae: 0.5579 - mse: 0.5415 - val_loss: 0.8111 - val_mae: 0.6863 - val_mse: 0.8111\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6178 - mae: 0.6044 - mse: 0.6178 - val_loss: 0.9890 - val_mae: 0.8084 - val_mse: 0.9890\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5788 - mae: 0.5920 - mse: 0.5788 - val_loss: 1.2538 - val_mae: 0.9160 - val_mse: 1.2538\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5840 - mae: 0.5955 - mse: 0.5840 - val_loss: 1.2098 - val_mae: 0.8675 - val_mse: 1.2098\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5869 - mae: 0.5983 - mse: 0.5869 - val_loss: 0.7581 - val_mae: 0.6805 - val_mse: 0.7581\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 993us/step - loss: 0.5653 - mae: 0.5936 - mse: 0.5653 - val_loss: 0.7805 - val_mae: 0.6716 - val_mse: 0.7805\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5976 - mae: 0.5996 - mse: 0.5976 - val_loss: 0.8269 - val_mae: 0.6961 - val_mse: 0.8269\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5590 - mae: 0.5752 - mse: 0.5590 - val_loss: 0.9491 - val_mae: 0.7911 - val_mse: 0.9491\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5525 - mae: 0.5704 - mse: 0.5525 - val_loss: 0.9202 - val_mae: 0.7830 - val_mse: 0.9202\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5781 - mae: 0.5780 - mse: 0.5781 - val_loss: 0.7174 - val_mae: 0.6746 - val_mse: 0.7174\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5366 - mae: 0.5660 - mse: 0.5366 - val_loss: 0.8119 - val_mae: 0.7302 - val_mse: 0.8119\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5974 - mae: 0.5994 - mse: 0.5974 - val_loss: 0.7284 - val_mae: 0.6757 - val_mse: 0.7284\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5203 - mae: 0.5571 - mse: 0.5203 - val_loss: 1.4166 - val_mae: 0.9480 - val_mse: 1.4166\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6037 - mae: 0.6026 - mse: 0.6037 - val_loss: 1.1584 - val_mae: 0.8282 - val_mse: 1.1584\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5260 - mae: 0.5588 - mse: 0.5260 - val_loss: 1.0685 - val_mae: 0.8441 - val_mse: 1.0685\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5566 - mae: 0.5744 - mse: 0.5566 - val_loss: 0.7793 - val_mae: 0.6624 - val_mse: 0.7793\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5340 - mae: 0.5599 - mse: 0.5340 - val_loss: 0.7265 - val_mae: 0.6572 - val_mse: 0.7265\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5720 - mae: 0.5771 - mse: 0.5720 - val_loss: 0.7255 - val_mae: 0.6559 - val_mse: 0.7255\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5351 - mae: 0.5721 - mse: 0.5351 - val_loss: 1.3674 - val_mae: 0.9660 - val_mse: 1.3674\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5451 - mae: 0.5638 - mse: 0.5451 - val_loss: 0.7729 - val_mae: 0.6644 - val_mse: 0.7729\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5681 - mae: 0.5841 - mse: 0.5681 - val_loss: 0.7939 - val_mae: 0.7194 - val_mse: 0.7939\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5154 - mae: 0.5578 - mse: 0.5154 - val_loss: 0.7745 - val_mae: 0.6654 - val_mse: 0.7745\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5337 - mae: 0.5621 - mse: 0.5337 - val_loss: 1.4307 - val_mae: 0.9576 - val_mse: 1.4307\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4941 - mae: 0.5448 - mse: 0.4941 - val_loss: 0.8279 - val_mae: 0.6911 - val_mse: 0.8279\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5361 - mae: 0.5698 - mse: 0.5361 - val_loss: 0.8249 - val_mae: 0.6796 - val_mse: 0.8249\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5021 - mae: 0.5492 - mse: 0.5021 - val_loss: 0.7197 - val_mae: 0.6613 - val_mse: 0.7197\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5533 - mae: 0.5587 - mse: 0.5533 - val_loss: 0.7165 - val_mae: 0.6617 - val_mse: 0.7165\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5567 - mae: 0.5843 - mse: 0.5567 - val_loss: 0.7505 - val_mae: 0.6753 - val_mse: 0.7505\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4827 - mae: 0.5364 - mse: 0.4827 - val_loss: 0.9986 - val_mae: 0.7990 - val_mse: 0.9986\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5626 - mae: 0.5804 - mse: 0.5626 - val_loss: 0.7457 - val_mae: 0.6636 - val_mse: 0.7457\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5234 - mae: 0.5555 - mse: 0.5234 - val_loss: 0.8417 - val_mae: 0.7406 - val_mse: 0.8417\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4793 - mae: 0.5301 - mse: 0.4793 - val_loss: 0.8612 - val_mae: 0.7596 - val_mse: 0.8612\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5453 - mae: 0.5736 - mse: 0.5453 - val_loss: 0.7777 - val_mae: 0.6676 - val_mse: 0.7777\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5062 - mae: 0.5522 - mse: 0.5062 - val_loss: 0.7705 - val_mae: 0.6985 - val_mse: 0.7705\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4720 - mae: 0.5275 - mse: 0.4720 - val_loss: 0.7846 - val_mae: 0.6690 - val_mse: 0.7846\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5362 - mae: 0.5723 - mse: 0.5362 - val_loss: 1.1010 - val_mae: 0.8136 - val_mse: 1.1010\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4887 - mae: 0.5375 - mse: 0.4887 - val_loss: 0.7264 - val_mae: 0.6579 - val_mse: 0.7264\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4910 - mae: 0.5437 - mse: 0.4910 - val_loss: 1.0090 - val_mae: 0.7641 - val_mse: 1.0090\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5220 - mae: 0.5516 - mse: 0.5220 - val_loss: 0.7499 - val_mae: 0.6662 - val_mse: 0.7499\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4547 - mae: 0.5172 - mse: 0.4547 - val_loss: 1.1996 - val_mae: 0.8589 - val_mse: 1.1996\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4867 - mae: 0.5310 - mse: 0.4867 - val_loss: 1.2549 - val_mae: 0.8660 - val_mse: 1.2549\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4777 - mae: 0.5261 - mse: 0.4777 - val_loss: 0.8364 - val_mae: 0.7394 - val_mse: 0.8364\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4624 - mae: 0.5294 - mse: 0.4624 - val_loss: 0.8215 - val_mae: 0.7341 - val_mse: 0.8215\n",
      "Kappa Score: 0.7615161007894311\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 124.3057 - mae: 5.8266 - mse: 124.3057 - val_loss: 78.4993 - val_mae: 8.0766 - val_mse: 78.4993\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 40.6165 - mae: 4.8406 - mse: 40.6165 - val_loss: 64.9465 - val_mae: 7.8050 - val_mse: 64.9465\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 17.0882 - mae: 3.0671 - mse: 17.0882 - val_loss: 21.1062 - val_mae: 4.3841 - val_mse: 21.1062\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 7.9457 - mae: 2.1039 - mse: 7.9457 - val_loss: 1.3372 - val_mae: 0.9075 - val_mse: 1.3372\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 5.6920 - mae: 1.8175 - mse: 5.6920 - val_loss: 4.2049 - val_mae: 1.8567 - val_mse: 4.2049\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.8885 - mae: 1.5441 - mse: 3.8885 - val_loss: 5.8854 - val_mae: 2.2504 - val_mse: 5.8854\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 997us/step - loss: 2.8375 - mae: 1.3545 - mse: 2.8375 - val_loss: 1.1647 - val_mae: 0.8161 - val_mse: 1.1647\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6182 - mae: 1.2825 - mse: 2.6182 - val_loss: 4.3171 - val_mae: 1.8950 - val_mse: 4.3171\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4175 - mae: 1.2500 - mse: 2.4175 - val_loss: 0.9945 - val_mae: 0.7573 - val_mse: 0.9945\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0836 - mae: 1.1693 - mse: 2.0836 - val_loss: 1.1559 - val_mae: 0.8225 - val_mse: 1.1559\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0261 - mae: 1.1402 - mse: 2.0261 - val_loss: 0.8371 - val_mae: 0.7121 - val_mse: 0.8371\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9812 - mae: 1.0914 - mse: 1.9812 - val_loss: 1.5048 - val_mae: 1.0140 - val_mse: 1.5048\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8497 - mae: 1.0968 - mse: 1.8497 - val_loss: 2.0489 - val_mae: 1.2297 - val_mse: 2.0489\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7906 - mae: 1.0673 - mse: 1.7906 - val_loss: 2.5712 - val_mae: 1.3308 - val_mse: 2.5712\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5988 - mae: 1.0056 - mse: 1.5988 - val_loss: 3.5355 - val_mae: 1.6982 - val_mse: 3.5355\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5092 - mae: 0.9769 - mse: 1.5092 - val_loss: 1.8615 - val_mae: 1.0862 - val_mse: 1.8615\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4718 - mae: 0.9619 - mse: 1.4718 - val_loss: 1.0414 - val_mae: 0.8221 - val_mse: 1.0414\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5676 - mae: 0.9933 - mse: 1.5676 - val_loss: 0.9845 - val_mae: 0.7930 - val_mse: 0.9845\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4080 - mae: 0.9470 - mse: 1.4080 - val_loss: 1.5662 - val_mae: 0.9768 - val_mse: 1.5662\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2542 - mae: 0.8820 - mse: 1.2542 - val_loss: 0.6723 - val_mae: 0.6365 - val_mse: 0.6723\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3448 - mae: 0.9198 - mse: 1.3448 - val_loss: 0.8753 - val_mae: 0.7403 - val_mse: 0.8753\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2552 - mae: 0.8789 - mse: 1.2552 - val_loss: 1.1295 - val_mae: 0.8669 - val_mse: 1.1295\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3304 - mae: 0.9291 - mse: 1.3304 - val_loss: 1.0125 - val_mae: 0.8129 - val_mse: 1.0125\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2640 - mae: 0.8759 - mse: 1.2640 - val_loss: 0.8959 - val_mae: 0.7529 - val_mse: 0.8959\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2636 - mae: 0.9051 - mse: 1.2636 - val_loss: 0.8510 - val_mae: 0.7329 - val_mse: 0.8510\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1537 - mae: 0.8440 - mse: 1.1537 - val_loss: 1.1869 - val_mae: 0.8924 - val_mse: 1.1869\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2043 - mae: 0.8793 - mse: 1.2043 - val_loss: 1.1887 - val_mae: 0.8704 - val_mse: 1.1887\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.1912 - mae: 0.8580 - mse: 1.1912 - val_loss: 0.7406 - val_mae: 0.6760 - val_mse: 0.7406\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.0160 - mae: 0.7977 - mse: 1.0160 - val_loss: 0.7383 - val_mae: 0.6823 - val_mse: 0.7383\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1673 - mae: 0.8561 - mse: 1.1673 - val_loss: 1.2075 - val_mae: 0.9079 - val_mse: 1.2075\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1605 - mae: 0.8617 - mse: 1.1605 - val_loss: 0.7727 - val_mae: 0.6994 - val_mse: 0.7727\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9746 - mae: 0.7804 - mse: 0.9746 - val_loss: 0.9549 - val_mae: 0.7882 - val_mse: 0.9549\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1003 - mae: 0.8179 - mse: 1.1003 - val_loss: 2.2890 - val_mae: 1.3259 - val_mse: 2.2890\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0956 - mae: 0.8383 - mse: 1.0956 - val_loss: 0.6680 - val_mae: 0.6405 - val_mse: 0.6680\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0712 - mae: 0.8142 - mse: 1.0712 - val_loss: 1.0148 - val_mae: 0.8158 - val_mse: 1.0148\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1299 - mae: 0.8503 - mse: 1.1299 - val_loss: 0.8283 - val_mae: 0.7198 - val_mse: 0.8283\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9300 - mae: 0.7595 - mse: 0.9300 - val_loss: 0.9801 - val_mae: 0.7936 - val_mse: 0.9801\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1480 - mae: 0.8510 - mse: 1.1480 - val_loss: 1.1817 - val_mae: 0.8947 - val_mse: 1.1817\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9435 - mae: 0.7632 - mse: 0.9435 - val_loss: 1.1666 - val_mae: 0.8680 - val_mse: 1.1666\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0100 - mae: 0.8086 - mse: 1.0100 - val_loss: 0.6472 - val_mae: 0.6325 - val_mse: 0.6472\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0091 - mae: 0.7943 - mse: 1.0091 - val_loss: 0.8365 - val_mae: 0.7282 - val_mse: 0.8365\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9504 - mae: 0.7713 - mse: 0.9504 - val_loss: 0.7050 - val_mae: 0.6477 - val_mse: 0.7050\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9251 - mae: 0.7621 - mse: 0.9251 - val_loss: 0.6071 - val_mae: 0.6116 - val_mse: 0.6071\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9579 - mae: 0.7769 - mse: 0.9579 - val_loss: 0.5965 - val_mae: 0.6131 - val_mse: 0.5965\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9832 - mae: 0.7831 - mse: 0.9832 - val_loss: 0.6576 - val_mae: 0.6354 - val_mse: 0.6576\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9235 - mae: 0.7577 - mse: 0.9235 - val_loss: 1.9163 - val_mae: 1.1651 - val_mse: 1.9163\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0134 - mae: 0.7870 - mse: 1.0134 - val_loss: 0.6201 - val_mae: 0.6152 - val_mse: 0.6201\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9059 - mae: 0.7622 - mse: 0.9059 - val_loss: 0.8820 - val_mae: 0.7558 - val_mse: 0.8820\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8915 - mae: 0.7507 - mse: 0.8915 - val_loss: 0.7864 - val_mae: 0.7058 - val_mse: 0.7864\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9657 - mae: 0.7770 - mse: 0.9657 - val_loss: 0.6167 - val_mae: 0.6255 - val_mse: 0.6167\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9211 - mae: 0.7574 - mse: 0.9211 - val_loss: 0.6810 - val_mae: 0.6597 - val_mse: 0.6810\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8166 - mae: 0.7091 - mse: 0.8166 - val_loss: 0.6297 - val_mae: 0.6331 - val_mse: 0.6297\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9113 - mae: 0.7570 - mse: 0.9113 - val_loss: 0.5897 - val_mae: 0.6103 - val_mse: 0.5897\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 956us/step - loss: 0.8916 - mae: 0.7394 - mse: 0.8916 - val_loss: 0.7457 - val_mae: 0.6766 - val_mse: 0.7457\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8805 - mae: 0.7359 - mse: 0.8805 - val_loss: 0.7517 - val_mae: 0.6970 - val_mse: 0.7517\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8675 - mae: 0.7336 - mse: 0.8675 - val_loss: 0.6372 - val_mae: 0.6435 - val_mse: 0.6372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8709 - mae: 0.7365 - mse: 0.8709 - val_loss: 1.2432 - val_mae: 0.9187 - val_mse: 1.2432\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8705 - mae: 0.7368 - mse: 0.8705 - val_loss: 0.7997 - val_mae: 0.7189 - val_mse: 0.7997\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8244 - mae: 0.7079 - mse: 0.8244 - val_loss: 0.7393 - val_mae: 0.6917 - val_mse: 0.7393\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9005 - mae: 0.7384 - mse: 0.9005 - val_loss: 0.9233 - val_mae: 0.7683 - val_mse: 0.9233\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8319 - mae: 0.7235 - mse: 0.8319 - val_loss: 1.3729 - val_mae: 0.9755 - val_mse: 1.3729\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8333 - mae: 0.7276 - mse: 0.8333 - val_loss: 1.2885 - val_mae: 0.8924 - val_mse: 1.2885\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9142 - mae: 0.7567 - mse: 0.9142 - val_loss: 0.6369 - val_mae: 0.6243 - val_mse: 0.6369\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7903 - mae: 0.7032 - mse: 0.7903 - val_loss: 1.6320 - val_mae: 1.0797 - val_mse: 1.6320\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8378 - mae: 0.7227 - mse: 0.8378 - val_loss: 1.4937 - val_mae: 1.0078 - val_mse: 1.4937\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8908 - mae: 0.7404 - mse: 0.8908 - val_loss: 0.6120 - val_mae: 0.6162 - val_mse: 0.6120\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8355 - mae: 0.7271 - mse: 0.8355 - val_loss: 0.5941 - val_mae: 0.6065 - val_mse: 0.5941\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8445 - mae: 0.7267 - mse: 0.8445 - val_loss: 0.6111 - val_mae: 0.6227 - val_mse: 0.6111\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7956 - mae: 0.6964 - mse: 0.7956 - val_loss: 0.6188 - val_mae: 0.6216 - val_mse: 0.6188\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8249 - mae: 0.7143 - mse: 0.8249 - val_loss: 1.0653 - val_mae: 0.8356 - val_mse: 1.0653\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7610 - mae: 0.6941 - mse: 0.7610 - val_loss: 0.5959 - val_mae: 0.6151 - val_mse: 0.5959\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8058 - mae: 0.7054 - mse: 0.8058 - val_loss: 0.6254 - val_mae: 0.6189 - val_mse: 0.6254\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7824 - mae: 0.6908 - mse: 0.7824 - val_loss: 0.8609 - val_mae: 0.7467 - val_mse: 0.8609\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7865 - mae: 0.6993 - mse: 0.7865 - val_loss: 0.7983 - val_mae: 0.7024 - val_mse: 0.7983\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7783 - mae: 0.6918 - mse: 0.7783 - val_loss: 1.0491 - val_mae: 0.8301 - val_mse: 1.0491\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7778 - mae: 0.6880 - mse: 0.7778 - val_loss: 0.6480 - val_mae: 0.6256 - val_mse: 0.6480\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7445 - mae: 0.6789 - mse: 0.7445 - val_loss: 0.6684 - val_mae: 0.6327 - val_mse: 0.6684\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7858 - mae: 0.6931 - mse: 0.7858 - val_loss: 0.6236 - val_mae: 0.6221 - val_mse: 0.6236\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7718 - mae: 0.6830 - mse: 0.7718 - val_loss: 0.9040 - val_mae: 0.7492 - val_mse: 0.9040\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7342 - mae: 0.6774 - mse: 0.7342 - val_loss: 1.3629 - val_mae: 0.9586 - val_mse: 1.3629\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7802 - mae: 0.6903 - mse: 0.7802 - val_loss: 1.2064 - val_mae: 0.8970 - val_mse: 1.2064\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7866 - mae: 0.6928 - mse: 0.7866 - val_loss: 0.7021 - val_mae: 0.6473 - val_mse: 0.7021\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7221 - mae: 0.6687 - mse: 0.7221 - val_loss: 1.0286 - val_mae: 0.8256 - val_mse: 1.0286\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7298 - mae: 0.6755 - mse: 0.7298 - val_loss: 1.4540 - val_mae: 1.0093 - val_mse: 1.4540\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7763 - mae: 0.6892 - mse: 0.7763 - val_loss: 0.7657 - val_mae: 0.6727 - val_mse: 0.7657\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7368 - mae: 0.6794 - mse: 0.7368 - val_loss: 1.6295 - val_mae: 1.0799 - val_mse: 1.6295\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6992 - mae: 0.6473 - mse: 0.6992 - val_loss: 1.9309 - val_mae: 1.2003 - val_mse: 1.9309\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7837 - mae: 0.6985 - mse: 0.7837 - val_loss: 0.7724 - val_mae: 0.7138 - val_mse: 0.7724\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7603 - mae: 0.6879 - mse: 0.7603 - val_loss: 0.7859 - val_mae: 0.7155 - val_mse: 0.7859\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7062 - mae: 0.6593 - mse: 0.7062 - val_loss: 0.7009 - val_mae: 0.6449 - val_mse: 0.7009\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8012 - mae: 0.6985 - mse: 0.8012 - val_loss: 0.6450 - val_mae: 0.6355 - val_mse: 0.6450\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6436 - mae: 0.6310 - mse: 0.6436 - val_loss: 0.6854 - val_mae: 0.6375 - val_mse: 0.6854\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7002 - mae: 0.6540 - mse: 0.7002 - val_loss: 0.6562 - val_mae: 0.6455 - val_mse: 0.6562\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.6743 - mae: 0.6491 - mse: 0.6743 - val_loss: 0.6324 - val_mae: 0.6304 - val_mse: 0.6324\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7565 - mae: 0.6780 - mse: 0.7565 - val_loss: 0.6267 - val_mae: 0.6326 - val_mse: 0.6267\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6419 - mae: 0.6234 - mse: 0.6419 - val_loss: 0.9952 - val_mae: 0.8072 - val_mse: 0.9952\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6839 - mae: 0.6500 - mse: 0.6839 - val_loss: 0.8639 - val_mae: 0.7466 - val_mse: 0.8639\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7426 - mae: 0.6740 - mse: 0.7426 - val_loss: 0.7429 - val_mae: 0.6797 - val_mse: 0.7429\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6910 - mae: 0.6544 - mse: 0.6910 - val_loss: 1.7727 - val_mae: 1.1416 - val_mse: 1.7727\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7106 - mae: 0.6579 - mse: 0.7106 - val_loss: 0.6471 - val_mae: 0.6219 - val_mse: 0.6471\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6508 - mae: 0.6293 - mse: 0.6508 - val_loss: 0.7431 - val_mae: 0.6994 - val_mse: 0.7431\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7076 - mae: 0.6537 - mse: 0.7076 - val_loss: 0.8474 - val_mae: 0.7205 - val_mse: 0.8474\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6426 - mae: 0.6233 - mse: 0.6426 - val_loss: 0.7926 - val_mae: 0.7208 - val_mse: 0.7926\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7252 - mae: 0.6679 - mse: 0.7252 - val_loss: 0.6185 - val_mae: 0.6238 - val_mse: 0.6185\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6637 - mae: 0.6395 - mse: 0.6637 - val_loss: 0.6323 - val_mae: 0.6338 - val_mse: 0.6323\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6827 - mae: 0.6399 - mse: 0.6827 - val_loss: 1.0484 - val_mae: 0.8185 - val_mse: 1.0484\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6323 - mae: 0.6310 - mse: 0.6323 - val_loss: 0.7930 - val_mae: 0.7115 - val_mse: 0.7930\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6169 - mae: 0.6162 - mse: 0.6169 - val_loss: 0.7783 - val_mae: 0.6843 - val_mse: 0.7783\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7206 - mae: 0.6642 - mse: 0.7206 - val_loss: 0.8004 - val_mae: 0.6993 - val_mse: 0.8004\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6254 - mae: 0.6133 - mse: 0.6254 - val_loss: 0.6556 - val_mae: 0.6398 - val_mse: 0.6556\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6897 - mae: 0.6460 - mse: 0.6897 - val_loss: 1.0949 - val_mae: 0.8511 - val_mse: 1.0949\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6554 - mae: 0.6370 - mse: 0.6554 - val_loss: 0.7351 - val_mae: 0.6874 - val_mse: 0.7351\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6581 - mae: 0.6300 - mse: 0.6581 - val_loss: 0.7183 - val_mae: 0.6565 - val_mse: 0.7183\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6196 - mae: 0.6126 - mse: 0.6196 - val_loss: 0.6962 - val_mae: 0.6677 - val_mse: 0.6962\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6335 - mae: 0.6062 - mse: 0.6335 - val_loss: 0.9844 - val_mae: 0.8069 - val_mse: 0.9844\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6818 - mae: 0.6497 - mse: 0.6818 - val_loss: 1.5071 - val_mae: 1.0331 - val_mse: 1.5071\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6195 - mae: 0.6127 - mse: 0.6195 - val_loss: 0.6473 - val_mae: 0.6340 - val_mse: 0.6473\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5874 - mae: 0.6000 - mse: 0.5874 - val_loss: 0.8289 - val_mae: 0.7318 - val_mse: 0.8289\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6374 - mae: 0.6168 - mse: 0.6374 - val_loss: 0.8215 - val_mae: 0.7168 - val_mse: 0.8215\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6404 - mae: 0.6368 - mse: 0.6404 - val_loss: 1.2560 - val_mae: 0.9059 - val_mse: 1.2560\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6366 - mae: 0.6162 - mse: 0.6366 - val_loss: 1.0178 - val_mae: 0.8185 - val_mse: 1.0178\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6389 - mae: 0.6279 - mse: 0.6389 - val_loss: 1.1051 - val_mae: 0.8519 - val_mse: 1.1051\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6200 - mae: 0.6019 - mse: 0.6200 - val_loss: 0.7654 - val_mae: 0.6895 - val_mse: 0.7654\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6261 - mae: 0.6173 - mse: 0.6261 - val_loss: 0.6376 - val_mae: 0.6409 - val_mse: 0.6376\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5926 - mae: 0.6095 - mse: 0.5926 - val_loss: 0.6707 - val_mae: 0.6567 - val_mse: 0.6707\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6018 - mae: 0.6136 - mse: 0.6018 - val_loss: 0.9373 - val_mae: 0.7675 - val_mse: 0.9373\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5805 - mae: 0.5946 - mse: 0.5805 - val_loss: 1.0721 - val_mae: 0.8411 - val_mse: 1.0721\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6307 - mae: 0.6068 - mse: 0.6307 - val_loss: 0.8249 - val_mae: 0.7327 - val_mse: 0.8249\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5987 - mae: 0.6012 - mse: 0.5987 - val_loss: 0.7736 - val_mae: 0.7070 - val_mse: 0.7736\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5847 - mae: 0.5910 - mse: 0.5847 - val_loss: 0.7313 - val_mae: 0.6919 - val_mse: 0.7313\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5544 - mae: 0.5820 - mse: 0.5544 - val_loss: 0.8304 - val_mae: 0.7135 - val_mse: 0.8304\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5653 - mae: 0.5863 - mse: 0.5653 - val_loss: 0.6976 - val_mae: 0.6648 - val_mse: 0.6976\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6291 - mae: 0.6240 - mse: 0.6291 - val_loss: 0.7284 - val_mae: 0.6640 - val_mse: 0.7284\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5486 - mae: 0.5796 - mse: 0.5486 - val_loss: 1.1019 - val_mae: 0.8527 - val_mse: 1.1019\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5890 - mae: 0.6034 - mse: 0.5890 - val_loss: 0.9567 - val_mae: 0.7750 - val_mse: 0.9567\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5934 - mae: 0.6097 - mse: 0.5934 - val_loss: 0.6679 - val_mae: 0.6407 - val_mse: 0.6679\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5736 - mae: 0.5824 - mse: 0.5736 - val_loss: 0.7114 - val_mae: 0.6677 - val_mse: 0.7114\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5568 - mae: 0.5786 - mse: 0.5568 - val_loss: 0.6216 - val_mae: 0.6281 - val_mse: 0.6216\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5673 - mae: 0.5903 - mse: 0.5673 - val_loss: 0.6494 - val_mae: 0.6524 - val_mse: 0.6494\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5680 - mae: 0.5888 - mse: 0.5680 - val_loss: 0.6632 - val_mae: 0.6600 - val_mse: 0.6632\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6032 - mae: 0.6066 - mse: 0.6032 - val_loss: 0.7738 - val_mae: 0.6886 - val_mse: 0.7738\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6182 - mae: 0.6108 - mse: 0.6182 - val_loss: 0.6628 - val_mae: 0.6383 - val_mse: 0.6628\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5107 - mae: 0.5541 - mse: 0.5107 - val_loss: 0.6942 - val_mae: 0.6584 - val_mse: 0.6942\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5975 - mae: 0.6036 - mse: 0.5975 - val_loss: 0.7744 - val_mae: 0.6925 - val_mse: 0.7744\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5518 - mae: 0.5756 - mse: 0.5518 - val_loss: 1.2960 - val_mae: 0.9281 - val_mse: 1.2960\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5752 - mae: 0.5918 - mse: 0.5752 - val_loss: 0.7525 - val_mae: 0.6974 - val_mse: 0.7525\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5566 - mae: 0.5757 - mse: 0.5566 - val_loss: 0.9166 - val_mae: 0.7630 - val_mse: 0.9166\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5505 - mae: 0.5759 - mse: 0.5505 - val_loss: 0.9041 - val_mae: 0.7499 - val_mse: 0.9041\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5284 - mae: 0.5678 - mse: 0.5284 - val_loss: 0.6836 - val_mae: 0.6531 - val_mse: 0.6836\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5500 - mae: 0.5754 - mse: 0.5500 - val_loss: 0.7544 - val_mae: 0.7051 - val_mse: 0.7544\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5083 - mae: 0.5497 - mse: 0.5083 - val_loss: 0.6932 - val_mae: 0.6593 - val_mse: 0.6932\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5456 - mae: 0.5695 - mse: 0.5456 - val_loss: 0.7235 - val_mae: 0.6837 - val_mse: 0.7235\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5487 - mae: 0.5810 - mse: 0.5487 - val_loss: 0.7750 - val_mae: 0.7068 - val_mse: 0.7750\n",
      "Kappa Score: 0.7217376995227909\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 74.7241 - mae: 5.7281 - mse: 74.7241 - val_loss: 7.1523 - val_mae: 2.1348 - val_mse: 7.1523\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 18.0991 - mae: 3.2103 - mse: 18.0991 - val_loss: 3.8193 - val_mae: 1.7213 - val_mse: 3.8193\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 11.7180 - mae: 2.6165 - mse: 11.7180 - val_loss: 3.2135 - val_mae: 1.4540 - val_mse: 3.2135\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.9048 - mae: 2.0563 - mse: 6.9048 - val_loss: 2.2961 - val_mae: 1.1334 - val_mse: 2.2961\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.3975 - mae: 1.6925 - mse: 4.3975 - val_loss: 11.2834 - val_mae: 3.1897 - val_mse: 11.2834\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.2432 - mae: 1.4451 - mse: 3.2432 - val_loss: 1.9366 - val_mae: 1.1608 - val_mse: 1.9366\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6041 - mae: 1.2782 - mse: 2.6041 - val_loss: 0.9956 - val_mae: 0.7696 - val_mse: 0.9956\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1161 - mae: 1.1449 - mse: 2.1161 - val_loss: 1.7949 - val_mae: 1.0437 - val_mse: 1.7949\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1121 - mae: 1.1486 - mse: 2.1121 - val_loss: 0.9394 - val_mae: 0.7351 - val_mse: 0.9394\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8601 - mae: 1.0891 - mse: 1.8601 - val_loss: 2.4963 - val_mae: 1.1956 - val_mse: 2.4963\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7830 - mae: 1.0431 - mse: 1.7830 - val_loss: 4.4333 - val_mae: 1.7929 - val_mse: 4.4333\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7822 - mae: 1.0575 - mse: 1.7822 - val_loss: 1.5842 - val_mae: 1.0097 - val_mse: 1.5842\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5867 - mae: 0.9956 - mse: 1.5867 - val_loss: 1.7679 - val_mae: 1.1118 - val_mse: 1.7679\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5109 - mae: 0.9891 - mse: 1.5109 - val_loss: 1.5509 - val_mae: 0.9939 - val_mse: 1.5509\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4374 - mae: 0.9527 - mse: 1.4374 - val_loss: 0.7512 - val_mae: 0.6890 - val_mse: 0.7512\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4302 - mae: 0.9310 - mse: 1.4302 - val_loss: 0.7930 - val_mae: 0.6942 - val_mse: 0.7930\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2926 - mae: 0.8895 - mse: 1.2926 - val_loss: 1.2429 - val_mae: 0.8775 - val_mse: 1.2429\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4430 - mae: 0.9319 - mse: 1.4430 - val_loss: 0.7954 - val_mae: 0.6988 - val_mse: 0.7954\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2291 - mae: 0.8668 - mse: 1.2291 - val_loss: 0.7540 - val_mae: 0.6828 - val_mse: 0.7540\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3359 - mae: 0.9148 - mse: 1.3359 - val_loss: 0.7475 - val_mae: 0.6967 - val_mse: 0.7475\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1866 - mae: 0.8682 - mse: 1.1866 - val_loss: 0.7927 - val_mae: 0.7023 - val_mse: 0.7927\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2439 - mae: 0.8888 - mse: 1.2439 - val_loss: 1.0130 - val_mae: 0.8151 - val_mse: 1.0130\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1468 - mae: 0.8483 - mse: 1.1468 - val_loss: 0.7232 - val_mae: 0.6759 - val_mse: 0.7232\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1022 - mae: 0.8285 - mse: 1.1022 - val_loss: 0.7056 - val_mae: 0.6725 - val_mse: 0.7056\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2345 - mae: 0.8733 - mse: 1.2345 - val_loss: 1.4912 - val_mae: 1.0166 - val_mse: 1.4912\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0826 - mae: 0.8249 - mse: 1.0826 - val_loss: 0.8201 - val_mae: 0.7219 - val_mse: 0.8201\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0925 - mae: 0.8427 - mse: 1.0925 - val_loss: 1.0652 - val_mae: 0.8261 - val_mse: 1.0652\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1642 - mae: 0.8511 - mse: 1.1642 - val_loss: 1.1290 - val_mae: 0.8479 - val_mse: 1.1290\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0135 - mae: 0.7869 - mse: 1.0135 - val_loss: 0.9238 - val_mae: 0.7691 - val_mse: 0.9238\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0740 - mae: 0.8231 - mse: 1.0740 - val_loss: 0.8006 - val_mae: 0.7174 - val_mse: 0.8006\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0220 - mae: 0.7982 - mse: 1.0220 - val_loss: 0.7639 - val_mae: 0.6955 - val_mse: 0.7639\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0542 - mae: 0.8056 - mse: 1.0542 - val_loss: 1.1541 - val_mae: 0.8780 - val_mse: 1.1541\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0388 - mae: 0.7975 - mse: 1.0388 - val_loss: 0.6649 - val_mae: 0.6578 - val_mse: 0.6649\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9937 - mae: 0.7866 - mse: 0.9937 - val_loss: 0.7395 - val_mae: 0.6881 - val_mse: 0.7395\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0764 - mae: 0.8245 - mse: 1.0764 - val_loss: 0.6490 - val_mae: 0.6377 - val_mse: 0.6490\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8957 - mae: 0.7531 - mse: 0.8957 - val_loss: 1.2836 - val_mae: 0.9367 - val_mse: 1.2836\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0049 - mae: 0.7920 - mse: 1.0049 - val_loss: 1.9362 - val_mae: 1.1752 - val_mse: 1.9362\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9871 - mae: 0.7754 - mse: 0.9871 - val_loss: 1.0333 - val_mae: 0.8066 - val_mse: 1.0333\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9790 - mae: 0.7793 - mse: 0.9790 - val_loss: 0.8744 - val_mae: 0.7542 - val_mse: 0.8744\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8969 - mae: 0.7479 - mse: 0.8969 - val_loss: 1.0058 - val_mae: 0.7843 - val_mse: 1.0058\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9718 - mae: 0.7708 - mse: 0.9718 - val_loss: 0.7050 - val_mae: 0.6770 - val_mse: 0.7050\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9563 - mae: 0.7699 - mse: 0.9563 - val_loss: 0.6826 - val_mae: 0.6599 - val_mse: 0.6826\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9640 - mae: 0.7672 - mse: 0.9640 - val_loss: 0.7466 - val_mae: 0.6893 - val_mse: 0.7466\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8863 - mae: 0.7320 - mse: 0.8863 - val_loss: 0.6548 - val_mae: 0.6472 - val_mse: 0.6548\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9538 - mae: 0.7607 - mse: 0.9538 - val_loss: 0.6889 - val_mae: 0.6719 - val_mse: 0.6889\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8630 - mae: 0.7252 - mse: 0.8630 - val_loss: 0.9987 - val_mae: 0.7989 - val_mse: 0.9987\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9580 - mae: 0.7764 - mse: 0.9580 - val_loss: 1.5302 - val_mae: 1.0298 - val_mse: 1.5302\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8641 - mae: 0.7269 - mse: 0.8641 - val_loss: 0.9392 - val_mae: 0.7686 - val_mse: 0.9392\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8805 - mae: 0.7366 - mse: 0.8805 - val_loss: 0.7305 - val_mae: 0.6858 - val_mse: 0.7305\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9298 - mae: 0.7606 - mse: 0.9298 - val_loss: 0.6995 - val_mae: 0.6731 - val_mse: 0.6995\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9102 - mae: 0.7403 - mse: 0.9102 - val_loss: 0.6722 - val_mae: 0.6416 - val_mse: 0.6722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7907 - mae: 0.7024 - mse: 0.7907 - val_loss: 0.8556 - val_mae: 0.7187 - val_mse: 0.8556\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8456 - mae: 0.7164 - mse: 0.8456 - val_loss: 0.9392 - val_mae: 0.7643 - val_mse: 0.9392\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8753 - mae: 0.7342 - mse: 0.8753 - val_loss: 0.9438 - val_mae: 0.7686 - val_mse: 0.9438\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8184 - mae: 0.7140 - mse: 0.8184 - val_loss: 0.7180 - val_mae: 0.6792 - val_mse: 0.7180\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7739 - mae: 0.6978 - mse: 0.7739 - val_loss: 0.8689 - val_mae: 0.7441 - val_mse: 0.8689\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8942 - mae: 0.7397 - mse: 0.8942 - val_loss: 1.0205 - val_mae: 0.8260 - val_mse: 1.0205\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7915 - mae: 0.6925 - mse: 0.7915 - val_loss: 0.8882 - val_mae: 0.7385 - val_mse: 0.8882\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9812 - mae: 0.7754 - mse: 0.9812 - val_loss: 0.7269 - val_mae: 0.6837 - val_mse: 0.7269\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7721 - mae: 0.6855 - mse: 0.7721 - val_loss: 0.9724 - val_mae: 0.7931 - val_mse: 0.9724\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8119 - mae: 0.7009 - mse: 0.8119 - val_loss: 0.6707 - val_mae: 0.6621 - val_mse: 0.6707\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7982 - mae: 0.6991 - mse: 0.7982 - val_loss: 1.1684 - val_mae: 0.8851 - val_mse: 1.1684\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8654 - mae: 0.7356 - mse: 0.8654 - val_loss: 0.6364 - val_mae: 0.6246 - val_mse: 0.6364\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7555 - mae: 0.6842 - mse: 0.7555 - val_loss: 0.6799 - val_mae: 0.6639 - val_mse: 0.6799\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7920 - mae: 0.6934 - mse: 0.7920 - val_loss: 0.7696 - val_mae: 0.6965 - val_mse: 0.7696\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8496 - mae: 0.7212 - mse: 0.8496 - val_loss: 0.6426 - val_mae: 0.6385 - val_mse: 0.6426\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7424 - mae: 0.6790 - mse: 0.7424 - val_loss: 0.6291 - val_mae: 0.6257 - val_mse: 0.6291\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8108 - mae: 0.6959 - mse: 0.8108 - val_loss: 0.7468 - val_mae: 0.6898 - val_mse: 0.7468\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7786 - mae: 0.6906 - mse: 0.7786 - val_loss: 0.6134 - val_mae: 0.6083 - val_mse: 0.6134\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7745 - mae: 0.6829 - mse: 0.7745 - val_loss: 0.7453 - val_mae: 0.7057 - val_mse: 0.7453\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7211 - mae: 0.6653 - mse: 0.7211 - val_loss: 0.7765 - val_mae: 0.6839 - val_mse: 0.7765\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7650 - mae: 0.6910 - mse: 0.7650 - val_loss: 1.0630 - val_mae: 0.8028 - val_mse: 1.0630\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7940 - mae: 0.6862 - mse: 0.7940 - val_loss: 0.6716 - val_mae: 0.6449 - val_mse: 0.6716\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6996 - mae: 0.6571 - mse: 0.6996 - val_loss: 1.1683 - val_mae: 0.8809 - val_mse: 1.1683\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8023 - mae: 0.6907 - mse: 0.8023 - val_loss: 0.8198 - val_mae: 0.7265 - val_mse: 0.8198\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8030 - mae: 0.7004 - mse: 0.8030 - val_loss: 0.6811 - val_mae: 0.6402 - val_mse: 0.6811\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7567 - mae: 0.6805 - mse: 0.7567 - val_loss: 0.7273 - val_mae: 0.6552 - val_mse: 0.7273\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7232 - mae: 0.6640 - mse: 0.7232 - val_loss: 1.0552 - val_mae: 0.8122 - val_mse: 1.0552\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7252 - mae: 0.6712 - mse: 0.7252 - val_loss: 0.6959 - val_mae: 0.6402 - val_mse: 0.6959\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7416 - mae: 0.6702 - mse: 0.7416 - val_loss: 0.6902 - val_mae: 0.6651 - val_mse: 0.6902\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7666 - mae: 0.6776 - mse: 0.7666 - val_loss: 0.8108 - val_mae: 0.7013 - val_mse: 0.8108\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7689 - mae: 0.6861 - mse: 0.7689 - val_loss: 0.6867 - val_mae: 0.6701 - val_mse: 0.6867\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7132 - mae: 0.6567 - mse: 0.7132 - val_loss: 0.7765 - val_mae: 0.6844 - val_mse: 0.7765\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7412 - mae: 0.6719 - mse: 0.7412 - val_loss: 0.6759 - val_mae: 0.6567 - val_mse: 0.6759\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7031 - mae: 0.6522 - mse: 0.7031 - val_loss: 1.0738 - val_mae: 0.8247 - val_mse: 1.0738\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7307 - mae: 0.6575 - mse: 0.7307 - val_loss: 0.7097 - val_mae: 0.6759 - val_mse: 0.7097\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7638 - mae: 0.6808 - mse: 0.7638 - val_loss: 0.8884 - val_mae: 0.7185 - val_mse: 0.8884\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7390 - mae: 0.6697 - mse: 0.7390 - val_loss: 0.8774 - val_mae: 0.7413 - val_mse: 0.8774\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6968 - mae: 0.6424 - mse: 0.6968 - val_loss: 0.8677 - val_mae: 0.7316 - val_mse: 0.8677\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6956 - mae: 0.6488 - mse: 0.6956 - val_loss: 0.6222 - val_mae: 0.6204 - val_mse: 0.6222\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7567 - mae: 0.6709 - mse: 0.7567 - val_loss: 1.0747 - val_mae: 0.8166 - val_mse: 1.0747\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6877 - mae: 0.6487 - mse: 0.6877 - val_loss: 0.9167 - val_mae: 0.7450 - val_mse: 0.9167\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6793 - mae: 0.6434 - mse: 0.6793 - val_loss: 0.6331 - val_mae: 0.6245 - val_mse: 0.6331\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6594 - mae: 0.6331 - mse: 0.6594 - val_loss: 0.9470 - val_mae: 0.7761 - val_mse: 0.9470\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7088 - mae: 0.6456 - mse: 0.7088 - val_loss: 0.8582 - val_mae: 0.7128 - val_mse: 0.8582\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7023 - mae: 0.6508 - mse: 0.7023 - val_loss: 0.7532 - val_mae: 0.6968 - val_mse: 0.7532\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6952 - mae: 0.6482 - mse: 0.6952 - val_loss: 0.6686 - val_mae: 0.6339 - val_mse: 0.6686\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6567 - mae: 0.6266 - mse: 0.6567 - val_loss: 0.9278 - val_mae: 0.7939 - val_mse: 0.9278\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6728 - mae: 0.6364 - mse: 0.6728 - val_loss: 0.6781 - val_mae: 0.6377 - val_mse: 0.6781\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6873 - mae: 0.6402 - mse: 0.6873 - val_loss: 0.7727 - val_mae: 0.7039 - val_mse: 0.7727\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6981 - mae: 0.6568 - mse: 0.6981 - val_loss: 0.8711 - val_mae: 0.7124 - val_mse: 0.8711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6731 - mae: 0.6338 - mse: 0.6731 - val_loss: 1.0495 - val_mae: 0.8104 - val_mse: 1.0495\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6826 - mae: 0.6335 - mse: 0.6826 - val_loss: 1.3320 - val_mae: 0.9713 - val_mse: 1.3320\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6605 - mae: 0.6256 - mse: 0.6605 - val_loss: 0.6610 - val_mae: 0.6423 - val_mse: 0.6610\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6603 - mae: 0.6309 - mse: 0.6603 - val_loss: 0.7298 - val_mae: 0.6588 - val_mse: 0.7298\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6412 - mae: 0.6088 - mse: 0.6412 - val_loss: 1.1751 - val_mae: 0.8921 - val_mse: 1.1751\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6776 - mae: 0.6419 - mse: 0.6776 - val_loss: 0.6700 - val_mae: 0.6556 - val_mse: 0.6700\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6188 - mae: 0.6005 - mse: 0.6188 - val_loss: 0.9676 - val_mae: 0.8033 - val_mse: 0.9676\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6754 - mae: 0.6381 - mse: 0.6754 - val_loss: 0.6639 - val_mae: 0.6423 - val_mse: 0.6639\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6342 - mae: 0.6129 - mse: 0.6342 - val_loss: 1.5881 - val_mae: 1.0471 - val_mse: 1.5881\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6888 - mae: 0.6501 - mse: 0.6888 - val_loss: 0.6276 - val_mae: 0.6238 - val_mse: 0.6276\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6694 - mae: 0.6442 - mse: 0.6694 - val_loss: 0.6706 - val_mae: 0.6463 - val_mse: 0.6706\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6425 - mae: 0.6183 - mse: 0.6425 - val_loss: 0.7328 - val_mae: 0.6835 - val_mse: 0.7328\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6089 - mae: 0.5939 - mse: 0.6089 - val_loss: 0.6687 - val_mae: 0.6409 - val_mse: 0.6687\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6494 - mae: 0.6287 - mse: 0.6494 - val_loss: 0.7190 - val_mae: 0.6462 - val_mse: 0.7190\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6178 - mae: 0.5993 - mse: 0.6178 - val_loss: 0.6642 - val_mae: 0.6457 - val_mse: 0.6642\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6483 - mae: 0.6174 - mse: 0.6483 - val_loss: 0.9542 - val_mae: 0.7769 - val_mse: 0.9542\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6490 - mae: 0.6252 - mse: 0.6490 - val_loss: 0.9583 - val_mae: 0.7550 - val_mse: 0.9583\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6736 - mae: 0.6375 - mse: 0.6736 - val_loss: 0.6922 - val_mae: 0.6670 - val_mse: 0.6922\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6228 - mae: 0.6080 - mse: 0.6228 - val_loss: 0.6992 - val_mae: 0.6524 - val_mse: 0.6992\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6507 - mae: 0.6222 - mse: 0.6507 - val_loss: 0.6946 - val_mae: 0.6644 - val_mse: 0.6946\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6228 - mae: 0.6048 - mse: 0.6228 - val_loss: 0.7907 - val_mae: 0.7175 - val_mse: 0.7907\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5975 - mae: 0.5955 - mse: 0.5975 - val_loss: 0.6782 - val_mae: 0.6490 - val_mse: 0.6782\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6913 - mae: 0.6363 - mse: 0.6913 - val_loss: 0.6715 - val_mae: 0.6449 - val_mse: 0.6715\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6410 - mae: 0.6161 - mse: 0.6410 - val_loss: 0.8339 - val_mae: 0.7229 - val_mse: 0.8339\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5961 - mae: 0.5916 - mse: 0.5961 - val_loss: 0.6866 - val_mae: 0.6461 - val_mse: 0.6866\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6710 - mae: 0.6333 - mse: 0.6710 - val_loss: 0.7476 - val_mae: 0.6823 - val_mse: 0.7476\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5970 - mae: 0.5964 - mse: 0.5970 - val_loss: 0.6990 - val_mae: 0.6709 - val_mse: 0.6990\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6175 - mae: 0.6150 - mse: 0.6175 - val_loss: 0.8764 - val_mae: 0.7459 - val_mse: 0.8764\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6263 - mae: 0.6116 - mse: 0.6263 - val_loss: 0.6796 - val_mae: 0.6350 - val_mse: 0.6796\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6417 - mae: 0.6242 - mse: 0.6417 - val_loss: 0.6910 - val_mae: 0.6507 - val_mse: 0.6910\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5910 - mae: 0.5848 - mse: 0.5910 - val_loss: 0.6895 - val_mae: 0.6598 - val_mse: 0.6895\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6488 - mae: 0.6176 - mse: 0.6488 - val_loss: 0.7122 - val_mae: 0.6646 - val_mse: 0.7122\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6302 - mae: 0.6110 - mse: 0.6302 - val_loss: 0.8701 - val_mae: 0.7298 - val_mse: 0.8701\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5613 - mae: 0.5713 - mse: 0.5613 - val_loss: 0.8026 - val_mae: 0.7018 - val_mse: 0.8026\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6117 - mae: 0.6076 - mse: 0.6117 - val_loss: 0.6760 - val_mae: 0.6407 - val_mse: 0.6760\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6399 - mae: 0.6067 - mse: 0.6399 - val_loss: 0.9173 - val_mae: 0.7411 - val_mse: 0.9173\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6304 - mae: 0.6129 - mse: 0.6304 - val_loss: 0.7145 - val_mae: 0.6541 - val_mse: 0.7145\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5389 - mae: 0.5685 - mse: 0.5389 - val_loss: 1.5640 - val_mae: 1.0211 - val_mse: 1.5640\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6015 - mae: 0.6007 - mse: 0.6015 - val_loss: 0.8817 - val_mae: 0.7569 - val_mse: 0.8817\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6072 - mae: 0.6002 - mse: 0.6072 - val_loss: 0.7387 - val_mae: 0.6795 - val_mse: 0.7387\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5944 - mae: 0.5995 - mse: 0.5944 - val_loss: 1.1839 - val_mae: 0.8591 - val_mse: 1.1839\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6113 - mae: 0.6012 - mse: 0.6113 - val_loss: 1.1993 - val_mae: 0.8721 - val_mse: 1.1993\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6120 - mae: 0.6071 - mse: 0.6120 - val_loss: 0.7037 - val_mae: 0.6601 - val_mse: 0.7037\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5833 - mae: 0.5933 - mse: 0.5833 - val_loss: 0.7373 - val_mae: 0.6650 - val_mse: 0.7373\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5730 - mae: 0.5855 - mse: 0.5730 - val_loss: 0.8511 - val_mae: 0.7407 - val_mse: 0.8511\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5707 - mae: 0.5791 - mse: 0.5707 - val_loss: 0.9308 - val_mae: 0.7809 - val_mse: 0.9308\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5864 - mae: 0.5947 - mse: 0.5864 - val_loss: 0.7229 - val_mae: 0.6737 - val_mse: 0.7229\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5589 - mae: 0.5782 - mse: 0.5589 - val_loss: 0.7092 - val_mae: 0.6654 - val_mse: 0.7092\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6014 - mae: 0.5932 - mse: 0.6014 - val_loss: 0.8137 - val_mae: 0.6993 - val_mse: 0.8137\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5478 - mae: 0.5640 - mse: 0.5478 - val_loss: 0.8051 - val_mae: 0.6991 - val_mse: 0.8051\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5815 - mae: 0.5849 - mse: 0.5815 - val_loss: 0.8551 - val_mae: 0.7501 - val_mse: 0.8551\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5506 - mae: 0.5600 - mse: 0.5506 - val_loss: 0.7415 - val_mae: 0.6666 - val_mse: 0.7415\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5545 - mae: 0.5705 - mse: 0.5545 - val_loss: 0.6783 - val_mae: 0.6562 - val_mse: 0.6783\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5896 - mae: 0.5851 - mse: 0.5896 - val_loss: 1.4274 - val_mae: 0.9741 - val_mse: 1.4274\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5623 - mae: 0.5751 - mse: 0.5623 - val_loss: 1.5755 - val_mae: 1.0375 - val_mse: 1.5755\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5877 - mae: 0.5844 - mse: 0.5877 - val_loss: 0.8460 - val_mae: 0.7077 - val_mse: 0.8460\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5576 - mae: 0.5664 - mse: 0.5576 - val_loss: 0.7003 - val_mae: 0.6521 - val_mse: 0.7003\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5746 - mae: 0.5963 - mse: 0.5746 - val_loss: 0.6770 - val_mae: 0.6474 - val_mse: 0.6770\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5217 - mae: 0.5488 - mse: 0.5217 - val_loss: 1.1663 - val_mae: 0.8572 - val_mse: 1.1663\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5603 - mae: 0.5703 - mse: 0.5603 - val_loss: 0.8328 - val_mae: 0.7044 - val_mse: 0.8328\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5808 - mae: 0.5860 - mse: 0.5808 - val_loss: 0.7499 - val_mae: 0.6798 - val_mse: 0.7499\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5615 - mae: 0.5793 - mse: 0.5615 - val_loss: 0.7025 - val_mae: 0.6608 - val_mse: 0.7025\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5245 - mae: 0.5677 - mse: 0.5245 - val_loss: 1.2120 - val_mae: 0.8597 - val_mse: 1.2120\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5512 - mae: 0.5773 - mse: 0.5512 - val_loss: 0.7116 - val_mae: 0.6688 - val_mse: 0.7116\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5762 - mae: 0.5685 - mse: 0.5762 - val_loss: 1.0342 - val_mae: 0.7932 - val_mse: 1.0342\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5157 - mae: 0.5536 - mse: 0.5157 - val_loss: 0.9715 - val_mae: 0.7993 - val_mse: 0.9715\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5506 - mae: 0.5747 - mse: 0.5506 - val_loss: 0.7133 - val_mae: 0.6562 - val_mse: 0.7133\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5127 - mae: 0.5471 - mse: 0.5127 - val_loss: 0.8328 - val_mae: 0.7113 - val_mse: 0.8328\n",
      "Kappa Score: 0.7668058626054205\n",
      "\n",
      "###########Set-2###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 170.5875 - mae: 6.5712 - mse: 170.5875 - val_loss: 26.2591 - val_mae: 3.6302 - val_mse: 26.2591\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 46.7153 - mae: 5.0268 - mse: 46.7153 - val_loss: 48.5139 - val_mae: 5.9985 - val_mse: 48.5139\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 20.8968 - mae: 3.8777 - mse: 20.8968 - val_loss: 44.8687 - val_mae: 5.4518 - val_mse: 44.8687\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 11.6074 - mae: 2.8849 - mse: 11.6074 - val_loss: 11.6451 - val_mae: 2.2788 - val_mse: 11.6451\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 6.9753 - mae: 1.9329 - mse: 6.9753 - val_loss: 6.1870 - val_mae: 2.2399 - val_mse: 6.1870\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 4.4543 - mae: 1.6835 - mse: 4.4543 - val_loss: 5.7516 - val_mae: 2.1258 - val_mse: 5.7516\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 4.3205 - mae: 1.6247 - mse: 4.3205 - val_loss: 9.3059 - val_mae: 2.8433 - val_mse: 9.3059\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.8074 - mae: 1.5491 - mse: 3.8074 - val_loss: 7.4294 - val_mae: 1.5826 - val_mse: 7.4294\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7597 - mae: 1.3318 - mse: 2.7597 - val_loss: 6.6547 - val_mae: 1.7921 - val_mse: 6.6547\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4809 - mae: 1.2226 - mse: 2.4809 - val_loss: 3.6459 - val_mae: 1.4795 - val_mse: 3.6459\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 2.1976 - mae: 1.1519 - mse: 2.1976 - val_loss: 5.2832 - val_mae: 1.6476 - val_mse: 5.2832\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0359 - mae: 1.1356 - mse: 2.0359 - val_loss: 3.7830 - val_mae: 1.1067 - val_mse: 3.7830\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8284 - mae: 1.0746 - mse: 1.8284 - val_loss: 2.5652 - val_mae: 0.9871 - val_mse: 2.5652\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8687 - mae: 1.0787 - mse: 1.8687 - val_loss: 4.8121 - val_mae: 1.3543 - val_mse: 4.8121\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9678 - mae: 1.1074 - mse: 1.9678 - val_loss: 2.8932 - val_mae: 1.2158 - val_mse: 2.8932\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7340 - mae: 1.0417 - mse: 1.7340 - val_loss: 5.5595 - val_mae: 1.1779 - val_mse: 5.5595\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9200 - mae: 1.0875 - mse: 1.9200 - val_loss: 2.8495 - val_mae: 1.0246 - val_mse: 2.8495\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6508 - mae: 0.9956 - mse: 1.6508 - val_loss: 3.2519 - val_mae: 1.0926 - val_mse: 3.2519\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7247 - mae: 1.0186 - mse: 1.7247 - val_loss: 5.0724 - val_mae: 1.1702 - val_mse: 5.0724\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6975 - mae: 1.0297 - mse: 1.6975 - val_loss: 3.1061 - val_mae: 1.0966 - val_mse: 3.1061\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5395 - mae: 0.9765 - mse: 1.5395 - val_loss: 6.6511 - val_mae: 1.3209 - val_mse: 6.6511\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5659 - mae: 0.9798 - mse: 1.5659 - val_loss: 2.5936 - val_mae: 1.0420 - val_mse: 2.5936\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6267 - mae: 0.9926 - mse: 1.6267 - val_loss: 5.0271 - val_mae: 1.0585 - val_mse: 5.0271\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4839 - mae: 0.9505 - mse: 1.4839 - val_loss: 3.6415 - val_mae: 1.2055 - val_mse: 3.6415\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.4763 - mae: 0.9501 - mse: 1.4763 - val_loss: 3.7027 - val_mae: 1.3520 - val_mse: 3.7027\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.5129 - mae: 0.9714 - mse: 1.5129 - val_loss: 3.5777 - val_mae: 1.1291 - val_mse: 3.5777\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.3900 - mae: 0.9276 - mse: 1.3900 - val_loss: 4.1955 - val_mae: 1.0623 - val_mse: 4.1955\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.4326 - mae: 0.9426 - mse: 1.4326 - val_loss: 2.5354 - val_mae: 1.0551 - val_mse: 2.5354\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.5990 - mae: 0.9852 - mse: 1.5990 - val_loss: 3.5020 - val_mae: 1.0603 - val_mse: 3.5020\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.3604 - mae: 0.9314 - mse: 1.3604 - val_loss: 2.7257 - val_mae: 1.0234 - val_mse: 2.7257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3692 - mae: 0.9131 - mse: 1.3692 - val_loss: 4.1621 - val_mae: 1.0538 - val_mse: 4.1621\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3434 - mae: 0.9094 - mse: 1.3434 - val_loss: 2.5374 - val_mae: 1.0030 - val_mse: 2.5374\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.3971 - mae: 0.9300 - mse: 1.3971 - val_loss: 4.5184 - val_mae: 1.0695 - val_mse: 4.5184\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.4417 - mae: 0.9523 - mse: 1.4417 - val_loss: 3.1583 - val_mae: 1.0137 - val_mse: 3.1583\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.2644 - mae: 0.8734 - mse: 1.2644 - val_loss: 5.3976 - val_mae: 1.0669 - val_mse: 5.3976\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.4174 - mae: 0.9345 - mse: 1.4174 - val_loss: 3.0231 - val_mae: 1.0662 - val_mse: 3.0231\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.2956 - mae: 0.8873 - mse: 1.2956 - val_loss: 3.3988 - val_mae: 1.2061 - val_mse: 3.3988\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.2762 - mae: 0.8807 - mse: 1.2762 - val_loss: 5.7423 - val_mae: 1.0774 - val_mse: 5.7423\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.2788 - mae: 0.8865 - mse: 1.2788 - val_loss: 3.4039 - val_mae: 1.1125 - val_mse: 3.4039\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.3295 - mae: 0.9032 - mse: 1.3295 - val_loss: 3.4774 - val_mae: 1.1323 - val_mse: 3.4774\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.2098 - mae: 0.8545 - mse: 1.2098 - val_loss: 2.6118 - val_mae: 0.9711 - val_mse: 2.6118\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.3484 - mae: 0.8983 - mse: 1.3484 - val_loss: 2.4763 - val_mae: 0.9795 - val_mse: 2.4763\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1.2050 - mae: 0.8503 - mse: 1.2050 - val_loss: 3.1495 - val_mae: 1.0107 - val_mse: 3.1495\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1.3526 - mae: 0.8977 - mse: 1.3526 - val_loss: 2.5414 - val_mae: 0.9636 - val_mse: 2.5414\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.2073 - mae: 0.8564 - mse: 1.2073 - val_loss: 3.5659 - val_mae: 1.0793 - val_mse: 3.5659\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1.2147 - mae: 0.8656 - mse: 1.2147 - val_loss: 3.1703 - val_mae: 1.1055 - val_mse: 3.1703\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 969us/step - loss: 1.2398 - mae: 0.8710 - mse: 1.2398 - val_loss: 3.2135 - val_mae: 1.0675 - val_mse: 3.2135\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.2014 - mae: 0.8465 - mse: 1.2014 - val_loss: 3.3408 - val_mae: 1.1495 - val_mse: 3.3408\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1.2076 - mae: 0.8562 - mse: 1.2076 - val_loss: 3.0462 - val_mae: 1.0239 - val_mse: 3.0462\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.1593 - mae: 0.8362 - mse: 1.1593 - val_loss: 3.5212 - val_mae: 1.0131 - val_mse: 3.5212\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.1407 - mae: 0.8350 - mse: 1.1407 - val_loss: 2.4941 - val_mae: 0.9836 - val_mse: 2.4941\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.1430 - mae: 0.8310 - mse: 1.1430 - val_loss: 3.0180 - val_mae: 1.1980 - val_mse: 3.0180\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.1270 - mae: 0.8287 - mse: 1.1270 - val_loss: 3.4437 - val_mae: 1.0579 - val_mse: 3.4437\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.1576 - mae: 0.8321 - mse: 1.1576 - val_loss: 2.5384 - val_mae: 0.9878 - val_mse: 2.5384\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.1702 - mae: 0.8428 - mse: 1.1702 - val_loss: 2.9874 - val_mae: 1.0005 - val_mse: 2.9874\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.1923 - mae: 0.8325 - mse: 1.1923 - val_loss: 2.6218 - val_mae: 0.9791 - val_mse: 2.6218\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.1537 - mae: 0.8286 - mse: 1.1537 - val_loss: 3.7108 - val_mae: 1.4736 - val_mse: 3.7108\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1.1253 - mae: 0.8221 - mse: 1.1253 - val_loss: 3.5365 - val_mae: 1.2501 - val_mse: 3.5365\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 971us/step - loss: 1.0917 - mae: 0.8186 - mse: 1.0917 - val_loss: 3.6855 - val_mae: 1.0719 - val_mse: 3.6855\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.1031 - mae: 0.8199 - mse: 1.1031 - val_loss: 2.4413 - val_mae: 0.9831 - val_mse: 2.4413\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1.0435 - mae: 0.7860 - mse: 1.0435 - val_loss: 3.9687 - val_mae: 1.1330 - val_mse: 3.9687\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 1.1362 - mae: 0.8220 - mse: 1.1362 - val_loss: 2.7075 - val_mae: 1.0075 - val_mse: 2.7075\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.0983 - mae: 0.8094 - mse: 1.0983 - val_loss: 3.6437 - val_mae: 1.0788 - val_mse: 3.6437\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0969 - mae: 0.8218 - mse: 1.0969 - val_loss: 2.7576 - val_mae: 1.0078 - val_mse: 2.7576\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.1508 - mae: 0.8296 - mse: 1.1508 - val_loss: 3.0635 - val_mae: 0.9982 - val_mse: 3.0635\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.1287 - mae: 0.8115 - mse: 1.1287 - val_loss: 2.7577 - val_mae: 0.9869 - val_mse: 2.7577\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.0736 - mae: 0.8143 - mse: 1.0736 - val_loss: 4.0274 - val_mae: 1.2068 - val_mse: 4.0274\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 961us/step - loss: 1.0250 - mae: 0.7820 - mse: 1.0250 - val_loss: 3.2865 - val_mae: 1.0841 - val_mse: 3.2865\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.0504 - mae: 0.8052 - mse: 1.0504 - val_loss: 3.0538 - val_mae: 1.0821 - val_mse: 3.0538\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.0787 - mae: 0.8168 - mse: 1.0787 - val_loss: 3.4291 - val_mae: 1.0962 - val_mse: 3.4291\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 989us/step - loss: 1.0310 - mae: 0.7828 - mse: 1.0310 - val_loss: 2.4971 - val_mae: 0.9777 - val_mse: 2.4971\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 969us/step - loss: 1.1329 - mae: 0.8305 - mse: 1.1329 - val_loss: 3.4178 - val_mae: 1.0767 - val_mse: 3.4178\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.9986 - mae: 0.7763 - mse: 0.9986 - val_loss: 2.7632 - val_mae: 1.0785 - val_mse: 2.7632\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.0426 - mae: 0.7968 - mse: 1.0426 - val_loss: 3.1128 - val_mae: 1.0945 - val_mse: 3.1128\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9297 - mae: 0.7490 - mse: 0.9297 - val_loss: 2.7000 - val_mae: 0.9937 - val_mse: 2.7000\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 986us/step - loss: 1.0719 - mae: 0.7989 - mse: 1.0719 - val_loss: 3.1549 - val_mae: 1.0284 - val_mse: 3.1549\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0422 - mae: 0.7881 - mse: 1.0422 - val_loss: 2.8900 - val_mae: 1.1468 - val_mse: 2.8900\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.0267 - mae: 0.7920 - mse: 1.0267 - val_loss: 2.6325 - val_mae: 1.0008 - val_mse: 2.6325\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.0060 - mae: 0.7800 - mse: 1.0060 - val_loss: 2.9503 - val_mae: 1.0759 - val_mse: 2.9503\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0077 - mae: 0.7764 - mse: 1.0077 - val_loss: 2.7941 - val_mae: 1.0045 - val_mse: 2.7941\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9238 - mae: 0.7448 - mse: 0.9238 - val_loss: 3.7439 - val_mae: 1.2247 - val_mse: 3.7439\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.0404 - mae: 0.8002 - mse: 1.0404 - val_loss: 3.1359 - val_mae: 1.1670 - val_mse: 3.1359\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.0081 - mae: 0.7732 - mse: 1.0081 - val_loss: 2.5425 - val_mae: 1.0029 - val_mse: 2.5425\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9747 - mae: 0.7597 - mse: 0.9747 - val_loss: 3.0241 - val_mae: 1.0047 - val_mse: 3.0241\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 960us/step - loss: 0.9370 - mae: 0.7412 - mse: 0.9370 - val_loss: 3.2800 - val_mae: 1.1094 - val_mse: 3.2800\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9804 - mae: 0.7644 - mse: 0.9804 - val_loss: 2.6077 - val_mae: 0.9828 - val_mse: 2.6077\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 1.0054 - mae: 0.7791 - mse: 1.0054 - val_loss: 3.3480 - val_mae: 1.0555 - val_mse: 3.3480\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9376 - mae: 0.7445 - mse: 0.9376 - val_loss: 2.8555 - val_mae: 1.0030 - val_mse: 2.8555\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.9641 - mae: 0.7611 - mse: 0.9641 - val_loss: 3.2786 - val_mae: 1.0100 - val_mse: 3.2786\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9668 - mae: 0.7552 - mse: 0.9668 - val_loss: 2.8295 - val_mae: 1.0049 - val_mse: 2.8295\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9979 - mae: 0.7704 - mse: 0.9979 - val_loss: 3.3545 - val_mae: 1.1477 - val_mse: 3.3545\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9083 - mae: 0.7381 - mse: 0.9083 - val_loss: 4.0182 - val_mae: 1.3555 - val_mse: 4.0182\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 1.0520 - mae: 0.8062 - mse: 1.0520 - val_loss: 3.1183 - val_mae: 1.0136 - val_mse: 3.1183\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9311 - mae: 0.7485 - mse: 0.9311 - val_loss: 3.5654 - val_mae: 1.2223 - val_mse: 3.5654\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9436 - mae: 0.7519 - mse: 0.9436 - val_loss: 2.8388 - val_mae: 1.0609 - val_mse: 2.8388\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9365 - mae: 0.7473 - mse: 0.9365 - val_loss: 3.3209 - val_mae: 1.1233 - val_mse: 3.3209\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.8783 - mae: 0.7232 - mse: 0.8783 - val_loss: 3.2496 - val_mae: 1.0491 - val_mse: 3.2496\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8940 - mae: 0.7328 - mse: 0.8940 - val_loss: 2.5843 - val_mae: 0.9960 - val_mse: 2.5843\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9452 - mae: 0.7544 - mse: 0.9452 - val_loss: 2.6689 - val_mae: 1.0122 - val_mse: 2.6689\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.9354 - mae: 0.7563 - mse: 0.9354 - val_loss: 2.6175 - val_mae: 1.1282 - val_mse: 2.6175\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9097 - mae: 0.7331 - mse: 0.9097 - val_loss: 2.6061 - val_mae: 0.9780 - val_mse: 2.6061\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.9010 - mae: 0.7275 - mse: 0.9010 - val_loss: 2.8452 - val_mae: 0.9983 - val_mse: 2.8452\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 987us/step - loss: 0.8411 - mae: 0.7169 - mse: 0.8411 - val_loss: 2.8475 - val_mae: 1.1414 - val_mse: 2.8475\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.8644 - mae: 0.7154 - mse: 0.8644 - val_loss: 3.7376 - val_mae: 1.1571 - val_mse: 3.7376\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.8950 - mae: 0.7350 - mse: 0.8950 - val_loss: 2.7990 - val_mae: 0.9968 - val_mse: 2.7990\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 956us/step - loss: 0.8525 - mae: 0.7075 - mse: 0.8525 - val_loss: 3.4390 - val_mae: 1.0745 - val_mse: 3.4390\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8867 - mae: 0.7211 - mse: 0.8867 - val_loss: 2.8785 - val_mae: 1.0499 - val_mse: 2.8785\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.8430 - mae: 0.7162 - mse: 0.8430 - val_loss: 2.4012 - val_mae: 0.9899 - val_mse: 2.4012\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.8878 - mae: 0.7280 - mse: 0.8878 - val_loss: 2.6297 - val_mae: 0.9917 - val_mse: 2.6297\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 969us/step - loss: 0.8387 - mae: 0.7076 - mse: 0.8387 - val_loss: 2.7743 - val_mae: 1.0220 - val_mse: 2.7743\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.8469 - mae: 0.7185 - mse: 0.8469 - val_loss: 2.5210 - val_mae: 0.9936 - val_mse: 2.5210\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.8709 - mae: 0.7113 - mse: 0.8709 - val_loss: 2.8682 - val_mae: 1.0284 - val_mse: 2.8682\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.8780 - mae: 0.7277 - mse: 0.8780 - val_loss: 2.9958 - val_mae: 1.0163 - val_mse: 2.9958\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 985us/step - loss: 0.8481 - mae: 0.7132 - mse: 0.8481 - val_loss: 3.3160 - val_mae: 1.0421 - val_mse: 3.3160\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8177 - mae: 0.6874 - mse: 0.8177 - val_loss: 4.1868 - val_mae: 1.3582 - val_mse: 4.1868\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.8585 - mae: 0.7295 - mse: 0.8585 - val_loss: 2.8856 - val_mae: 1.0085 - val_mse: 2.8856\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7897 - mae: 0.6856 - mse: 0.7897 - val_loss: 2.6308 - val_mae: 1.0628 - val_mse: 2.6308\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7630 - mae: 0.6696 - mse: 0.7630 - val_loss: 2.8208 - val_mae: 1.0768 - val_mse: 2.8208\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8933 - mae: 0.7297 - mse: 0.8933 - val_loss: 3.7185 - val_mae: 1.1066 - val_mse: 3.7185\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7823 - mae: 0.6831 - mse: 0.7823 - val_loss: 3.4755 - val_mae: 1.1336 - val_mse: 3.4755\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.8392 - mae: 0.7107 - mse: 0.8392 - val_loss: 2.7043 - val_mae: 1.0817 - val_mse: 2.7043\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7964 - mae: 0.6890 - mse: 0.7964 - val_loss: 2.9496 - val_mae: 1.0365 - val_mse: 2.9496\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7715 - mae: 0.6716 - mse: 0.7715 - val_loss: 2.7291 - val_mae: 1.0080 - val_mse: 2.7291\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7379 - mae: 0.6582 - mse: 0.7379 - val_loss: 3.2060 - val_mae: 1.0568 - val_mse: 3.2060\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8409 - mae: 0.7177 - mse: 0.8409 - val_loss: 2.7856 - val_mae: 1.0103 - val_mse: 2.7856\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7798 - mae: 0.6762 - mse: 0.7798 - val_loss: 2.9458 - val_mae: 1.0425 - val_mse: 2.9458\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7876 - mae: 0.6929 - mse: 0.7876 - val_loss: 3.6062 - val_mae: 1.0840 - val_mse: 3.6062\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 971us/step - loss: 0.7457 - mae: 0.6586 - mse: 0.7457 - val_loss: 3.0210 - val_mae: 1.0263 - val_mse: 3.0210\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 997us/step - loss: 0.7867 - mae: 0.6929 - mse: 0.7867 - val_loss: 3.1356 - val_mae: 1.0605 - val_mse: 3.1356\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7943 - mae: 0.6962 - mse: 0.7943 - val_loss: 2.6281 - val_mae: 1.0504 - val_mse: 2.6281\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7736 - mae: 0.6731 - mse: 0.7736 - val_loss: 3.0193 - val_mae: 1.0704 - val_mse: 3.0193\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.8033 - mae: 0.6879 - mse: 0.8033 - val_loss: 2.9110 - val_mae: 1.0431 - val_mse: 2.9110\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.7198 - mae: 0.6484 - mse: 0.7198 - val_loss: 3.1323 - val_mae: 1.0891 - val_mse: 3.1323\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.7565 - mae: 0.6627 - mse: 0.7565 - val_loss: 3.0046 - val_mae: 1.0366 - val_mse: 3.0046\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7530 - mae: 0.6612 - mse: 0.7530 - val_loss: 2.5792 - val_mae: 1.0333 - val_mse: 2.5792\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.7359 - mae: 0.6586 - mse: 0.7359 - val_loss: 3.4638 - val_mae: 1.1516 - val_mse: 3.4638\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7751 - mae: 0.6898 - mse: 0.7751 - val_loss: 3.0952 - val_mae: 1.1038 - val_mse: 3.0952\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 949us/step - loss: 0.7179 - mae: 0.6627 - mse: 0.7179 - val_loss: 2.7737 - val_mae: 1.0878 - val_mse: 2.7737\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7247 - mae: 0.6601 - mse: 0.7247 - val_loss: 2.5068 - val_mae: 1.0129 - val_mse: 2.5068\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7588 - mae: 0.6655 - mse: 0.7588 - val_loss: 2.7084 - val_mae: 1.0386 - val_mse: 2.7084\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7127 - mae: 0.6524 - mse: 0.7127 - val_loss: 2.5455 - val_mae: 1.0057 - val_mse: 2.5455\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.7209 - mae: 0.6445 - mse: 0.7209 - val_loss: 3.2275 - val_mae: 1.0788 - val_mse: 3.2275\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 969us/step - loss: 0.6897 - mae: 0.6369 - mse: 0.6897 - val_loss: 2.6317 - val_mae: 1.0604 - val_mse: 2.6317\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.7701 - mae: 0.6746 - mse: 0.7701 - val_loss: 3.1012 - val_mae: 1.0823 - val_mse: 3.1012\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.6960 - mae: 0.6379 - mse: 0.6960 - val_loss: 3.1843 - val_mae: 1.0946 - val_mse: 3.1843\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 943us/step - loss: 0.6985 - mae: 0.6452 - mse: 0.6985 - val_loss: 2.5248 - val_mae: 0.9950 - val_mse: 2.5248\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7090 - mae: 0.6507 - mse: 0.7090 - val_loss: 2.6976 - val_mae: 1.0230 - val_mse: 2.6976\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 986us/step - loss: 0.7171 - mae: 0.6401 - mse: 0.7171 - val_loss: 2.8378 - val_mae: 1.0178 - val_mse: 2.8378\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 969us/step - loss: 0.7018 - mae: 0.6345 - mse: 0.7018 - val_loss: 2.8168 - val_mae: 1.0462 - val_mse: 2.8168\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.7161 - mae: 0.6503 - mse: 0.7161 - val_loss: 2.9581 - val_mae: 1.0256 - val_mse: 2.9581\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.7003 - mae: 0.6369 - mse: 0.7003 - val_loss: 3.4768 - val_mae: 1.0970 - val_mse: 3.4768\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.6318 - mae: 0.6185 - mse: 0.6318 - val_loss: 2.6936 - val_mae: 1.0152 - val_mse: 2.6936\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 979us/step - loss: 0.7479 - mae: 0.6631 - mse: 0.7479 - val_loss: 3.0373 - val_mae: 1.0480 - val_mse: 3.0373\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6546 - mae: 0.6165 - mse: 0.6546 - val_loss: 3.2696 - val_mae: 1.0640 - val_mse: 3.2696\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 989us/step - loss: 0.6214 - mae: 0.6019 - mse: 0.6214 - val_loss: 3.9245 - val_mae: 1.2139 - val_mse: 3.9245\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 985us/step - loss: 0.7343 - mae: 0.6648 - mse: 0.7343 - val_loss: 3.5970 - val_mae: 1.1383 - val_mse: 3.5970\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6350 - mae: 0.6166 - mse: 0.6350 - val_loss: 3.2810 - val_mae: 1.1622 - val_mse: 3.2810\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.6463 - mae: 0.6172 - mse: 0.6463 - val_loss: 3.3750 - val_mae: 1.0531 - val_mse: 3.3750\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6927 - mae: 0.6366 - mse: 0.6927 - val_loss: 2.6513 - val_mae: 1.0170 - val_mse: 2.6513\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6397 - mae: 0.6094 - mse: 0.6397 - val_loss: 3.8950 - val_mae: 1.1698 - val_mse: 3.8950\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.6950 - mae: 0.6487 - mse: 0.6950 - val_loss: 2.4620 - val_mae: 1.0020 - val_mse: 2.4620\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 998us/step - loss: 0.6182 - mae: 0.5962 - mse: 0.6182 - val_loss: 3.0763 - val_mae: 1.0241 - val_mse: 3.0763\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6481 - mae: 0.6220 - mse: 0.6481 - val_loss: 2.7760 - val_mae: 1.0216 - val_mse: 2.7760\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6399 - mae: 0.6123 - mse: 0.6399 - val_loss: 3.4387 - val_mae: 1.1226 - val_mse: 3.4387\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6328 - mae: 0.6010 - mse: 0.6328 - val_loss: 2.8850 - val_mae: 1.0438 - val_mse: 2.8850\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.6772 - mae: 0.6286 - mse: 0.6772 - val_loss: 3.5800 - val_mae: 1.0855 - val_mse: 3.5800\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5609 - mae: 0.5716 - mse: 0.5609 - val_loss: 2.7937 - val_mae: 1.0167 - val_mse: 2.7937\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6240 - mae: 0.6031 - mse: 0.6240 - val_loss: 2.8040 - val_mae: 1.0274 - val_mse: 2.8040\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5777 - mae: 0.5860 - mse: 0.5777 - val_loss: 3.0069 - val_mae: 1.0395 - val_mse: 3.0069\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6096 - mae: 0.6039 - mse: 0.6096 - val_loss: 3.2859 - val_mae: 1.1382 - val_mse: 3.2859\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6533 - mae: 0.6196 - mse: 0.6533 - val_loss: 3.1255 - val_mae: 1.0544 - val_mse: 3.1255\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.5902 - mae: 0.5783 - mse: 0.5902 - val_loss: 3.2562 - val_mae: 1.0826 - val_mse: 3.2562\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6025 - mae: 0.5967 - mse: 0.6025 - val_loss: 3.1557 - val_mae: 1.0554 - val_mse: 3.1557\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6198 - mae: 0.5975 - mse: 0.6198 - val_loss: 3.9911 - val_mae: 1.2396 - val_mse: 3.9911\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5877 - mae: 0.5930 - mse: 0.5877 - val_loss: 2.8671 - val_mae: 1.1660 - val_mse: 2.8671\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6150 - mae: 0.5983 - mse: 0.6150 - val_loss: 2.7643 - val_mae: 1.0350 - val_mse: 2.7643\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5722 - mae: 0.5783 - mse: 0.5722 - val_loss: 2.7338 - val_mae: 1.0229 - val_mse: 2.7338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.5611 - mae: 0.5762 - mse: 0.5611 - val_loss: 2.9551 - val_mae: 1.0364 - val_mse: 2.9551\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5889 - mae: 0.5961 - mse: 0.5889 - val_loss: 2.8822 - val_mae: 1.0423 - val_mse: 2.8822\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 942us/step - loss: 0.5653 - mae: 0.5748 - mse: 0.5653 - val_loss: 2.6432 - val_mae: 1.0384 - val_mse: 2.6432\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.6017 - mae: 0.5963 - mse: 0.6017 - val_loss: 3.7541 - val_mae: 1.1978 - val_mse: 3.7541\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5711 - mae: 0.5686 - mse: 0.5711 - val_loss: 3.9752 - val_mae: 1.2001 - val_mse: 3.9752\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5896 - mae: 0.5918 - mse: 0.5896 - val_loss: 2.8822 - val_mae: 1.1434 - val_mse: 2.8822\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 969us/step - loss: 0.5889 - mae: 0.5905 - mse: 0.5889 - val_loss: 2.4605 - val_mae: 0.9954 - val_mse: 2.4605\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5601 - mae: 0.5787 - mse: 0.5601 - val_loss: 3.7029 - val_mae: 1.0479 - val_mse: 3.7029\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5285 - mae: 0.5459 - mse: 0.5285 - val_loss: 4.0633 - val_mae: 1.1497 - val_mse: 4.0633\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.5538 - mae: 0.5642 - mse: 0.5538 - val_loss: 3.3031 - val_mae: 1.0490 - val_mse: 3.3031\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5418 - mae: 0.5633 - mse: 0.5418 - val_loss: 2.5582 - val_mae: 1.0847 - val_mse: 2.5582\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5516 - mae: 0.5748 - mse: 0.5516 - val_loss: 3.8523 - val_mae: 1.0622 - val_mse: 3.8523\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5235 - mae: 0.5497 - mse: 0.5235 - val_loss: 3.5542 - val_mae: 1.0435 - val_mse: 3.5542\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4763 - mae: 0.5200 - mse: 0.4763 - val_loss: 2.9818 - val_mae: 1.1964 - val_mse: 2.9818\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5493 - mae: 0.5654 - mse: 0.5493 - val_loss: 3.0766 - val_mae: 1.0422 - val_mse: 3.0766\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5526 - mae: 0.5692 - mse: 0.5526 - val_loss: 2.8198 - val_mae: 1.0940 - val_mse: 2.8198\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5314 - mae: 0.5683 - mse: 0.5314 - val_loss: 3.0703 - val_mae: 1.0381 - val_mse: 3.0703\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4936 - mae: 0.5295 - mse: 0.4936 - val_loss: 2.7844 - val_mae: 1.2024 - val_mse: 2.7844\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5570 - mae: 0.5718 - mse: 0.5570 - val_loss: 3.2148 - val_mae: 1.0661 - val_mse: 3.2148\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5213 - mae: 0.5581 - mse: 0.5213 - val_loss: 2.5185 - val_mae: 1.0390 - val_mse: 2.5185\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5159 - mae: 0.5525 - mse: 0.5159 - val_loss: 3.1950 - val_mae: 1.0810 - val_mse: 3.1950\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4818 - mae: 0.5304 - mse: 0.4818 - val_loss: 2.5904 - val_mae: 1.0324 - val_mse: 2.5904\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5167 - mae: 0.5534 - mse: 0.5167 - val_loss: 2.6309 - val_mae: 1.0552 - val_mse: 2.6309\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5297 - mae: 0.5562 - mse: 0.5297 - val_loss: 3.6678 - val_mae: 1.0915 - val_mse: 3.6678\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4805 - mae: 0.5294 - mse: 0.4805 - val_loss: 2.8053 - val_mae: 1.0291 - val_mse: 2.8053\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4824 - mae: 0.5224 - mse: 0.4824 - val_loss: 2.8398 - val_mae: 1.0942 - val_mse: 2.8398\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4843 - mae: 0.5371 - mse: 0.4843 - val_loss: 3.0506 - val_mae: 1.0424 - val_mse: 3.0506\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4903 - mae: 0.5416 - mse: 0.4903 - val_loss: 2.8841 - val_mae: 1.0695 - val_mse: 2.8841\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4646 - mae: 0.5158 - mse: 0.4646 - val_loss: 3.1346 - val_mae: 1.1967 - val_mse: 3.1346\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5221 - mae: 0.5516 - mse: 0.5221 - val_loss: 2.7184 - val_mae: 1.1073 - val_mse: 2.7184\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4594 - mae: 0.5185 - mse: 0.4594 - val_loss: 2.5403 - val_mae: 1.0343 - val_mse: 2.5403\n",
      "Kappa Score: 0.7390783309728728\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 87.2432 - mae: 4.2791 - mse: 87.2432 - val_loss: 63.9910 - val_mae: 7.6630 - val_mse: 63.9910\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 20.0533 - mae: 3.5520 - mse: 20.0533 - val_loss: 12.8034 - val_mae: 3.0566 - val_mse: 12.8034\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 12.4113 - mae: 3.0355 - mse: 12.4113 - val_loss: 6.8050 - val_mae: 2.3334 - val_mse: 6.8050\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 5.9748 - mae: 2.0250 - mse: 5.9748 - val_loss: 8.1108 - val_mae: 2.5847 - val_mse: 8.1108\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.8301 - mae: 1.5740 - mse: 3.8301 - val_loss: 10.1458 - val_mae: 2.9815 - val_mse: 10.1458\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.0045 - mae: 1.3756 - mse: 3.0045 - val_loss: 3.0808 - val_mae: 1.2191 - val_mse: 3.0808\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.0295 - mae: 1.4116 - mse: 3.0295 - val_loss: 2.4291 - val_mae: 1.0491 - val_mse: 2.4291\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2711 - mae: 1.1957 - mse: 2.2711 - val_loss: 3.7545 - val_mae: 1.0437 - val_mse: 3.7545\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5528 - mae: 1.2662 - mse: 2.5528 - val_loss: 2.3295 - val_mae: 0.9812 - val_mse: 2.3295\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0806 - mae: 1.1511 - mse: 2.0806 - val_loss: 2.2219 - val_mae: 0.9689 - val_mse: 2.2219\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0234 - mae: 1.1386 - mse: 2.0234 - val_loss: 3.7368 - val_mae: 1.0992 - val_mse: 3.7368\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8051 - mae: 1.0588 - mse: 1.8051 - val_loss: 2.1311 - val_mae: 0.9507 - val_mse: 2.1311\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8005 - mae: 1.0648 - mse: 1.8005 - val_loss: 3.0946 - val_mae: 1.4413 - val_mse: 3.0946\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7976 - mae: 1.0538 - mse: 1.7976 - val_loss: 4.5704 - val_mae: 1.2094 - val_mse: 4.5704\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7382 - mae: 1.0544 - mse: 1.7382 - val_loss: 2.3327 - val_mae: 1.0188 - val_mse: 2.3327\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7538 - mae: 1.0383 - mse: 1.7538 - val_loss: 4.6881 - val_mae: 1.1418 - val_mse: 4.6881\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7489 - mae: 1.0503 - mse: 1.7489 - val_loss: 2.5012 - val_mae: 1.2031 - val_mse: 2.5012\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6481 - mae: 1.0074 - mse: 1.6481 - val_loss: 4.2425 - val_mae: 1.2322 - val_mse: 4.2425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1.6669 - mae: 1.0093 - mse: 1.6669 - val_loss: 2.5039 - val_mae: 1.1570 - val_mse: 2.5039\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5587 - mae: 0.9890 - mse: 1.5587 - val_loss: 4.1346 - val_mae: 1.0484 - val_mse: 4.1346\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.5504 - mae: 0.9784 - mse: 1.5504 - val_loss: 1.9875 - val_mae: 1.0015 - val_mse: 1.9875\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 969us/step - loss: 1.5057 - mae: 0.9604 - mse: 1.5057 - val_loss: 2.4884 - val_mae: 1.0157 - val_mse: 2.4884\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.5318 - mae: 0.9709 - mse: 1.5318 - val_loss: 5.0368 - val_mae: 1.0410 - val_mse: 5.0368\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4972 - mae: 0.9684 - mse: 1.4972 - val_loss: 4.0686 - val_mae: 1.4365 - val_mse: 4.0686\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3832 - mae: 0.9169 - mse: 1.3832 - val_loss: 2.7927 - val_mae: 0.9676 - val_mse: 2.7927\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3461 - mae: 0.9061 - mse: 1.3461 - val_loss: 3.1876 - val_mae: 1.1998 - val_mse: 3.1876\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3847 - mae: 0.9109 - mse: 1.3847 - val_loss: 2.2466 - val_mae: 0.9393 - val_mse: 2.2466\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4212 - mae: 0.9216 - mse: 1.4212 - val_loss: 3.4353 - val_mae: 1.0021 - val_mse: 3.4353\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3260 - mae: 0.9040 - mse: 1.3260 - val_loss: 2.5253 - val_mae: 1.0098 - val_mse: 2.5253\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3365 - mae: 0.9057 - mse: 1.3365 - val_loss: 4.5184 - val_mae: 1.3519 - val_mse: 4.5184\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4031 - mae: 0.9060 - mse: 1.4031 - val_loss: 2.4109 - val_mae: 0.9925 - val_mse: 2.4109\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2831 - mae: 0.8848 - mse: 1.2831 - val_loss: 2.3999 - val_mae: 0.9811 - val_mse: 2.3999\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3647 - mae: 0.9088 - mse: 1.3647 - val_loss: 3.5662 - val_mae: 0.9940 - val_mse: 3.5662\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.2766 - mae: 0.8892 - mse: 1.2766 - val_loss: 2.2721 - val_mae: 1.0955 - val_mse: 2.2721\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3495 - mae: 0.9080 - mse: 1.3495 - val_loss: 4.2644 - val_mae: 1.1923 - val_mse: 4.2644\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2713 - mae: 0.8773 - mse: 1.2713 - val_loss: 1.9149 - val_mae: 0.9388 - val_mse: 1.9149\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1725 - mae: 0.8553 - mse: 1.1725 - val_loss: 4.3270 - val_mae: 1.0352 - val_mse: 4.3270\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3050 - mae: 0.8970 - mse: 1.3050 - val_loss: 2.3679 - val_mae: 0.9582 - val_mse: 2.3679\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2085 - mae: 0.8602 - mse: 1.2085 - val_loss: 5.6997 - val_mae: 1.3015 - val_mse: 5.6997\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2079 - mae: 0.8598 - mse: 1.2079 - val_loss: 2.9843 - val_mae: 1.1618 - val_mse: 2.9843\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1544 - mae: 0.8440 - mse: 1.1544 - val_loss: 4.7026 - val_mae: 1.0724 - val_mse: 4.7026\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2701 - mae: 0.8795 - mse: 1.2701 - val_loss: 2.5162 - val_mae: 1.2140 - val_mse: 2.5162\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1496 - mae: 0.8357 - mse: 1.1496 - val_loss: 5.4797 - val_mae: 1.0836 - val_mse: 5.4797\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2439 - mae: 0.8829 - mse: 1.2439 - val_loss: 2.0275 - val_mae: 0.9545 - val_mse: 2.0275\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1559 - mae: 0.8199 - mse: 1.1559 - val_loss: 4.1357 - val_mae: 1.0178 - val_mse: 4.1357\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1638 - mae: 0.8454 - mse: 1.1638 - val_loss: 1.9990 - val_mae: 0.9189 - val_mse: 1.9990\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1596 - mae: 0.8466 - mse: 1.1596 - val_loss: 3.8439 - val_mae: 1.0396 - val_mse: 3.8439\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1790 - mae: 0.8417 - mse: 1.1790 - val_loss: 2.2788 - val_mae: 0.9432 - val_mse: 2.2788\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1103 - mae: 0.8201 - mse: 1.1103 - val_loss: 4.5852 - val_mae: 1.1107 - val_mse: 4.5852\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1996 - mae: 0.8435 - mse: 1.1996 - val_loss: 2.4607 - val_mae: 0.9686 - val_mse: 2.4607\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1500 - mae: 0.8481 - mse: 1.1500 - val_loss: 3.5167 - val_mae: 1.0942 - val_mse: 3.5167\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0941 - mae: 0.8050 - mse: 1.0941 - val_loss: 2.1292 - val_mae: 0.9230 - val_mse: 2.1292\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.2033 - mae: 0.8333 - mse: 1.2033 - val_loss: 3.6820 - val_mae: 1.0279 - val_mse: 3.6820\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1521 - mae: 0.8476 - mse: 1.1521 - val_loss: 2.0511 - val_mae: 0.9080 - val_mse: 2.0511\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1446 - mae: 0.8345 - mse: 1.1446 - val_loss: 3.3951 - val_mae: 0.9915 - val_mse: 3.3951\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1013 - mae: 0.8086 - mse: 1.1013 - val_loss: 2.1080 - val_mae: 0.9333 - val_mse: 2.1080\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.0474 - mae: 0.7903 - mse: 1.0474 - val_loss: 4.2577 - val_mae: 1.0310 - val_mse: 4.2577\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0910 - mae: 0.8128 - mse: 1.0910 - val_loss: 2.1949 - val_mae: 0.9332 - val_mse: 2.1949\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0343 - mae: 0.7908 - mse: 1.0343 - val_loss: 2.0455 - val_mae: 0.9303 - val_mse: 2.0455\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0750 - mae: 0.8051 - mse: 1.0750 - val_loss: 3.2020 - val_mae: 1.0312 - val_mse: 3.2020\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0505 - mae: 0.8041 - mse: 1.0505 - val_loss: 2.2893 - val_mae: 0.9532 - val_mse: 2.2893\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.0858 - mae: 0.8071 - mse: 1.0858 - val_loss: 3.0510 - val_mae: 1.0002 - val_mse: 3.0510\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0676 - mae: 0.7998 - mse: 1.0676 - val_loss: 2.1408 - val_mae: 0.9267 - val_mse: 2.1408\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 1.0235 - mae: 0.7838 - mse: 1.0235 - val_loss: 3.5827 - val_mae: 1.0890 - val_mse: 3.5827\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1036 - mae: 0.8213 - mse: 1.1036 - val_loss: 2.4918 - val_mae: 0.9802 - val_mse: 2.4918\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9988 - mae: 0.7797 - mse: 0.9988 - val_loss: 2.4614 - val_mae: 1.1464 - val_mse: 2.4614\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0600 - mae: 0.8087 - mse: 1.0600 - val_loss: 3.9330 - val_mae: 1.1235 - val_mse: 3.9330\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0173 - mae: 0.7792 - mse: 1.0173 - val_loss: 3.3782 - val_mae: 1.0699 - val_mse: 3.3782\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0589 - mae: 0.7946 - mse: 1.0589 - val_loss: 2.0093 - val_mae: 0.9062 - val_mse: 2.0093\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9819 - mae: 0.7602 - mse: 0.9819 - val_loss: 3.0279 - val_mae: 0.9920 - val_mse: 3.0279\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0145 - mae: 0.7885 - mse: 1.0145 - val_loss: 2.0604 - val_mae: 0.9217 - val_mse: 2.0604\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9235 - mae: 0.7467 - mse: 0.9235 - val_loss: 3.0697 - val_mae: 0.9866 - val_mse: 3.0697\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9641 - mae: 0.7647 - mse: 0.9641 - val_loss: 2.3006 - val_mae: 0.9777 - val_mse: 2.3006\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0227 - mae: 0.7837 - mse: 1.0227 - val_loss: 3.0293 - val_mae: 0.9963 - val_mse: 3.0293\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9801 - mae: 0.7673 - mse: 0.9801 - val_loss: 2.1702 - val_mae: 0.9428 - val_mse: 2.1702\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0022 - mae: 0.7674 - mse: 1.0022 - val_loss: 3.7428 - val_mae: 1.0205 - val_mse: 3.7428\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0212 - mae: 0.7757 - mse: 1.0212 - val_loss: 1.9877 - val_mae: 0.9090 - val_mse: 1.9877\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9356 - mae: 0.7431 - mse: 0.9356 - val_loss: 3.3275 - val_mae: 1.0065 - val_mse: 3.3275\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9726 - mae: 0.7553 - mse: 0.9726 - val_loss: 3.0792 - val_mae: 1.1336 - val_mse: 3.0792\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9295 - mae: 0.7420 - mse: 0.9295 - val_loss: 2.6874 - val_mae: 0.9442 - val_mse: 2.6874\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9426 - mae: 0.7607 - mse: 0.9426 - val_loss: 2.4233 - val_mae: 0.9534 - val_mse: 2.4233\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9672 - mae: 0.7550 - mse: 0.9672 - val_loss: 3.6366 - val_mae: 0.9825 - val_mse: 3.6366\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9468 - mae: 0.7418 - mse: 0.9468 - val_loss: 2.9246 - val_mae: 1.2488 - val_mse: 2.9246\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9528 - mae: 0.7597 - mse: 0.9528 - val_loss: 3.1774 - val_mae: 0.9743 - val_mse: 3.1774\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9155 - mae: 0.7340 - mse: 0.9155 - val_loss: 2.5952 - val_mae: 1.0058 - val_mse: 2.5952\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9331 - mae: 0.7398 - mse: 0.9331 - val_loss: 3.1920 - val_mae: 0.9815 - val_mse: 3.1920\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9495 - mae: 0.7609 - mse: 0.9495 - val_loss: 2.4042 - val_mae: 0.9406 - val_mse: 2.4042\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9169 - mae: 0.7317 - mse: 0.9169 - val_loss: 3.4754 - val_mae: 1.1336 - val_mse: 3.4754\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8842 - mae: 0.7209 - mse: 0.8842 - val_loss: 2.2731 - val_mae: 0.9736 - val_mse: 2.2731\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9336 - mae: 0.7412 - mse: 0.9336 - val_loss: 2.8453 - val_mae: 0.9687 - val_mse: 2.8453\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9011 - mae: 0.7296 - mse: 0.9011 - val_loss: 2.5804 - val_mae: 1.1065 - val_mse: 2.5804\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9050 - mae: 0.7313 - mse: 0.9050 - val_loss: 2.9108 - val_mae: 0.9816 - val_mse: 2.9108\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9181 - mae: 0.7399 - mse: 0.9181 - val_loss: 2.2291 - val_mae: 0.9305 - val_mse: 2.2291\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8993 - mae: 0.7248 - mse: 0.8993 - val_loss: 3.4142 - val_mae: 0.9926 - val_mse: 3.4142\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8836 - mae: 0.7228 - mse: 0.8836 - val_loss: 2.3193 - val_mae: 0.9560 - val_mse: 2.3193\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8924 - mae: 0.7306 - mse: 0.8924 - val_loss: 3.0570 - val_mae: 1.0723 - val_mse: 3.0570\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9237 - mae: 0.7358 - mse: 0.9237 - val_loss: 2.2779 - val_mae: 0.9461 - val_mse: 2.2779\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8765 - mae: 0.7136 - mse: 0.8765 - val_loss: 2.3242 - val_mae: 0.9682 - val_mse: 2.3242\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8910 - mae: 0.7249 - mse: 0.8910 - val_loss: 2.9016 - val_mae: 1.0021 - val_mse: 2.9016\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9303 - mae: 0.7384 - mse: 0.9303 - val_loss: 2.0097 - val_mae: 0.9186 - val_mse: 2.0097\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8988 - mae: 0.7289 - mse: 0.8988 - val_loss: 2.8089 - val_mae: 0.9684 - val_mse: 2.8089\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8297 - mae: 0.7063 - mse: 0.8297 - val_loss: 2.1232 - val_mae: 0.9945 - val_mse: 2.1232\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8532 - mae: 0.7104 - mse: 0.8532 - val_loss: 3.4017 - val_mae: 1.1077 - val_mse: 3.4017\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8508 - mae: 0.7041 - mse: 0.8508 - val_loss: 2.3698 - val_mae: 0.9981 - val_mse: 2.3698\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8354 - mae: 0.7051 - mse: 0.8354 - val_loss: 3.0165 - val_mae: 0.9784 - val_mse: 3.0165\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8393 - mae: 0.7088 - mse: 0.8393 - val_loss: 2.0858 - val_mae: 0.9287 - val_mse: 2.0858\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8813 - mae: 0.7204 - mse: 0.8813 - val_loss: 2.9562 - val_mae: 0.9694 - val_mse: 2.9562\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8567 - mae: 0.7199 - mse: 0.8567 - val_loss: 2.0075 - val_mae: 0.9010 - val_mse: 2.0075\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8269 - mae: 0.7087 - mse: 0.8269 - val_loss: 2.6297 - val_mae: 1.0557 - val_mse: 2.6297\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.8479 - mae: 0.7056 - mse: 0.8479 - val_loss: 2.1208 - val_mae: 0.9352 - val_mse: 2.1208\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8117 - mae: 0.6954 - mse: 0.8117 - val_loss: 2.7658 - val_mae: 0.9847 - val_mse: 2.7658\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8623 - mae: 0.7121 - mse: 0.8623 - val_loss: 2.2338 - val_mae: 0.9566 - val_mse: 2.2338\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8269 - mae: 0.7011 - mse: 0.8269 - val_loss: 3.1251 - val_mae: 1.1727 - val_mse: 3.1251\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8237 - mae: 0.6922 - mse: 0.8237 - val_loss: 2.4007 - val_mae: 0.9848 - val_mse: 2.4007\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8655 - mae: 0.7115 - mse: 0.8655 - val_loss: 2.5956 - val_mae: 1.0292 - val_mse: 2.5956\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8213 - mae: 0.7001 - mse: 0.8213 - val_loss: 2.0681 - val_mae: 0.9285 - val_mse: 2.0681\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7534 - mae: 0.6762 - mse: 0.7534 - val_loss: 3.4091 - val_mae: 1.2656 - val_mse: 3.4091\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8748 - mae: 0.7221 - mse: 0.8748 - val_loss: 2.2889 - val_mae: 0.9679 - val_mse: 2.2889\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8443 - mae: 0.7045 - mse: 0.8443 - val_loss: 2.3564 - val_mae: 0.9958 - val_mse: 2.3564\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7803 - mae: 0.6808 - mse: 0.7803 - val_loss: 2.2087 - val_mae: 1.0332 - val_mse: 2.2087\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8163 - mae: 0.6930 - mse: 0.8163 - val_loss: 2.9004 - val_mae: 1.0511 - val_mse: 2.9004\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8090 - mae: 0.6890 - mse: 0.8090 - val_loss: 2.1206 - val_mae: 1.0153 - val_mse: 2.1206\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7946 - mae: 0.6817 - mse: 0.7946 - val_loss: 2.0387 - val_mae: 0.9358 - val_mse: 2.0387\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7479 - mae: 0.6667 - mse: 0.7479 - val_loss: 2.1992 - val_mae: 0.9408 - val_mse: 2.1992\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8360 - mae: 0.6955 - mse: 0.8360 - val_loss: 2.1280 - val_mae: 0.9335 - val_mse: 2.1280\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7501 - mae: 0.6532 - mse: 0.7501 - val_loss: 2.6753 - val_mae: 1.0353 - val_mse: 2.6753\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7677 - mae: 0.6661 - mse: 0.7677 - val_loss: 2.7027 - val_mae: 1.0774 - val_mse: 2.7027\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7398 - mae: 0.6580 - mse: 0.7398 - val_loss: 2.3817 - val_mae: 0.9531 - val_mse: 2.3817\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7785 - mae: 0.6735 - mse: 0.7785 - val_loss: 2.3313 - val_mae: 1.0136 - val_mse: 2.3313\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7610 - mae: 0.6677 - mse: 0.7610 - val_loss: 2.3415 - val_mae: 0.9706 - val_mse: 2.3415\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7791 - mae: 0.6683 - mse: 0.7791 - val_loss: 2.2238 - val_mae: 0.9658 - val_mse: 2.2238\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7098 - mae: 0.6413 - mse: 0.7098 - val_loss: 2.0006 - val_mae: 0.9237 - val_mse: 2.0006\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7881 - mae: 0.6703 - mse: 0.7881 - val_loss: 2.7194 - val_mae: 0.9674 - val_mse: 2.7194\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7614 - mae: 0.6573 - mse: 0.7614 - val_loss: 1.9772 - val_mae: 0.9361 - val_mse: 1.9772\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7437 - mae: 0.6551 - mse: 0.7437 - val_loss: 2.6075 - val_mae: 0.9742 - val_mse: 2.6075\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7387 - mae: 0.6432 - mse: 0.7387 - val_loss: 2.1840 - val_mae: 0.9497 - val_mse: 2.1840\n",
      "Kappa Score: 0.6514215531288761\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 82.8280 - mae: 4.5898 - mse: 82.8280 - val_loss: 89.1201 - val_mae: 9.0598 - val_mse: 89.1201\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 20.2451 - mae: 3.4145 - mse: 20.2451 - val_loss: 37.7442 - val_mae: 5.8071 - val_mse: 37.7442\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 8.7839 - mae: 2.4077 - mse: 8.7839 - val_loss: 4.9336 - val_mae: 1.4999 - val_mse: 4.9336\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.5137 - mae: 2.0827 - mse: 6.5137 - val_loss: 4.1831 - val_mae: 1.3867 - val_mse: 4.1831\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.4756 - mae: 1.6991 - mse: 4.4756 - val_loss: 4.5755 - val_mae: 1.8065 - val_mse: 4.5755\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8415 - mae: 1.3501 - mse: 2.8415 - val_loss: 6.3733 - val_mae: 1.3029 - val_mse: 6.3733\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.2898 - mae: 1.4252 - mse: 3.2898 - val_loss: 3.7613 - val_mae: 1.1352 - val_mse: 3.7613\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6761 - mae: 1.3223 - mse: 2.6761 - val_loss: 16.3706 - val_mae: 2.5551 - val_mse: 16.3706\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8086 - mae: 1.3118 - mse: 2.8086 - val_loss: 7.3304 - val_mae: 2.0024 - val_mse: 7.3304\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 2.4448 - mae: 1.2214 - mse: 2.4448 - val_loss: 5.0947 - val_mae: 1.3698 - val_mse: 5.0947\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3339 - mae: 1.1917 - mse: 2.3339 - val_loss: 3.6510 - val_mae: 1.1897 - val_mse: 3.6510\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2240 - mae: 1.1652 - mse: 2.2240 - val_loss: 5.6006 - val_mae: 1.7215 - val_mse: 5.6006\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8865 - mae: 1.0897 - mse: 1.8865 - val_loss: 2.7752 - val_mae: 1.1298 - val_mse: 2.7752\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0337 - mae: 1.1368 - mse: 2.0337 - val_loss: 5.5388 - val_mae: 1.1448 - val_mse: 5.5388\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8374 - mae: 1.0576 - mse: 1.8374 - val_loss: 3.2545 - val_mae: 1.3191 - val_mse: 3.2545\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8356 - mae: 1.0726 - mse: 1.8356 - val_loss: 7.3650 - val_mae: 1.4307 - val_mse: 7.3650\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8139 - mae: 1.0638 - mse: 1.8139 - val_loss: 2.9794 - val_mae: 1.0955 - val_mse: 2.9794\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6637 - mae: 1.0222 - mse: 1.6637 - val_loss: 7.1861 - val_mae: 1.3830 - val_mse: 7.1861\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7954 - mae: 1.0436 - mse: 1.7954 - val_loss: 3.7203 - val_mae: 1.1773 - val_mse: 3.7203\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7928 - mae: 1.0520 - mse: 1.7928 - val_loss: 5.7149 - val_mae: 1.2868 - val_mse: 5.7149\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5817 - mae: 0.9921 - mse: 1.5817 - val_loss: 5.1261 - val_mae: 1.4294 - val_mse: 5.1261\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6737 - mae: 1.0225 - mse: 1.6737 - val_loss: 5.6720 - val_mae: 1.5685 - val_mse: 5.6720\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6016 - mae: 0.9818 - mse: 1.6016 - val_loss: 3.1992 - val_mae: 1.3476 - val_mse: 3.1992\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6870 - mae: 1.0296 - mse: 1.6870 - val_loss: 5.9797 - val_mae: 1.2048 - val_mse: 5.9797\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6570 - mae: 1.0216 - mse: 1.6570 - val_loss: 3.7358 - val_mae: 1.2031 - val_mse: 3.7358\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.5165 - mae: 0.9628 - mse: 1.5165 - val_loss: 3.5945 - val_mae: 1.1245 - val_mse: 3.5945\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4459 - mae: 0.9330 - mse: 1.4459 - val_loss: 3.8964 - val_mae: 1.2656 - val_mse: 3.8964\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5526 - mae: 0.9868 - mse: 1.5526 - val_loss: 4.2347 - val_mae: 1.1594 - val_mse: 4.2347\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5119 - mae: 0.9585 - mse: 1.5119 - val_loss: 4.0147 - val_mae: 1.1609 - val_mse: 4.0147\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4375 - mae: 0.9438 - mse: 1.4375 - val_loss: 2.7080 - val_mae: 1.0236 - val_mse: 2.7080\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3863 - mae: 0.9248 - mse: 1.3863 - val_loss: 5.0395 - val_mae: 1.2179 - val_mse: 5.0395\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2660 - mae: 0.8837 - mse: 1.2660 - val_loss: 5.0079 - val_mae: 1.5243 - val_mse: 5.0079\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4489 - mae: 0.9257 - mse: 1.4489 - val_loss: 4.4625 - val_mae: 1.1138 - val_mse: 4.4625\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3937 - mae: 0.9235 - mse: 1.3937 - val_loss: 3.6926 - val_mae: 1.1538 - val_mse: 3.6926\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2865 - mae: 0.8909 - mse: 1.2865 - val_loss: 5.1178 - val_mae: 1.1429 - val_mse: 5.1178\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3843 - mae: 0.9164 - mse: 1.3843 - val_loss: 2.9696 - val_mae: 1.0406 - val_mse: 2.9696\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2489 - mae: 0.8699 - mse: 1.2489 - val_loss: 7.0691 - val_mae: 1.4748 - val_mse: 7.0691\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2566 - mae: 0.8720 - mse: 1.2566 - val_loss: 3.8056 - val_mae: 1.2420 - val_mse: 3.8056\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3063 - mae: 0.8866 - mse: 1.3063 - val_loss: 4.9388 - val_mae: 1.2645 - val_mse: 4.9388\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2913 - mae: 0.8847 - mse: 1.2913 - val_loss: 3.3822 - val_mae: 1.1247 - val_mse: 3.3822\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2493 - mae: 0.8901 - mse: 1.2493 - val_loss: 4.2513 - val_mae: 1.0957 - val_mse: 4.2513\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1997 - mae: 0.8605 - mse: 1.1997 - val_loss: 2.9362 - val_mae: 1.2289 - val_mse: 2.9362\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2072 - mae: 0.8566 - mse: 1.2072 - val_loss: 3.9754 - val_mae: 1.1121 - val_mse: 3.9754\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2824 - mae: 0.8820 - mse: 1.2824 - val_loss: 3.2817 - val_mae: 1.2837 - val_mse: 3.2817\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1546 - mae: 0.8408 - mse: 1.1546 - val_loss: 4.7508 - val_mae: 1.0987 - val_mse: 4.7508\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.2379 - mae: 0.8625 - mse: 1.2379 - val_loss: 2.8710 - val_mae: 1.1348 - val_mse: 2.8710\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2538 - mae: 0.8719 - mse: 1.2538 - val_loss: 4.4559 - val_mae: 1.1881 - val_mse: 4.4559\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1257 - mae: 0.8231 - mse: 1.1257 - val_loss: 2.7218 - val_mae: 1.0746 - val_mse: 2.7218\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2017 - mae: 0.8547 - mse: 1.2017 - val_loss: 3.8707 - val_mae: 1.0817 - val_mse: 3.8707\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1349 - mae: 0.8123 - mse: 1.1349 - val_loss: 3.4101 - val_mae: 1.1407 - val_mse: 3.4101\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1143 - mae: 0.8261 - mse: 1.1143 - val_loss: 5.6137 - val_mae: 1.1878 - val_mse: 5.6137\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1913 - mae: 0.8601 - mse: 1.1913 - val_loss: 2.8361 - val_mae: 1.0467 - val_mse: 2.8361\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1261 - mae: 0.8256 - mse: 1.1261 - val_loss: 2.8478 - val_mae: 1.0502 - val_mse: 2.8478\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1083 - mae: 0.8130 - mse: 1.1083 - val_loss: 3.6074 - val_mae: 1.2490 - val_mse: 3.6074\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1033 - mae: 0.8186 - mse: 1.1033 - val_loss: 2.7853 - val_mae: 1.1304 - val_mse: 2.7853\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1077 - mae: 0.8186 - mse: 1.1077 - val_loss: 4.9273 - val_mae: 1.2696 - val_mse: 4.9273\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1107 - mae: 0.8207 - mse: 1.1107 - val_loss: 3.2600 - val_mae: 1.3252 - val_mse: 3.2600\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1218 - mae: 0.8192 - mse: 1.1218 - val_loss: 4.4702 - val_mae: 1.1645 - val_mse: 4.4702\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0120 - mae: 0.7818 - mse: 1.0120 - val_loss: 3.1213 - val_mae: 1.0567 - val_mse: 3.1213\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1210 - mae: 0.8269 - mse: 1.1210 - val_loss: 2.8744 - val_mae: 1.0249 - val_mse: 2.8744\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0723 - mae: 0.8099 - mse: 1.0723 - val_loss: 2.6693 - val_mae: 1.1396 - val_mse: 2.6693\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0531 - mae: 0.7923 - mse: 1.0531 - val_loss: 3.6795 - val_mae: 1.0750 - val_mse: 3.6795\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1279 - mae: 0.8211 - mse: 1.1279 - val_loss: 2.7929 - val_mae: 1.0156 - val_mse: 2.7929\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0747 - mae: 0.8059 - mse: 1.0747 - val_loss: 3.3511 - val_mae: 1.0683 - val_mse: 3.3511\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0483 - mae: 0.7924 - mse: 1.0483 - val_loss: 3.6487 - val_mae: 1.2060 - val_mse: 3.6487\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0701 - mae: 0.8099 - mse: 1.0701 - val_loss: 3.5985 - val_mae: 1.0750 - val_mse: 3.5985\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9958 - mae: 0.7610 - mse: 0.9958 - val_loss: 2.6667 - val_mae: 1.0179 - val_mse: 2.6667\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0410 - mae: 0.7943 - mse: 1.0410 - val_loss: 3.7133 - val_mae: 1.1177 - val_mse: 3.7133\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0016 - mae: 0.7836 - mse: 1.0016 - val_loss: 2.6564 - val_mae: 1.1127 - val_mse: 2.6564\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0780 - mae: 0.8018 - mse: 1.0780 - val_loss: 3.4770 - val_mae: 1.0722 - val_mse: 3.4770\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0278 - mae: 0.7849 - mse: 1.0278 - val_loss: 2.5776 - val_mae: 1.0090 - val_mse: 2.5776\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0061 - mae: 0.7810 - mse: 1.0061 - val_loss: 3.3438 - val_mae: 1.1453 - val_mse: 3.3438\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9925 - mae: 0.7775 - mse: 0.9925 - val_loss: 2.8031 - val_mae: 1.1764 - val_mse: 2.8031\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9553 - mae: 0.7579 - mse: 0.9553 - val_loss: 2.5367 - val_mae: 0.9956 - val_mse: 2.5367\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0102 - mae: 0.7680 - mse: 1.0102 - val_loss: 2.8181 - val_mae: 1.0713 - val_mse: 2.8181\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0220 - mae: 0.7724 - mse: 1.0220 - val_loss: 2.7692 - val_mae: 1.1648 - val_mse: 2.7692\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9928 - mae: 0.7647 - mse: 0.9928 - val_loss: 3.3626 - val_mae: 1.0687 - val_mse: 3.3626\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9668 - mae: 0.7674 - mse: 0.9668 - val_loss: 2.6789 - val_mae: 1.0649 - val_mse: 2.6789\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0008 - mae: 0.7700 - mse: 1.0008 - val_loss: 3.3321 - val_mae: 1.1945 - val_mse: 3.3321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9409 - mae: 0.7429 - mse: 0.9409 - val_loss: 2.9075 - val_mae: 1.0996 - val_mse: 2.9075\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9493 - mae: 0.7525 - mse: 0.9493 - val_loss: 3.4367 - val_mae: 1.1180 - val_mse: 3.4367\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9495 - mae: 0.7417 - mse: 0.9495 - val_loss: 3.1443 - val_mae: 1.0710 - val_mse: 3.1443\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9149 - mae: 0.7436 - mse: 0.9149 - val_loss: 3.5830 - val_mae: 1.2004 - val_mse: 3.5830\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9023 - mae: 0.7231 - mse: 0.9023 - val_loss: 3.4394 - val_mae: 1.1233 - val_mse: 3.4394\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8920 - mae: 0.7190 - mse: 0.8920 - val_loss: 2.6975 - val_mae: 1.0482 - val_mse: 2.6975\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9343 - mae: 0.7354 - mse: 0.9343 - val_loss: 2.9887 - val_mae: 1.1594 - val_mse: 2.9887\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8879 - mae: 0.7244 - mse: 0.8879 - val_loss: 2.8914 - val_mae: 1.0445 - val_mse: 2.8914\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9541 - mae: 0.7510 - mse: 0.9541 - val_loss: 2.8835 - val_mae: 1.1253 - val_mse: 2.8835\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9040 - mae: 0.7325 - mse: 0.9040 - val_loss: 2.4907 - val_mae: 1.0224 - val_mse: 2.4907\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8549 - mae: 0.7100 - mse: 0.8549 - val_loss: 3.0240 - val_mae: 1.0785 - val_mse: 3.0240\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9145 - mae: 0.7372 - mse: 0.9145 - val_loss: 2.9687 - val_mae: 1.0655 - val_mse: 2.9687\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8700 - mae: 0.7169 - mse: 0.8700 - val_loss: 2.6448 - val_mae: 1.1104 - val_mse: 2.6448\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8918 - mae: 0.7204 - mse: 0.8918 - val_loss: 3.1072 - val_mae: 1.0567 - val_mse: 3.1072\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9268 - mae: 0.7394 - mse: 0.9268 - val_loss: 3.0701 - val_mae: 1.0694 - val_mse: 3.0701\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8779 - mae: 0.7250 - mse: 0.8779 - val_loss: 2.6098 - val_mae: 1.0916 - val_mse: 2.6098\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8306 - mae: 0.6918 - mse: 0.8306 - val_loss: 3.0708 - val_mae: 1.1707 - val_mse: 3.0708\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8669 - mae: 0.7111 - mse: 0.8669 - val_loss: 2.7766 - val_mae: 1.0574 - val_mse: 2.7766\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8947 - mae: 0.7165 - mse: 0.8947 - val_loss: 2.7708 - val_mae: 1.0489 - val_mse: 2.7708\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8027 - mae: 0.6916 - mse: 0.8027 - val_loss: 2.8910 - val_mae: 1.1506 - val_mse: 2.8910\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8860 - mae: 0.7234 - mse: 0.8860 - val_loss: 2.6123 - val_mae: 1.0834 - val_mse: 2.6123\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8176 - mae: 0.7016 - mse: 0.8176 - val_loss: 2.7692 - val_mae: 1.0792 - val_mse: 2.7692\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8316 - mae: 0.7010 - mse: 0.8316 - val_loss: 2.5914 - val_mae: 1.0318 - val_mse: 2.5914\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8261 - mae: 0.6970 - mse: 0.8261 - val_loss: 3.5793 - val_mae: 1.1494 - val_mse: 3.5793\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8301 - mae: 0.6952 - mse: 0.8301 - val_loss: 3.1158 - val_mae: 1.0733 - val_mse: 3.1158\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8199 - mae: 0.6914 - mse: 0.8199 - val_loss: 2.7290 - val_mae: 1.0422 - val_mse: 2.7290\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8368 - mae: 0.7040 - mse: 0.8368 - val_loss: 2.6920 - val_mae: 1.0331 - val_mse: 2.6920\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8702 - mae: 0.7123 - mse: 0.8702 - val_loss: 3.0935 - val_mae: 1.0655 - val_mse: 3.0935\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7823 - mae: 0.6721 - mse: 0.7823 - val_loss: 2.9384 - val_mae: 1.1169 - val_mse: 2.9384\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8009 - mae: 0.6861 - mse: 0.8009 - val_loss: 3.4136 - val_mae: 1.1285 - val_mse: 3.4136\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8252 - mae: 0.6921 - mse: 0.8252 - val_loss: 2.9768 - val_mae: 1.0637 - val_mse: 2.9768\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8320 - mae: 0.7011 - mse: 0.8320 - val_loss: 2.8310 - val_mae: 1.0523 - val_mse: 2.8310\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7548 - mae: 0.6631 - mse: 0.7548 - val_loss: 2.7832 - val_mae: 1.0400 - val_mse: 2.7832\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8299 - mae: 0.6998 - mse: 0.8299 - val_loss: 2.6122 - val_mae: 1.1323 - val_mse: 2.6122\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8082 - mae: 0.6927 - mse: 0.8082 - val_loss: 3.3342 - val_mae: 1.1102 - val_mse: 3.3342\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7442 - mae: 0.6585 - mse: 0.7442 - val_loss: 3.6231 - val_mae: 1.2395 - val_mse: 3.6231\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8119 - mae: 0.6801 - mse: 0.8119 - val_loss: 2.7546 - val_mae: 1.1991 - val_mse: 2.7546\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7321 - mae: 0.6529 - mse: 0.7321 - val_loss: 2.5317 - val_mae: 1.0829 - val_mse: 2.5317\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7416 - mae: 0.6613 - mse: 0.7416 - val_loss: 2.9231 - val_mae: 1.0679 - val_mse: 2.9231\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7907 - mae: 0.6778 - mse: 0.7907 - val_loss: 2.7805 - val_mae: 1.0432 - val_mse: 2.7805\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6840 - mae: 0.6262 - mse: 0.6840 - val_loss: 2.5693 - val_mae: 1.0684 - val_mse: 2.5693\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7447 - mae: 0.6587 - mse: 0.7447 - val_loss: 2.8760 - val_mae: 1.0778 - val_mse: 2.8760\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7146 - mae: 0.6422 - mse: 0.7146 - val_loss: 2.6301 - val_mae: 1.1521 - val_mse: 2.6301\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7624 - mae: 0.6555 - mse: 0.7624 - val_loss: 3.0337 - val_mae: 1.0905 - val_mse: 3.0337\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7167 - mae: 0.6465 - mse: 0.7167 - val_loss: 2.9725 - val_mae: 1.2571 - val_mse: 2.9725\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7726 - mae: 0.6687 - mse: 0.7726 - val_loss: 2.6837 - val_mae: 1.1131 - val_mse: 2.6837\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6976 - mae: 0.6358 - mse: 0.6976 - val_loss: 2.5877 - val_mae: 1.0251 - val_mse: 2.5877\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6904 - mae: 0.6336 - mse: 0.6904 - val_loss: 2.6141 - val_mae: 1.0659 - val_mse: 2.6141\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7382 - mae: 0.6413 - mse: 0.7382 - val_loss: 2.5092 - val_mae: 1.0734 - val_mse: 2.5092\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7384 - mae: 0.6610 - mse: 0.7384 - val_loss: 2.8061 - val_mae: 1.0639 - val_mse: 2.8061\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7043 - mae: 0.6331 - mse: 0.7043 - val_loss: 2.6018 - val_mae: 1.1407 - val_mse: 2.6018\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7061 - mae: 0.6328 - mse: 0.7061 - val_loss: 2.7766 - val_mae: 1.0620 - val_mse: 2.7766\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7332 - mae: 0.6586 - mse: 0.7332 - val_loss: 2.5285 - val_mae: 1.0600 - val_mse: 2.5285\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6570 - mae: 0.6128 - mse: 0.6570 - val_loss: 2.8696 - val_mae: 1.2385 - val_mse: 2.8696\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7490 - mae: 0.6549 - mse: 0.7490 - val_loss: 3.1510 - val_mae: 1.1385 - val_mse: 3.1510\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6886 - mae: 0.6326 - mse: 0.6886 - val_loss: 2.6142 - val_mae: 1.0941 - val_mse: 2.6142\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6506 - mae: 0.6169 - mse: 0.6506 - val_loss: 2.5341 - val_mae: 1.0414 - val_mse: 2.5341\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6486 - mae: 0.6205 - mse: 0.6486 - val_loss: 2.5435 - val_mae: 1.0643 - val_mse: 2.5435\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6921 - mae: 0.6281 - mse: 0.6921 - val_loss: 2.6075 - val_mae: 1.0959 - val_mse: 2.6075\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6857 - mae: 0.6282 - mse: 0.6857 - val_loss: 3.0488 - val_mae: 1.1036 - val_mse: 3.0488\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6713 - mae: 0.6110 - mse: 0.6713 - val_loss: 2.7608 - val_mae: 1.0632 - val_mse: 2.7608\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6367 - mae: 0.6037 - mse: 0.6367 - val_loss: 2.5878 - val_mae: 1.0307 - val_mse: 2.5878\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6359 - mae: 0.6046 - mse: 0.6359 - val_loss: 3.3658 - val_mae: 1.1772 - val_mse: 3.3658\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7306 - mae: 0.6419 - mse: 0.7306 - val_loss: 2.6230 - val_mae: 1.0425 - val_mse: 2.6230\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6564 - mae: 0.6084 - mse: 0.6564 - val_loss: 2.8698 - val_mae: 1.0828 - val_mse: 2.8698\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6384 - mae: 0.6115 - mse: 0.6384 - val_loss: 3.2352 - val_mae: 1.1515 - val_mse: 3.2352\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6208 - mae: 0.5919 - mse: 0.6208 - val_loss: 2.6336 - val_mae: 1.0544 - val_mse: 2.6336\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6815 - mae: 0.6226 - mse: 0.6815 - val_loss: 2.8480 - val_mae: 1.0733 - val_mse: 2.8480\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6422 - mae: 0.6023 - mse: 0.6422 - val_loss: 3.0941 - val_mae: 1.1154 - val_mse: 3.0941\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6124 - mae: 0.5918 - mse: 0.6124 - val_loss: 3.3086 - val_mae: 1.1307 - val_mse: 3.3086\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6457 - mae: 0.6102 - mse: 0.6457 - val_loss: 2.6394 - val_mae: 1.0641 - val_mse: 2.6394\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6254 - mae: 0.5940 - mse: 0.6254 - val_loss: 2.5241 - val_mae: 1.0677 - val_mse: 2.5241\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6735 - mae: 0.6209 - mse: 0.6735 - val_loss: 2.6375 - val_mae: 1.1271 - val_mse: 2.6375\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5837 - mae: 0.5825 - mse: 0.5837 - val_loss: 2.5596 - val_mae: 1.0533 - val_mse: 2.5596\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6565 - mae: 0.6200 - mse: 0.6565 - val_loss: 2.8932 - val_mae: 1.0691 - val_mse: 2.8932\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5869 - mae: 0.5781 - mse: 0.5869 - val_loss: 2.6728 - val_mae: 1.0622 - val_mse: 2.6728\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6286 - mae: 0.5902 - mse: 0.6286 - val_loss: 2.6003 - val_mae: 1.1091 - val_mse: 2.6003\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5955 - mae: 0.5844 - mse: 0.5955 - val_loss: 2.8065 - val_mae: 1.0768 - val_mse: 2.8065\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5835 - mae: 0.5710 - mse: 0.5835 - val_loss: 2.7084 - val_mae: 1.0554 - val_mse: 2.7084\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5937 - mae: 0.5789 - mse: 0.5937 - val_loss: 2.9174 - val_mae: 1.2000 - val_mse: 2.9174\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5863 - mae: 0.5755 - mse: 0.5863 - val_loss: 2.7720 - val_mae: 1.0655 - val_mse: 2.7720\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5971 - mae: 0.5803 - mse: 0.5971 - val_loss: 2.6924 - val_mae: 1.0597 - val_mse: 2.6924\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6043 - mae: 0.5949 - mse: 0.6043 - val_loss: 3.1830 - val_mae: 1.1435 - val_mse: 3.1830\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5839 - mae: 0.5715 - mse: 0.5839 - val_loss: 4.0268 - val_mae: 1.3006 - val_mse: 4.0268\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5781 - mae: 0.5801 - mse: 0.5781 - val_loss: 2.7452 - val_mae: 1.0748 - val_mse: 2.7452\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5953 - mae: 0.5833 - mse: 0.5953 - val_loss: 2.7716 - val_mae: 1.0839 - val_mse: 2.7716\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5453 - mae: 0.5579 - mse: 0.5453 - val_loss: 2.7132 - val_mae: 1.1485 - val_mse: 2.7132\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5825 - mae: 0.5820 - mse: 0.5825 - val_loss: 3.0842 - val_mae: 1.1410 - val_mse: 3.0842\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5902 - mae: 0.5823 - mse: 0.5902 - val_loss: 2.7637 - val_mae: 1.0797 - val_mse: 2.7637\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5774 - mae: 0.5777 - mse: 0.5774 - val_loss: 3.3188 - val_mae: 1.3626 - val_mse: 3.3188\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5778 - mae: 0.5721 - mse: 0.5778 - val_loss: 2.6881 - val_mae: 1.1712 - val_mse: 2.6881\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5713 - mae: 0.5807 - mse: 0.5713 - val_loss: 4.1625 - val_mae: 1.3320 - val_mse: 4.1625\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5578 - mae: 0.5776 - mse: 0.5578 - val_loss: 2.5945 - val_mae: 1.0703 - val_mse: 2.5945\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5276 - mae: 0.5463 - mse: 0.5276 - val_loss: 2.6268 - val_mae: 1.1014 - val_mse: 2.6268\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5881 - mae: 0.5854 - mse: 0.5881 - val_loss: 2.5481 - val_mae: 1.0824 - val_mse: 2.5481\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5377 - mae: 0.5550 - mse: 0.5377 - val_loss: 2.7222 - val_mae: 1.0874 - val_mse: 2.7222\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5713 - mae: 0.5699 - mse: 0.5713 - val_loss: 2.6454 - val_mae: 1.0775 - val_mse: 2.6454\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5036 - mae: 0.5371 - mse: 0.5036 - val_loss: 3.4817 - val_mae: 1.2210 - val_mse: 3.4817\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5827 - mae: 0.5808 - mse: 0.5827 - val_loss: 2.6748 - val_mae: 1.1529 - val_mse: 2.6748\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5659 - mae: 0.5669 - mse: 0.5659 - val_loss: 3.0901 - val_mae: 1.1358 - val_mse: 3.0901\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5375 - mae: 0.5637 - mse: 0.5375 - val_loss: 4.0729 - val_mae: 1.3312 - val_mse: 4.0729\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4982 - mae: 0.5344 - mse: 0.4982 - val_loss: 2.9131 - val_mae: 1.2072 - val_mse: 2.9131\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5514 - mae: 0.5722 - mse: 0.5514 - val_loss: 4.1042 - val_mae: 1.3141 - val_mse: 4.1042\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5112 - mae: 0.5412 - mse: 0.5112 - val_loss: 2.6821 - val_mae: 1.1086 - val_mse: 2.6821\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5115 - mae: 0.5450 - mse: 0.5115 - val_loss: 2.6007 - val_mae: 1.1404 - val_mse: 2.6007\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5432 - mae: 0.5586 - mse: 0.5432 - val_loss: 2.8256 - val_mae: 1.0815 - val_mse: 2.8256\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5044 - mae: 0.5302 - mse: 0.5044 - val_loss: 2.7039 - val_mae: 1.0699 - val_mse: 2.7039\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5281 - mae: 0.5432 - mse: 0.5281 - val_loss: 3.1708 - val_mae: 1.1586 - val_mse: 3.1708\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4763 - mae: 0.5183 - mse: 0.4763 - val_loss: 2.7380 - val_mae: 1.1750 - val_mse: 2.7380\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5408 - mae: 0.5580 - mse: 0.5408 - val_loss: 2.6798 - val_mae: 1.1600 - val_mse: 2.6798\n",
      "Kappa Score: 0.6678665606295258\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 153.1388 - mae: 6.4311 - mse: 153.1388 - val_loss: 124.2847 - val_mae: 9.8495 - val_mse: 124.2847\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 30.9693 - mae: 3.4787 - mse: 30.9693 - val_loss: 108.0147 - val_mae: 9.8361 - val_mse: 108.0147\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 19.8261 - mae: 3.0716 - mse: 19.8261 - val_loss: 76.7909 - val_mae: 7.7728 - val_mse: 76.7909\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 17.0074 - mae: 2.6251 - mse: 17.0074 - val_loss: 33.1417 - val_mae: 5.3934 - val_mse: 33.1417\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 13.0043 - mae: 2.6029 - mse: 13.0043 - val_loss: 7.5583 - val_mae: 1.7071 - val_mse: 7.5583\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 5.9596 - mae: 1.9276 - mse: 5.9596 - val_loss: 9.8003 - val_mae: 1.2777 - val_mse: 9.8003\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.8394 - mae: 2.0507 - mse: 6.8394 - val_loss: 18.6186 - val_mae: 2.1704 - val_mse: 18.6186\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.6257 - mae: 1.4969 - mse: 3.6257 - val_loss: 16.1609 - val_mae: 1.3783 - val_mse: 16.1609\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.0405 - mae: 1.3281 - mse: 3.0405 - val_loss: 12.7650 - val_mae: 2.0236 - val_mse: 12.7650\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6510 - mae: 1.2709 - mse: 2.6510 - val_loss: 9.3654 - val_mae: 1.6814 - val_mse: 9.3654\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6435 - mae: 1.2803 - mse: 2.6435 - val_loss: 15.4175 - val_mae: 1.4202 - val_mse: 15.4175\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0025 - mae: 1.1055 - mse: 2.0025 - val_loss: 13.1255 - val_mae: 1.3224 - val_mse: 13.1255\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1699 - mae: 1.1608 - mse: 2.1699 - val_loss: 18.8633 - val_mae: 1.4241 - val_mse: 18.8633\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8614 - mae: 1.0593 - mse: 1.8614 - val_loss: 22.9511 - val_mae: 1.4121 - val_mse: 22.9511\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0304 - mae: 1.1257 - mse: 2.0304 - val_loss: 33.0425 - val_mae: 1.6213 - val_mse: 33.0425\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9225 - mae: 1.0862 - mse: 1.9225 - val_loss: 19.3489 - val_mae: 1.4435 - val_mse: 19.3489\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7925 - mae: 1.0406 - mse: 1.7925 - val_loss: 17.5370 - val_mae: 1.3135 - val_mse: 17.5370\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7162 - mae: 1.0372 - mse: 1.7162 - val_loss: 26.9682 - val_mae: 1.3756 - val_mse: 26.9682\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6949 - mae: 0.9956 - mse: 1.6949 - val_loss: 23.7227 - val_mae: 1.5469 - val_mse: 23.7227\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6669 - mae: 1.0146 - mse: 1.6669 - val_loss: 26.3690 - val_mae: 1.4411 - val_mse: 26.3690\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5419 - mae: 0.9706 - mse: 1.5419 - val_loss: 26.4014 - val_mae: 1.7680 - val_mse: 26.4014\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8622 - mae: 1.0466 - mse: 1.8622 - val_loss: 25.8349 - val_mae: 1.6128 - val_mse: 25.8349\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4764 - mae: 0.9426 - mse: 1.4764 - val_loss: 30.6319 - val_mae: 1.3963 - val_mse: 30.6319\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5481 - mae: 0.9704 - mse: 1.5481 - val_loss: 29.9318 - val_mae: 1.6581 - val_mse: 29.9318\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6043 - mae: 0.9835 - mse: 1.6043 - val_loss: 29.5940 - val_mae: 1.4775 - val_mse: 29.5940\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4729 - mae: 0.9460 - mse: 1.4729 - val_loss: 28.3441 - val_mae: 1.3931 - val_mse: 28.3441\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3800 - mae: 0.9238 - mse: 1.3800 - val_loss: 31.9199 - val_mae: 1.6468 - val_mse: 31.9199\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4245 - mae: 0.9392 - mse: 1.4245 - val_loss: 33.8149 - val_mae: 1.5834 - val_mse: 33.8149\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4913 - mae: 0.9517 - mse: 1.4913 - val_loss: 20.9305 - val_mae: 1.3606 - val_mse: 20.9305\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3778 - mae: 0.9203 - mse: 1.3778 - val_loss: 25.4371 - val_mae: 1.5034 - val_mse: 25.4371\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3509 - mae: 0.9000 - mse: 1.3509 - val_loss: 19.3816 - val_mae: 1.6785 - val_mse: 19.3816\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3699 - mae: 0.9300 - mse: 1.3699 - val_loss: 26.5818 - val_mae: 1.7194 - val_mse: 26.5818\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3740 - mae: 0.9190 - mse: 1.3740 - val_loss: 20.5312 - val_mae: 1.3495 - val_mse: 20.5312\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3970 - mae: 0.9126 - mse: 1.3970 - val_loss: 18.8951 - val_mae: 1.6491 - val_mse: 18.8951\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3380 - mae: 0.8977 - mse: 1.3380 - val_loss: 21.1822 - val_mae: 1.6595 - val_mse: 21.1822\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3038 - mae: 0.8934 - mse: 1.3038 - val_loss: 22.3252 - val_mae: 1.4261 - val_mse: 22.3252\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3403 - mae: 0.8994 - mse: 1.3403 - val_loss: 20.1881 - val_mae: 1.3065 - val_mse: 20.1881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2388 - mae: 0.8535 - mse: 1.2388 - val_loss: 33.6646 - val_mae: 1.4497 - val_mse: 33.6646\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2983 - mae: 0.8758 - mse: 1.2983 - val_loss: 26.0674 - val_mae: 1.3715 - val_mse: 26.0674\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2006 - mae: 0.8542 - mse: 1.2006 - val_loss: 20.4124 - val_mae: 1.5706 - val_mse: 20.4124\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3214 - mae: 0.8862 - mse: 1.3214 - val_loss: 15.8967 - val_mae: 1.3534 - val_mse: 15.8967\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2682 - mae: 0.8594 - mse: 1.2682 - val_loss: 20.8450 - val_mae: 1.3336 - val_mse: 20.8450\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2507 - mae: 0.8632 - mse: 1.2507 - val_loss: 18.4646 - val_mae: 1.3067 - val_mse: 18.4646\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1918 - mae: 0.8367 - mse: 1.1918 - val_loss: 24.0360 - val_mae: 1.4828 - val_mse: 24.0360\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2045 - mae: 0.8490 - mse: 1.2045 - val_loss: 28.5461 - val_mae: 1.4582 - val_mse: 28.5461\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2056 - mae: 0.8519 - mse: 1.2056 - val_loss: 38.4394 - val_mae: 1.5641 - val_mse: 38.4394\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1939 - mae: 0.8478 - mse: 1.1939 - val_loss: 29.2390 - val_mae: 1.6352 - val_mse: 29.2390\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1929 - mae: 0.8575 - mse: 1.1929 - val_loss: 22.4902 - val_mae: 1.4794 - val_mse: 22.4902\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1409 - mae: 0.8380 - mse: 1.1409 - val_loss: 22.6467 - val_mae: 1.4243 - val_mse: 22.6467\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1578 - mae: 0.8303 - mse: 1.1578 - val_loss: 23.5912 - val_mae: 1.3197 - val_mse: 23.5912\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0967 - mae: 0.8199 - mse: 1.0967 - val_loss: 20.5202 - val_mae: 1.3027 - val_mse: 20.5202\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1969 - mae: 0.8603 - mse: 1.1969 - val_loss: 27.7794 - val_mae: 1.3716 - val_mse: 27.7794\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1243 - mae: 0.8201 - mse: 1.1243 - val_loss: 19.9767 - val_mae: 1.2814 - val_mse: 19.9767\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2209 - mae: 0.8535 - mse: 1.2209 - val_loss: 20.3293 - val_mae: 1.3280 - val_mse: 20.3293\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0983 - mae: 0.8147 - mse: 1.0983 - val_loss: 22.0695 - val_mae: 1.3772 - val_mse: 22.0695\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1581 - mae: 0.8414 - mse: 1.1581 - val_loss: 21.7250 - val_mae: 1.3479 - val_mse: 21.7250\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0967 - mae: 0.8148 - mse: 1.0967 - val_loss: 17.5116 - val_mae: 1.2754 - val_mse: 17.5116\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2227 - mae: 0.8473 - mse: 1.2227 - val_loss: 25.3442 - val_mae: 1.5489 - val_mse: 25.3442\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0809 - mae: 0.8038 - mse: 1.0809 - val_loss: 23.6243 - val_mae: 1.4654 - val_mse: 23.6243\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1742 - mae: 0.8383 - mse: 1.1742 - val_loss: 25.8997 - val_mae: 1.4147 - val_mse: 25.8997\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0679 - mae: 0.7932 - mse: 1.0679 - val_loss: 17.5932 - val_mae: 1.2711 - val_mse: 17.5932\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1382 - mae: 0.8242 - mse: 1.1382 - val_loss: 19.9845 - val_mae: 1.5856 - val_mse: 19.9845\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0455 - mae: 0.7815 - mse: 1.0455 - val_loss: 19.2550 - val_mae: 1.7240 - val_mse: 19.2550\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1060 - mae: 0.8106 - mse: 1.1060 - val_loss: 16.5342 - val_mae: 1.2539 - val_mse: 16.5342\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1127 - mae: 0.8185 - mse: 1.1127 - val_loss: 15.0477 - val_mae: 1.3088 - val_mse: 15.0477\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0603 - mae: 0.7880 - mse: 1.0603 - val_loss: 15.9249 - val_mae: 1.3364 - val_mse: 15.9249\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1213 - mae: 0.8150 - mse: 1.1213 - val_loss: 21.2926 - val_mae: 1.3968 - val_mse: 21.2926\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0573 - mae: 0.7851 - mse: 1.0573 - val_loss: 20.7353 - val_mae: 1.7662 - val_mse: 20.7353\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0965 - mae: 0.8157 - mse: 1.0965 - val_loss: 16.7796 - val_mae: 1.3279 - val_mse: 16.7796\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1330 - mae: 0.8168 - mse: 1.1330 - val_loss: 18.1349 - val_mae: 1.2853 - val_mse: 18.1349\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0497 - mae: 0.7914 - mse: 1.0497 - val_loss: 26.2458 - val_mae: 1.5076 - val_mse: 26.2458\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0440 - mae: 0.7900 - mse: 1.0440 - val_loss: 20.6899 - val_mae: 1.3079 - val_mse: 20.6899\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0162 - mae: 0.7744 - mse: 1.0162 - val_loss: 19.1251 - val_mae: 1.2821 - val_mse: 19.1251\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0056 - mae: 0.7724 - mse: 1.0056 - val_loss: 25.0155 - val_mae: 1.3494 - val_mse: 25.0155\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0529 - mae: 0.7869 - mse: 1.0529 - val_loss: 18.3049 - val_mae: 1.3804 - val_mse: 18.3049\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0859 - mae: 0.8060 - mse: 1.0859 - val_loss: 21.9041 - val_mae: 1.3215 - val_mse: 21.9041\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0037 - mae: 0.7758 - mse: 1.0037 - val_loss: 18.5171 - val_mae: 1.3303 - val_mse: 18.5171\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0362 - mae: 0.7850 - mse: 1.0362 - val_loss: 15.5479 - val_mae: 1.2872 - val_mse: 15.5479\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9895 - mae: 0.7700 - mse: 0.9895 - val_loss: 17.2647 - val_mae: 1.2646 - val_mse: 17.2647\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0610 - mae: 0.7933 - mse: 1.0610 - val_loss: 17.6564 - val_mae: 1.2644 - val_mse: 17.6564\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9804 - mae: 0.7623 - mse: 0.9804 - val_loss: 16.6260 - val_mae: 1.3591 - val_mse: 16.6260\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9450 - mae: 0.7499 - mse: 0.9450 - val_loss: 16.3296 - val_mae: 1.6369 - val_mse: 16.3296\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0244 - mae: 0.7846 - mse: 1.0244 - val_loss: 23.6989 - val_mae: 1.3326 - val_mse: 23.6989\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9786 - mae: 0.7549 - mse: 0.9786 - val_loss: 19.5256 - val_mae: 1.4352 - val_mse: 19.5256\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0447 - mae: 0.7837 - mse: 1.0447 - val_loss: 17.3567 - val_mae: 1.2538 - val_mse: 17.3567\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0126 - mae: 0.7730 - mse: 1.0126 - val_loss: 18.9346 - val_mae: 1.2786 - val_mse: 18.9346\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9882 - mae: 0.7698 - mse: 0.9882 - val_loss: 18.8788 - val_mae: 1.2696 - val_mse: 18.8788\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9513 - mae: 0.7471 - mse: 0.9513 - val_loss: 19.0749 - val_mae: 1.4563 - val_mse: 19.0749\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0160 - mae: 0.7705 - mse: 1.0160 - val_loss: 17.6195 - val_mae: 1.4290 - val_mse: 17.6195\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9804 - mae: 0.7648 - mse: 0.9804 - val_loss: 17.2605 - val_mae: 1.3509 - val_mse: 17.2605\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9730 - mae: 0.7394 - mse: 0.9730 - val_loss: 17.6970 - val_mae: 1.3397 - val_mse: 17.6970\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9898 - mae: 0.7682 - mse: 0.9898 - val_loss: 20.6559 - val_mae: 1.3476 - val_mse: 20.6559\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9401 - mae: 0.7423 - mse: 0.9401 - val_loss: 23.6050 - val_mae: 1.4034 - val_mse: 23.6050\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9107 - mae: 0.7318 - mse: 0.9107 - val_loss: 20.4813 - val_mae: 1.3190 - val_mse: 20.4813\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9764 - mae: 0.7565 - mse: 0.9764 - val_loss: 19.8128 - val_mae: 1.3206 - val_mse: 19.8128\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9591 - mae: 0.7548 - mse: 0.9591 - val_loss: 23.6645 - val_mae: 1.4718 - val_mse: 23.6645\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9708 - mae: 0.7598 - mse: 0.9708 - val_loss: 20.4707 - val_mae: 1.3110 - val_mse: 20.4707\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9304 - mae: 0.7434 - mse: 0.9304 - val_loss: 18.9000 - val_mae: 1.4195 - val_mse: 18.9000\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9545 - mae: 0.7535 - mse: 0.9545 - val_loss: 22.1321 - val_mae: 1.3319 - val_mse: 22.1321\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9487 - mae: 0.7431 - mse: 0.9487 - val_loss: 19.8075 - val_mae: 1.2890 - val_mse: 19.8075\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9848 - mae: 0.7559 - mse: 0.9848 - val_loss: 17.0246 - val_mae: 1.2610 - val_mse: 17.0246\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8952 - mae: 0.7246 - mse: 0.8952 - val_loss: 19.3252 - val_mae: 1.3852 - val_mse: 19.3252\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9811 - mae: 0.7558 - mse: 0.9811 - val_loss: 21.2669 - val_mae: 1.3207 - val_mse: 21.2669\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9446 - mae: 0.7385 - mse: 0.9446 - val_loss: 20.7428 - val_mae: 1.3423 - val_mse: 20.7428\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8674 - mae: 0.6998 - mse: 0.8674 - val_loss: 19.8445 - val_mae: 1.2970 - val_mse: 19.8445\n",
      "Kappa Score: 0.6742474037071119\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 117.1402 - mae: 6.5560 - mse: 117.1402 - val_loss: 104.2334 - val_mae: 9.7935 - val_mse: 104.2334\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 33.8782 - mae: 4.2108 - mse: 33.8782 - val_loss: 7.8360 - val_mae: 1.9914 - val_mse: 7.8360\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 15.5312 - mae: 2.8555 - mse: 15.5312 - val_loss: 13.6658 - val_mae: 3.4613 - val_mse: 13.6658\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 10.9574 - mae: 2.8724 - mse: 10.9574 - val_loss: 8.5041 - val_mae: 2.6817 - val_mse: 8.5041\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 5.3927 - mae: 1.7613 - mse: 5.3927 - val_loss: 2.4788 - val_mae: 1.0029 - val_mse: 2.4788\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.3456 - mae: 1.6309 - mse: 4.3456 - val_loss: 2.6690 - val_mae: 1.0326 - val_mse: 2.6690\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.1751 - mae: 1.4294 - mse: 3.1751 - val_loss: 3.8212 - val_mae: 1.2557 - val_mse: 3.8212\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3591 - mae: 1.2141 - mse: 2.3591 - val_loss: 2.3579 - val_mae: 0.9801 - val_mse: 2.3579\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2100 - mae: 1.1754 - mse: 2.2100 - val_loss: 3.8377 - val_mae: 1.3725 - val_mse: 3.8377\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4739 - mae: 1.2459 - mse: 2.4739 - val_loss: 3.0016 - val_mae: 1.1347 - val_mse: 3.0016\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1071 - mae: 1.1295 - mse: 2.1071 - val_loss: 2.3869 - val_mae: 0.9678 - val_mse: 2.3869\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8986 - mae: 1.0895 - mse: 1.8986 - val_loss: 2.0442 - val_mae: 0.9062 - val_mse: 2.0442\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8087 - mae: 1.0433 - mse: 1.8087 - val_loss: 2.3343 - val_mae: 0.9407 - val_mse: 2.3343\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6223 - mae: 1.0067 - mse: 1.6223 - val_loss: 2.1052 - val_mae: 0.9206 - val_mse: 2.1052\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7514 - mae: 1.0366 - mse: 1.7514 - val_loss: 2.3745 - val_mae: 0.9369 - val_mse: 2.3745\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5727 - mae: 0.9815 - mse: 1.5727 - val_loss: 2.3142 - val_mae: 0.9700 - val_mse: 2.3142\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5114 - mae: 0.9792 - mse: 1.5114 - val_loss: 2.3535 - val_mae: 0.9925 - val_mse: 2.3535\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5854 - mae: 0.9801 - mse: 1.5854 - val_loss: 2.2030 - val_mae: 0.9398 - val_mse: 2.2030\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4300 - mae: 0.9493 - mse: 1.4300 - val_loss: 2.2999 - val_mae: 0.9238 - val_mse: 2.2999\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5443 - mae: 0.9799 - mse: 1.5443 - val_loss: 2.4431 - val_mae: 1.0176 - val_mse: 2.4431\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4740 - mae: 0.9443 - mse: 1.4740 - val_loss: 2.1224 - val_mae: 0.8883 - val_mse: 2.1224\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5351 - mae: 0.9725 - mse: 1.5351 - val_loss: 2.5994 - val_mae: 1.2211 - val_mse: 2.5994\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3861 - mae: 0.9176 - mse: 1.3861 - val_loss: 2.1081 - val_mae: 0.8980 - val_mse: 2.1081\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4596 - mae: 0.9523 - mse: 1.4596 - val_loss: 2.3298 - val_mae: 1.0884 - val_mse: 2.3298\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4144 - mae: 0.9293 - mse: 1.4144 - val_loss: 2.1658 - val_mae: 0.9498 - val_mse: 2.1658\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4231 - mae: 0.9408 - mse: 1.4231 - val_loss: 2.1031 - val_mae: 0.9734 - val_mse: 2.1031\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4482 - mae: 0.9482 - mse: 1.4482 - val_loss: 3.2409 - val_mae: 1.1580 - val_mse: 3.2409\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3814 - mae: 0.9168 - mse: 1.3814 - val_loss: 2.2779 - val_mae: 1.0473 - val_mse: 2.2779\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4285 - mae: 0.9283 - mse: 1.4285 - val_loss: 3.2632 - val_mae: 1.0705 - val_mse: 3.2632\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3211 - mae: 0.8962 - mse: 1.3211 - val_loss: 2.7870 - val_mae: 1.1148 - val_mse: 2.7870\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4405 - mae: 0.9318 - mse: 1.4405 - val_loss: 2.2409 - val_mae: 0.9275 - val_mse: 2.2409\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2291 - mae: 0.8695 - mse: 1.2291 - val_loss: 1.9997 - val_mae: 0.8807 - val_mse: 1.9997\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3709 - mae: 0.9158 - mse: 1.3709 - val_loss: 2.7189 - val_mae: 1.2266 - val_mse: 2.7189\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3021 - mae: 0.8925 - mse: 1.3021 - val_loss: 2.2961 - val_mae: 0.9585 - val_mse: 2.2961\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3493 - mae: 0.9073 - mse: 1.3493 - val_loss: 2.9982 - val_mae: 1.1141 - val_mse: 2.9982\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3303 - mae: 0.8883 - mse: 1.3303 - val_loss: 2.0615 - val_mae: 0.8929 - val_mse: 2.0615\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2747 - mae: 0.8762 - mse: 1.2747 - val_loss: 2.2367 - val_mae: 1.0021 - val_mse: 2.2367\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.4695 - mae: 1.0273 - mse: 1.469 - 0s 1ms/step - loss: 1.2270 - mae: 0.8644 - mse: 1.2270 - val_loss: 2.8764 - val_mae: 1.3254 - val_mse: 2.8764\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2535 - mae: 0.8714 - mse: 1.2535 - val_loss: 2.2923 - val_mae: 0.9060 - val_mse: 2.2923\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1745 - mae: 0.8486 - mse: 1.1745 - val_loss: 2.1508 - val_mae: 0.9273 - val_mse: 2.1508\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1962 - mae: 0.8384 - mse: 1.1962 - val_loss: 2.1306 - val_mae: 0.8874 - val_mse: 2.1306\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2271 - mae: 0.8664 - mse: 1.2271 - val_loss: 2.1228 - val_mae: 0.9492 - val_mse: 2.1228\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1335 - mae: 0.8302 - mse: 1.1335 - val_loss: 2.0852 - val_mae: 0.8827 - val_mse: 2.0852\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2017 - mae: 0.8577 - mse: 1.2017 - val_loss: 2.3134 - val_mae: 0.9541 - val_mse: 2.3134\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1395 - mae: 0.8381 - mse: 1.1395 - val_loss: 3.0005 - val_mae: 1.1500 - val_mse: 3.0005\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1479 - mae: 0.8318 - mse: 1.1479 - val_loss: 2.1663 - val_mae: 0.9035 - val_mse: 2.1663\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1464 - mae: 0.8313 - mse: 1.1464 - val_loss: 2.0652 - val_mae: 0.8928 - val_mse: 2.0652\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1488 - mae: 0.8312 - mse: 1.1488 - val_loss: 2.1620 - val_mae: 0.8935 - val_mse: 2.1620\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1493 - mae: 0.8299 - mse: 1.1493 - val_loss: 2.0513 - val_mae: 0.8773 - val_mse: 2.0513\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0908 - mae: 0.8046 - mse: 1.0908 - val_loss: 2.6698 - val_mae: 1.0334 - val_mse: 2.6698\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0716 - mae: 0.7949 - mse: 1.0716 - val_loss: 1.9856 - val_mae: 0.9019 - val_mse: 1.9856\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1200 - mae: 0.8185 - mse: 1.1200 - val_loss: 2.2275 - val_mae: 1.0039 - val_mse: 2.2275\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1189 - mae: 0.8303 - mse: 1.1189 - val_loss: 2.0583 - val_mae: 0.8838 - val_mse: 2.0583\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0934 - mae: 0.7957 - mse: 1.0934 - val_loss: 2.1025 - val_mae: 0.8977 - val_mse: 2.1025\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0941 - mae: 0.8150 - mse: 1.0941 - val_loss: 2.3238 - val_mae: 0.9944 - val_mse: 2.3238\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0811 - mae: 0.8064 - mse: 1.0811 - val_loss: 2.0696 - val_mae: 0.9096 - val_mse: 2.0696\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0603 - mae: 0.7959 - mse: 1.0603 - val_loss: 2.1377 - val_mae: 0.9040 - val_mse: 2.1377\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0919 - mae: 0.8108 - mse: 1.0919 - val_loss: 2.1291 - val_mae: 0.9538 - val_mse: 2.1291\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0788 - mae: 0.8048 - mse: 1.0788 - val_loss: 1.9874 - val_mae: 0.8785 - val_mse: 1.9874\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0863 - mae: 0.8041 - mse: 1.0863 - val_loss: 3.0176 - val_mae: 1.1562 - val_mse: 3.0176\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0507 - mae: 0.7989 - mse: 1.0507 - val_loss: 2.3694 - val_mae: 1.1120 - val_mse: 2.3694\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0640 - mae: 0.7981 - mse: 1.0640 - val_loss: 2.0978 - val_mae: 0.9354 - val_mse: 2.0978\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0518 - mae: 0.7848 - mse: 1.0518 - val_loss: 2.2752 - val_mae: 0.9561 - val_mse: 2.2752\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0981 - mae: 0.8080 - mse: 1.0981 - val_loss: 2.1108 - val_mae: 0.9293 - val_mse: 2.1108\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0472 - mae: 0.7943 - mse: 1.0472 - val_loss: 2.1900 - val_mae: 0.9298 - val_mse: 2.1900\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0358 - mae: 0.7843 - mse: 1.0358 - val_loss: 2.4541 - val_mae: 1.1184 - val_mse: 2.4541\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0486 - mae: 0.7959 - mse: 1.0486 - val_loss: 1.9788 - val_mae: 0.8754 - val_mse: 1.9788\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9459 - mae: 0.7439 - mse: 0.9459 - val_loss: 2.7724 - val_mae: 1.1062 - val_mse: 2.7724\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0483 - mae: 0.7829 - mse: 1.0483 - val_loss: 2.1300 - val_mae: 0.9870 - val_mse: 2.1300\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0290 - mae: 0.7797 - mse: 1.0290 - val_loss: 2.1475 - val_mae: 0.9035 - val_mse: 2.1475\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9644 - mae: 0.7529 - mse: 0.9644 - val_loss: 1.9770 - val_mae: 0.9052 - val_mse: 1.9770\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0632 - mae: 0.8008 - mse: 1.0632 - val_loss: 2.2660 - val_mae: 0.9457 - val_mse: 2.2660\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9604 - mae: 0.7623 - mse: 0.9604 - val_loss: 2.1335 - val_mae: 0.9296 - val_mse: 2.1335\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9561 - mae: 0.7537 - mse: 0.9561 - val_loss: 2.2756 - val_mae: 0.9445 - val_mse: 2.2756\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0470 - mae: 0.7932 - mse: 1.0470 - val_loss: 2.2023 - val_mae: 0.9332 - val_mse: 2.2023\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9571 - mae: 0.7464 - mse: 0.9571 - val_loss: 2.3823 - val_mae: 0.9853 - val_mse: 2.3823\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0168 - mae: 0.7744 - mse: 1.0168 - val_loss: 1.9690 - val_mae: 0.8741 - val_mse: 1.9690\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0476 - mae: 0.7874 - mse: 1.0476 - val_loss: 2.0472 - val_mae: 0.9089 - val_mse: 2.0472\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9603 - mae: 0.7548 - mse: 0.9603 - val_loss: 1.9903 - val_mae: 0.9055 - val_mse: 1.9903\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0076 - mae: 0.7732 - mse: 1.0076 - val_loss: 2.0321 - val_mae: 0.8833 - val_mse: 2.0321\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9433 - mae: 0.7423 - mse: 0.9433 - val_loss: 3.1221 - val_mae: 1.2413 - val_mse: 3.1221\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9984 - mae: 0.7714 - mse: 0.9984 - val_loss: 2.0344 - val_mae: 0.8781 - val_mse: 2.0344\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9851 - mae: 0.7611 - mse: 0.9851 - val_loss: 2.1348 - val_mae: 0.9955 - val_mse: 2.1348\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9258 - mae: 0.7386 - mse: 0.9258 - val_loss: 2.1299 - val_mae: 0.9182 - val_mse: 2.1299\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8874 - mae: 0.7275 - mse: 0.8874 - val_loss: 2.8028 - val_mae: 1.1372 - val_mse: 2.8028\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9576 - mae: 0.7487 - mse: 0.9576 - val_loss: 2.3559 - val_mae: 1.1048 - val_mse: 2.3559\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9794 - mae: 0.7584 - mse: 0.9794 - val_loss: 2.1827 - val_mae: 0.9233 - val_mse: 2.1827\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9383 - mae: 0.7469 - mse: 0.9383 - val_loss: 2.0521 - val_mae: 0.9090 - val_mse: 2.0521\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9032 - mae: 0.7238 - mse: 0.9032 - val_loss: 2.2032 - val_mae: 1.0385 - val_mse: 2.2032\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9276 - mae: 0.7343 - mse: 0.9276 - val_loss: 2.0043 - val_mae: 0.8959 - val_mse: 2.0043\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8927 - mae: 0.7284 - mse: 0.8927 - val_loss: 2.0643 - val_mae: 0.8856 - val_mse: 2.0643\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9012 - mae: 0.7275 - mse: 0.9012 - val_loss: 3.2270 - val_mae: 1.2715 - val_mse: 3.2270\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9105 - mae: 0.7221 - mse: 0.9105 - val_loss: 2.0612 - val_mae: 0.8837 - val_mse: 2.0612\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8407 - mae: 0.6938 - mse: 0.8407 - val_loss: 2.3932 - val_mae: 1.0290 - val_mse: 2.3932\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9252 - mae: 0.7346 - mse: 0.9252 - val_loss: 2.0174 - val_mae: 0.8809 - val_mse: 2.0174\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9143 - mae: 0.7316 - mse: 0.9143 - val_loss: 2.1475 - val_mae: 0.9187 - val_mse: 2.1475\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8986 - mae: 0.7321 - mse: 0.8986 - val_loss: 2.1389 - val_mae: 0.9087 - val_mse: 2.1389\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8791 - mae: 0.7113 - mse: 0.8791 - val_loss: 2.7688 - val_mae: 1.1240 - val_mse: 2.7688\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8517 - mae: 0.7003 - mse: 0.8517 - val_loss: 2.1721 - val_mae: 1.0030 - val_mse: 2.1721\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9119 - mae: 0.7295 - mse: 0.9119 - val_loss: 2.7403 - val_mae: 1.1017 - val_mse: 2.7403\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8377 - mae: 0.6946 - mse: 0.8377 - val_loss: 3.3471 - val_mae: 1.2938 - val_mse: 3.3471\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8690 - mae: 0.7175 - mse: 0.8690 - val_loss: 2.7543 - val_mae: 1.1026 - val_mse: 2.7543\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8702 - mae: 0.7130 - mse: 0.8702 - val_loss: 1.9996 - val_mae: 0.8796 - val_mse: 1.9996\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9134 - mae: 0.7366 - mse: 0.9134 - val_loss: 2.0083 - val_mae: 0.9533 - val_mse: 2.0083\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8571 - mae: 0.7003 - mse: 0.8571 - val_loss: 2.0672 - val_mae: 0.9650 - val_mse: 2.0672\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8855 - mae: 0.7113 - mse: 0.8855 - val_loss: 2.3414 - val_mae: 0.9866 - val_mse: 2.3414\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8795 - mae: 0.7075 - mse: 0.8795 - val_loss: 1.9603 - val_mae: 0.8833 - val_mse: 1.9603\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8480 - mae: 0.6930 - mse: 0.8480 - val_loss: 1.8907 - val_mae: 0.8594 - val_mse: 1.8907\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8452 - mae: 0.6938 - mse: 0.8452 - val_loss: 2.0400 - val_mae: 0.8843 - val_mse: 2.0400\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8548 - mae: 0.6996 - mse: 0.8548 - val_loss: 2.1745 - val_mae: 1.0344 - val_mse: 2.1745\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9187 - mae: 0.7248 - mse: 0.9187 - val_loss: 2.0191 - val_mae: 0.8778 - val_mse: 2.0191\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8217 - mae: 0.6986 - mse: 0.8217 - val_loss: 1.9254 - val_mae: 0.8712 - val_mse: 1.9254\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8488 - mae: 0.7092 - mse: 0.8488 - val_loss: 2.3277 - val_mae: 0.9599 - val_mse: 2.3277\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8696 - mae: 0.7047 - mse: 0.8696 - val_loss: 2.0918 - val_mae: 0.8978 - val_mse: 2.0918\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7345 - mae: 0.6519 - mse: 0.7345 - val_loss: 1.8521 - val_mae: 0.8677 - val_mse: 1.8521\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8651 - mae: 0.7067 - mse: 0.8651 - val_loss: 1.9906 - val_mae: 0.8855 - val_mse: 1.9906\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7613 - mae: 0.6707 - mse: 0.7613 - val_loss: 2.6858 - val_mae: 1.0955 - val_mse: 2.6858\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8248 - mae: 0.6953 - mse: 0.8248 - val_loss: 1.9889 - val_mae: 0.9204 - val_mse: 1.9889\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8108 - mae: 0.6760 - mse: 0.8108 - val_loss: 1.9750 - val_mae: 0.8735 - val_mse: 1.9750\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7836 - mae: 0.6768 - mse: 0.7836 - val_loss: 2.0069 - val_mae: 0.8764 - val_mse: 2.0069\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7967 - mae: 0.6755 - mse: 0.7967 - val_loss: 1.9955 - val_mae: 0.8914 - val_mse: 1.9955\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7686 - mae: 0.6702 - mse: 0.7686 - val_loss: 1.9585 - val_mae: 0.8925 - val_mse: 1.9585\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7727 - mae: 0.6719 - mse: 0.7727 - val_loss: 2.4729 - val_mae: 1.0296 - val_mse: 2.4729\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8335 - mae: 0.6961 - mse: 0.8335 - val_loss: 2.1884 - val_mae: 1.0565 - val_mse: 2.1884\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8218 - mae: 0.6873 - mse: 0.8218 - val_loss: 2.0669 - val_mae: 0.9034 - val_mse: 2.0669\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7948 - mae: 0.6793 - mse: 0.7948 - val_loss: 2.2779 - val_mae: 0.9849 - val_mse: 2.2779\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7964 - mae: 0.6749 - mse: 0.7964 - val_loss: 2.0380 - val_mae: 0.8918 - val_mse: 2.0380\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7435 - mae: 0.6600 - mse: 0.7435 - val_loss: 2.9927 - val_mae: 1.1843 - val_mse: 2.9927\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7943 - mae: 0.6801 - mse: 0.7943 - val_loss: 2.0470 - val_mae: 0.9331 - val_mse: 2.0470\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7847 - mae: 0.6802 - mse: 0.7847 - val_loss: 1.9438 - val_mae: 0.9226 - val_mse: 1.9438\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7807 - mae: 0.6682 - mse: 0.7807 - val_loss: 2.0399 - val_mae: 0.8952 - val_mse: 2.0399\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7263 - mae: 0.6458 - mse: 0.7263 - val_loss: 2.4500 - val_mae: 1.0206 - val_mse: 2.4500\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7712 - mae: 0.6620 - mse: 0.7712 - val_loss: 1.9736 - val_mae: 0.8823 - val_mse: 1.9736\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7483 - mae: 0.6555 - mse: 0.7483 - val_loss: 1.9698 - val_mae: 0.8771 - val_mse: 1.9698\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7534 - mae: 0.6679 - mse: 0.7534 - val_loss: 2.6546 - val_mae: 1.0945 - val_mse: 2.6546\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7762 - mae: 0.6746 - mse: 0.7762 - val_loss: 2.1766 - val_mae: 0.9308 - val_mse: 2.1766\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7301 - mae: 0.6466 - mse: 0.7301 - val_loss: 2.0013 - val_mae: 0.9017 - val_mse: 2.0013\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7394 - mae: 0.6584 - mse: 0.7394 - val_loss: 2.0866 - val_mae: 0.9438 - val_mse: 2.0866\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7722 - mae: 0.6626 - mse: 0.7722 - val_loss: 1.9871 - val_mae: 0.9292 - val_mse: 1.9871\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7311 - mae: 0.6453 - mse: 0.7311 - val_loss: 1.9748 - val_mae: 0.8914 - val_mse: 1.9748\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7346 - mae: 0.6532 - mse: 0.7346 - val_loss: 2.2843 - val_mae: 0.9927 - val_mse: 2.2843\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7092 - mae: 0.6385 - mse: 0.7092 - val_loss: 1.9525 - val_mae: 0.9088 - val_mse: 1.9525\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7166 - mae: 0.6561 - mse: 0.7166 - val_loss: 1.9480 - val_mae: 0.9220 - val_mse: 1.9480\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7179 - mae: 0.6418 - mse: 0.7179 - val_loss: 1.9728 - val_mae: 0.8928 - val_mse: 1.9728\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7620 - mae: 0.6660 - mse: 0.7620 - val_loss: 2.1816 - val_mae: 1.0500 - val_mse: 2.1816\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6946 - mae: 0.6323 - mse: 0.6946 - val_loss: 2.0699 - val_mae: 0.8970 - val_mse: 2.0699\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7296 - mae: 0.6558 - mse: 0.7296 - val_loss: 2.2002 - val_mae: 0.9678 - val_mse: 2.2002\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7035 - mae: 0.6306 - mse: 0.7035 - val_loss: 2.0439 - val_mae: 0.9052 - val_mse: 2.0439\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7219 - mae: 0.6489 - mse: 0.7219 - val_loss: 2.2657 - val_mae: 0.9526 - val_mse: 2.2657\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7087 - mae: 0.6271 - mse: 0.7087 - val_loss: 2.0425 - val_mae: 0.8931 - val_mse: 2.0425\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6985 - mae: 0.6175 - mse: 0.6985 - val_loss: 2.0420 - val_mae: 0.9037 - val_mse: 2.0420\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6741 - mae: 0.6239 - mse: 0.6741 - val_loss: 2.0563 - val_mae: 1.0033 - val_mse: 2.0563\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6976 - mae: 0.6254 - mse: 0.6976 - val_loss: 2.0618 - val_mae: 0.9110 - val_mse: 2.0618\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6825 - mae: 0.6310 - mse: 0.6825 - val_loss: 2.1255 - val_mae: 0.9300 - val_mse: 2.1255\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6902 - mae: 0.6238 - mse: 0.6902 - val_loss: 1.9111 - val_mae: 0.8959 - val_mse: 1.9111\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7288 - mae: 0.6437 - mse: 0.7288 - val_loss: 1.9654 - val_mae: 0.8922 - val_mse: 1.9654\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6841 - mae: 0.6311 - mse: 0.6841 - val_loss: 2.3148 - val_mae: 0.9784 - val_mse: 2.3148\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6143 - mae: 0.5892 - mse: 0.6143 - val_loss: 2.0542 - val_mae: 0.9172 - val_mse: 2.0542\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6973 - mae: 0.6313 - mse: 0.6973 - val_loss: 2.1973 - val_mae: 0.9460 - val_mse: 2.1973\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7288 - mae: 0.6402 - mse: 0.7288 - val_loss: 1.9485 - val_mae: 0.8908 - val_mse: 1.9485\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6724 - mae: 0.6246 - mse: 0.6724 - val_loss: 1.9668 - val_mae: 0.8952 - val_mse: 1.9668\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.6718 - mae: 0.6214 - mse: 0.6718 - val_loss: 2.0526 - val_mae: 0.9168 - val_mse: 2.0526\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6420 - mae: 0.6055 - mse: 0.6420 - val_loss: 2.2858 - val_mae: 0.9960 - val_mse: 2.2858\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6604 - mae: 0.6154 - mse: 0.6604 - val_loss: 2.0152 - val_mae: 0.8986 - val_mse: 2.0152\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6193 - mae: 0.5884 - mse: 0.6193 - val_loss: 2.0199 - val_mae: 0.9048 - val_mse: 2.0199\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6589 - mae: 0.6203 - mse: 0.6589 - val_loss: 2.3914 - val_mae: 0.9938 - val_mse: 2.3914\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6410 - mae: 0.6073 - mse: 0.6410 - val_loss: 1.9735 - val_mae: 0.9539 - val_mse: 1.9735\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6546 - mae: 0.6029 - mse: 0.6546 - val_loss: 2.2618 - val_mae: 0.9738 - val_mse: 2.2618\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6493 - mae: 0.6049 - mse: 0.6493 - val_loss: 2.3803 - val_mae: 0.9938 - val_mse: 2.3803\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6561 - mae: 0.6126 - mse: 0.6561 - val_loss: 2.0796 - val_mae: 0.9235 - val_mse: 2.0796\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6500 - mae: 0.6008 - mse: 0.6500 - val_loss: 1.8684 - val_mae: 0.8914 - val_mse: 1.8684\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6295 - mae: 0.5971 - mse: 0.6295 - val_loss: 1.9684 - val_mae: 0.9194 - val_mse: 1.9684\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6397 - mae: 0.5988 - mse: 0.6397 - val_loss: 2.0180 - val_mae: 1.0296 - val_mse: 2.0180\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5948 - mae: 0.5905 - mse: 0.5948 - val_loss: 1.8862 - val_mae: 0.9121 - val_mse: 1.8862\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6051 - mae: 0.5920 - mse: 0.6051 - val_loss: 1.9486 - val_mae: 0.9118 - val_mse: 1.9486\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6028 - mae: 0.5877 - mse: 0.6028 - val_loss: 1.8637 - val_mae: 0.8978 - val_mse: 1.8637\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6106 - mae: 0.5952 - mse: 0.6106 - val_loss: 1.8431 - val_mae: 0.9298 - val_mse: 1.8431\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6084 - mae: 0.5829 - mse: 0.6084 - val_loss: 1.8522 - val_mae: 0.8902 - val_mse: 1.8522\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6189 - mae: 0.5932 - mse: 0.6189 - val_loss: 1.9844 - val_mae: 0.9402 - val_mse: 1.9844\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5913 - mae: 0.5770 - mse: 0.5913 - val_loss: 1.9036 - val_mae: 0.9216 - val_mse: 1.9036\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5626 - mae: 0.5597 - mse: 0.5626 - val_loss: 2.3159 - val_mae: 0.9821 - val_mse: 2.3159\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6051 - mae: 0.5917 - mse: 0.6051 - val_loss: 1.9973 - val_mae: 0.9132 - val_mse: 1.9973\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6125 - mae: 0.5934 - mse: 0.6125 - val_loss: 1.9091 - val_mae: 0.9019 - val_mse: 1.9091\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5601 - mae: 0.5654 - mse: 0.5601 - val_loss: 2.0493 - val_mae: 0.9281 - val_mse: 2.0493\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6122 - mae: 0.5925 - mse: 0.6122 - val_loss: 1.9814 - val_mae: 0.9264 - val_mse: 1.9814\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6308 - mae: 0.5904 - mse: 0.6308 - val_loss: 2.1497 - val_mae: 0.9559 - val_mse: 2.1497\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5394 - mae: 0.5463 - mse: 0.5394 - val_loss: 2.0099 - val_mae: 0.9444 - val_mse: 2.0099\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5430 - mae: 0.5627 - mse: 0.5430 - val_loss: 2.6737 - val_mae: 1.1005 - val_mse: 2.6737\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 903us/step - loss: 0.5452 - mae: 0.5579 - mse: 0.5452 - val_loss: 2.0405 - val_mae: 0.9300 - val_mse: 2.0405\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.5680 - mae: 0.5752 - mse: 0.5680 - val_loss: 3.0040 - val_mae: 1.1612 - val_mse: 3.0040\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5588 - mae: 0.5716 - mse: 0.5588 - val_loss: 2.3946 - val_mae: 1.0017 - val_mse: 2.3946\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5771 - mae: 0.5746 - mse: 0.5771 - val_loss: 2.1508 - val_mae: 0.9559 - val_mse: 2.1508\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 994us/step - loss: 0.5597 - mae: 0.5658 - mse: 0.5597 - val_loss: 2.0935 - val_mae: 0.9442 - val_mse: 2.0935\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5340 - mae: 0.5487 - mse: 0.5340 - val_loss: 2.2802 - val_mae: 0.9740 - val_mse: 2.2802\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5544 - mae: 0.5574 - mse: 0.5544 - val_loss: 2.1627 - val_mae: 0.9718 - val_mse: 2.1627\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5440 - mae: 0.5525 - mse: 0.5440 - val_loss: 2.0691 - val_mae: 0.9460 - val_mse: 2.0691\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5810 - mae: 0.5778 - mse: 0.5810 - val_loss: 3.2119 - val_mae: 1.2225 - val_mse: 3.2119\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5161 - mae: 0.5389 - mse: 0.5161 - val_loss: 2.6185 - val_mae: 1.0959 - val_mse: 2.6185\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5524 - mae: 0.5514 - mse: 0.5524 - val_loss: 1.9413 - val_mae: 0.9471 - val_mse: 1.9413\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5418 - mae: 0.5473 - mse: 0.5418 - val_loss: 2.0036 - val_mae: 0.9307 - val_mse: 2.0036\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5582 - mae: 0.5691 - mse: 0.5582 - val_loss: 2.2723 - val_mae: 0.9825 - val_mse: 2.2723\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5422 - mae: 0.5642 - mse: 0.5422 - val_loss: 1.9184 - val_mae: 0.9177 - val_mse: 1.9184\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5186 - mae: 0.5433 - mse: 0.5186 - val_loss: 2.3584 - val_mae: 1.0375 - val_mse: 2.3584\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5117 - mae: 0.5363 - mse: 0.5117 - val_loss: 2.0153 - val_mae: 0.9198 - val_mse: 2.0153\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5239 - mae: 0.5568 - mse: 0.5239 - val_loss: 2.0962 - val_mae: 0.9543 - val_mse: 2.0962\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5670 - mae: 0.5737 - mse: 0.5670 - val_loss: 1.8811 - val_mae: 0.9410 - val_mse: 1.8811\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5252 - mae: 0.5530 - mse: 0.5252 - val_loss: 1.7978 - val_mae: 0.9168 - val_mse: 1.7978\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5108 - mae: 0.5398 - mse: 0.5108 - val_loss: 2.0053 - val_mae: 0.9343 - val_mse: 2.0053\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5611 - mae: 0.5653 - mse: 0.5611 - val_loss: 2.2901 - val_mae: 0.9871 - val_mse: 2.2901\n",
      "Epoch 210/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4945 - mae: 0.5288 - mse: 0.4945 - val_loss: 2.0028 - val_mae: 0.9259 - val_mse: 2.0028\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5197 - mae: 0.5405 - mse: 0.5197 - val_loss: 2.1030 - val_mae: 1.0524 - val_mse: 2.1030\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5284 - mae: 0.5506 - mse: 0.5284 - val_loss: 2.4605 - val_mae: 1.0192 - val_mse: 2.4605\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5096 - mae: 0.5372 - mse: 0.5096 - val_loss: 2.2602 - val_mae: 0.9789 - val_mse: 2.2602\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4651 - mae: 0.5195 - mse: 0.4651 - val_loss: 2.6187 - val_mae: 1.0480 - val_mse: 2.6187\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5090 - mae: 0.5385 - mse: 0.5090 - val_loss: 1.9836 - val_mae: 0.9279 - val_mse: 1.9836\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4735 - mae: 0.5258 - mse: 0.4735 - val_loss: 2.1219 - val_mae: 0.9457 - val_mse: 2.1219\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5146 - mae: 0.5292 - mse: 0.5146 - val_loss: 2.6721 - val_mae: 1.0933 - val_mse: 2.6721\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5122 - mae: 0.5416 - mse: 0.5122 - val_loss: 2.0434 - val_mae: 0.9432 - val_mse: 2.0434\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5071 - mae: 0.5395 - mse: 0.5071 - val_loss: 2.0066 - val_mae: 0.9305 - val_mse: 2.0066\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5279 - mae: 0.5490 - mse: 0.5279 - val_loss: 1.9362 - val_mae: 0.9405 - val_mse: 1.9362\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4847 - mae: 0.5186 - mse: 0.4847 - val_loss: 2.3504 - val_mae: 1.0078 - val_mse: 2.3504\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4932 - mae: 0.5293 - mse: 0.4932 - val_loss: 1.9866 - val_mae: 0.9498 - val_mse: 1.9866\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4928 - mae: 0.5398 - mse: 0.4928 - val_loss: 2.4509 - val_mae: 1.0309 - val_mse: 2.4509\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4595 - mae: 0.5088 - mse: 0.4595 - val_loss: 1.7663 - val_mae: 0.9252 - val_mse: 1.7663\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4947 - mae: 0.5224 - mse: 0.4947 - val_loss: 2.2607 - val_mae: 0.9836 - val_mse: 2.2607\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5088 - mae: 0.5344 - mse: 0.5088 - val_loss: 1.9742 - val_mae: 0.9863 - val_mse: 1.9742\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4913 - mae: 0.5276 - mse: 0.4913 - val_loss: 2.1171 - val_mae: 0.9606 - val_mse: 2.1171\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4813 - mae: 0.5268 - mse: 0.4813 - val_loss: 1.9836 - val_mae: 0.9394 - val_mse: 1.9836\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4722 - mae: 0.5124 - mse: 0.4722 - val_loss: 2.2563 - val_mae: 0.9751 - val_mse: 2.2563\n",
      "Epoch 230/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4759 - mae: 0.5220 - mse: 0.4759 - val_loss: 1.9047 - val_mae: 0.9517 - val_mse: 1.9047\n",
      "Epoch 231/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4560 - mae: 0.5071 - mse: 0.4560 - val_loss: 2.0925 - val_mae: 0.9593 - val_mse: 2.0925\n",
      "Epoch 232/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4493 - mae: 0.5055 - mse: 0.4493 - val_loss: 1.9310 - val_mae: 0.9328 - val_mse: 1.9310\n",
      "Epoch 233/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4664 - mae: 0.5110 - mse: 0.4664 - val_loss: 2.3191 - val_mae: 1.0327 - val_mse: 2.3191\n",
      "Epoch 234/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4770 - mae: 0.5123 - mse: 0.4770 - val_loss: 2.4953 - val_mae: 1.0478 - val_mse: 2.4953\n",
      "Epoch 235/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4150 - mae: 0.4994 - mse: 0.4150 - val_loss: 2.0067 - val_mae: 0.9416 - val_mse: 2.0067\n",
      "Epoch 236/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4222 - mae: 0.4859 - mse: 0.4222 - val_loss: 1.8901 - val_mae: 0.9497 - val_mse: 1.8901\n",
      "Epoch 237/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4532 - mae: 0.5045 - mse: 0.4532 - val_loss: 2.3938 - val_mae: 1.0232 - val_mse: 2.3938\n",
      "Epoch 238/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4441 - mae: 0.5082 - mse: 0.4441 - val_loss: 2.0380 - val_mae: 0.9498 - val_mse: 2.0380\n",
      "Epoch 239/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4029 - mae: 0.4717 - mse: 0.4029 - val_loss: 2.6710 - val_mae: 1.0800 - val_mse: 2.6710\n",
      "Epoch 240/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4750 - mae: 0.5170 - mse: 0.4750 - val_loss: 1.9966 - val_mae: 0.9382 - val_mse: 1.9966\n",
      "Epoch 241/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4488 - mae: 0.4981 - mse: 0.4488 - val_loss: 2.0636 - val_mae: 0.9561 - val_mse: 2.0636\n",
      "Epoch 242/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4490 - mae: 0.5104 - mse: 0.4490 - val_loss: 2.3926 - val_mae: 1.0217 - val_mse: 2.3926\n",
      "Epoch 243/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4666 - mae: 0.5087 - mse: 0.4666 - val_loss: 2.1398 - val_mae: 0.9649 - val_mse: 2.1398\n",
      "Epoch 244/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4172 - mae: 0.4846 - mse: 0.4172 - val_loss: 2.0293 - val_mae: 1.0083 - val_mse: 2.0293\n",
      "Epoch 245/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4406 - mae: 0.4976 - mse: 0.4406 - val_loss: 2.4125 - val_mae: 1.0195 - val_mse: 2.4125\n",
      "Epoch 246/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4080 - mae: 0.4770 - mse: 0.4080 - val_loss: 2.8687 - val_mae: 1.1513 - val_mse: 2.8687\n",
      "Epoch 247/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4326 - mae: 0.4978 - mse: 0.4326 - val_loss: 2.3733 - val_mae: 1.0355 - val_mse: 2.3733\n",
      "Epoch 248/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4090 - mae: 0.4730 - mse: 0.4090 - val_loss: 2.1319 - val_mae: 0.9961 - val_mse: 2.1319\n",
      "Epoch 249/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4475 - mae: 0.4997 - mse: 0.4475 - val_loss: 2.0064 - val_mae: 0.9402 - val_mse: 2.0064\n",
      "Epoch 250/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4247 - mae: 0.4910 - mse: 0.4247 - val_loss: 2.0371 - val_mae: 0.9566 - val_mse: 2.0371\n",
      "Epoch 251/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4306 - mae: 0.4901 - mse: 0.4306 - val_loss: 2.1075 - val_mae: 1.0488 - val_mse: 2.1075\n",
      "Epoch 252/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4187 - mae: 0.4854 - mse: 0.4187 - val_loss: 1.9683 - val_mae: 0.9665 - val_mse: 1.9683\n",
      "Epoch 253/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3992 - mae: 0.4747 - mse: 0.3992 - val_loss: 2.1753 - val_mae: 0.9639 - val_mse: 2.1753\n",
      "Epoch 254/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4027 - mae: 0.4844 - mse: 0.4027 - val_loss: 2.1070 - val_mae: 0.9503 - val_mse: 2.1070\n",
      "Epoch 255/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3837 - mae: 0.4643 - mse: 0.3837 - val_loss: 2.5522 - val_mae: 1.0679 - val_mse: 2.5522\n",
      "Epoch 256/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4187 - mae: 0.4846 - mse: 0.4187 - val_loss: 2.0865 - val_mae: 0.9575 - val_mse: 2.0865\n",
      "Epoch 257/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3739 - mae: 0.4595 - mse: 0.3739 - val_loss: 2.0369 - val_mae: 0.9668 - val_mse: 2.0369\n",
      "Epoch 258/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4190 - mae: 0.4877 - mse: 0.4190 - val_loss: 2.2143 - val_mae: 0.9829 - val_mse: 2.2143\n",
      "Epoch 259/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4243 - mae: 0.4959 - mse: 0.4243 - val_loss: 1.9420 - val_mae: 0.9617 - val_mse: 1.9420\n",
      "Epoch 260/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3714 - mae: 0.4578 - mse: 0.3714 - val_loss: 2.0303 - val_mae: 0.9501 - val_mse: 2.0303\n",
      "Epoch 261/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3859 - mae: 0.4631 - mse: 0.3859 - val_loss: 1.9593 - val_mae: 1.0240 - val_mse: 1.9593\n",
      "Epoch 262/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4099 - mae: 0.4781 - mse: 0.4099 - val_loss: 1.9126 - val_mae: 0.9361 - val_mse: 1.9126\n",
      "Epoch 263/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3763 - mae: 0.4687 - mse: 0.3763 - val_loss: 2.1294 - val_mae: 0.9666 - val_mse: 2.1294\n",
      "Epoch 264/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3565 - mae: 0.4511 - mse: 0.3565 - val_loss: 2.0807 - val_mae: 1.0614 - val_mse: 2.0807\n",
      "Epoch 265/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3835 - mae: 0.4577 - mse: 0.3835 - val_loss: 2.2417 - val_mae: 0.9895 - val_mse: 2.2417\n",
      "Epoch 266/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4205 - mae: 0.4827 - mse: 0.4205 - val_loss: 2.0572 - val_mae: 0.9486 - val_mse: 2.0572\n",
      "Epoch 267/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3861 - mae: 0.4722 - mse: 0.3861 - val_loss: 2.2875 - val_mae: 1.0165 - val_mse: 2.2875\n",
      "Epoch 268/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3680 - mae: 0.4608 - mse: 0.3680 - val_loss: 2.3843 - val_mae: 1.0187 - val_mse: 2.3843\n",
      "Epoch 269/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3573 - mae: 0.4523 - mse: 0.3573 - val_loss: 2.3288 - val_mae: 1.0421 - val_mse: 2.3288\n",
      "Epoch 270/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3945 - mae: 0.4747 - mse: 0.3945 - val_loss: 1.9955 - val_mae: 0.9826 - val_mse: 1.9955\n",
      "Epoch 271/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3797 - mae: 0.4671 - mse: 0.3797 - val_loss: 2.2612 - val_mae: 0.9780 - val_mse: 2.2612\n",
      "Epoch 272/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3511 - mae: 0.4449 - mse: 0.3511 - val_loss: 1.8698 - val_mae: 0.9235 - val_mse: 1.8698\n",
      "Epoch 273/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3749 - mae: 0.4658 - mse: 0.3749 - val_loss: 2.1755 - val_mae: 0.9778 - val_mse: 2.1755\n",
      "Epoch 274/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3622 - mae: 0.4509 - mse: 0.3622 - val_loss: 2.1027 - val_mae: 0.9601 - val_mse: 2.1027\n",
      "Epoch 275/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3669 - mae: 0.4574 - mse: 0.3669 - val_loss: 2.6980 - val_mae: 1.1046 - val_mse: 2.6980\n",
      "Epoch 276/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3687 - mae: 0.4572 - mse: 0.3687 - val_loss: 1.9709 - val_mae: 1.0239 - val_mse: 1.9709\n",
      "Epoch 277/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3615 - mae: 0.4472 - mse: 0.3615 - val_loss: 2.2476 - val_mae: 1.0070 - val_mse: 2.2476\n",
      "Epoch 278/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3725 - mae: 0.4537 - mse: 0.3725 - val_loss: 3.0430 - val_mae: 1.1702 - val_mse: 3.0430\n",
      "Epoch 279/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3219 - mae: 0.4229 - mse: 0.3219 - val_loss: 1.9273 - val_mae: 0.9459 - val_mse: 1.9273\n",
      "Epoch 280/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3435 - mae: 0.4414 - mse: 0.3435 - val_loss: 2.2802 - val_mae: 0.9925 - val_mse: 2.2802\n",
      "Epoch 281/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3256 - mae: 0.4305 - mse: 0.3256 - val_loss: 2.4653 - val_mae: 1.0634 - val_mse: 2.4653\n",
      "Epoch 282/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3239 - mae: 0.4231 - mse: 0.3239 - val_loss: 2.6115 - val_mae: 1.0732 - val_mse: 2.6115\n",
      "Epoch 283/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3479 - mae: 0.4442 - mse: 0.3479 - val_loss: 1.9115 - val_mae: 1.0025 - val_mse: 1.9115\n",
      "Epoch 284/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3473 - mae: 0.4454 - mse: 0.3473 - val_loss: 1.9621 - val_mae: 1.0016 - val_mse: 1.9621\n",
      "Epoch 285/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3169 - mae: 0.4187 - mse: 0.3169 - val_loss: 2.0400 - val_mae: 0.9611 - val_mse: 2.0400\n",
      "Epoch 286/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3529 - mae: 0.4382 - mse: 0.3529 - val_loss: 2.2600 - val_mae: 0.9944 - val_mse: 2.2600\n",
      "Epoch 287/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3279 - mae: 0.4365 - mse: 0.3279 - val_loss: 2.2632 - val_mae: 1.0077 - val_mse: 2.2632\n",
      "Epoch 288/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3488 - mae: 0.4504 - mse: 0.3488 - val_loss: 1.9996 - val_mae: 1.0377 - val_mse: 1.9996\n",
      "Epoch 289/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3156 - mae: 0.4251 - mse: 0.3156 - val_loss: 2.2494 - val_mae: 1.0084 - val_mse: 2.2494\n",
      "Epoch 290/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3371 - mae: 0.4303 - mse: 0.3371 - val_loss: 2.0084 - val_mae: 0.9587 - val_mse: 2.0084\n",
      "Epoch 291/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3255 - mae: 0.4349 - mse: 0.3255 - val_loss: 1.9866 - val_mae: 0.9361 - val_mse: 1.9866\n",
      "Epoch 292/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3181 - mae: 0.4366 - mse: 0.3181 - val_loss: 2.0998 - val_mae: 1.0009 - val_mse: 2.0998\n",
      "Epoch 293/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2790 - mae: 0.3978 - mse: 0.2790 - val_loss: 1.9551 - val_mae: 0.9637 - val_mse: 1.9551\n",
      "Epoch 294/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3252 - mae: 0.4437 - mse: 0.3252 - val_loss: 2.0227 - val_mae: 0.9460 - val_mse: 2.0227\n",
      "Epoch 295/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3302 - mae: 0.4429 - mse: 0.3302 - val_loss: 2.2830 - val_mae: 0.9945 - val_mse: 2.2830\n",
      "Epoch 296/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3054 - mae: 0.4198 - mse: 0.3054 - val_loss: 1.9840 - val_mae: 0.9842 - val_mse: 1.9840\n",
      "Epoch 297/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3331 - mae: 0.4299 - mse: 0.3331 - val_loss: 2.4656 - val_mae: 1.0313 - val_mse: 2.4656\n",
      "Epoch 298/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2886 - mae: 0.3955 - mse: 0.2886 - val_loss: 1.9467 - val_mae: 1.0340 - val_mse: 1.9467\n",
      "Epoch 299/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3325 - mae: 0.4353 - mse: 0.3325 - val_loss: 2.1089 - val_mae: 1.0323 - val_mse: 2.1089\n",
      "Epoch 300/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3401 - mae: 0.4229 - mse: 0.3401 - val_loss: 2.0794 - val_mae: 0.9717 - val_mse: 2.0794\n",
      "Epoch 301/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2802 - mae: 0.4006 - mse: 0.2802 - val_loss: 2.3135 - val_mae: 1.0129 - val_mse: 2.3135\n",
      "Epoch 302/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3262 - mae: 0.4330 - mse: 0.3262 - val_loss: 2.2470 - val_mae: 0.9708 - val_mse: 2.2470\n",
      "Epoch 303/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2966 - mae: 0.4093 - mse: 0.2966 - val_loss: 2.8825 - val_mae: 1.1253 - val_mse: 2.8825\n",
      "Epoch 304/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2742 - mae: 0.3899 - mse: 0.2742 - val_loss: 2.1632 - val_mae: 0.9920 - val_mse: 2.1632\n",
      "Epoch 305/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2996 - mae: 0.4128 - mse: 0.2996 - val_loss: 2.0062 - val_mae: 0.9769 - val_mse: 2.0062\n",
      "Epoch 306/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3043 - mae: 0.4155 - mse: 0.3043 - val_loss: 3.0034 - val_mae: 1.1524 - val_mse: 3.0034\n",
      "Epoch 307/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3167 - mae: 0.4346 - mse: 0.3167 - val_loss: 2.0965 - val_mae: 0.9710 - val_mse: 2.0965\n",
      "Epoch 308/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2606 - mae: 0.3787 - mse: 0.2606 - val_loss: 2.1384 - val_mae: 0.9869 - val_mse: 2.1384\n",
      "Epoch 309/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2976 - mae: 0.4073 - mse: 0.2976 - val_loss: 2.6385 - val_mae: 1.0863 - val_mse: 2.6385\n",
      "Epoch 310/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2896 - mae: 0.3991 - mse: 0.2896 - val_loss: 2.0087 - val_mae: 0.9651 - val_mse: 2.0087\n",
      "Epoch 311/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2902 - mae: 0.3967 - mse: 0.2902 - val_loss: 2.0485 - val_mae: 0.9768 - val_mse: 2.0485\n",
      "Epoch 312/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3084 - mae: 0.4155 - mse: 0.3084 - val_loss: 2.1402 - val_mae: 0.9741 - val_mse: 2.1402\n",
      "Epoch 313/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3050 - mae: 0.4146 - mse: 0.3050 - val_loss: 2.4048 - val_mae: 1.0386 - val_mse: 2.4048\n",
      "Epoch 314/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2877 - mae: 0.3893 - mse: 0.2877 - val_loss: 1.9826 - val_mae: 1.0146 - val_mse: 1.9826\n",
      "Epoch 315/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2711 - mae: 0.3875 - mse: 0.2711 - val_loss: 2.3622 - val_mae: 1.0559 - val_mse: 2.3622\n",
      "Epoch 316/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2939 - mae: 0.4149 - mse: 0.2939 - val_loss: 2.0457 - val_mae: 0.9641 - val_mse: 2.0457\n",
      "Epoch 317/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2906 - mae: 0.4123 - mse: 0.2906 - val_loss: 1.9688 - val_mae: 1.0046 - val_mse: 1.9688\n",
      "Epoch 318/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2562 - mae: 0.3787 - mse: 0.2562 - val_loss: 2.3697 - val_mae: 1.0257 - val_mse: 2.3697\n",
      "Epoch 319/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2829 - mae: 0.4120 - mse: 0.2829 - val_loss: 2.1086 - val_mae: 0.9721 - val_mse: 2.1086\n",
      "Epoch 320/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2507 - mae: 0.3693 - mse: 0.2507 - val_loss: 2.0063 - val_mae: 1.0312 - val_mse: 2.0063\n",
      "Epoch 321/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2804 - mae: 0.3988 - mse: 0.2804 - val_loss: 2.5500 - val_mae: 1.1021 - val_mse: 2.5500\n",
      "Epoch 322/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2960 - mae: 0.4002 - mse: 0.2960 - val_loss: 2.1826 - val_mae: 0.9690 - val_mse: 2.1826\n",
      "Epoch 323/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2600 - mae: 0.3868 - mse: 0.2600 - val_loss: 2.4258 - val_mae: 1.0142 - val_mse: 2.4258\n",
      "Epoch 324/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2881 - mae: 0.4044 - mse: 0.2881 - val_loss: 2.6628 - val_mae: 1.0911 - val_mse: 2.6628\n",
      "Kappa Score: 0.6278302727758959\n",
      "\n",
      "###########Set-3###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 90.6478 - mae: 5.3477 - mse: 90.6478 - val_loss: 26.3299 - val_mae: 4.6149 - val_mse: 26.3299\n",
      "Epoch 2/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 19.2094 - mae: 2.9639 - mse: 19.2094 - val_loss: 60.6997 - val_mae: 7.1748 - val_mse: 60.6997\n",
      "Epoch 3/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 13.2253 - mae: 2.8205 - mse: 13.2253 - val_loss: 1.5482 - val_mae: 0.9720 - val_mse: 1.5482\n",
      "Epoch 4/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 8.4639 - mae: 2.3448 - mse: 8.4639 - val_loss: 9.9766 - val_mae: 2.9526 - val_mse: 9.9766\n",
      "Epoch 5/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 4.4050 - mae: 1.6623 - mse: 4.4050 - val_loss: 6.2763 - val_mae: 2.1882 - val_mse: 6.2763\n",
      "Epoch 6/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.7182 - mae: 1.5454 - mse: 3.7182 - val_loss: 1.2573 - val_mae: 0.8495 - val_mse: 1.2573\n",
      "Epoch 7/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.1508 - mae: 1.4178 - mse: 3.1508 - val_loss: 1.3966 - val_mae: 0.8792 - val_mse: 1.3966\n",
      "Epoch 8/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.6597 - mae: 1.3117 - mse: 2.6597 - val_loss: 1.4022 - val_mae: 0.9035 - val_mse: 1.4022\n",
      "Epoch 9/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.4243 - mae: 1.2279 - mse: 2.4243 - val_loss: 1.7132 - val_mae: 0.9845 - val_mse: 1.7132\n",
      "Epoch 10/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.0161 - mae: 1.1257 - mse: 2.0161 - val_loss: 1.0778 - val_mae: 0.8064 - val_mse: 1.0778\n",
      "Epoch 11/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.1287 - mae: 1.1499 - mse: 2.1287 - val_loss: 3.0328 - val_mae: 1.5114 - val_mse: 3.0328\n",
      "Epoch 12/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.9886 - mae: 1.1241 - mse: 1.9886 - val_loss: 2.4791 - val_mae: 1.3243 - val_mse: 2.4791\n",
      "Epoch 13/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6982 - mae: 1.0190 - mse: 1.6982 - val_loss: 1.1084 - val_mae: 0.8294 - val_mse: 1.1084\n",
      "Epoch 14/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7071 - mae: 1.0399 - mse: 1.7071 - val_loss: 1.3408 - val_mae: 0.8885 - val_mse: 1.3408\n",
      "Epoch 15/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.8085 - mae: 1.0494 - mse: 1.8085 - val_loss: 1.0467 - val_mae: 0.7890 - val_mse: 1.0467\n",
      "Epoch 16/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6760 - mae: 1.0131 - mse: 1.6760 - val_loss: 1.9842 - val_mae: 1.1521 - val_mse: 1.9842\n",
      "Epoch 17/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6674 - mae: 1.0034 - mse: 1.6674 - val_loss: 1.2312 - val_mae: 0.8811 - val_mse: 1.2312\n",
      "Epoch 18/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6631 - mae: 1.0091 - mse: 1.6631 - val_loss: 1.0932 - val_mae: 0.8255 - val_mse: 1.0932\n",
      "Epoch 19/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4606 - mae: 0.9284 - mse: 1.4606 - val_loss: 2.0658 - val_mae: 1.1769 - val_mse: 2.0658\n",
      "Epoch 20/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5125 - mae: 0.9531 - mse: 1.5125 - val_loss: 1.0603 - val_mae: 0.7929 - val_mse: 1.0603\n",
      "Epoch 21/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3630 - mae: 0.9050 - mse: 1.3630 - val_loss: 1.9606 - val_mae: 1.1065 - val_mse: 1.9606\n",
      "Epoch 22/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5343 - mae: 0.9740 - mse: 1.5343 - val_loss: 0.9644 - val_mae: 0.7740 - val_mse: 0.9644\n",
      "Epoch 23/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4649 - mae: 0.9318 - mse: 1.4649 - val_loss: 1.2567 - val_mae: 0.8908 - val_mse: 1.2567\n",
      "Epoch 24/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4633 - mae: 0.9402 - mse: 1.4633 - val_loss: 1.0223 - val_mae: 0.7785 - val_mse: 1.0223\n",
      "Epoch 25/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5252 - mae: 0.9483 - mse: 1.5252 - val_loss: 0.9508 - val_mae: 0.7580 - val_mse: 0.9508\n",
      "Epoch 26/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3460 - mae: 0.9033 - mse: 1.3460 - val_loss: 1.4270 - val_mae: 0.9374 - val_mse: 1.4270\n",
      "Epoch 27/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4972 - mae: 0.9609 - mse: 1.4972 - val_loss: 0.9239 - val_mae: 0.7503 - val_mse: 0.9239\n",
      "Epoch 28/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3718 - mae: 0.9185 - mse: 1.3718 - val_loss: 1.0800 - val_mae: 0.8035 - val_mse: 1.0800\n",
      "Epoch 29/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4677 - mae: 0.9489 - mse: 1.4677 - val_loss: 0.9559 - val_mae: 0.7716 - val_mse: 0.9559\n",
      "Epoch 30/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3985 - mae: 0.9053 - mse: 1.3985 - val_loss: 1.3600 - val_mae: 0.9298 - val_mse: 1.3600\n",
      "Epoch 31/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3088 - mae: 0.8870 - mse: 1.3088 - val_loss: 1.7001 - val_mae: 1.0540 - val_mse: 1.7001\n",
      "Epoch 32/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3507 - mae: 0.9045 - mse: 1.3507 - val_loss: 2.5041 - val_mae: 1.3397 - val_mse: 2.5041\n",
      "Epoch 33/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3453 - mae: 0.9031 - mse: 1.3453 - val_loss: 1.5855 - val_mae: 0.9927 - val_mse: 1.5855\n",
      "Epoch 34/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3551 - mae: 0.9064 - mse: 1.3551 - val_loss: 1.0244 - val_mae: 0.7836 - val_mse: 1.0244\n",
      "Epoch 35/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3157 - mae: 0.8995 - mse: 1.3157 - val_loss: 1.0905 - val_mae: 0.8071 - val_mse: 1.0905\n",
      "Epoch 36/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3076 - mae: 0.8930 - mse: 1.3076 - val_loss: 1.1532 - val_mae: 0.8590 - val_mse: 1.1532\n",
      "Epoch 37/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4220 - mae: 0.9114 - mse: 1.4220 - val_loss: 0.9584 - val_mae: 0.7535 - val_mse: 0.9584\n",
      "Epoch 38/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2351 - mae: 0.8595 - mse: 1.2351 - val_loss: 0.9352 - val_mae: 0.7622 - val_mse: 0.9352\n",
      "Epoch 39/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2694 - mae: 0.8711 - mse: 1.2694 - val_loss: 1.8751 - val_mae: 1.1220 - val_mse: 1.8751\n",
      "Epoch 40/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3225 - mae: 0.8978 - mse: 1.3225 - val_loss: 1.0101 - val_mae: 0.7743 - val_mse: 1.0101\n",
      "Epoch 41/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2703 - mae: 0.8823 - mse: 1.2703 - val_loss: 1.2292 - val_mae: 0.8662 - val_mse: 1.2292\n",
      "Epoch 42/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2890 - mae: 0.8765 - mse: 1.2890 - val_loss: 0.9197 - val_mae: 0.7538 - val_mse: 0.9197\n",
      "Epoch 43/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2186 - mae: 0.8679 - mse: 1.2186 - val_loss: 1.0830 - val_mae: 0.8301 - val_mse: 1.0830\n",
      "Epoch 44/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2870 - mae: 0.8916 - mse: 1.2870 - val_loss: 0.8549 - val_mae: 0.7204 - val_mse: 0.8549\n",
      "Epoch 45/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2685 - mae: 0.8673 - mse: 1.2685 - val_loss: 1.6197 - val_mae: 1.0373 - val_mse: 1.6197\n",
      "Epoch 46/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2197 - mae: 0.8640 - mse: 1.2197 - val_loss: 0.9019 - val_mae: 0.7346 - val_mse: 0.9019\n",
      "Epoch 47/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2195 - mae: 0.8504 - mse: 1.2195 - val_loss: 1.1104 - val_mae: 0.8224 - val_mse: 1.1104\n",
      "Epoch 48/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1769 - mae: 0.8428 - mse: 1.1769 - val_loss: 0.9232 - val_mae: 0.7540 - val_mse: 0.9232\n",
      "Epoch 49/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2375 - mae: 0.8801 - mse: 1.2375 - val_loss: 0.8816 - val_mae: 0.7378 - val_mse: 0.8816\n",
      "Epoch 50/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1759 - mae: 0.8345 - mse: 1.1759 - val_loss: 1.1041 - val_mae: 0.8422 - val_mse: 1.1041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1249 - mae: 0.8324 - mse: 1.1249 - val_loss: 0.9104 - val_mae: 0.7544 - val_mse: 0.9104\n",
      "Epoch 52/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1781 - mae: 0.8338 - mse: 1.1781 - val_loss: 1.5373 - val_mae: 1.0088 - val_mse: 1.5373\n",
      "Epoch 53/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2153 - mae: 0.8630 - mse: 1.2153 - val_loss: 1.2887 - val_mae: 0.8845 - val_mse: 1.2887\n",
      "Epoch 54/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2153 - mae: 0.8569 - mse: 1.2153 - val_loss: 1.1999 - val_mae: 0.8804 - val_mse: 1.1999\n",
      "Epoch 55/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1974 - mae: 0.8503 - mse: 1.1974 - val_loss: 1.4955 - val_mae: 0.9928 - val_mse: 1.4955\n",
      "Epoch 56/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2343 - mae: 0.8620 - mse: 1.2343 - val_loss: 0.8462 - val_mae: 0.7163 - val_mse: 0.8462\n",
      "Epoch 57/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0854 - mae: 0.8089 - mse: 1.0854 - val_loss: 0.9481 - val_mae: 0.7560 - val_mse: 0.9481\n",
      "Epoch 58/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1744 - mae: 0.8390 - mse: 1.1744 - val_loss: 1.0448 - val_mae: 0.7937 - val_mse: 1.0448\n",
      "Epoch 59/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0722 - mae: 0.8033 - mse: 1.0722 - val_loss: 1.9058 - val_mae: 1.1508 - val_mse: 1.9058\n",
      "Epoch 60/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1011 - mae: 0.8107 - mse: 1.1011 - val_loss: 0.8719 - val_mae: 0.7318 - val_mse: 0.8719\n",
      "Epoch 61/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0606 - mae: 0.8072 - mse: 1.0606 - val_loss: 0.8648 - val_mae: 0.7236 - val_mse: 0.8648\n",
      "Epoch 62/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1683 - mae: 0.8384 - mse: 1.1683 - val_loss: 1.0347 - val_mae: 0.7937 - val_mse: 1.0347\n",
      "Epoch 63/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0487 - mae: 0.7993 - mse: 1.0487 - val_loss: 1.5218 - val_mae: 1.0072 - val_mse: 1.5218\n",
      "Epoch 64/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1510 - mae: 0.8267 - mse: 1.1510 - val_loss: 0.8041 - val_mae: 0.6989 - val_mse: 0.8041\n",
      "Epoch 65/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0282 - mae: 0.7787 - mse: 1.0282 - val_loss: 0.8474 - val_mae: 0.7257 - val_mse: 0.8474\n",
      "Epoch 66/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0675 - mae: 0.8183 - mse: 1.0675 - val_loss: 1.1153 - val_mae: 0.8503 - val_mse: 1.1153\n",
      "Epoch 67/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0582 - mae: 0.7936 - mse: 1.0582 - val_loss: 0.9247 - val_mae: 0.7666 - val_mse: 0.9247\n",
      "Epoch 68/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1567 - mae: 0.8311 - mse: 1.1567 - val_loss: 0.8493 - val_mae: 0.7156 - val_mse: 0.8493\n",
      "Epoch 69/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0538 - mae: 0.7900 - mse: 1.0538 - val_loss: 0.8013 - val_mae: 0.6963 - val_mse: 0.8013\n",
      "Epoch 70/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0613 - mae: 0.8013 - mse: 1.0613 - val_loss: 0.8637 - val_mae: 0.7406 - val_mse: 0.8637\n",
      "Epoch 71/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0564 - mae: 0.7961 - mse: 1.0564 - val_loss: 0.8868 - val_mae: 0.7499 - val_mse: 0.8868\n",
      "Epoch 72/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0016 - mae: 0.7772 - mse: 1.0016 - val_loss: 1.4502 - val_mae: 0.9889 - val_mse: 1.4502\n",
      "Epoch 73/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1001 - mae: 0.8061 - mse: 1.1001 - val_loss: 1.2600 - val_mae: 0.8914 - val_mse: 1.2600\n",
      "Epoch 74/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0937 - mae: 0.8019 - mse: 1.0937 - val_loss: 0.8529 - val_mae: 0.7330 - val_mse: 0.8529\n",
      "Epoch 75/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0130 - mae: 0.7784 - mse: 1.0130 - val_loss: 0.8538 - val_mae: 0.7333 - val_mse: 0.8538\n",
      "Epoch 76/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9908 - mae: 0.7672 - mse: 0.9908 - val_loss: 1.3089 - val_mae: 0.9342 - val_mse: 1.3089\n",
      "Epoch 77/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0173 - mae: 0.7995 - mse: 1.0173 - val_loss: 0.8657 - val_mae: 0.7405 - val_mse: 0.8657\n",
      "Epoch 78/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9676 - mae: 0.7597 - mse: 0.9676 - val_loss: 1.4409 - val_mae: 0.9856 - val_mse: 1.4409\n",
      "Epoch 79/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0358 - mae: 0.7732 - mse: 1.0358 - val_loss: 1.1029 - val_mae: 0.8455 - val_mse: 1.1029\n",
      "Epoch 80/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0948 - mae: 0.8129 - mse: 1.0948 - val_loss: 0.7898 - val_mae: 0.6944 - val_mse: 0.7898\n",
      "Epoch 81/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9643 - mae: 0.7512 - mse: 0.9643 - val_loss: 1.5038 - val_mae: 0.9859 - val_mse: 1.5038\n",
      "Epoch 82/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0358 - mae: 0.7873 - mse: 1.0358 - val_loss: 0.7930 - val_mae: 0.6961 - val_mse: 0.7930\n",
      "Epoch 83/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9573 - mae: 0.7433 - mse: 0.9573 - val_loss: 0.7885 - val_mae: 0.6925 - val_mse: 0.7885\n",
      "Epoch 84/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9929 - mae: 0.7646 - mse: 0.9929 - val_loss: 0.9005 - val_mae: 0.7327 - val_mse: 0.9005\n",
      "Epoch 85/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0919 - mae: 0.8096 - mse: 1.0919 - val_loss: 0.9844 - val_mae: 0.7972 - val_mse: 0.9844\n",
      "Epoch 86/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9682 - mae: 0.7600 - mse: 0.9682 - val_loss: 0.7896 - val_mae: 0.6916 - val_mse: 0.7896\n",
      "Epoch 87/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9563 - mae: 0.7530 - mse: 0.9563 - val_loss: 1.4000 - val_mae: 0.9679 - val_mse: 1.4000\n",
      "Epoch 88/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0623 - mae: 0.7970 - mse: 1.0623 - val_loss: 0.9814 - val_mae: 0.7898 - val_mse: 0.9814\n",
      "Epoch 89/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9995 - mae: 0.7638 - mse: 0.9995 - val_loss: 1.0694 - val_mae: 0.8346 - val_mse: 1.0694\n",
      "Epoch 90/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9911 - mae: 0.7694 - mse: 0.9911 - val_loss: 0.7992 - val_mae: 0.7066 - val_mse: 0.7992\n",
      "Epoch 91/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9166 - mae: 0.7390 - mse: 0.9166 - val_loss: 1.6740 - val_mae: 1.0451 - val_mse: 1.6740\n",
      "Epoch 92/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9976 - mae: 0.7683 - mse: 0.9976 - val_loss: 1.4740 - val_mae: 0.9877 - val_mse: 1.4740\n",
      "Epoch 93/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9395 - mae: 0.7496 - mse: 0.9395 - val_loss: 0.8095 - val_mae: 0.7128 - val_mse: 0.8095\n",
      "Epoch 94/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9642 - mae: 0.7575 - mse: 0.9642 - val_loss: 1.2404 - val_mae: 0.8970 - val_mse: 1.2404\n",
      "Epoch 95/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8730 - mae: 0.7148 - mse: 0.8730 - val_loss: 0.7717 - val_mae: 0.6830 - val_mse: 0.7717\n",
      "Epoch 96/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9138 - mae: 0.7272 - mse: 0.9138 - val_loss: 1.5757 - val_mae: 1.0094 - val_mse: 1.5757\n",
      "Epoch 97/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9307 - mae: 0.7354 - mse: 0.9307 - val_loss: 0.8677 - val_mae: 0.7297 - val_mse: 0.8677\n",
      "Epoch 98/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9696 - mae: 0.7417 - mse: 0.9696 - val_loss: 1.0571 - val_mae: 0.8296 - val_mse: 1.0571\n",
      "Epoch 99/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9808 - mae: 0.7598 - mse: 0.9808 - val_loss: 0.8409 - val_mae: 0.7169 - val_mse: 0.8409\n",
      "Epoch 100/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9497 - mae: 0.7385 - mse: 0.9497 - val_loss: 1.1456 - val_mae: 0.8574 - val_mse: 1.1456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9590 - mae: 0.7551 - mse: 0.9590 - val_loss: 1.2205 - val_mae: 0.8964 - val_mse: 1.2205\n",
      "Epoch 102/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8723 - mae: 0.7132 - mse: 0.8723 - val_loss: 1.1423 - val_mae: 0.8603 - val_mse: 1.1423\n",
      "Epoch 103/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9468 - mae: 0.7370 - mse: 0.9468 - val_loss: 0.9489 - val_mae: 0.7842 - val_mse: 0.9489\n",
      "Epoch 104/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8922 - mae: 0.7204 - mse: 0.8922 - val_loss: 1.6378 - val_mae: 1.0610 - val_mse: 1.6378\n",
      "Epoch 105/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9352 - mae: 0.7302 - mse: 0.9352 - val_loss: 1.0229 - val_mae: 0.7911 - val_mse: 1.0229\n",
      "Epoch 106/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8739 - mae: 0.7044 - mse: 0.8739 - val_loss: 0.8551 - val_mae: 0.7176 - val_mse: 0.8551\n",
      "Epoch 107/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9210 - mae: 0.7392 - mse: 0.9210 - val_loss: 0.7933 - val_mae: 0.7071 - val_mse: 0.7933\n",
      "Epoch 108/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9289 - mae: 0.7400 - mse: 0.9289 - val_loss: 0.7592 - val_mae: 0.6796 - val_mse: 0.7592\n",
      "Epoch 109/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9351 - mae: 0.7415 - mse: 0.9351 - val_loss: 0.8062 - val_mae: 0.7071 - val_mse: 0.8062\n",
      "Epoch 110/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9304 - mae: 0.7394 - mse: 0.9304 - val_loss: 0.7701 - val_mae: 0.6858 - val_mse: 0.7701\n",
      "Epoch 111/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9368 - mae: 0.7455 - mse: 0.9368 - val_loss: 0.8801 - val_mae: 0.7507 - val_mse: 0.8801\n",
      "Epoch 112/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8873 - mae: 0.7180 - mse: 0.8873 - val_loss: 0.7755 - val_mae: 0.6914 - val_mse: 0.7755\n",
      "Epoch 113/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8832 - mae: 0.7113 - mse: 0.8832 - val_loss: 0.8089 - val_mae: 0.7073 - val_mse: 0.8089\n",
      "Epoch 114/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8749 - mae: 0.7183 - mse: 0.8749 - val_loss: 0.7958 - val_mae: 0.7006 - val_mse: 0.7958\n",
      "Epoch 115/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8751 - mae: 0.7106 - mse: 0.8751 - val_loss: 0.7635 - val_mae: 0.6861 - val_mse: 0.7635\n",
      "Epoch 116/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8853 - mae: 0.7236 - mse: 0.8853 - val_loss: 0.7526 - val_mae: 0.6768 - val_mse: 0.7526\n",
      "Epoch 117/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9037 - mae: 0.7209 - mse: 0.9037 - val_loss: 0.8030 - val_mae: 0.7036 - val_mse: 0.8030\n",
      "Epoch 118/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8661 - mae: 0.7057 - mse: 0.8661 - val_loss: 0.7791 - val_mae: 0.6836 - val_mse: 0.7791\n",
      "Epoch 119/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8825 - mae: 0.7151 - mse: 0.8825 - val_loss: 0.8974 - val_mae: 0.7475 - val_mse: 0.8974\n",
      "Epoch 120/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9175 - mae: 0.7372 - mse: 0.9175 - val_loss: 0.9690 - val_mae: 0.7807 - val_mse: 0.9690\n",
      "Epoch 121/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8830 - mae: 0.7265 - mse: 0.8830 - val_loss: 0.8939 - val_mae: 0.7532 - val_mse: 0.8939\n",
      "Epoch 122/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8723 - mae: 0.7179 - mse: 0.8723 - val_loss: 0.7599 - val_mae: 0.6794 - val_mse: 0.7599\n",
      "Epoch 123/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8544 - mae: 0.6955 - mse: 0.8544 - val_loss: 1.7263 - val_mae: 1.0727 - val_mse: 1.7263\n",
      "Epoch 124/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8624 - mae: 0.7115 - mse: 0.8624 - val_loss: 1.3468 - val_mae: 0.9303 - val_mse: 1.3468\n",
      "Epoch 125/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9657 - mae: 0.7513 - mse: 0.9657 - val_loss: 0.7610 - val_mae: 0.6834 - val_mse: 0.7610\n",
      "Epoch 126/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7786 - mae: 0.6696 - mse: 0.7786 - val_loss: 1.6710 - val_mae: 1.0461 - val_mse: 1.6710\n",
      "Epoch 127/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8564 - mae: 0.7068 - mse: 0.8564 - val_loss: 0.8788 - val_mae: 0.7438 - val_mse: 0.8788\n",
      "Epoch 128/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8604 - mae: 0.6997 - mse: 0.8604 - val_loss: 0.8020 - val_mae: 0.7026 - val_mse: 0.8020\n",
      "Epoch 129/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8220 - mae: 0.6828 - mse: 0.8220 - val_loss: 2.0060 - val_mae: 1.1849 - val_mse: 2.0060\n",
      "Epoch 130/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8897 - mae: 0.7216 - mse: 0.8897 - val_loss: 0.8823 - val_mae: 0.7450 - val_mse: 0.8823\n",
      "Epoch 131/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8767 - mae: 0.7154 - mse: 0.8767 - val_loss: 0.8106 - val_mae: 0.7108 - val_mse: 0.8106\n",
      "Epoch 132/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8736 - mae: 0.7143 - mse: 0.8736 - val_loss: 0.7664 - val_mae: 0.6867 - val_mse: 0.7664\n",
      "Epoch 133/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7834 - mae: 0.6737 - mse: 0.7834 - val_loss: 0.8194 - val_mae: 0.7138 - val_mse: 0.8194\n",
      "Epoch 134/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8528 - mae: 0.7030 - mse: 0.8528 - val_loss: 0.7651 - val_mae: 0.6882 - val_mse: 0.7651\n",
      "Epoch 135/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8137 - mae: 0.6934 - mse: 0.8137 - val_loss: 0.7656 - val_mae: 0.6785 - val_mse: 0.7656\n",
      "Epoch 136/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8746 - mae: 0.7121 - mse: 0.8746 - val_loss: 0.8356 - val_mae: 0.7157 - val_mse: 0.8356\n",
      "Epoch 137/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7435 - mae: 0.6560 - mse: 0.7435 - val_loss: 0.9442 - val_mae: 0.7717 - val_mse: 0.9442\n",
      "Epoch 138/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8480 - mae: 0.6997 - mse: 0.8480 - val_loss: 2.3657 - val_mae: 1.3144 - val_mse: 2.3657\n",
      "Epoch 139/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8318 - mae: 0.6936 - mse: 0.8318 - val_loss: 0.7928 - val_mae: 0.6962 - val_mse: 0.7928\n",
      "Epoch 140/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8094 - mae: 0.6787 - mse: 0.8094 - val_loss: 0.8675 - val_mae: 0.7303 - val_mse: 0.8675\n",
      "Epoch 141/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8217 - mae: 0.6977 - mse: 0.8217 - val_loss: 0.7720 - val_mae: 0.6883 - val_mse: 0.7720\n",
      "Epoch 142/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7669 - mae: 0.6706 - mse: 0.7669 - val_loss: 0.7640 - val_mae: 0.6871 - val_mse: 0.7640\n",
      "Epoch 143/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7855 - mae: 0.6665 - mse: 0.7855 - val_loss: 1.0334 - val_mae: 0.8095 - val_mse: 1.0334\n",
      "Epoch 144/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7875 - mae: 0.6675 - mse: 0.7875 - val_loss: 0.8685 - val_mae: 0.7458 - val_mse: 0.8685\n",
      "Epoch 145/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8178 - mae: 0.6881 - mse: 0.8178 - val_loss: 0.9939 - val_mae: 0.7897 - val_mse: 0.9939\n",
      "Epoch 146/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8141 - mae: 0.6973 - mse: 0.8141 - val_loss: 1.2881 - val_mae: 0.9216 - val_mse: 1.2881\n",
      "Epoch 147/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8185 - mae: 0.6875 - mse: 0.8185 - val_loss: 0.8665 - val_mae: 0.7268 - val_mse: 0.8665\n",
      "Epoch 148/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8021 - mae: 0.6760 - mse: 0.8021 - val_loss: 0.7430 - val_mae: 0.6730 - val_mse: 0.7430\n",
      "Epoch 149/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7839 - mae: 0.6626 - mse: 0.7839 - val_loss: 0.8965 - val_mae: 0.7547 - val_mse: 0.8965\n",
      "Epoch 150/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7907 - mae: 0.6648 - mse: 0.7907 - val_loss: 1.8999 - val_mae: 1.1454 - val_mse: 1.8999\n",
      "Epoch 151/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8234 - mae: 0.6881 - mse: 0.8234 - val_loss: 0.7536 - val_mae: 0.6831 - val_mse: 0.7536\n",
      "Epoch 152/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7926 - mae: 0.6788 - mse: 0.7926 - val_loss: 1.0688 - val_mae: 0.8306 - val_mse: 1.0688\n",
      "Epoch 153/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7775 - mae: 0.6779 - mse: 0.7775 - val_loss: 0.7563 - val_mae: 0.6763 - val_mse: 0.7563\n",
      "Epoch 154/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7776 - mae: 0.6660 - mse: 0.7776 - val_loss: 0.8467 - val_mae: 0.7263 - val_mse: 0.8467\n",
      "Epoch 155/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7800 - mae: 0.6860 - mse: 0.780 - 0s 2ms/step - loss: 0.7556 - mae: 0.6543 - mse: 0.7556 - val_loss: 0.7738 - val_mae: 0.6876 - val_mse: 0.7738\n",
      "Epoch 156/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8094 - mae: 0.6867 - mse: 0.8094 - val_loss: 1.1338 - val_mae: 0.8495 - val_mse: 1.1338\n",
      "Epoch 157/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7557 - mae: 0.6615 - mse: 0.7557 - val_loss: 0.8314 - val_mae: 0.7270 - val_mse: 0.8314\n",
      "Epoch 158/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7750 - mae: 0.6651 - mse: 0.7750 - val_loss: 0.9910 - val_mae: 0.7937 - val_mse: 0.9910\n",
      "Epoch 159/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7700 - mae: 0.6652 - mse: 0.7700 - val_loss: 0.8849 - val_mae: 0.7420 - val_mse: 0.8849\n",
      "Epoch 160/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7731 - mae: 0.6781 - mse: 0.7731 - val_loss: 0.7968 - val_mae: 0.7004 - val_mse: 0.7968\n",
      "Epoch 161/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6886 - mae: 0.6230 - mse: 0.6886 - val_loss: 1.0990 - val_mae: 0.8361 - val_mse: 1.0990\n",
      "Epoch 162/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8150 - mae: 0.6875 - mse: 0.8150 - val_loss: 1.1268 - val_mae: 0.8496 - val_mse: 1.1268\n",
      "Epoch 163/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7438 - mae: 0.6508 - mse: 0.7438 - val_loss: 0.7296 - val_mae: 0.6710 - val_mse: 0.7296\n",
      "Epoch 164/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7542 - mae: 0.6550 - mse: 0.7542 - val_loss: 0.7976 - val_mae: 0.6970 - val_mse: 0.7976\n",
      "Epoch 165/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7571 - mae: 0.6607 - mse: 0.7571 - val_loss: 0.8581 - val_mae: 0.7254 - val_mse: 0.8581\n",
      "Epoch 166/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7327 - mae: 0.6464 - mse: 0.7327 - val_loss: 1.0515 - val_mae: 0.8011 - val_mse: 1.0515\n",
      "Epoch 167/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7283 - mae: 0.6370 - mse: 0.7283 - val_loss: 0.8716 - val_mae: 0.7305 - val_mse: 0.8716\n",
      "Epoch 168/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7452 - mae: 0.6438 - mse: 0.7452 - val_loss: 0.8006 - val_mae: 0.6986 - val_mse: 0.8006\n",
      "Epoch 169/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7558 - mae: 0.6672 - mse: 0.7558 - val_loss: 0.9193 - val_mae: 0.7615 - val_mse: 0.9193\n",
      "Epoch 170/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7292 - mae: 0.6439 - mse: 0.7292 - val_loss: 1.3338 - val_mae: 0.9243 - val_mse: 1.3338\n",
      "Epoch 171/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7216 - mae: 0.6413 - mse: 0.7216 - val_loss: 1.0942 - val_mae: 0.8356 - val_mse: 1.0942\n",
      "Epoch 172/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7235 - mae: 0.6364 - mse: 0.7235 - val_loss: 0.9046 - val_mae: 0.7526 - val_mse: 0.9046\n",
      "Epoch 173/1000\n",
      "35/35 [==============================] - 0s 912us/step - loss: 0.7719 - mae: 0.6711 - mse: 0.7719 - val_loss: 0.7575 - val_mae: 0.6839 - val_mse: 0.7575\n",
      "Epoch 174/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7384 - mae: 0.6507 - mse: 0.7384 - val_loss: 0.7499 - val_mae: 0.6823 - val_mse: 0.7499\n",
      "Epoch 175/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6845 - mae: 0.6222 - mse: 0.6845 - val_loss: 0.7574 - val_mae: 0.6791 - val_mse: 0.7574\n",
      "Epoch 176/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7496 - mae: 0.6585 - mse: 0.7496 - val_loss: 0.7827 - val_mae: 0.6926 - val_mse: 0.7827\n",
      "Epoch 177/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7351 - mae: 0.6535 - mse: 0.7351 - val_loss: 0.8901 - val_mae: 0.7355 - val_mse: 0.8901\n",
      "Epoch 178/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7274 - mae: 0.6454 - mse: 0.7274 - val_loss: 0.7912 - val_mae: 0.6980 - val_mse: 0.7912\n",
      "Epoch 179/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6966 - mae: 0.6353 - mse: 0.6966 - val_loss: 1.3518 - val_mae: 0.9519 - val_mse: 1.3518\n",
      "Epoch 180/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6942 - mae: 0.6357 - mse: 0.6942 - val_loss: 0.7587 - val_mae: 0.6790 - val_mse: 0.7587\n",
      "Epoch 181/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6772 - mae: 0.6213 - mse: 0.6772 - val_loss: 0.7655 - val_mae: 0.6883 - val_mse: 0.7655\n",
      "Epoch 182/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7028 - mae: 0.6342 - mse: 0.7028 - val_loss: 0.7889 - val_mae: 0.6963 - val_mse: 0.7889\n",
      "Epoch 183/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7184 - mae: 0.6372 - mse: 0.7184 - val_loss: 0.7907 - val_mae: 0.6934 - val_mse: 0.7907\n",
      "Epoch 184/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6995 - mae: 0.6305 - mse: 0.6995 - val_loss: 0.8644 - val_mae: 0.7422 - val_mse: 0.8644\n",
      "Epoch 185/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7015 - mae: 0.6278 - mse: 0.7015 - val_loss: 0.9508 - val_mae: 0.7645 - val_mse: 0.9508\n",
      "Epoch 186/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8323 - mae: 0.6657 - mse: 0.8323 - val_loss: 0.9096 - val_mae: 0.7594 - val_mse: 0.9096\n",
      "Epoch 187/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6528 - mae: 0.6025 - mse: 0.6528 - val_loss: 0.8127 - val_mae: 0.6991 - val_mse: 0.8127\n",
      "Epoch 188/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7280 - mae: 0.6427 - mse: 0.7280 - val_loss: 1.2710 - val_mae: 0.9029 - val_mse: 1.2710\n",
      "Epoch 189/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7044 - mae: 0.6410 - mse: 0.7044 - val_loss: 0.9468 - val_mae: 0.7623 - val_mse: 0.9468\n",
      "Epoch 190/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6848 - mae: 0.6175 - mse: 0.6848 - val_loss: 1.0908 - val_mae: 0.8383 - val_mse: 1.0908\n",
      "Epoch 191/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6635 - mae: 0.6150 - mse: 0.6635 - val_loss: 0.9684 - val_mae: 0.7603 - val_mse: 0.9684\n",
      "Epoch 192/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6464 - mae: 0.6074 - mse: 0.6464 - val_loss: 1.2896 - val_mae: 0.9035 - val_mse: 1.2896\n",
      "Epoch 193/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6811 - mae: 0.6202 - mse: 0.6811 - val_loss: 0.8251 - val_mae: 0.7063 - val_mse: 0.8251\n",
      "Epoch 194/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7048 - mae: 0.6243 - mse: 0.7048 - val_loss: 0.9082 - val_mae: 0.7608 - val_mse: 0.9082\n",
      "Epoch 195/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7128 - mae: 0.6318 - mse: 0.7128 - val_loss: 0.8693 - val_mae: 0.7399 - val_mse: 0.8693\n",
      "Epoch 196/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6778 - mae: 0.6193 - mse: 0.6778 - val_loss: 0.7679 - val_mae: 0.6902 - val_mse: 0.7679\n",
      "Epoch 197/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7283 - mae: 0.6374 - mse: 0.7283 - val_loss: 0.8564 - val_mae: 0.7272 - val_mse: 0.8564\n",
      "Epoch 198/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6630 - mae: 0.6187 - mse: 0.6630 - val_loss: 0.8811 - val_mae: 0.7394 - val_mse: 0.8811\n",
      "Epoch 199/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6544 - mae: 0.6074 - mse: 0.6544 - val_loss: 0.9242 - val_mae: 0.7599 - val_mse: 0.9242\n",
      "Epoch 200/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6395 - mae: 0.5970 - mse: 0.6395 - val_loss: 1.3358 - val_mae: 0.9424 - val_mse: 1.3358\n",
      "Epoch 201/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6891 - mae: 0.6198 - mse: 0.6891 - val_loss: 0.7874 - val_mae: 0.6965 - val_mse: 0.7874\n",
      "Epoch 202/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6568 - mae: 0.6119 - mse: 0.6568 - val_loss: 0.9075 - val_mae: 0.7412 - val_mse: 0.9075\n",
      "Epoch 203/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7131 - mae: 0.6402 - mse: 0.7131 - val_loss: 0.7800 - val_mae: 0.6870 - val_mse: 0.7800\n",
      "Epoch 204/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6454 - mae: 0.6103 - mse: 0.6454 - val_loss: 1.3980 - val_mae: 0.9720 - val_mse: 1.3980\n",
      "Epoch 205/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6706 - mae: 0.6150 - mse: 0.6706 - val_loss: 0.8158 - val_mae: 0.7060 - val_mse: 0.8158\n",
      "Epoch 206/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6882 - mae: 0.6235 - mse: 0.6882 - val_loss: 0.9970 - val_mae: 0.7849 - val_mse: 0.9970\n",
      "Epoch 207/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6684 - mae: 0.6047 - mse: 0.6684 - val_loss: 0.8422 - val_mae: 0.7222 - val_mse: 0.8422\n",
      "Epoch 208/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6641 - mae: 0.6239 - mse: 0.6641 - val_loss: 0.9364 - val_mae: 0.7660 - val_mse: 0.9364\n",
      "Epoch 209/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6341 - mae: 0.5925 - mse: 0.6341 - val_loss: 0.9877 - val_mae: 0.7823 - val_mse: 0.9877\n",
      "Epoch 210/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6729 - mae: 0.6122 - mse: 0.6729 - val_loss: 0.8664 - val_mae: 0.7303 - val_mse: 0.8664\n",
      "Epoch 211/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6726 - mae: 0.6182 - mse: 0.6726 - val_loss: 0.8795 - val_mae: 0.7430 - val_mse: 0.8795\n",
      "Epoch 212/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.6384 - mae: 0.6064 - mse: 0.6384 - val_loss: 0.9410 - val_mae: 0.7665 - val_mse: 0.9410\n",
      "Epoch 213/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6658 - mae: 0.6018 - mse: 0.6658 - val_loss: 0.8394 - val_mae: 0.7145 - val_mse: 0.8394\n",
      "Epoch 214/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7018 - mae: 0.6332 - mse: 0.7018 - val_loss: 0.9738 - val_mae: 0.7695 - val_mse: 0.9738\n",
      "Epoch 215/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5972 - mae: 0.5851 - mse: 0.5972 - val_loss: 0.8325 - val_mae: 0.7133 - val_mse: 0.8325\n",
      "Epoch 216/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6336 - mae: 0.6147 - mse: 0.6336 - val_loss: 0.8010 - val_mae: 0.7024 - val_mse: 0.8010\n",
      "Epoch 217/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6314 - mae: 0.5958 - mse: 0.6314 - val_loss: 0.8896 - val_mae: 0.7496 - val_mse: 0.8896\n",
      "Epoch 218/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6727 - mae: 0.6249 - mse: 0.6727 - val_loss: 1.0877 - val_mae: 0.8154 - val_mse: 1.0877\n",
      "Epoch 219/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6142 - mae: 0.5834 - mse: 0.6142 - val_loss: 0.9964 - val_mae: 0.7955 - val_mse: 0.9964\n",
      "Epoch 220/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6743 - mae: 0.6160 - mse: 0.6743 - val_loss: 0.8198 - val_mae: 0.7105 - val_mse: 0.8198\n",
      "Epoch 221/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6246 - mae: 0.5886 - mse: 0.6246 - val_loss: 0.8524 - val_mae: 0.7236 - val_mse: 0.8524\n",
      "Epoch 222/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6142 - mae: 0.5939 - mse: 0.6142 - val_loss: 1.0193 - val_mae: 0.7989 - val_mse: 1.0193\n",
      "Epoch 223/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6484 - mae: 0.6050 - mse: 0.6484 - val_loss: 1.1353 - val_mae: 0.8477 - val_mse: 1.1353\n",
      "Epoch 224/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6641 - mae: 0.6137 - mse: 0.6641 - val_loss: 0.8609 - val_mae: 0.7303 - val_mse: 0.8609\n",
      "Epoch 225/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6079 - mae: 0.5848 - mse: 0.6079 - val_loss: 0.8024 - val_mae: 0.7003 - val_mse: 0.8024\n",
      "Epoch 226/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.6043 - mae: 0.5806 - mse: 0.6043 - val_loss: 0.8116 - val_mae: 0.7072 - val_mse: 0.8116\n",
      "Epoch 227/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6639 - mae: 0.6111 - mse: 0.6639 - val_loss: 1.2337 - val_mae: 0.8951 - val_mse: 1.2337\n",
      "Epoch 228/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6128 - mae: 0.5838 - mse: 0.6128 - val_loss: 1.5605 - val_mae: 0.9947 - val_mse: 1.5605\n",
      "Epoch 229/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6573 - mae: 0.6032 - mse: 0.6573 - val_loss: 0.8253 - val_mae: 0.7107 - val_mse: 0.8253\n",
      "Epoch 230/1000\n",
      "35/35 [==============================] - 0s 995us/step - loss: 0.6188 - mae: 0.5857 - mse: 0.6188 - val_loss: 0.8341 - val_mae: 0.7065 - val_mse: 0.8341\n",
      "Epoch 231/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6388 - mae: 0.5987 - mse: 0.6388 - val_loss: 0.8474 - val_mae: 0.7267 - val_mse: 0.8474\n",
      "Epoch 232/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5503 - mae: 0.5565 - mse: 0.5503 - val_loss: 1.2903 - val_mae: 0.9128 - val_mse: 1.2903\n",
      "Epoch 233/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6183 - mae: 0.5979 - mse: 0.6183 - val_loss: 0.8887 - val_mae: 0.7403 - val_mse: 0.8887\n",
      "Epoch 234/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5962 - mae: 0.5856 - mse: 0.5962 - val_loss: 1.0012 - val_mae: 0.7829 - val_mse: 1.0012\n",
      "Epoch 235/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6464 - mae: 0.6112 - mse: 0.6464 - val_loss: 0.8387 - val_mae: 0.7138 - val_mse: 0.8387\n",
      "Epoch 236/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5994 - mae: 0.5734 - mse: 0.5994 - val_loss: 0.9195 - val_mae: 0.7536 - val_mse: 0.9195\n",
      "Epoch 237/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5795 - mae: 0.5710 - mse: 0.5795 - val_loss: 1.2117 - val_mae: 0.8688 - val_mse: 1.2117\n",
      "Epoch 238/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5949 - mae: 0.5861 - mse: 0.5949 - val_loss: 0.8408 - val_mae: 0.7200 - val_mse: 0.8408\n",
      "Epoch 239/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5939 - mae: 0.5711 - mse: 0.5939 - val_loss: 0.9802 - val_mae: 0.7832 - val_mse: 0.9802\n",
      "Epoch 240/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6036 - mae: 0.5839 - mse: 0.6036 - val_loss: 0.8203 - val_mae: 0.7043 - val_mse: 0.8203\n",
      "Epoch 241/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5592 - mae: 0.5662 - mse: 0.5592 - val_loss: 0.8863 - val_mae: 0.7493 - val_mse: 0.8863\n",
      "Epoch 242/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5998 - mae: 0.5826 - mse: 0.5998 - val_loss: 0.9590 - val_mae: 0.7740 - val_mse: 0.9590\n",
      "Epoch 243/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5700 - mae: 0.5668 - mse: 0.5700 - val_loss: 0.9080 - val_mae: 0.7493 - val_mse: 0.9080\n",
      "Epoch 244/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5761 - mae: 0.5687 - mse: 0.5761 - val_loss: 0.8626 - val_mae: 0.7291 - val_mse: 0.8626\n",
      "Epoch 245/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5790 - mae: 0.5651 - mse: 0.5790 - val_loss: 1.1638 - val_mae: 0.8656 - val_mse: 1.1638\n",
      "Epoch 246/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6056 - mae: 0.5762 - mse: 0.6056 - val_loss: 1.1342 - val_mae: 0.8503 - val_mse: 1.1342\n",
      "Epoch 247/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5702 - mae: 0.5687 - mse: 0.5702 - val_loss: 0.8501 - val_mae: 0.7154 - val_mse: 0.8501\n",
      "Epoch 248/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5681 - mae: 0.5657 - mse: 0.5681 - val_loss: 1.5507 - val_mae: 0.9840 - val_mse: 1.5507\n",
      "Epoch 249/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5887 - mae: 0.5712 - mse: 0.5887 - val_loss: 0.8737 - val_mae: 0.7294 - val_mse: 0.8737\n",
      "Epoch 250/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6026 - mae: 0.5807 - mse: 0.6026 - val_loss: 0.8878 - val_mae: 0.7349 - val_mse: 0.8878\n",
      "Epoch 251/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5200 - mae: 0.5485 - mse: 0.5200 - val_loss: 0.8608 - val_mae: 0.7229 - val_mse: 0.8608\n",
      "Epoch 252/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5659 - mae: 0.5635 - mse: 0.5659 - val_loss: 0.8901 - val_mae: 0.7427 - val_mse: 0.8901\n",
      "Epoch 253/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5525 - mae: 0.5613 - mse: 0.5525 - val_loss: 0.9254 - val_mae: 0.7527 - val_mse: 0.9254\n",
      "Epoch 254/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5721 - mae: 0.5639 - mse: 0.5721 - val_loss: 1.2089 - val_mae: 0.8748 - val_mse: 1.2089\n",
      "Epoch 255/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5828 - mae: 0.5684 - mse: 0.5828 - val_loss: 0.9626 - val_mae: 0.7724 - val_mse: 0.9626\n",
      "Epoch 256/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5844 - mae: 0.5746 - mse: 0.5844 - val_loss: 0.9027 - val_mae: 0.7415 - val_mse: 0.9027\n",
      "Epoch 257/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5772 - mae: 0.5699 - mse: 0.5772 - val_loss: 0.9348 - val_mae: 0.7616 - val_mse: 0.9348\n",
      "Epoch 258/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5330 - mae: 0.5483 - mse: 0.5330 - val_loss: 1.0616 - val_mae: 0.8086 - val_mse: 1.0616\n",
      "Epoch 259/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5839 - mae: 0.5780 - mse: 0.5839 - val_loss: 0.8920 - val_mae: 0.7271 - val_mse: 0.8920\n",
      "Epoch 260/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5504 - mae: 0.5530 - mse: 0.5504 - val_loss: 1.0708 - val_mae: 0.8091 - val_mse: 1.0708\n",
      "Epoch 261/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5799 - mae: 0.5675 - mse: 0.5799 - val_loss: 0.9575 - val_mae: 0.7703 - val_mse: 0.9575\n",
      "Epoch 262/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5800 - mae: 0.5711 - mse: 0.5800 - val_loss: 1.0615 - val_mae: 0.8269 - val_mse: 1.0615\n",
      "Epoch 263/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5828 - mae: 0.5775 - mse: 0.5828 - val_loss: 0.9331 - val_mae: 0.7567 - val_mse: 0.9331\n",
      "Kappa Score: 0.7447071912211838\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 168.9489 - mae: 6.5467 - mse: 168.9489 - val_loss: 41.1433 - val_mae: 6.2042 - val_mse: 41.1433\n",
      "Epoch 2/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 32.9816 - mae: 5.1754 - mse: 32.9816 - val_loss: 32.1611 - val_mae: 5.1361 - val_mse: 32.1611\n",
      "Epoch 3/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 15.9136 - mae: 3.2425 - mse: 15.9136 - val_loss: 3.5452 - val_mae: 1.6336 - val_mse: 3.5452\n",
      "Epoch 4/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 8.9212 - mae: 2.2234 - mse: 8.9212 - val_loss: 1.9190 - val_mae: 1.0197 - val_mse: 1.9190\n",
      "Epoch 5/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 5.7697 - mae: 1.8093 - mse: 5.7697 - val_loss: 1.7358 - val_mae: 0.9856 - val_mse: 1.7358\n",
      "Epoch 6/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 4.0727 - mae: 1.6378 - mse: 4.0727 - val_loss: 2.0993 - val_mae: 1.0930 - val_mse: 2.0993\n",
      "Epoch 7/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.7683 - mae: 1.5700 - mse: 3.7683 - val_loss: 1.8136 - val_mae: 1.0298 - val_mse: 1.8136\n",
      "Epoch 8/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 2.8259 - mae: 1.3177 - mse: 2.8259 - val_loss: 5.7731 - val_mae: 2.1844 - val_mse: 5.7731\n",
      "Epoch 9/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.7845 - mae: 1.3190 - mse: 2.7845 - val_loss: 5.0813 - val_mae: 2.0449 - val_mse: 5.0813\n",
      "Epoch 10/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.6668 - mae: 1.2849 - mse: 2.6668 - val_loss: 3.8443 - val_mae: 1.7139 - val_mse: 3.8443\n",
      "Epoch 11/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.3702 - mae: 1.2262 - mse: 2.3702 - val_loss: 6.1323 - val_mae: 2.2548 - val_mse: 6.1323\n",
      "Epoch 12/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.0748 - mae: 1.1124 - mse: 2.0748 - val_loss: 1.1704 - val_mae: 0.8448 - val_mse: 1.1704\n",
      "Epoch 13/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.0908 - mae: 1.1477 - mse: 2.0908 - val_loss: 1.2332 - val_mae: 0.8641 - val_mse: 1.2332\n",
      "Epoch 14/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.8669 - mae: 1.0797 - mse: 1.8669 - val_loss: 2.0616 - val_mae: 1.1481 - val_mse: 2.0616\n",
      "Epoch 15/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.9330 - mae: 1.1185 - mse: 1.9330 - val_loss: 1.1486 - val_mae: 0.8341 - val_mse: 1.1486\n",
      "Epoch 16/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7956 - mae: 1.0498 - mse: 1.7956 - val_loss: 1.1366 - val_mae: 0.8308 - val_mse: 1.1366\n",
      "Epoch 17/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5959 - mae: 1.0024 - mse: 1.5959 - val_loss: 1.0881 - val_mae: 0.8128 - val_mse: 1.0881\n",
      "Epoch 18/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5226 - mae: 0.9781 - mse: 1.5226 - val_loss: 1.2842 - val_mae: 0.8775 - val_mse: 1.2842\n",
      "Epoch 19/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 1.4885 - mae: 0.9387 - mse: 1.4885 - val_loss: 1.2277 - val_mae: 0.8595 - val_mse: 1.2277\n",
      "Epoch 20/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 1.6810 - mae: 1.0158 - mse: 1.6810 - val_loss: 3.1014 - val_mae: 1.5140 - val_mse: 3.1014\n",
      "Epoch 21/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.4633 - mae: 0.9462 - mse: 1.4633 - val_loss: 1.0569 - val_mae: 0.8001 - val_mse: 1.0569\n",
      "Epoch 22/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4526 - mae: 0.9572 - mse: 1.4526 - val_loss: 1.0538 - val_mae: 0.7982 - val_mse: 1.0538\n",
      "Epoch 23/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4496 - mae: 0.9498 - mse: 1.4496 - val_loss: 1.6799 - val_mae: 1.0420 - val_mse: 1.6799\n",
      "Epoch 24/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4804 - mae: 0.9620 - mse: 1.4804 - val_loss: 1.3068 - val_mae: 0.9026 - val_mse: 1.3068\n",
      "Epoch 25/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5677 - mae: 0.9628 - mse: 1.5677 - val_loss: 2.7358 - val_mae: 1.4080 - val_mse: 2.7358\n",
      "Epoch 26/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4367 - mae: 0.9354 - mse: 1.4367 - val_loss: 1.1653 - val_mae: 0.8472 - val_mse: 1.1653\n",
      "Epoch 27/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2996 - mae: 0.9055 - mse: 1.2996 - val_loss: 1.1236 - val_mae: 0.8331 - val_mse: 1.1236\n",
      "Epoch 28/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.3857 - mae: 0.9087 - mse: 1.3857 - val_loss: 1.7042 - val_mae: 1.0223 - val_mse: 1.7042\n",
      "Epoch 29/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.3289 - mae: 0.9058 - mse: 1.3289 - val_loss: 1.0138 - val_mae: 0.7886 - val_mse: 1.0138\n",
      "Epoch 30/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.2876 - mae: 0.8862 - mse: 1.2876 - val_loss: 2.7653 - val_mae: 1.3594 - val_mse: 2.7653\n",
      "Epoch 31/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 1.5167 - mae: 0.9690 - mse: 1.5167 - val_loss: 1.1384 - val_mae: 0.8189 - val_mse: 1.1384\n",
      "Epoch 32/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.2529 - mae: 0.8745 - mse: 1.2529 - val_loss: 1.0389 - val_mae: 0.7888 - val_mse: 1.0389\n",
      "Epoch 33/1000\n",
      "35/35 [==============================] - 0s 979us/step - loss: 1.2725 - mae: 0.8892 - mse: 1.2725 - val_loss: 1.0842 - val_mae: 0.8154 - val_mse: 1.0842\n",
      "Epoch 34/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 997us/step - loss: 1.2686 - mae: 0.8780 - mse: 1.2686 - val_loss: 1.3919 - val_mae: 0.9344 - val_mse: 1.3919\n",
      "Epoch 35/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 1.2791 - mae: 0.8944 - mse: 1.2791 - val_loss: 0.9846 - val_mae: 0.7734 - val_mse: 0.9846\n",
      "Epoch 36/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1683 - mae: 0.8554 - mse: 1.1683 - val_loss: 3.0269 - val_mae: 1.4351 - val_mse: 3.0269\n",
      "Epoch 37/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3718 - mae: 0.9006 - mse: 1.3718 - val_loss: 1.8529 - val_mae: 1.0829 - val_mse: 1.8529\n",
      "Epoch 38/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2196 - mae: 0.8764 - mse: 1.2196 - val_loss: 1.0421 - val_mae: 0.8032 - val_mse: 1.0421\n",
      "Epoch 39/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2644 - mae: 0.8923 - mse: 1.2644 - val_loss: 1.1506 - val_mae: 0.8462 - val_mse: 1.1506\n",
      "Epoch 40/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2454 - mae: 0.8724 - mse: 1.2454 - val_loss: 1.0774 - val_mae: 0.8122 - val_mse: 1.0774\n",
      "Epoch 41/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2130 - mae: 0.8658 - mse: 1.2130 - val_loss: 0.9822 - val_mae: 0.7637 - val_mse: 0.9822\n",
      "Epoch 42/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3158 - mae: 0.8984 - mse: 1.3158 - val_loss: 1.2671 - val_mae: 0.8744 - val_mse: 1.2671\n",
      "Epoch 43/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1817 - mae: 0.8521 - mse: 1.1817 - val_loss: 1.1035 - val_mae: 0.8120 - val_mse: 1.1035\n",
      "Epoch 44/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1688 - mae: 0.8488 - mse: 1.1688 - val_loss: 1.1510 - val_mae: 0.8457 - val_mse: 1.1510\n",
      "Epoch 45/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1842 - mae: 0.8462 - mse: 1.1842 - val_loss: 1.6569 - val_mae: 1.0410 - val_mse: 1.6569\n",
      "Epoch 46/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 1.1641 - mae: 0.8477 - mse: 1.1641 - val_loss: 1.0215 - val_mae: 0.7799 - val_mse: 1.0215\n",
      "Epoch 47/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2246 - mae: 0.8647 - mse: 1.2246 - val_loss: 1.8035 - val_mae: 1.0968 - val_mse: 1.8035\n",
      "Epoch 48/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2078 - mae: 0.8782 - mse: 1.2078 - val_loss: 1.1474 - val_mae: 0.8463 - val_mse: 1.1474\n",
      "Epoch 49/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2173 - mae: 0.8547 - mse: 1.2173 - val_loss: 2.9116 - val_mae: 1.4708 - val_mse: 2.9116\n",
      "Epoch 50/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2942 - mae: 0.9026 - mse: 1.2942 - val_loss: 1.2921 - val_mae: 0.8980 - val_mse: 1.2921\n",
      "Epoch 51/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 1.1668 - mae: 0.8423 - mse: 1.1668 - val_loss: 2.1897 - val_mae: 1.2328 - val_mse: 2.1897\n",
      "Epoch 52/1000\n",
      "35/35 [==============================] - 0s 1000us/step - loss: 1.1631 - mae: 0.8434 - mse: 1.1631 - val_loss: 0.9687 - val_mae: 0.7544 - val_mse: 0.9687\n",
      "Epoch 53/1000\n",
      "35/35 [==============================] - 0s 986us/step - loss: 1.1119 - mae: 0.8221 - mse: 1.1119 - val_loss: 1.0539 - val_mae: 0.7898 - val_mse: 1.0539\n",
      "Epoch 54/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.1611 - mae: 0.8454 - mse: 1.1611 - val_loss: 1.1913 - val_mae: 0.8604 - val_mse: 1.1913\n",
      "Epoch 55/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1360 - mae: 0.8429 - mse: 1.1360 - val_loss: 0.9070 - val_mae: 0.7343 - val_mse: 0.9070\n",
      "Epoch 56/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1315 - mae: 0.8282 - mse: 1.1315 - val_loss: 0.9139 - val_mae: 0.7401 - val_mse: 0.9139\n",
      "Epoch 57/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.1419 - mae: 0.8365 - mse: 1.1419 - val_loss: 1.2690 - val_mae: 0.8916 - val_mse: 1.2690\n",
      "Epoch 58/1000\n",
      "35/35 [==============================] - 0s 995us/step - loss: 1.1810 - mae: 0.8503 - mse: 1.1810 - val_loss: 1.3122 - val_mae: 0.9038 - val_mse: 1.3122\n",
      "Epoch 59/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 1.1128 - mae: 0.8195 - mse: 1.1128 - val_loss: 1.9141 - val_mae: 1.1336 - val_mse: 1.9141\n",
      "Epoch 60/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 1.2068 - mae: 0.8713 - mse: 1.2068 - val_loss: 0.9023 - val_mae: 0.7363 - val_mse: 0.9023\n",
      "Epoch 61/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.0625 - mae: 0.8109 - mse: 1.0625 - val_loss: 1.4565 - val_mae: 0.9716 - val_mse: 1.4565\n",
      "Epoch 62/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0702 - mae: 0.8113 - mse: 1.0702 - val_loss: 1.3516 - val_mae: 0.9140 - val_mse: 1.3516\n",
      "Epoch 63/1000\n",
      "35/35 [==============================] - 0s 940us/step - loss: 1.1282 - mae: 0.8324 - mse: 1.1282 - val_loss: 0.9416 - val_mae: 0.7455 - val_mse: 0.9416\n",
      "Epoch 64/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0936 - mae: 0.8222 - mse: 1.0936 - val_loss: 1.5865 - val_mae: 1.0143 - val_mse: 1.5865\n",
      "Epoch 65/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0870 - mae: 0.8127 - mse: 1.0870 - val_loss: 0.9381 - val_mae: 0.7489 - val_mse: 0.9381\n",
      "Epoch 66/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0869 - mae: 0.8188 - mse: 1.0869 - val_loss: 1.7175 - val_mae: 1.0691 - val_mse: 1.7175\n",
      "Epoch 67/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.0886 - mae: 0.8150 - mse: 1.0886 - val_loss: 2.0841 - val_mae: 1.1872 - val_mse: 2.0841\n",
      "Epoch 68/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.0682 - mae: 0.8145 - mse: 1.0682 - val_loss: 0.9517 - val_mae: 0.7595 - val_mse: 0.9517\n",
      "Epoch 69/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0749 - mae: 0.8144 - mse: 1.0749 - val_loss: 0.9209 - val_mae: 0.7422 - val_mse: 0.9209\n",
      "Epoch 70/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1157 - mae: 0.8173 - mse: 1.1157 - val_loss: 1.0367 - val_mae: 0.7897 - val_mse: 1.0367\n",
      "Epoch 71/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1190 - mae: 0.8194 - mse: 1.1190 - val_loss: 1.1231 - val_mae: 0.8289 - val_mse: 1.1231\n",
      "Epoch 72/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.0576 - mae: 0.7908 - mse: 1.0576 - val_loss: 0.8772 - val_mae: 0.7169 - val_mse: 0.8772\n",
      "Epoch 73/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.1787 - mae: 0.8329 - mse: 1.1787 - val_loss: 1.0115 - val_mae: 0.7797 - val_mse: 1.0115\n",
      "Epoch 74/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0408 - mae: 0.7985 - mse: 1.0408 - val_loss: 1.0805 - val_mae: 0.8082 - val_mse: 1.0805\n",
      "Epoch 75/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0666 - mae: 0.7991 - mse: 1.0666 - val_loss: 1.2595 - val_mae: 0.8719 - val_mse: 1.2595\n",
      "Epoch 76/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0518 - mae: 0.7976 - mse: 1.0518 - val_loss: 1.1934 - val_mae: 0.8564 - val_mse: 1.1934\n",
      "Epoch 77/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9719 - mae: 0.7686 - mse: 0.9719 - val_loss: 1.7532 - val_mae: 1.0577 - val_mse: 1.7532\n",
      "Epoch 78/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0959 - mae: 0.8183 - mse: 1.0959 - val_loss: 0.8776 - val_mae: 0.7198 - val_mse: 0.8776\n",
      "Epoch 79/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9662 - mae: 0.7683 - mse: 0.9662 - val_loss: 1.4262 - val_mae: 0.9482 - val_mse: 1.4262\n",
      "Epoch 80/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0941 - mae: 0.8206 - mse: 1.0941 - val_loss: 0.8734 - val_mae: 0.7205 - val_mse: 0.8734\n",
      "Epoch 81/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0729 - mae: 0.8122 - mse: 1.0729 - val_loss: 0.9478 - val_mae: 0.7500 - val_mse: 0.9478\n",
      "Epoch 82/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9633 - mae: 0.7635 - mse: 0.9633 - val_loss: 1.2709 - val_mae: 0.8962 - val_mse: 1.2709\n",
      "Epoch 83/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1044 - mae: 0.8261 - mse: 1.1044 - val_loss: 0.8652 - val_mae: 0.7120 - val_mse: 0.8652\n",
      "Epoch 84/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0078 - mae: 0.7869 - mse: 1.0078 - val_loss: 0.9321 - val_mae: 0.7416 - val_mse: 0.9321\n",
      "Epoch 85/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0270 - mae: 0.7952 - mse: 1.0270 - val_loss: 2.1518 - val_mae: 1.2144 - val_mse: 2.1518\n",
      "Epoch 86/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0283 - mae: 0.7915 - mse: 1.0283 - val_loss: 1.1969 - val_mae: 0.8564 - val_mse: 1.1969\n",
      "Epoch 87/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9976 - mae: 0.7823 - mse: 0.9976 - val_loss: 1.0556 - val_mae: 0.7849 - val_mse: 1.0556\n",
      "Epoch 88/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0333 - mae: 0.7908 - mse: 1.0333 - val_loss: 0.9559 - val_mae: 0.7507 - val_mse: 0.9559\n",
      "Epoch 89/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0634 - mae: 0.8055 - mse: 1.0634 - val_loss: 1.0468 - val_mae: 0.7901 - val_mse: 1.0468\n",
      "Epoch 90/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9846 - mae: 0.7729 - mse: 0.9846 - val_loss: 0.9459 - val_mae: 0.7534 - val_mse: 0.9459\n",
      "Epoch 91/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9836 - mae: 0.7742 - mse: 0.9836 - val_loss: 1.2371 - val_mae: 0.8716 - val_mse: 1.2371\n",
      "Epoch 92/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.0567 - mae: 0.7998 - mse: 1.0567 - val_loss: 0.9255 - val_mae: 0.7398 - val_mse: 0.9255\n",
      "Epoch 93/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9977 - mae: 0.7713 - mse: 0.9977 - val_loss: 0.8843 - val_mae: 0.7225 - val_mse: 0.8843\n",
      "Epoch 94/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9857 - mae: 0.7689 - mse: 0.9857 - val_loss: 0.8923 - val_mae: 0.7288 - val_mse: 0.8923\n",
      "Epoch 95/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0005 - mae: 0.7663 - mse: 1.0005 - val_loss: 1.2350 - val_mae: 0.8715 - val_mse: 1.2350\n",
      "Epoch 96/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0174 - mae: 0.7819 - mse: 1.0174 - val_loss: 1.0852 - val_mae: 0.8057 - val_mse: 1.0852\n",
      "Epoch 97/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9910 - mae: 0.7770 - mse: 0.9910 - val_loss: 0.9950 - val_mae: 0.7668 - val_mse: 0.9950\n",
      "Epoch 98/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9608 - mae: 0.7644 - mse: 0.9608 - val_loss: 1.0141 - val_mae: 0.7841 - val_mse: 1.0141\n",
      "Epoch 99/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9606 - mae: 0.7560 - mse: 0.9606 - val_loss: 1.0937 - val_mae: 0.8178 - val_mse: 1.0937\n",
      "Epoch 100/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9581 - mae: 0.7570 - mse: 0.9581 - val_loss: 1.0108 - val_mae: 0.7842 - val_mse: 1.0108\n",
      "Epoch 101/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9328 - mae: 0.7462 - mse: 0.9328 - val_loss: 1.1562 - val_mae: 0.8387 - val_mse: 1.1562\n",
      "Epoch 102/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0026 - mae: 0.7736 - mse: 1.0026 - val_loss: 0.9232 - val_mae: 0.7399 - val_mse: 0.9232\n",
      "Epoch 103/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9778 - mae: 0.7705 - mse: 0.9778 - val_loss: 1.3503 - val_mae: 0.9227 - val_mse: 1.3503\n",
      "Epoch 104/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9280 - mae: 0.7379 - mse: 0.9280 - val_loss: 0.9118 - val_mae: 0.7357 - val_mse: 0.9118\n",
      "Epoch 105/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9998 - mae: 0.7743 - mse: 0.9998 - val_loss: 1.2729 - val_mae: 0.8884 - val_mse: 1.2729\n",
      "Epoch 106/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9560 - mae: 0.7557 - mse: 0.9560 - val_loss: 0.8560 - val_mae: 0.7040 - val_mse: 0.8560\n",
      "Epoch 107/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9376 - mae: 0.7400 - mse: 0.9376 - val_loss: 1.9118 - val_mae: 1.1211 - val_mse: 1.9118\n",
      "Epoch 108/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0120 - mae: 0.7657 - mse: 1.0120 - val_loss: 0.8717 - val_mae: 0.7152 - val_mse: 0.8717\n",
      "Epoch 109/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9402 - mae: 0.7535 - mse: 0.9402 - val_loss: 0.8551 - val_mae: 0.7064 - val_mse: 0.8551\n",
      "Epoch 110/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9091 - mae: 0.7449 - mse: 0.9091 - val_loss: 0.9796 - val_mae: 0.7673 - val_mse: 0.9796\n",
      "Epoch 111/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8735 - mae: 0.7204 - mse: 0.8735 - val_loss: 0.8982 - val_mae: 0.7230 - val_mse: 0.8982\n",
      "Epoch 112/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9527 - mae: 0.7525 - mse: 0.9527 - val_loss: 2.1157 - val_mae: 1.1958 - val_mse: 2.1157\n",
      "Epoch 113/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9317 - mae: 0.7351 - mse: 0.9317 - val_loss: 0.8518 - val_mae: 0.7089 - val_mse: 0.8518\n",
      "Epoch 114/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0096 - mae: 0.7699 - mse: 1.0096 - val_loss: 1.2638 - val_mae: 0.8795 - val_mse: 1.2638\n",
      "Epoch 115/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9600 - mae: 0.7689 - mse: 0.9600 - val_loss: 0.8514 - val_mae: 0.7069 - val_mse: 0.8514\n",
      "Epoch 116/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9091 - mae: 0.7325 - mse: 0.9091 - val_loss: 0.9726 - val_mae: 0.7628 - val_mse: 0.9726\n",
      "Epoch 117/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9155 - mae: 0.7449 - mse: 0.9155 - val_loss: 1.8356 - val_mae: 1.1165 - val_mse: 1.8356\n",
      "Epoch 118/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8999 - mae: 0.7301 - mse: 0.8999 - val_loss: 0.8690 - val_mae: 0.7140 - val_mse: 0.8690\n",
      "Epoch 119/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9219 - mae: 0.7364 - mse: 0.9219 - val_loss: 1.5055 - val_mae: 0.9731 - val_mse: 1.5055\n",
      "Epoch 120/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9003 - mae: 0.7241 - mse: 0.9003 - val_loss: 1.1924 - val_mae: 0.8620 - val_mse: 1.1924\n",
      "Epoch 121/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8920 - mae: 0.7204 - mse: 0.8920 - val_loss: 0.8903 - val_mae: 0.7196 - val_mse: 0.8903\n",
      "Epoch 122/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9438 - mae: 0.7590 - mse: 0.9438 - val_loss: 2.2754 - val_mae: 1.2609 - val_mse: 2.2754\n",
      "Epoch 123/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9103 - mae: 0.7397 - mse: 0.9103 - val_loss: 1.6453 - val_mae: 1.0424 - val_mse: 1.6453\n",
      "Epoch 124/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8679 - mae: 0.7152 - mse: 0.8679 - val_loss: 0.8395 - val_mae: 0.7003 - val_mse: 0.8395\n",
      "Epoch 125/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9302 - mae: 0.7437 - mse: 0.9302 - val_loss: 1.1374 - val_mae: 0.8354 - val_mse: 1.1374\n",
      "Epoch 126/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8398 - mae: 0.7019 - mse: 0.8398 - val_loss: 0.9870 - val_mae: 0.7597 - val_mse: 0.9870\n",
      "Epoch 127/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9080 - mae: 0.7299 - mse: 0.9080 - val_loss: 1.1828 - val_mae: 0.8535 - val_mse: 1.1828\n",
      "Epoch 128/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8184 - mae: 0.6900 - mse: 0.8184 - val_loss: 1.1323 - val_mae: 0.8254 - val_mse: 1.1323\n",
      "Epoch 129/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8981 - mae: 0.7233 - mse: 0.8981 - val_loss: 1.0429 - val_mae: 0.7941 - val_mse: 1.0429\n",
      "Epoch 130/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8981 - mae: 0.7320 - mse: 0.8981 - val_loss: 0.9057 - val_mae: 0.7262 - val_mse: 0.9057\n",
      "Epoch 131/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9375 - mae: 0.7482 - mse: 0.9375 - val_loss: 0.9976 - val_mae: 0.7543 - val_mse: 0.9976\n",
      "Epoch 132/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8707 - mae: 0.7149 - mse: 0.8707 - val_loss: 0.9499 - val_mae: 0.7576 - val_mse: 0.9499\n",
      "Epoch 133/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8043 - mae: 0.6947 - mse: 0.8043 - val_loss: 0.8278 - val_mae: 0.6872 - val_mse: 0.8278\n",
      "Epoch 134/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9154 - mae: 0.7301 - mse: 0.9154 - val_loss: 0.8838 - val_mae: 0.7130 - val_mse: 0.8838\n",
      "Epoch 135/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8998 - mae: 0.7305 - mse: 0.8998 - val_loss: 0.8997 - val_mae: 0.7186 - val_mse: 0.8997\n",
      "Epoch 136/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8179 - mae: 0.6905 - mse: 0.8179 - val_loss: 1.4576 - val_mae: 0.9568 - val_mse: 1.4576\n",
      "Epoch 137/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8671 - mae: 0.7176 - mse: 0.8671 - val_loss: 0.8585 - val_mae: 0.7070 - val_mse: 0.8585\n",
      "Epoch 138/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9098 - mae: 0.7221 - mse: 0.9098 - val_loss: 0.8609 - val_mae: 0.6983 - val_mse: 0.8609\n",
      "Epoch 139/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8645 - mae: 0.7214 - mse: 0.8645 - val_loss: 0.8258 - val_mae: 0.6810 - val_mse: 0.8258\n",
      "Epoch 140/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8452 - mae: 0.7062 - mse: 0.8452 - val_loss: 0.8135 - val_mae: 0.6799 - val_mse: 0.8135\n",
      "Epoch 141/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8709 - mae: 0.7152 - mse: 0.8709 - val_loss: 1.0144 - val_mae: 0.7679 - val_mse: 1.0144\n",
      "Epoch 142/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8031 - mae: 0.6917 - mse: 0.8031 - val_loss: 0.8387 - val_mae: 0.6929 - val_mse: 0.8387\n",
      "Epoch 143/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8152 - mae: 0.6951 - mse: 0.8152 - val_loss: 0.9466 - val_mae: 0.7485 - val_mse: 0.9466\n",
      "Epoch 144/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8642 - mae: 0.7160 - mse: 0.8642 - val_loss: 0.9385 - val_mae: 0.7564 - val_mse: 0.9385\n",
      "Epoch 145/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8275 - mae: 0.7076 - mse: 0.8275 - val_loss: 0.8627 - val_mae: 0.7047 - val_mse: 0.8627\n",
      "Epoch 146/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8604 - mae: 0.7161 - mse: 0.8604 - val_loss: 0.9503 - val_mae: 0.7410 - val_mse: 0.9503\n",
      "Epoch 147/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8443 - mae: 0.7117 - mse: 0.8443 - val_loss: 1.0545 - val_mae: 0.8134 - val_mse: 1.0545\n",
      "Epoch 148/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8295 - mae: 0.6942 - mse: 0.8295 - val_loss: 1.0073 - val_mae: 0.7700 - val_mse: 1.0073\n",
      "Epoch 149/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8431 - mae: 0.7001 - mse: 0.8431 - val_loss: 0.8539 - val_mae: 0.7076 - val_mse: 0.8539\n",
      "Epoch 150/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8628 - mae: 0.7189 - mse: 0.8628 - val_loss: 1.8646 - val_mae: 1.1055 - val_mse: 1.8646\n",
      "Epoch 151/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7986 - mae: 0.6840 - mse: 0.7986 - val_loss: 0.8943 - val_mae: 0.7121 - val_mse: 0.8943\n",
      "Epoch 152/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8334 - mae: 0.6974 - mse: 0.8334 - val_loss: 1.0194 - val_mae: 0.7668 - val_mse: 1.0194\n",
      "Epoch 153/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7209 - mae: 0.6422 - mse: 0.7209 - val_loss: 0.9730 - val_mae: 0.7731 - val_mse: 0.9730\n",
      "Epoch 154/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8374 - mae: 0.6935 - mse: 0.8374 - val_loss: 2.1568 - val_mae: 1.1974 - val_mse: 2.1568\n",
      "Epoch 155/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8669 - mae: 0.7128 - mse: 0.8669 - val_loss: 1.0227 - val_mae: 0.8004 - val_mse: 1.0227\n",
      "Epoch 156/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7947 - mae: 0.6805 - mse: 0.7947 - val_loss: 0.8418 - val_mae: 0.6817 - val_mse: 0.8418\n",
      "Epoch 157/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7575 - mae: 0.6635 - mse: 0.7575 - val_loss: 1.0601 - val_mae: 0.8011 - val_mse: 1.0601\n",
      "Epoch 158/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8511 - mae: 0.6994 - mse: 0.8511 - val_loss: 0.8647 - val_mae: 0.7172 - val_mse: 0.8647\n",
      "Epoch 159/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7844 - mae: 0.6797 - mse: 0.7844 - val_loss: 0.8981 - val_mae: 0.7175 - val_mse: 0.8981\n",
      "Epoch 160/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7669 - mae: 0.6734 - mse: 0.7669 - val_loss: 0.9459 - val_mae: 0.7450 - val_mse: 0.9459\n",
      "Epoch 161/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8032 - mae: 0.6954 - mse: 0.8032 - val_loss: 1.2436 - val_mae: 0.8677 - val_mse: 1.2436\n",
      "Epoch 162/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8141 - mae: 0.6895 - mse: 0.8141 - val_loss: 0.8145 - val_mae: 0.6818 - val_mse: 0.8145\n",
      "Epoch 163/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7643 - mae: 0.6676 - mse: 0.7643 - val_loss: 1.9694 - val_mae: 1.1545 - val_mse: 1.9694\n",
      "Epoch 164/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8664 - mae: 0.7160 - mse: 0.8664 - val_loss: 0.8903 - val_mae: 0.7236 - val_mse: 0.8903\n",
      "Epoch 165/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7563 - mae: 0.6644 - mse: 0.7563 - val_loss: 0.8849 - val_mae: 0.7068 - val_mse: 0.8849\n",
      "Epoch 166/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8244 - mae: 0.6868 - mse: 0.8244 - val_loss: 0.9433 - val_mae: 0.7495 - val_mse: 0.9433\n",
      "Epoch 167/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7496 - mae: 0.6601 - mse: 0.7496 - val_loss: 2.1077 - val_mae: 1.1766 - val_mse: 2.1077\n",
      "Epoch 168/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8061 - mae: 0.6857 - mse: 0.8061 - val_loss: 0.9928 - val_mae: 0.7794 - val_mse: 0.9928\n",
      "Epoch 169/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7470 - mae: 0.6583 - mse: 0.7470 - val_loss: 2.0344 - val_mae: 1.1372 - val_mse: 2.0344\n",
      "Epoch 170/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8214 - mae: 0.6946 - mse: 0.8214 - val_loss: 0.9630 - val_mae: 0.7533 - val_mse: 0.9630\n",
      "Epoch 171/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7684 - mae: 0.6668 - mse: 0.7684 - val_loss: 0.8683 - val_mae: 0.7151 - val_mse: 0.8683\n",
      "Epoch 172/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7392 - mae: 0.6493 - mse: 0.7392 - val_loss: 0.8622 - val_mae: 0.6942 - val_mse: 0.8622\n",
      "Epoch 173/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8169 - mae: 0.6824 - mse: 0.8169 - val_loss: 0.8762 - val_mae: 0.7259 - val_mse: 0.8762\n",
      "Epoch 174/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7291 - mae: 0.6491 - mse: 0.7291 - val_loss: 1.0776 - val_mae: 0.7997 - val_mse: 1.0776\n",
      "Epoch 175/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7645 - mae: 0.6765 - mse: 0.7645 - val_loss: 0.8848 - val_mae: 0.7146 - val_mse: 0.8848\n",
      "Epoch 176/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7257 - mae: 0.6519 - mse: 0.7257 - val_loss: 0.8587 - val_mae: 0.7135 - val_mse: 0.8587\n",
      "Epoch 177/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8163 - mae: 0.6874 - mse: 0.8163 - val_loss: 0.8340 - val_mae: 0.6943 - val_mse: 0.8340\n",
      "Epoch 178/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7236 - mae: 0.6587 - mse: 0.7236 - val_loss: 0.9909 - val_mae: 0.7525 - val_mse: 0.9909\n",
      "Epoch 179/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8169 - mae: 0.6840 - mse: 0.8169 - val_loss: 0.8975 - val_mae: 0.7122 - val_mse: 0.8975\n",
      "Epoch 180/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7456 - mae: 0.6652 - mse: 0.7456 - val_loss: 0.9506 - val_mae: 0.7470 - val_mse: 0.9506\n",
      "Epoch 181/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7948 - mae: 0.6793 - mse: 0.7948 - val_loss: 0.9058 - val_mae: 0.7335 - val_mse: 0.9058\n",
      "Epoch 182/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7511 - mae: 0.6644 - mse: 0.7511 - val_loss: 0.9530 - val_mae: 0.7456 - val_mse: 0.9530\n",
      "Epoch 183/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7280 - mae: 0.6518 - mse: 0.7280 - val_loss: 1.8812 - val_mae: 1.1290 - val_mse: 1.8812\n",
      "Epoch 184/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7307 - mae: 0.6478 - mse: 0.7307 - val_loss: 0.9568 - val_mae: 0.7351 - val_mse: 0.9568\n",
      "Epoch 185/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7208 - mae: 0.6495 - mse: 0.7208 - val_loss: 0.8322 - val_mae: 0.6880 - val_mse: 0.8322\n",
      "Epoch 186/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7026 - mae: 0.6366 - mse: 0.7026 - val_loss: 0.9933 - val_mae: 0.7573 - val_mse: 0.9933\n",
      "Epoch 187/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7629 - mae: 0.6619 - mse: 0.7629 - val_loss: 0.8669 - val_mae: 0.7110 - val_mse: 0.8669\n",
      "Epoch 188/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7032 - mae: 0.6393 - mse: 0.7032 - val_loss: 0.9595 - val_mae: 0.7311 - val_mse: 0.9595\n",
      "Epoch 189/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7603 - mae: 0.6599 - mse: 0.7603 - val_loss: 1.0708 - val_mae: 0.8132 - val_mse: 1.0708\n",
      "Epoch 190/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7271 - mae: 0.6454 - mse: 0.7271 - val_loss: 1.0879 - val_mae: 0.7893 - val_mse: 1.0879\n",
      "Epoch 191/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7311 - mae: 0.6582 - mse: 0.7311 - val_loss: 1.2863 - val_mae: 0.8990 - val_mse: 1.2863\n",
      "Epoch 192/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7035 - mae: 0.6391 - mse: 0.7035 - val_loss: 0.8741 - val_mae: 0.7162 - val_mse: 0.8741\n",
      "Epoch 193/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6907 - mae: 0.6319 - mse: 0.6907 - val_loss: 1.1415 - val_mae: 0.8257 - val_mse: 1.1415\n",
      "Epoch 194/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7233 - mae: 0.6432 - mse: 0.7233 - val_loss: 1.1164 - val_mae: 0.8172 - val_mse: 1.1164\n",
      "Epoch 195/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7600 - mae: 0.6657 - mse: 0.7600 - val_loss: 0.9473 - val_mae: 0.7509 - val_mse: 0.9473\n",
      "Epoch 196/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6949 - mae: 0.6432 - mse: 0.6949 - val_loss: 0.9226 - val_mae: 0.7515 - val_mse: 0.9226\n",
      "Epoch 197/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7672 - mae: 0.6709 - mse: 0.7672 - val_loss: 1.0415 - val_mae: 0.7724 - val_mse: 1.0415\n",
      "Epoch 198/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6862 - mae: 0.6274 - mse: 0.6862 - val_loss: 0.8716 - val_mae: 0.6996 - val_mse: 0.8716\n",
      "Epoch 199/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7827 - mae: 0.6618 - mse: 0.7827 - val_loss: 0.9594 - val_mae: 0.7394 - val_mse: 0.9594\n",
      "Epoch 200/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6620 - mae: 0.6201 - mse: 0.6620 - val_loss: 1.1350 - val_mae: 0.8348 - val_mse: 1.1350\n",
      "Epoch 201/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7029 - mae: 0.6369 - mse: 0.7029 - val_loss: 0.9978 - val_mae: 0.7709 - val_mse: 0.9978\n",
      "Epoch 202/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7212 - mae: 0.6548 - mse: 0.7212 - val_loss: 1.0683 - val_mae: 0.8025 - val_mse: 1.0683\n",
      "Epoch 203/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6567 - mae: 0.6209 - mse: 0.6567 - val_loss: 2.1795 - val_mae: 1.2053 - val_mse: 2.1795\n",
      "Epoch 204/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7759 - mae: 0.6734 - mse: 0.7759 - val_loss: 0.9853 - val_mae: 0.7413 - val_mse: 0.9853\n",
      "Epoch 205/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7218 - mae: 0.6460 - mse: 0.7218 - val_loss: 0.9876 - val_mae: 0.7633 - val_mse: 0.9876\n",
      "Epoch 206/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6681 - mae: 0.6256 - mse: 0.6681 - val_loss: 0.9142 - val_mae: 0.7242 - val_mse: 0.9142\n",
      "Epoch 207/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6303 - mae: 0.6032 - mse: 0.6303 - val_loss: 1.4332 - val_mae: 0.9494 - val_mse: 1.4332\n",
      "Epoch 208/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.7197 - mae: 0.6499 - mse: 0.7197 - val_loss: 1.0076 - val_mae: 0.7697 - val_mse: 1.0076\n",
      "Epoch 209/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6568 - mae: 0.6104 - mse: 0.6568 - val_loss: 0.8974 - val_mae: 0.7217 - val_mse: 0.8974\n",
      "Epoch 210/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6997 - mae: 0.6359 - mse: 0.6997 - val_loss: 1.5298 - val_mae: 0.9904 - val_mse: 1.5298\n",
      "Epoch 211/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6986 - mae: 0.6352 - mse: 0.6986 - val_loss: 1.1915 - val_mae: 0.8438 - val_mse: 1.1915\n",
      "Epoch 212/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6555 - mae: 0.6117 - mse: 0.6555 - val_loss: 0.9090 - val_mae: 0.7297 - val_mse: 0.9090\n",
      "Epoch 213/1000\n",
      "35/35 [==============================] - 0s 982us/step - loss: 0.6203 - mae: 0.6016 - mse: 0.6203 - val_loss: 1.0333 - val_mae: 0.7632 - val_mse: 1.0333\n",
      "Epoch 214/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7023 - mae: 0.6357 - mse: 0.7023 - val_loss: 0.8746 - val_mae: 0.7015 - val_mse: 0.8746\n",
      "Epoch 215/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7202 - mae: 0.6441 - mse: 0.7202 - val_loss: 1.0677 - val_mae: 0.7865 - val_mse: 1.0677\n",
      "Epoch 216/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6493 - mae: 0.6161 - mse: 0.6493 - val_loss: 0.8569 - val_mae: 0.6901 - val_mse: 0.8569\n",
      "Epoch 217/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6430 - mae: 0.6149 - mse: 0.6430 - val_loss: 1.1876 - val_mae: 0.8211 - val_mse: 1.1876\n",
      "Epoch 218/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6788 - mae: 0.6350 - mse: 0.6788 - val_loss: 0.9226 - val_mae: 0.7214 - val_mse: 0.9226\n",
      "Epoch 219/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6507 - mae: 0.6084 - mse: 0.6507 - val_loss: 1.1654 - val_mae: 0.8373 - val_mse: 1.1654\n",
      "Epoch 220/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6632 - mae: 0.6255 - mse: 0.6632 - val_loss: 0.8830 - val_mae: 0.7104 - val_mse: 0.8830\n",
      "Epoch 221/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6369 - mae: 0.6062 - mse: 0.6369 - val_loss: 0.9690 - val_mae: 0.7425 - val_mse: 0.9690\n",
      "Epoch 222/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6761 - mae: 0.6244 - mse: 0.6761 - val_loss: 0.8612 - val_mae: 0.6926 - val_mse: 0.8612\n",
      "Epoch 223/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5997 - mae: 0.5943 - mse: 0.5997 - val_loss: 0.9598 - val_mae: 0.7432 - val_mse: 0.9598\n",
      "Epoch 224/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6780 - mae: 0.6257 - mse: 0.6780 - val_loss: 0.9442 - val_mae: 0.7313 - val_mse: 0.9442\n",
      "Epoch 225/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6225 - mae: 0.5996 - mse: 0.6225 - val_loss: 1.6311 - val_mae: 1.0124 - val_mse: 1.6311\n",
      "Epoch 226/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6544 - mae: 0.6174 - mse: 0.6544 - val_loss: 1.0225 - val_mae: 0.7600 - val_mse: 1.0225\n",
      "Epoch 227/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.6399 - mae: 0.6032 - mse: 0.6399 - val_loss: 0.9810 - val_mae: 0.7660 - val_mse: 0.9810\n",
      "Epoch 228/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6213 - mae: 0.6031 - mse: 0.6213 - val_loss: 0.9953 - val_mae: 0.7468 - val_mse: 0.9953\n",
      "Epoch 229/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6598 - mae: 0.6192 - mse: 0.6598 - val_loss: 1.2387 - val_mae: 0.8502 - val_mse: 1.2387\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5946 - mae: 0.5842 - mse: 0.5946 - val_loss: 0.8903 - val_mae: 0.7124 - val_mse: 0.8903\n",
      "Epoch 231/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6264 - mae: 0.5932 - mse: 0.6264 - val_loss: 1.3509 - val_mae: 0.9123 - val_mse: 1.3509\n",
      "Epoch 232/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5939 - mae: 0.5866 - mse: 0.5939 - val_loss: 1.3220 - val_mae: 0.9031 - val_mse: 1.3220\n",
      "Epoch 233/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6569 - mae: 0.6159 - mse: 0.6569 - val_loss: 1.0182 - val_mae: 0.7728 - val_mse: 1.0182\n",
      "Epoch 234/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5778 - mae: 0.5758 - mse: 0.5778 - val_loss: 1.2346 - val_mae: 0.8619 - val_mse: 1.2346\n",
      "Epoch 235/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6354 - mae: 0.6077 - mse: 0.6354 - val_loss: 0.9130 - val_mae: 0.7126 - val_mse: 0.9130\n",
      "Epoch 236/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6096 - mae: 0.5893 - mse: 0.6096 - val_loss: 0.9318 - val_mae: 0.7234 - val_mse: 0.9318\n",
      "Epoch 237/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6287 - mae: 0.6080 - mse: 0.6287 - val_loss: 1.1986 - val_mae: 0.8492 - val_mse: 1.1986\n",
      "Epoch 238/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6388 - mae: 0.6101 - mse: 0.6388 - val_loss: 1.0502 - val_mae: 0.7805 - val_mse: 1.0502\n",
      "Epoch 239/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.0339 - mae: 0.7734 - mse: 1.033 - 0s 1ms/step - loss: 0.6251 - mae: 0.5999 - mse: 0.6251 - val_loss: 1.4432 - val_mae: 0.8973 - val_mse: 1.4432\n",
      "Epoch 240/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6104 - mae: 0.5958 - mse: 0.6104 - val_loss: 1.0486 - val_mae: 0.7728 - val_mse: 1.0486\n",
      "Kappa Score: 0.6976803437214096\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      " 1/35 [..............................] - ETA: 0s - loss: 76.0323 - mae: 8.5465 - mse: 76.0323WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 77.9250 - mae: 4.5566 - mse: 77.9250 - val_loss: 35.2025 - val_mae: 5.7192 - val_mse: 35.2025\n",
      "Epoch 2/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 17.2203 - mae: 3.3911 - mse: 17.2203 - val_loss: 7.1635 - val_mae: 2.1313 - val_mse: 7.1635\n",
      "Epoch 3/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 9.0796 - mae: 2.3342 - mse: 9.0796 - val_loss: 1.7761 - val_mae: 1.0617 - val_mse: 1.7761\n",
      "Epoch 4/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 8.3331 - mae: 2.1824 - mse: 8.3331 - val_loss: 2.6714 - val_mae: 1.3929 - val_mse: 2.6714\n",
      "Epoch 5/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.8493 - mae: 1.5273 - mse: 3.8493 - val_loss: 7.0442 - val_mae: 2.1514 - val_mse: 7.0442\n",
      "Epoch 6/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.8539 - mae: 1.5542 - mse: 3.8539 - val_loss: 1.5752 - val_mae: 0.9385 - val_mse: 1.5752\n",
      "Epoch 7/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.4113 - mae: 1.2211 - mse: 2.4113 - val_loss: 7.7577 - val_mae: 2.6086 - val_mse: 7.7577\n",
      "Epoch 8/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.4946 - mae: 1.2355 - mse: 2.4946 - val_loss: 2.9821 - val_mae: 1.4042 - val_mse: 2.9821\n",
      "Epoch 9/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.2919 - mae: 1.1860 - mse: 2.2919 - val_loss: 3.3685 - val_mae: 1.6191 - val_mse: 3.3685\n",
      "Epoch 10/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.1489 - mae: 1.1781 - mse: 2.1489 - val_loss: 1.8680 - val_mae: 1.0188 - val_mse: 1.8680\n",
      "Epoch 11/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 2.0797 - mae: 1.1487 - mse: 2.0797 - val_loss: 1.3911 - val_mae: 0.9192 - val_mse: 1.3911\n",
      "Epoch 12/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.8475 - mae: 1.0653 - mse: 1.8475 - val_loss: 3.0599 - val_mae: 1.4987 - val_mse: 3.0599\n",
      "Epoch 13/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7484 - mae: 1.0492 - mse: 1.7484 - val_loss: 1.1571 - val_mae: 0.8371 - val_mse: 1.1571\n",
      "Epoch 14/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.9866 - mae: 1.1044 - mse: 1.9866 - val_loss: 6.5069 - val_mae: 2.3606 - val_mse: 6.5069\n",
      "Epoch 15/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.8903 - mae: 1.0722 - mse: 1.8903 - val_loss: 1.1661 - val_mae: 0.8470 - val_mse: 1.1661\n",
      "Epoch 16/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.6419 - mae: 1.0061 - mse: 1.6419 - val_loss: 1.2418 - val_mae: 0.8621 - val_mse: 1.2418\n",
      "Epoch 17/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5923 - mae: 0.9900 - mse: 1.5923 - val_loss: 1.4352 - val_mae: 0.9382 - val_mse: 1.4352\n",
      "Epoch 18/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6491 - mae: 1.0066 - mse: 1.6491 - val_loss: 1.1649 - val_mae: 0.8469 - val_mse: 1.1649\n",
      "Epoch 19/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5702 - mae: 0.9760 - mse: 1.5702 - val_loss: 2.1065 - val_mae: 1.1450 - val_mse: 2.1065\n",
      "Epoch 20/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4412 - mae: 0.9287 - mse: 1.4412 - val_loss: 1.0838 - val_mae: 0.8225 - val_mse: 1.0838\n",
      "Epoch 21/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5366 - mae: 0.9781 - mse: 1.5366 - val_loss: 1.0185 - val_mae: 0.7999 - val_mse: 1.0185\n",
      "Epoch 22/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.4790 - mae: 0.9601 - mse: 1.4790 - val_loss: 1.5181 - val_mae: 0.9590 - val_mse: 1.5181\n",
      "Epoch 23/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.5200 - mae: 0.9613 - mse: 1.5200 - val_loss: 2.1694 - val_mae: 1.2017 - val_mse: 2.1694\n",
      "Epoch 24/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4324 - mae: 0.9441 - mse: 1.4324 - val_loss: 1.3581 - val_mae: 0.9206 - val_mse: 1.3581\n",
      "Epoch 25/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4217 - mae: 0.9443 - mse: 1.4217 - val_loss: 0.9788 - val_mae: 0.7852 - val_mse: 0.9788\n",
      "Epoch 26/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4440 - mae: 0.9375 - mse: 1.4440 - val_loss: 1.0355 - val_mae: 0.8058 - val_mse: 1.0355\n",
      "Epoch 27/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.3302 - mae: 0.8981 - mse: 1.3302 - val_loss: 2.1201 - val_mae: 1.1984 - val_mse: 2.1201\n",
      "Epoch 28/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.4011 - mae: 0.9348 - mse: 1.4011 - val_loss: 2.8290 - val_mae: 1.4424 - val_mse: 2.8290\n",
      "Epoch 29/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.3316 - mae: 0.8951 - mse: 1.3316 - val_loss: 3.3471 - val_mae: 1.5906 - val_mse: 3.3471\n",
      "Epoch 30/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3383 - mae: 0.9013 - mse: 1.3383 - val_loss: 0.9760 - val_mae: 0.7830 - val_mse: 0.9760\n",
      "Epoch 31/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4729 - mae: 0.9530 - mse: 1.4729 - val_loss: 0.9635 - val_mae: 0.7715 - val_mse: 0.9635\n",
      "Epoch 32/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2050 - mae: 0.8583 - mse: 1.2050 - val_loss: 2.8346 - val_mae: 1.3887 - val_mse: 2.8346\n",
      "Epoch 33/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.3502 - mae: 0.9087 - mse: 1.3502 - val_loss: 0.9826 - val_mae: 0.7767 - val_mse: 0.9826\n",
      "Epoch 34/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.3568 - mae: 0.9057 - mse: 1.3568 - val_loss: 2.2347 - val_mae: 1.2095 - val_mse: 2.2347\n",
      "Epoch 35/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.3114 - mae: 0.9039 - mse: 1.3114 - val_loss: 1.8923 - val_mae: 1.1276 - val_mse: 1.8923\n",
      "Epoch 36/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3120 - mae: 0.8994 - mse: 1.3120 - val_loss: 1.5976 - val_mae: 1.0238 - val_mse: 1.5976\n",
      "Epoch 37/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2606 - mae: 0.8783 - mse: 1.2606 - val_loss: 2.7970 - val_mae: 1.4395 - val_mse: 2.7970\n",
      "Epoch 38/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2410 - mae: 0.8678 - mse: 1.2410 - val_loss: 0.8869 - val_mae: 0.7453 - val_mse: 0.8869\n",
      "Epoch 39/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2603 - mae: 0.8667 - mse: 1.2603 - val_loss: 0.9598 - val_mae: 0.7674 - val_mse: 0.9598\n",
      "Epoch 40/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2561 - mae: 0.8720 - mse: 1.2561 - val_loss: 0.9961 - val_mae: 0.7795 - val_mse: 0.9961\n",
      "Epoch 41/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2772 - mae: 0.8708 - mse: 1.2772 - val_loss: 1.4584 - val_mae: 0.9665 - val_mse: 1.4584\n",
      "Epoch 42/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2511 - mae: 0.8713 - mse: 1.2511 - val_loss: 1.0539 - val_mae: 0.8053 - val_mse: 1.0539\n",
      "Epoch 43/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2073 - mae: 0.8601 - mse: 1.2073 - val_loss: 1.0680 - val_mae: 0.8070 - val_mse: 1.0680\n",
      "Epoch 44/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1600 - mae: 0.8337 - mse: 1.1600 - val_loss: 0.8687 - val_mae: 0.7411 - val_mse: 0.8687\n",
      "Epoch 45/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2204 - mae: 0.8583 - mse: 1.2204 - val_loss: 1.2347 - val_mae: 0.8762 - val_mse: 1.2347\n",
      "Epoch 46/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0995 - mae: 0.8204 - mse: 1.0995 - val_loss: 1.1050 - val_mae: 0.8289 - val_mse: 1.1050\n",
      "Epoch 47/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2368 - mae: 0.8632 - mse: 1.2368 - val_loss: 0.8865 - val_mae: 0.7479 - val_mse: 0.8865\n",
      "Epoch 48/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1238 - mae: 0.8285 - mse: 1.1238 - val_loss: 2.8126 - val_mae: 1.4469 - val_mse: 2.8126\n",
      "Epoch 49/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.1949 - mae: 0.8526 - mse: 1.1949 - val_loss: 1.2070 - val_mae: 0.8707 - val_mse: 1.2070\n",
      "Epoch 50/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1651 - mae: 0.8452 - mse: 1.1651 - val_loss: 0.9309 - val_mae: 0.7607 - val_mse: 0.9309\n",
      "Epoch 51/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.0981 - mae: 0.8219 - mse: 1.0981 - val_loss: 1.3496 - val_mae: 0.9238 - val_mse: 1.3496\n",
      "Epoch 52/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.1835 - mae: 0.8421 - mse: 1.1835 - val_loss: 0.8722 - val_mae: 0.7433 - val_mse: 0.8722\n",
      "Epoch 53/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 1.1988 - mae: 0.8469 - mse: 1.1988 - val_loss: 0.9080 - val_mae: 0.7589 - val_mse: 0.9080\n",
      "Epoch 54/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1287 - mae: 0.8301 - mse: 1.1287 - val_loss: 0.8971 - val_mae: 0.7438 - val_mse: 0.8971\n",
      "Epoch 55/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1803 - mae: 0.8484 - mse: 1.1803 - val_loss: 0.8788 - val_mae: 0.7455 - val_mse: 0.8788\n",
      "Epoch 56/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1268 - mae: 0.8227 - mse: 1.1268 - val_loss: 0.8948 - val_mae: 0.7429 - val_mse: 0.8948\n",
      "Epoch 57/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1087 - mae: 0.8226 - mse: 1.1087 - val_loss: 1.1706 - val_mae: 0.8607 - val_mse: 1.1706\n",
      "Epoch 58/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0674 - mae: 0.8074 - mse: 1.0674 - val_loss: 1.7657 - val_mae: 1.0939 - val_mse: 1.7657\n",
      "Epoch 59/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1102 - mae: 0.8222 - mse: 1.1102 - val_loss: 1.3678 - val_mae: 0.9300 - val_mse: 1.3678\n",
      "Epoch 60/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0956 - mae: 0.8109 - mse: 1.0956 - val_loss: 1.7870 - val_mae: 1.1020 - val_mse: 1.7870\n",
      "Epoch 61/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0940 - mae: 0.8107 - mse: 1.0940 - val_loss: 0.9304 - val_mae: 0.7563 - val_mse: 0.9304\n",
      "Epoch 62/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1722 - mae: 0.8423 - mse: 1.1722 - val_loss: 0.9073 - val_mae: 0.7508 - val_mse: 0.9073\n",
      "Epoch 63/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9943 - mae: 0.7723 - mse: 0.9943 - val_loss: 0.8261 - val_mae: 0.7217 - val_mse: 0.8261\n",
      "Epoch 64/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 1.1338 - mae: 0.8244 - mse: 1.1338 - val_loss: 1.0220 - val_mae: 0.7951 - val_mse: 1.0220\n",
      "Epoch 65/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1313 - mae: 0.8301 - mse: 1.1313 - val_loss: 1.0157 - val_mae: 0.7995 - val_mse: 1.0157\n",
      "Epoch 66/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0275 - mae: 0.7905 - mse: 1.0275 - val_loss: 0.9287 - val_mae: 0.7624 - val_mse: 0.9287\n",
      "Epoch 67/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0798 - mae: 0.8091 - mse: 1.0798 - val_loss: 0.8273 - val_mae: 0.7166 - val_mse: 0.8273\n",
      "Epoch 68/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0338 - mae: 0.7961 - mse: 1.0338 - val_loss: 1.7127 - val_mae: 1.0785 - val_mse: 1.7127\n",
      "Epoch 69/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9911 - mae: 0.7668 - mse: 0.9911 - val_loss: 1.4466 - val_mae: 0.9731 - val_mse: 1.4466\n",
      "Epoch 70/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0134 - mae: 0.7834 - mse: 1.0134 - val_loss: 0.9418 - val_mae: 0.7663 - val_mse: 0.9418\n",
      "Epoch 71/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0970 - mae: 0.8188 - mse: 1.0970 - val_loss: 1.2864 - val_mae: 0.8974 - val_mse: 1.2864\n",
      "Epoch 72/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0186 - mae: 0.7828 - mse: 1.0186 - val_loss: 1.0932 - val_mae: 0.8257 - val_mse: 1.0932\n",
      "Epoch 73/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9580 - mae: 0.7688 - mse: 0.9580 - val_loss: 0.7730 - val_mae: 0.7008 - val_mse: 0.7730\n",
      "Epoch 74/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0476 - mae: 0.7948 - mse: 1.0476 - val_loss: 0.8260 - val_mae: 0.7213 - val_mse: 0.8260\n",
      "Epoch 75/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0238 - mae: 0.7945 - mse: 1.0238 - val_loss: 2.1137 - val_mae: 1.2192 - val_mse: 2.1137\n",
      "Epoch 76/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0233 - mae: 0.7770 - mse: 1.0233 - val_loss: 0.8272 - val_mae: 0.7183 - val_mse: 0.8272\n",
      "Epoch 77/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9863 - mae: 0.7731 - mse: 0.9863 - val_loss: 0.8252 - val_mae: 0.7198 - val_mse: 0.8252\n",
      "Epoch 78/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9758 - mae: 0.7630 - mse: 0.9758 - val_loss: 1.4441 - val_mae: 0.9688 - val_mse: 1.4441\n",
      "Epoch 79/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.9648 - mae: 0.7496 - mse: 0.9648 - val_loss: 2.1793 - val_mae: 1.2545 - val_mse: 2.1793\n",
      "Epoch 80/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9856 - mae: 0.7679 - mse: 0.9856 - val_loss: 0.7657 - val_mae: 0.6972 - val_mse: 0.7657\n",
      "Epoch 81/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 1.0554 - mae: 0.7893 - mse: 1.0554 - val_loss: 0.8359 - val_mae: 0.7253 - val_mse: 0.8359\n",
      "Epoch 82/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9792 - mae: 0.7628 - mse: 0.9792 - val_loss: 0.8043 - val_mae: 0.7104 - val_mse: 0.8043\n",
      "Epoch 83/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9763 - mae: 0.7649 - mse: 0.9763 - val_loss: 1.0724 - val_mae: 0.8235 - val_mse: 1.0724\n",
      "Epoch 84/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9375 - mae: 0.7510 - mse: 0.9375 - val_loss: 0.8423 - val_mae: 0.7258 - val_mse: 0.8423\n",
      "Epoch 85/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9202 - mae: 0.7422 - mse: 0.9202 - val_loss: 1.0551 - val_mae: 0.8132 - val_mse: 1.0551\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 997us/step - loss: 0.9627 - mae: 0.7618 - mse: 0.9627 - val_loss: 0.8648 - val_mae: 0.7271 - val_mse: 0.8648\n",
      "Epoch 87/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9056 - mae: 0.7412 - mse: 0.9056 - val_loss: 1.0130 - val_mae: 0.7954 - val_mse: 1.0130\n",
      "Epoch 88/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9496 - mae: 0.7582 - mse: 0.9496 - val_loss: 1.3223 - val_mae: 0.9249 - val_mse: 1.3223\n",
      "Epoch 89/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9307 - mae: 0.7359 - mse: 0.9307 - val_loss: 1.0050 - val_mae: 0.8110 - val_mse: 1.0050\n",
      "Epoch 90/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9387 - mae: 0.7513 - mse: 0.9387 - val_loss: 0.9010 - val_mae: 0.7511 - val_mse: 0.9010\n",
      "Epoch 91/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9152 - mae: 0.7428 - mse: 0.9152 - val_loss: 1.1455 - val_mae: 0.8488 - val_mse: 1.1455\n",
      "Epoch 92/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.8890 - mae: 0.7378 - mse: 0.8890 - val_loss: 0.9858 - val_mae: 0.7909 - val_mse: 0.9858\n",
      "Epoch 93/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9799 - mae: 0.7647 - mse: 0.9799 - val_loss: 0.7781 - val_mae: 0.7010 - val_mse: 0.7781\n",
      "Epoch 94/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.8886 - mae: 0.7322 - mse: 0.8886 - val_loss: 0.9000 - val_mae: 0.7496 - val_mse: 0.9000\n",
      "Epoch 95/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.9533 - mae: 0.7619 - mse: 0.9533 - val_loss: 0.9034 - val_mae: 0.7554 - val_mse: 0.9034\n",
      "Epoch 96/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.8805 - mae: 0.7250 - mse: 0.8805 - val_loss: 0.8684 - val_mae: 0.7396 - val_mse: 0.8684\n",
      "Epoch 97/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.9371 - mae: 0.7395 - mse: 0.9371 - val_loss: 1.2380 - val_mae: 0.8851 - val_mse: 1.2380\n",
      "Epoch 98/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9417 - mae: 0.7513 - mse: 0.9417 - val_loss: 0.9160 - val_mae: 0.7547 - val_mse: 0.9160\n",
      "Epoch 99/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8730 - mae: 0.7193 - mse: 0.8730 - val_loss: 0.7558 - val_mae: 0.6886 - val_mse: 0.7558\n",
      "Epoch 100/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9155 - mae: 0.7438 - mse: 0.9155 - val_loss: 0.9900 - val_mae: 0.7848 - val_mse: 0.9900\n",
      "Epoch 101/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8726 - mae: 0.7244 - mse: 0.8726 - val_loss: 1.1013 - val_mae: 0.8273 - val_mse: 1.1013\n",
      "Epoch 102/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.9400 - mae: 0.7422 - mse: 0.9400 - val_loss: 0.9786 - val_mae: 0.7837 - val_mse: 0.9786\n",
      "Epoch 103/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8653 - mae: 0.7333 - mse: 0.8653 - val_loss: 0.8536 - val_mae: 0.7286 - val_mse: 0.8536\n",
      "Epoch 104/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.8734 - mae: 0.7302 - mse: 0.8734 - val_loss: 0.9804 - val_mae: 0.7956 - val_mse: 0.9804\n",
      "Epoch 105/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.8912 - mae: 0.7337 - mse: 0.8912 - val_loss: 0.7634 - val_mae: 0.6880 - val_mse: 0.7634\n",
      "Epoch 106/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.9036 - mae: 0.7268 - mse: 0.9036 - val_loss: 0.7576 - val_mae: 0.6867 - val_mse: 0.7576\n",
      "Epoch 107/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.8471 - mae: 0.7138 - mse: 0.8471 - val_loss: 1.1986 - val_mae: 0.8788 - val_mse: 1.1986\n",
      "Epoch 108/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8807 - mae: 0.7333 - mse: 0.8807 - val_loss: 0.8731 - val_mae: 0.7444 - val_mse: 0.8731\n",
      "Epoch 109/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8600 - mae: 0.7176 - mse: 0.8600 - val_loss: 0.7528 - val_mae: 0.6862 - val_mse: 0.7528\n",
      "Epoch 110/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8882 - mae: 0.7233 - mse: 0.8882 - val_loss: 1.3317 - val_mae: 0.9418 - val_mse: 1.3317\n",
      "Epoch 111/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8414 - mae: 0.7190 - mse: 0.8414 - val_loss: 1.3102 - val_mae: 0.9331 - val_mse: 1.3102\n",
      "Epoch 112/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8327 - mae: 0.7154 - mse: 0.8327 - val_loss: 0.8418 - val_mae: 0.7192 - val_mse: 0.8418\n",
      "Epoch 113/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8499 - mae: 0.6988 - mse: 0.8499 - val_loss: 1.0182 - val_mae: 0.7973 - val_mse: 1.0182\n",
      "Epoch 114/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8399 - mae: 0.7200 - mse: 0.8399 - val_loss: 0.8554 - val_mae: 0.7403 - val_mse: 0.8554\n",
      "Epoch 115/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8515 - mae: 0.7080 - mse: 0.8515 - val_loss: 1.0599 - val_mae: 0.8130 - val_mse: 1.0599\n",
      "Epoch 116/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7937 - mae: 0.6899 - mse: 0.7937 - val_loss: 0.7822 - val_mae: 0.6969 - val_mse: 0.7822\n",
      "Epoch 117/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.8297 - mae: 0.6984 - mse: 0.8297 - val_loss: 0.9149 - val_mae: 0.7582 - val_mse: 0.9149\n",
      "Epoch 118/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8028 - mae: 0.7013 - mse: 0.8028 - val_loss: 0.9427 - val_mae: 0.7609 - val_mse: 0.9427\n",
      "Epoch 119/1000\n",
      "35/35 [==============================] - 0s 988us/step - loss: 0.7837 - mae: 0.6819 - mse: 0.7837 - val_loss: 1.1685 - val_mae: 0.8550 - val_mse: 1.1685\n",
      "Epoch 120/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.8636 - mae: 0.7097 - mse: 0.8636 - val_loss: 0.7591 - val_mae: 0.6921 - val_mse: 0.7591\n",
      "Epoch 121/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.7770 - mae: 0.6804 - mse: 0.7770 - val_loss: 1.7153 - val_mae: 1.0982 - val_mse: 1.7153\n",
      "Epoch 122/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.8263 - mae: 0.7021 - mse: 0.8263 - val_loss: 0.8394 - val_mae: 0.7302 - val_mse: 0.8394\n",
      "Epoch 123/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.8343 - mae: 0.7078 - mse: 0.8343 - val_loss: 0.9938 - val_mae: 0.7930 - val_mse: 0.9938\n",
      "Epoch 124/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8409 - mae: 0.7112 - mse: 0.8409 - val_loss: 1.0099 - val_mae: 0.8079 - val_mse: 1.0099\n",
      "Epoch 125/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7881 - mae: 0.6733 - mse: 0.7881 - val_loss: 1.0551 - val_mae: 0.8262 - val_mse: 1.0551\n",
      "Epoch 126/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7966 - mae: 0.6856 - mse: 0.7966 - val_loss: 0.9599 - val_mae: 0.7719 - val_mse: 0.9599\n",
      "Epoch 127/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7409 - mae: 0.6625 - mse: 0.7409 - val_loss: 0.9187 - val_mae: 0.7545 - val_mse: 0.9187\n",
      "Epoch 128/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.8259 - mae: 0.6989 - mse: 0.8259 - val_loss: 0.7686 - val_mae: 0.6936 - val_mse: 0.7686\n",
      "Epoch 129/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.8113 - mae: 0.6814 - mse: 0.8113 - val_loss: 0.7664 - val_mae: 0.6960 - val_mse: 0.7664\n",
      "Epoch 130/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7581 - mae: 0.6647 - mse: 0.7581 - val_loss: 1.1239 - val_mae: 0.8544 - val_mse: 1.1239\n",
      "Epoch 131/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.1421 - mae: 0.7279 - mse: 1.142 - 0s 969us/step - loss: 0.8077 - mae: 0.6841 - mse: 0.8077 - val_loss: 0.7531 - val_mae: 0.6949 - val_mse: 0.7531\n",
      "Epoch 132/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7824 - mae: 0.6857 - mse: 0.7824 - val_loss: 1.0628 - val_mae: 0.8280 - val_mse: 1.0628\n",
      "Epoch 133/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7933 - mae: 0.6891 - mse: 0.7933 - val_loss: 0.9034 - val_mae: 0.7598 - val_mse: 0.9034\n",
      "Epoch 134/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.7073 - mae: 0.6491 - mse: 0.7073 - val_loss: 0.8474 - val_mae: 0.7215 - val_mse: 0.8474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.7928 - mae: 0.6772 - mse: 0.7928 - val_loss: 0.7486 - val_mae: 0.6931 - val_mse: 0.7486\n",
      "Epoch 136/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7724 - mae: 0.6775 - mse: 0.7724 - val_loss: 0.7812 - val_mae: 0.7083 - val_mse: 0.7812\n",
      "Epoch 137/1000\n",
      "35/35 [==============================] - 0s 996us/step - loss: 0.7557 - mae: 0.6622 - mse: 0.7557 - val_loss: 0.9442 - val_mae: 0.7676 - val_mse: 0.9442\n",
      "Epoch 138/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8264 - mae: 0.6974 - mse: 0.8264 - val_loss: 0.9264 - val_mae: 0.7581 - val_mse: 0.9264\n",
      "Epoch 139/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7001 - mae: 0.6453 - mse: 0.7001 - val_loss: 0.7661 - val_mae: 0.7006 - val_mse: 0.7661\n",
      "Epoch 140/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7599 - mae: 0.6739 - mse: 0.7599 - val_loss: 0.7561 - val_mae: 0.6904 - val_mse: 0.7561\n",
      "Epoch 141/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7041 - mae: 0.6417 - mse: 0.7041 - val_loss: 1.5657 - val_mae: 1.0480 - val_mse: 1.5657\n",
      "Epoch 142/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.7606 - mae: 0.6798 - mse: 0.7606 - val_loss: 0.8993 - val_mae: 0.7491 - val_mse: 0.8993\n",
      "Epoch 143/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.7663 - mae: 0.6736 - mse: 0.7663 - val_loss: 0.7849 - val_mae: 0.6951 - val_mse: 0.7849\n",
      "Epoch 144/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.7404 - mae: 0.6534 - mse: 0.7404 - val_loss: 0.8284 - val_mae: 0.7231 - val_mse: 0.8284\n",
      "Epoch 145/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7939 - mae: 0.6804 - mse: 0.7939 - val_loss: 0.7862 - val_mae: 0.7048 - val_mse: 0.7862\n",
      "Epoch 146/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6939 - mae: 0.6352 - mse: 0.6939 - val_loss: 0.8176 - val_mae: 0.7263 - val_mse: 0.8176\n",
      "Epoch 147/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.6990 - mae: 0.6407 - mse: 0.6990 - val_loss: 0.7395 - val_mae: 0.6802 - val_mse: 0.7395\n",
      "Epoch 148/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.6675 - mae: 0.6294 - mse: 0.6675 - val_loss: 1.9349 - val_mae: 1.1752 - val_mse: 1.9349\n",
      "Epoch 149/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7360 - mae: 0.6618 - mse: 0.7360 - val_loss: 1.0519 - val_mae: 0.8246 - val_mse: 1.0519\n",
      "Epoch 150/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7604 - mae: 0.6754 - mse: 0.7604 - val_loss: 0.7263 - val_mae: 0.6798 - val_mse: 0.7263\n",
      "Epoch 151/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.7366 - mae: 0.6572 - mse: 0.7366 - val_loss: 0.8505 - val_mae: 0.7136 - val_mse: 0.8505\n",
      "Epoch 152/1000\n",
      "35/35 [==============================] - 0s 984us/step - loss: 0.6893 - mae: 0.6374 - mse: 0.6893 - val_loss: 1.5131 - val_mae: 1.0152 - val_mse: 1.5131\n",
      "Epoch 153/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.7652 - mae: 0.6670 - mse: 0.7652 - val_loss: 0.8135 - val_mae: 0.7047 - val_mse: 0.8135\n",
      "Epoch 154/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6662 - mae: 0.6203 - mse: 0.6662 - val_loss: 1.1878 - val_mae: 0.8901 - val_mse: 1.1878\n",
      "Epoch 155/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7313 - mae: 0.6595 - mse: 0.7313 - val_loss: 0.8443 - val_mae: 0.7276 - val_mse: 0.8443\n",
      "Epoch 156/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6930 - mae: 0.6384 - mse: 0.6930 - val_loss: 0.7758 - val_mae: 0.7017 - val_mse: 0.7758\n",
      "Epoch 157/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7002 - mae: 0.6396 - mse: 0.7002 - val_loss: 0.7840 - val_mae: 0.7106 - val_mse: 0.7840\n",
      "Epoch 158/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7048 - mae: 0.6426 - mse: 0.7048 - val_loss: 1.9228 - val_mae: 1.1604 - val_mse: 1.9228\n",
      "Epoch 159/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7058 - mae: 0.6433 - mse: 0.7058 - val_loss: 0.8253 - val_mae: 0.7127 - val_mse: 0.8253\n",
      "Epoch 160/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6950 - mae: 0.6383 - mse: 0.6950 - val_loss: 0.9112 - val_mae: 0.7441 - val_mse: 0.9112\n",
      "Epoch 161/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7333 - mae: 0.6544 - mse: 0.7333 - val_loss: 0.8411 - val_mae: 0.7354 - val_mse: 0.8411\n",
      "Epoch 162/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6992 - mae: 0.6266 - mse: 0.6992 - val_loss: 1.0746 - val_mae: 0.8121 - val_mse: 1.0746\n",
      "Epoch 163/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.6983 - mae: 0.6331 - mse: 0.6983 - val_loss: 0.7440 - val_mae: 0.6899 - val_mse: 0.7440\n",
      "Epoch 164/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6912 - mae: 0.6325 - mse: 0.6912 - val_loss: 0.7382 - val_mae: 0.6874 - val_mse: 0.7382\n",
      "Epoch 165/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7176 - mae: 0.6457 - mse: 0.7176 - val_loss: 1.1375 - val_mae: 0.8624 - val_mse: 1.1375\n",
      "Epoch 166/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6473 - mae: 0.6126 - mse: 0.6473 - val_loss: 0.9442 - val_mae: 0.7765 - val_mse: 0.9442\n",
      "Epoch 167/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6608 - mae: 0.6209 - mse: 0.6608 - val_loss: 0.7311 - val_mae: 0.6795 - val_mse: 0.7311\n",
      "Epoch 168/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.7062 - mae: 0.6417 - mse: 0.7062 - val_loss: 0.7463 - val_mae: 0.6900 - val_mse: 0.7463\n",
      "Epoch 169/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6789 - mae: 0.6292 - mse: 0.6789 - val_loss: 1.0791 - val_mae: 0.7991 - val_mse: 1.0791\n",
      "Epoch 170/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6561 - mae: 0.6167 - mse: 0.6561 - val_loss: 0.9373 - val_mae: 0.7756 - val_mse: 0.9373\n",
      "Epoch 171/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6614 - mae: 0.6229 - mse: 0.6614 - val_loss: 0.7861 - val_mae: 0.7059 - val_mse: 0.7861\n",
      "Epoch 172/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6603 - mae: 0.6257 - mse: 0.6603 - val_loss: 1.0120 - val_mae: 0.8081 - val_mse: 1.0120\n",
      "Epoch 173/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6898 - mae: 0.6324 - mse: 0.6898 - val_loss: 0.7461 - val_mae: 0.6864 - val_mse: 0.7461\n",
      "Epoch 174/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6508 - mae: 0.6164 - mse: 0.6508 - val_loss: 1.1448 - val_mae: 0.8731 - val_mse: 1.1448\n",
      "Epoch 175/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6572 - mae: 0.6278 - mse: 0.6572 - val_loss: 0.7659 - val_mae: 0.6984 - val_mse: 0.7659\n",
      "Epoch 176/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6671 - mae: 0.6302 - mse: 0.6671 - val_loss: 0.7904 - val_mae: 0.7064 - val_mse: 0.7904\n",
      "Epoch 177/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6429 - mae: 0.6155 - mse: 0.6429 - val_loss: 0.7865 - val_mae: 0.7048 - val_mse: 0.7865\n",
      "Epoch 178/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6241 - mae: 0.6055 - mse: 0.6241 - val_loss: 1.1085 - val_mae: 0.8488 - val_mse: 1.1085\n",
      "Epoch 179/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6189 - mae: 0.5941 - mse: 0.6189 - val_loss: 1.0104 - val_mae: 0.7869 - val_mse: 1.0104\n",
      "Epoch 180/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6465 - mae: 0.6270 - mse: 0.6465 - val_loss: 1.6944 - val_mae: 1.0335 - val_mse: 1.6944\n",
      "Epoch 181/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6691 - mae: 0.6156 - mse: 0.6691 - val_loss: 0.8258 - val_mae: 0.7295 - val_mse: 0.8258\n",
      "Epoch 182/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6260 - mae: 0.6038 - mse: 0.6260 - val_loss: 0.8618 - val_mae: 0.7258 - val_mse: 0.8618\n",
      "Epoch 183/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6441 - mae: 0.6131 - mse: 0.6441 - val_loss: 0.7791 - val_mae: 0.7082 - val_mse: 0.7791\n",
      "Epoch 184/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6178 - mae: 0.5963 - mse: 0.6178 - val_loss: 0.8199 - val_mae: 0.7270 - val_mse: 0.8199\n",
      "Epoch 185/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6195 - mae: 0.5965 - mse: 0.6195 - val_loss: 1.0271 - val_mae: 0.8003 - val_mse: 1.0271\n",
      "Epoch 186/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6700 - mae: 0.6265 - mse: 0.6700 - val_loss: 0.7821 - val_mae: 0.7088 - val_mse: 0.7821\n",
      "Epoch 187/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6313 - mae: 0.6059 - mse: 0.6313 - val_loss: 0.8596 - val_mae: 0.7379 - val_mse: 0.8596\n",
      "Epoch 188/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6675 - mae: 0.6203 - mse: 0.6675 - val_loss: 0.8782 - val_mae: 0.7461 - val_mse: 0.8782\n",
      "Epoch 189/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6159 - mae: 0.5942 - mse: 0.6159 - val_loss: 0.9763 - val_mae: 0.7963 - val_mse: 0.9763\n",
      "Epoch 190/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5973 - mae: 0.5962 - mse: 0.5973 - val_loss: 0.7713 - val_mae: 0.7036 - val_mse: 0.7713\n",
      "Epoch 191/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6146 - mae: 0.6033 - mse: 0.6146 - val_loss: 0.8157 - val_mae: 0.7222 - val_mse: 0.8157\n",
      "Epoch 192/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6183 - mae: 0.5934 - mse: 0.6183 - val_loss: 0.7572 - val_mae: 0.7041 - val_mse: 0.7572\n",
      "Epoch 193/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6330 - mae: 0.5985 - mse: 0.6330 - val_loss: 0.8150 - val_mae: 0.7321 - val_mse: 0.8150\n",
      "Epoch 194/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6298 - mae: 0.5985 - mse: 0.6298 - val_loss: 0.8380 - val_mae: 0.7370 - val_mse: 0.8380\n",
      "Epoch 195/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6164 - mae: 0.5958 - mse: 0.6164 - val_loss: 0.9086 - val_mae: 0.7652 - val_mse: 0.9086\n",
      "Epoch 196/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6044 - mae: 0.5899 - mse: 0.6044 - val_loss: 0.7940 - val_mae: 0.7210 - val_mse: 0.7940\n",
      "Epoch 197/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6564 - mae: 0.6107 - mse: 0.6564 - val_loss: 0.8874 - val_mae: 0.7395 - val_mse: 0.8874\n",
      "Epoch 198/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5941 - mae: 0.5903 - mse: 0.5941 - val_loss: 0.8696 - val_mae: 0.7489 - val_mse: 0.8696\n",
      "Epoch 199/1000\n",
      "35/35 [==============================] - 0s 993us/step - loss: 0.6515 - mae: 0.6203 - mse: 0.6515 - val_loss: 0.8142 - val_mae: 0.7230 - val_mse: 0.8142\n",
      "Epoch 200/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6028 - mae: 0.5837 - mse: 0.6028 - val_loss: 0.9640 - val_mae: 0.7916 - val_mse: 0.9640\n",
      "Epoch 201/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.5643 - mae: 0.5762 - mse: 0.5643 - val_loss: 0.8816 - val_mae: 0.7363 - val_mse: 0.8816\n",
      "Epoch 202/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.6492 - mae: 0.6099 - mse: 0.6492 - val_loss: 0.8316 - val_mae: 0.7391 - val_mse: 0.8316\n",
      "Epoch 203/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5784 - mae: 0.5793 - mse: 0.5784 - val_loss: 0.9820 - val_mae: 0.7779 - val_mse: 0.9820\n",
      "Epoch 204/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.6174 - mae: 0.5952 - mse: 0.6174 - val_loss: 0.7629 - val_mae: 0.7120 - val_mse: 0.7629\n",
      "Epoch 205/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5711 - mae: 0.5670 - mse: 0.5711 - val_loss: 1.1838 - val_mae: 0.8871 - val_mse: 1.1838\n",
      "Epoch 206/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5924 - mae: 0.5915 - mse: 0.5924 - val_loss: 0.8024 - val_mae: 0.7262 - val_mse: 0.8024\n",
      "Epoch 207/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5923 - mae: 0.5787 - mse: 0.5923 - val_loss: 0.7553 - val_mae: 0.6992 - val_mse: 0.7553\n",
      "Epoch 208/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5644 - mae: 0.5682 - mse: 0.5644 - val_loss: 1.8995 - val_mae: 1.1615 - val_mse: 1.8995\n",
      "Epoch 209/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5905 - mae: 0.5869 - mse: 0.5905 - val_loss: 0.8189 - val_mae: 0.7300 - val_mse: 0.8189\n",
      "Epoch 210/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6099 - mae: 0.5894 - mse: 0.6099 - val_loss: 0.7794 - val_mae: 0.7185 - val_mse: 0.7794\n",
      "Epoch 211/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6084 - mae: 0.5817 - mse: 0.6084 - val_loss: 0.9188 - val_mae: 0.7691 - val_mse: 0.9188\n",
      "Epoch 212/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5614 - mae: 0.5646 - mse: 0.5614 - val_loss: 0.9032 - val_mae: 0.7560 - val_mse: 0.9032\n",
      "Epoch 213/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5680 - mae: 0.5691 - mse: 0.5680 - val_loss: 0.8811 - val_mae: 0.7634 - val_mse: 0.8811\n",
      "Epoch 214/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5450 - mae: 0.5581 - mse: 0.5450 - val_loss: 1.2322 - val_mae: 0.8839 - val_mse: 1.2322\n",
      "Epoch 215/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6027 - mae: 0.5805 - mse: 0.6027 - val_loss: 0.7762 - val_mae: 0.7058 - val_mse: 0.7762\n",
      "Epoch 216/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5757 - mae: 0.5748 - mse: 0.5757 - val_loss: 0.7751 - val_mae: 0.7129 - val_mse: 0.7751\n",
      "Epoch 217/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5866 - mae: 0.5821 - mse: 0.5866 - val_loss: 0.9117 - val_mae: 0.7697 - val_mse: 0.9117\n",
      "Epoch 218/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5606 - mae: 0.5691 - mse: 0.5606 - val_loss: 0.7906 - val_mae: 0.7103 - val_mse: 0.7906\n",
      "Epoch 219/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5675 - mae: 0.5598 - mse: 0.5675 - val_loss: 0.7599 - val_mae: 0.6911 - val_mse: 0.7599\n",
      "Epoch 220/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5423 - mae: 0.5556 - mse: 0.5423 - val_loss: 0.8012 - val_mae: 0.7221 - val_mse: 0.8012\n",
      "Epoch 221/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5158 - mae: 0.5437 - mse: 0.5158 - val_loss: 1.1525 - val_mae: 0.8849 - val_mse: 1.1525\n",
      "Epoch 222/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5947 - mae: 0.5939 - mse: 0.5947 - val_loss: 0.8848 - val_mae: 0.7595 - val_mse: 0.8848\n",
      "Epoch 223/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5459 - mae: 0.5570 - mse: 0.5459 - val_loss: 1.7013 - val_mae: 1.0775 - val_mse: 1.7013\n",
      "Epoch 224/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5540 - mae: 0.5607 - mse: 0.5540 - val_loss: 0.9482 - val_mae: 0.7961 - val_mse: 0.9482\n",
      "Epoch 225/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5604 - mae: 0.5750 - mse: 0.5604 - val_loss: 1.3671 - val_mae: 0.9599 - val_mse: 1.3671\n",
      "Epoch 226/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5324 - mae: 0.5553 - mse: 0.5324 - val_loss: 0.8342 - val_mae: 0.7272 - val_mse: 0.8342\n",
      "Epoch 227/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5286 - mae: 0.5582 - mse: 0.5286 - val_loss: 1.2689 - val_mae: 0.9037 - val_mse: 1.2689\n",
      "Epoch 228/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5652 - mae: 0.5721 - mse: 0.5652 - val_loss: 0.8112 - val_mae: 0.7302 - val_mse: 0.8112\n",
      "Epoch 229/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5269 - mae: 0.5481 - mse: 0.5269 - val_loss: 0.9271 - val_mae: 0.7675 - val_mse: 0.9271\n",
      "Epoch 230/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5394 - mae: 0.5500 - mse: 0.5394 - val_loss: 0.8726 - val_mae: 0.7500 - val_mse: 0.8726\n",
      "Epoch 231/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5564 - mae: 0.5643 - mse: 0.5564 - val_loss: 0.8446 - val_mae: 0.7502 - val_mse: 0.8446\n",
      "Epoch 232/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5248 - mae: 0.5432 - mse: 0.5248 - val_loss: 0.8674 - val_mae: 0.7339 - val_mse: 0.8674\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4914 - mae: 0.5317 - mse: 0.4914 - val_loss: 0.9571 - val_mae: 0.7714 - val_mse: 0.9571\n",
      "Epoch 234/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5626 - mae: 0.5746 - mse: 0.5626 - val_loss: 0.8071 - val_mae: 0.7236 - val_mse: 0.8071\n",
      "Epoch 235/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.5455 - mae: 0.5549 - mse: 0.5455 - val_loss: 0.7958 - val_mae: 0.7148 - val_mse: 0.7958\n",
      "Epoch 236/1000\n",
      "35/35 [==============================] - 0s 997us/step - loss: 0.4960 - mae: 0.5371 - mse: 0.4960 - val_loss: 1.0413 - val_mae: 0.7858 - val_mse: 1.0413\n",
      "Epoch 237/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5406 - mae: 0.5543 - mse: 0.5406 - val_loss: 1.0097 - val_mae: 0.8099 - val_mse: 1.0097\n",
      "Epoch 238/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5466 - mae: 0.5616 - mse: 0.5466 - val_loss: 0.8539 - val_mae: 0.7468 - val_mse: 0.8539\n",
      "Epoch 239/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5385 - mae: 0.5549 - mse: 0.5385 - val_loss: 1.1645 - val_mae: 0.8795 - val_mse: 1.1645\n",
      "Epoch 240/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5117 - mae: 0.5377 - mse: 0.5117 - val_loss: 0.8553 - val_mae: 0.7379 - val_mse: 0.8553\n",
      "Epoch 241/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5615 - mae: 0.5706 - mse: 0.5615 - val_loss: 0.8748 - val_mae: 0.7380 - val_mse: 0.8748\n",
      "Epoch 242/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5020 - mae: 0.5314 - mse: 0.5020 - val_loss: 0.9092 - val_mae: 0.7771 - val_mse: 0.9092\n",
      "Epoch 243/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5348 - mae: 0.5485 - mse: 0.5348 - val_loss: 1.0820 - val_mae: 0.8389 - val_mse: 1.0820\n",
      "Epoch 244/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4951 - mae: 0.5353 - mse: 0.4951 - val_loss: 1.2017 - val_mae: 0.8908 - val_mse: 1.2017\n",
      "Epoch 245/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.4967 - mae: 0.5302 - mse: 0.4967 - val_loss: 0.8258 - val_mae: 0.7337 - val_mse: 0.8258\n",
      "Epoch 246/1000\n",
      "35/35 [==============================] - 0s 968us/step - loss: 0.5383 - mae: 0.5553 - mse: 0.5383 - val_loss: 0.8442 - val_mae: 0.7425 - val_mse: 0.8442\n",
      "Epoch 247/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.4846 - mae: 0.5260 - mse: 0.4846 - val_loss: 0.8717 - val_mae: 0.7336 - val_mse: 0.8717\n",
      "Epoch 248/1000\n",
      "35/35 [==============================] - 0s 969us/step - loss: 0.4884 - mae: 0.5303 - mse: 0.4884 - val_loss: 1.2276 - val_mae: 0.8602 - val_mse: 1.2276\n",
      "Epoch 249/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5045 - mae: 0.5360 - mse: 0.5045 - val_loss: 0.9520 - val_mae: 0.7551 - val_mse: 0.9520\n",
      "Epoch 250/1000\n",
      "35/35 [==============================] - 0s 998us/step - loss: 0.5720 - mae: 0.5688 - mse: 0.5720 - val_loss: 0.8228 - val_mae: 0.7333 - val_mse: 0.8228\n",
      "Kappa Score: 0.673726948099594\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 178.8257 - mae: 6.9859 - mse: 178.8257 - val_loss: 133.4415 - val_mae: 11.1367 - val_mse: 133.4415\n",
      "Epoch 2/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 56.9425 - mae: 6.3989 - mse: 56.9425 - val_loss: 9.0938 - val_mae: 2.5454 - val_mse: 9.0938\n",
      "Epoch 3/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 26.6515 - mae: 4.0969 - mse: 26.6515 - val_loss: 8.0583 - val_mae: 2.6690 - val_mse: 8.0583\n",
      "Epoch 4/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 15.6275 - mae: 3.5201 - mse: 15.6275 - val_loss: 11.2151 - val_mae: 2.8636 - val_mse: 11.2151\n",
      "Epoch 5/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 8.1924 - mae: 2.4188 - mse: 8.1924 - val_loss: 14.8211 - val_mae: 3.5967 - val_mse: 14.8211\n",
      "Epoch 6/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 5.4407 - mae: 1.8853 - mse: 5.4407 - val_loss: 3.7320 - val_mae: 1.6158 - val_mse: 3.7320\n",
      "Epoch 7/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 4.8336 - mae: 1.7626 - mse: 4.8336 - val_loss: 2.7791 - val_mae: 1.3364 - val_mse: 2.7791\n",
      "Epoch 8/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.6080 - mae: 1.5307 - mse: 3.6080 - val_loss: 1.9927 - val_mae: 1.1382 - val_mse: 1.9927\n",
      "Epoch 9/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.0274 - mae: 1.4072 - mse: 3.0274 - val_loss: 1.1918 - val_mae: 0.8495 - val_mse: 1.1918\n",
      "Epoch 10/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.7909 - mae: 1.2924 - mse: 2.7909 - val_loss: 2.9177 - val_mae: 1.4484 - val_mse: 2.9177\n",
      "Epoch 11/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.4079 - mae: 1.2231 - mse: 2.4079 - val_loss: 2.5098 - val_mae: 1.2327 - val_mse: 2.5098\n",
      "Epoch 12/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.4629 - mae: 1.2542 - mse: 2.4629 - val_loss: 1.4583 - val_mae: 0.9375 - val_mse: 1.4583\n",
      "Epoch 13/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.1093 - mae: 1.1637 - mse: 2.1093 - val_loss: 1.0782 - val_mae: 0.7975 - val_mse: 1.0782\n",
      "Epoch 14/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.9037 - mae: 1.0973 - mse: 1.9037 - val_loss: 4.3765 - val_mae: 1.8715 - val_mse: 4.3765\n",
      "Epoch 15/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.2484 - mae: 1.1700 - mse: 2.2484 - val_loss: 1.7588 - val_mae: 1.0452 - val_mse: 1.7588\n",
      "Epoch 16/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7635 - mae: 1.0519 - mse: 1.7635 - val_loss: 2.0788 - val_mae: 1.1462 - val_mse: 2.0788\n",
      "Epoch 17/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.9027 - mae: 1.0804 - mse: 1.9027 - val_loss: 1.6345 - val_mae: 1.0086 - val_mse: 1.6345\n",
      "Epoch 18/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.8741 - mae: 1.0884 - mse: 1.8741 - val_loss: 1.1870 - val_mae: 0.8253 - val_mse: 1.1870\n",
      "Epoch 19/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7259 - mae: 1.0409 - mse: 1.7259 - val_loss: 1.0233 - val_mae: 0.7818 - val_mse: 1.0233\n",
      "Epoch 20/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7085 - mae: 1.0294 - mse: 1.7085 - val_loss: 1.0867 - val_mae: 0.8029 - val_mse: 1.0867\n",
      "Epoch 21/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7542 - mae: 1.0363 - mse: 1.7542 - val_loss: 1.4305 - val_mae: 0.9502 - val_mse: 1.4305\n",
      "Epoch 22/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6487 - mae: 1.0332 - mse: 1.6487 - val_loss: 1.0921 - val_mae: 0.7997 - val_mse: 1.0921\n",
      "Epoch 23/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7264 - mae: 1.0286 - mse: 1.7264 - val_loss: 1.0069 - val_mae: 0.7774 - val_mse: 1.0069\n",
      "Epoch 24/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5161 - mae: 0.9690 - mse: 1.5161 - val_loss: 1.1813 - val_mae: 0.8303 - val_mse: 1.1813\n",
      "Epoch 25/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4474 - mae: 0.9397 - mse: 1.4474 - val_loss: 1.2924 - val_mae: 0.8993 - val_mse: 1.2924\n",
      "Epoch 26/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.1323 - mae: 0.8766 - mse: 1.132 - 0s 1ms/step - loss: 1.6439 - mae: 1.0055 - mse: 1.6439 - val_loss: 1.0708 - val_mae: 0.8124 - val_mse: 1.0708\n",
      "Epoch 27/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5851 - mae: 0.9871 - mse: 1.5851 - val_loss: 1.8169 - val_mae: 1.0900 - val_mse: 1.8169\n",
      "Epoch 28/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4603 - mae: 0.9400 - mse: 1.4603 - val_loss: 1.0814 - val_mae: 0.7976 - val_mse: 1.0814\n",
      "Epoch 29/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5754 - mae: 0.9845 - mse: 1.5754 - val_loss: 1.0815 - val_mae: 0.7961 - val_mse: 1.0815\n",
      "Epoch 30/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4528 - mae: 0.9372 - mse: 1.4528 - val_loss: 1.3655 - val_mae: 0.9084 - val_mse: 1.3655\n",
      "Epoch 31/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4537 - mae: 0.9572 - mse: 1.4537 - val_loss: 1.0702 - val_mae: 0.7937 - val_mse: 1.0702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4258 - mae: 0.9318 - mse: 1.4258 - val_loss: 1.1158 - val_mae: 0.8263 - val_mse: 1.1158\n",
      "Epoch 33/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3595 - mae: 0.9144 - mse: 1.3595 - val_loss: 1.5945 - val_mae: 1.0160 - val_mse: 1.5945\n",
      "Epoch 34/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4039 - mae: 0.9304 - mse: 1.4039 - val_loss: 1.1186 - val_mae: 0.8251 - val_mse: 1.1186\n",
      "Epoch 35/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3113 - mae: 0.9016 - mse: 1.3113 - val_loss: 2.2484 - val_mae: 1.2430 - val_mse: 2.2484\n",
      "Epoch 36/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4347 - mae: 0.9242 - mse: 1.4347 - val_loss: 1.6915 - val_mae: 1.0405 - val_mse: 1.6915\n",
      "Epoch 37/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2608 - mae: 0.8748 - mse: 1.2608 - val_loss: 1.1198 - val_mae: 0.8310 - val_mse: 1.1198\n",
      "Epoch 38/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3072 - mae: 0.8972 - mse: 1.3072 - val_loss: 1.2924 - val_mae: 0.9055 - val_mse: 1.2924\n",
      "Epoch 39/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2703 - mae: 0.8890 - mse: 1.2703 - val_loss: 1.4104 - val_mae: 0.9555 - val_mse: 1.4104\n",
      "Epoch 40/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3264 - mae: 0.8936 - mse: 1.3264 - val_loss: 1.3762 - val_mae: 0.9135 - val_mse: 1.3762\n",
      "Epoch 41/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2187 - mae: 0.8537 - mse: 1.2187 - val_loss: 1.4675 - val_mae: 0.9781 - val_mse: 1.4675\n",
      "Epoch 42/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2416 - mae: 0.8791 - mse: 1.2416 - val_loss: 1.7175 - val_mae: 1.0410 - val_mse: 1.7175\n",
      "Epoch 43/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3039 - mae: 0.8861 - mse: 1.3039 - val_loss: 0.9138 - val_mae: 0.7398 - val_mse: 0.9138\n",
      "Epoch 44/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.2171 - mae: 0.8506 - mse: 1.2171 - val_loss: 1.0236 - val_mae: 0.7936 - val_mse: 1.0236\n",
      "Epoch 45/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2026 - mae: 0.8566 - mse: 1.2026 - val_loss: 0.9139 - val_mae: 0.7391 - val_mse: 0.9139\n",
      "Epoch 46/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2451 - mae: 0.8596 - mse: 1.2451 - val_loss: 1.0680 - val_mae: 0.7939 - val_mse: 1.0680\n",
      "Epoch 47/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2328 - mae: 0.8745 - mse: 1.2328 - val_loss: 1.1145 - val_mae: 0.8131 - val_mse: 1.1145\n",
      "Epoch 48/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2037 - mae: 0.8693 - mse: 1.2037 - val_loss: 0.9412 - val_mae: 0.7508 - val_mse: 0.9412\n",
      "Epoch 49/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1980 - mae: 0.8536 - mse: 1.1980 - val_loss: 1.3921 - val_mae: 0.9501 - val_mse: 1.3921\n",
      "Epoch 50/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2646 - mae: 0.8814 - mse: 1.2646 - val_loss: 1.0019 - val_mae: 0.7671 - val_mse: 1.0019\n",
      "Epoch 51/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1456 - mae: 0.8302 - mse: 1.1456 - val_loss: 0.9233 - val_mae: 0.7431 - val_mse: 0.9233\n",
      "Epoch 52/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2160 - mae: 0.8571 - mse: 1.2160 - val_loss: 0.9882 - val_mae: 0.7574 - val_mse: 0.9882\n",
      "Epoch 53/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1594 - mae: 0.8440 - mse: 1.1594 - val_loss: 0.9364 - val_mae: 0.7440 - val_mse: 0.9364\n",
      "Epoch 54/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1361 - mae: 0.8415 - mse: 1.1361 - val_loss: 1.0567 - val_mae: 0.8131 - val_mse: 1.0567\n",
      "Epoch 55/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1982 - mae: 0.8572 - mse: 1.1982 - val_loss: 0.9255 - val_mae: 0.7383 - val_mse: 0.9255\n",
      "Epoch 56/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1725 - mae: 0.8474 - mse: 1.1725 - val_loss: 2.1586 - val_mae: 1.2058 - val_mse: 2.1586\n",
      "Epoch 57/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1318 - mae: 0.8239 - mse: 1.1318 - val_loss: 0.9282 - val_mae: 0.7486 - val_mse: 0.9282\n",
      "Epoch 58/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0433 - mae: 0.7955 - mse: 1.0433 - val_loss: 1.1569 - val_mae: 0.8404 - val_mse: 1.1569\n",
      "Epoch 59/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1458 - mae: 0.8337 - mse: 1.1458 - val_loss: 0.8901 - val_mae: 0.7274 - val_mse: 0.8901\n",
      "Epoch 60/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1045 - mae: 0.8240 - mse: 1.1045 - val_loss: 0.9207 - val_mae: 0.7362 - val_mse: 0.9207\n",
      "Epoch 61/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1079 - mae: 0.8273 - mse: 1.1079 - val_loss: 1.7625 - val_mae: 1.0910 - val_mse: 1.7625\n",
      "Epoch 62/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1348 - mae: 0.8288 - mse: 1.1348 - val_loss: 1.1198 - val_mae: 0.8455 - val_mse: 1.1198\n",
      "Epoch 63/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0682 - mae: 0.7968 - mse: 1.0682 - val_loss: 1.8598 - val_mae: 1.1134 - val_mse: 1.8598\n",
      "Epoch 64/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1355 - mae: 0.8357 - mse: 1.1355 - val_loss: 0.9092 - val_mae: 0.7424 - val_mse: 0.9092\n",
      "Epoch 65/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1768 - mae: 0.8437 - mse: 1.1768 - val_loss: 0.9294 - val_mae: 0.7373 - val_mse: 0.9294\n",
      "Epoch 66/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0142 - mae: 0.7775 - mse: 1.0142 - val_loss: 1.5117 - val_mae: 1.0022 - val_mse: 1.5117\n",
      "Epoch 67/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1325 - mae: 0.8408 - mse: 1.1325 - val_loss: 0.9558 - val_mae: 0.7630 - val_mse: 0.9558\n",
      "Epoch 68/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0066 - mae: 0.7784 - mse: 1.0066 - val_loss: 0.8947 - val_mae: 0.7234 - val_mse: 0.8947\n",
      "Epoch 69/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0736 - mae: 0.8031 - mse: 1.0736 - val_loss: 1.5191 - val_mae: 1.0091 - val_mse: 1.5191\n",
      "Epoch 70/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0628 - mae: 0.8015 - mse: 1.0628 - val_loss: 2.3521 - val_mae: 1.3006 - val_mse: 2.3521\n",
      "Epoch 71/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9884 - mae: 0.7698 - mse: 0.9884 - val_loss: 0.9272 - val_mae: 0.7488 - val_mse: 0.9272\n",
      "Epoch 72/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1096 - mae: 0.8102 - mse: 1.1096 - val_loss: 0.9822 - val_mae: 0.7789 - val_mse: 0.9822\n",
      "Epoch 73/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0131 - mae: 0.7839 - mse: 1.0131 - val_loss: 0.9050 - val_mae: 0.7453 - val_mse: 0.9050\n",
      "Epoch 74/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0474 - mae: 0.7886 - mse: 1.0474 - val_loss: 1.2147 - val_mae: 0.8540 - val_mse: 1.2147\n",
      "Epoch 75/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0960 - mae: 0.8217 - mse: 1.0960 - val_loss: 0.9952 - val_mae: 0.7588 - val_mse: 0.9952\n",
      "Epoch 76/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9532 - mae: 0.7564 - mse: 0.9532 - val_loss: 1.2770 - val_mae: 0.9137 - val_mse: 1.2770\n",
      "Epoch 77/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9827 - mae: 0.7735 - mse: 0.9827 - val_loss: 1.0510 - val_mae: 0.7860 - val_mse: 1.0510\n",
      "Epoch 78/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0796 - mae: 0.8018 - mse: 1.0796 - val_loss: 0.8843 - val_mae: 0.7219 - val_mse: 0.8843\n",
      "Epoch 79/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8934 - mae: 0.7392 - mse: 0.8934 - val_loss: 1.3554 - val_mae: 0.9011 - val_mse: 1.3554\n",
      "Epoch 80/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0057 - mae: 0.7797 - mse: 1.0057 - val_loss: 0.8982 - val_mae: 0.7452 - val_mse: 0.8982\n",
      "Epoch 81/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9251 - mae: 0.7340 - mse: 0.9251 - val_loss: 1.4158 - val_mae: 0.9369 - val_mse: 1.4158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9474 - mae: 0.7555 - mse: 0.9474 - val_loss: 0.9314 - val_mae: 0.7588 - val_mse: 0.9314\n",
      "Epoch 83/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0124 - mae: 0.7772 - mse: 1.0124 - val_loss: 0.8748 - val_mae: 0.7105 - val_mse: 0.8748\n",
      "Epoch 84/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9550 - mae: 0.7520 - mse: 0.9550 - val_loss: 0.9099 - val_mae: 0.7481 - val_mse: 0.9099\n",
      "Epoch 85/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9614 - mae: 0.7663 - mse: 0.9614 - val_loss: 1.3011 - val_mae: 0.9241 - val_mse: 1.3011\n",
      "Epoch 86/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9644 - mae: 0.7644 - mse: 0.9644 - val_loss: 1.3752 - val_mae: 0.9351 - val_mse: 1.3752\n",
      "Epoch 87/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9014 - mae: 0.7342 - mse: 0.9014 - val_loss: 0.9951 - val_mae: 0.7597 - val_mse: 0.9951\n",
      "Epoch 88/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9283 - mae: 0.7502 - mse: 0.9283 - val_loss: 1.5331 - val_mae: 1.0193 - val_mse: 1.5331\n",
      "Epoch 89/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9730 - mae: 0.7704 - mse: 0.9730 - val_loss: 1.4908 - val_mae: 0.9655 - val_mse: 1.4908\n",
      "Epoch 90/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0154 - mae: 0.7746 - mse: 1.0154 - val_loss: 0.8618 - val_mae: 0.7250 - val_mse: 0.8618\n",
      "Epoch 91/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9039 - mae: 0.7306 - mse: 0.9039 - val_loss: 1.2730 - val_mae: 0.8737 - val_mse: 1.2730\n",
      "Epoch 92/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9454 - mae: 0.7566 - mse: 0.9454 - val_loss: 0.8579 - val_mae: 0.7064 - val_mse: 0.8579\n",
      "Epoch 93/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8750 - mae: 0.7278 - mse: 0.8750 - val_loss: 0.8551 - val_mae: 0.7182 - val_mse: 0.8551\n",
      "Epoch 94/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9276 - mae: 0.7425 - mse: 0.9276 - val_loss: 1.2155 - val_mae: 0.8684 - val_mse: 1.2155\n",
      "Epoch 95/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8969 - mae: 0.7339 - mse: 0.8969 - val_loss: 1.0336 - val_mae: 0.7686 - val_mse: 1.0336\n",
      "Epoch 96/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8872 - mae: 0.7256 - mse: 0.8872 - val_loss: 0.9324 - val_mae: 0.7634 - val_mse: 0.9324\n",
      "Epoch 97/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9033 - mae: 0.7455 - mse: 0.9033 - val_loss: 1.1503 - val_mae: 0.8367 - val_mse: 1.1503\n",
      "Epoch 98/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8855 - mae: 0.7206 - mse: 0.8855 - val_loss: 1.2385 - val_mae: 0.8523 - val_mse: 1.2385\n",
      "Epoch 99/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8856 - mae: 0.7285 - mse: 0.8856 - val_loss: 0.9260 - val_mae: 0.7604 - val_mse: 0.9260\n",
      "Epoch 100/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9095 - mae: 0.7376 - mse: 0.9095 - val_loss: 0.9846 - val_mae: 0.7596 - val_mse: 0.9846\n",
      "Epoch 101/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8535 - mae: 0.7162 - mse: 0.8535 - val_loss: 1.1711 - val_mae: 0.8411 - val_mse: 1.1711\n",
      "Epoch 102/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8681 - mae: 0.7256 - mse: 0.8681 - val_loss: 0.8431 - val_mae: 0.7066 - val_mse: 0.8431\n",
      "Epoch 103/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8489 - mae: 0.7137 - mse: 0.8489 - val_loss: 1.0531 - val_mae: 0.7794 - val_mse: 1.0531\n",
      "Epoch 104/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9325 - mae: 0.7472 - mse: 0.9325 - val_loss: 0.9285 - val_mae: 0.7510 - val_mse: 0.9285\n",
      "Epoch 105/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8130 - mae: 0.6985 - mse: 0.8130 - val_loss: 0.9276 - val_mae: 0.7341 - val_mse: 0.9276\n",
      "Epoch 106/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7934 - mae: 0.6897 - mse: 0.7934 - val_loss: 1.8588 - val_mae: 1.1039 - val_mse: 1.8588\n",
      "Epoch 107/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9554 - mae: 0.7610 - mse: 0.9554 - val_loss: 1.1269 - val_mae: 0.8154 - val_mse: 1.1269\n",
      "Epoch 108/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9421 - mae: 0.7349 - mse: 0.9421 - val_loss: 1.2289 - val_mae: 0.8587 - val_mse: 1.2289\n",
      "Epoch 109/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8500 - mae: 0.7129 - mse: 0.8500 - val_loss: 1.0306 - val_mae: 0.7867 - val_mse: 1.0306\n",
      "Epoch 110/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7933 - mae: 0.6864 - mse: 0.7933 - val_loss: 1.5363 - val_mae: 1.0102 - val_mse: 1.5363\n",
      "Epoch 111/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8807 - mae: 0.7237 - mse: 0.8807 - val_loss: 0.8639 - val_mae: 0.7132 - val_mse: 0.8639\n",
      "Epoch 112/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8253 - mae: 0.7037 - mse: 0.8253 - val_loss: 1.0332 - val_mae: 0.7843 - val_mse: 1.0332\n",
      "Epoch 113/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8126 - mae: 0.6989 - mse: 0.8126 - val_loss: 0.8529 - val_mae: 0.7073 - val_mse: 0.8529\n",
      "Epoch 114/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8245 - mae: 0.7000 - mse: 0.8245 - val_loss: 0.8335 - val_mae: 0.7059 - val_mse: 0.8335\n",
      "Epoch 115/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8325 - mae: 0.7040 - mse: 0.8325 - val_loss: 0.9235 - val_mae: 0.7533 - val_mse: 0.9235\n",
      "Epoch 116/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8440 - mae: 0.7173 - mse: 0.8440 - val_loss: 0.8235 - val_mae: 0.6849 - val_mse: 0.8235\n",
      "Epoch 117/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8162 - mae: 0.6929 - mse: 0.8162 - val_loss: 0.8295 - val_mae: 0.7014 - val_mse: 0.8295\n",
      "Epoch 118/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7932 - mae: 0.6913 - mse: 0.7932 - val_loss: 1.2813 - val_mae: 0.8899 - val_mse: 1.2813\n",
      "Epoch 119/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8008 - mae: 0.6891 - mse: 0.8008 - val_loss: 0.8482 - val_mae: 0.7044 - val_mse: 0.8482\n",
      "Epoch 120/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8124 - mae: 0.7052 - mse: 0.8124 - val_loss: 0.9716 - val_mae: 0.7679 - val_mse: 0.9716\n",
      "Epoch 121/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8086 - mae: 0.6936 - mse: 0.8086 - val_loss: 1.3569 - val_mae: 0.9557 - val_mse: 1.3569\n",
      "Epoch 122/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8290 - mae: 0.7135 - mse: 0.8290 - val_loss: 0.8957 - val_mae: 0.7268 - val_mse: 0.8957\n",
      "Epoch 123/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7967 - mae: 0.6878 - mse: 0.7967 - val_loss: 1.1221 - val_mae: 0.7983 - val_mse: 1.1221\n",
      "Epoch 124/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8110 - mae: 0.6930 - mse: 0.8110 - val_loss: 0.8620 - val_mae: 0.7157 - val_mse: 0.8620\n",
      "Epoch 125/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8093 - mae: 0.6973 - mse: 0.8093 - val_loss: 0.8603 - val_mae: 0.7029 - val_mse: 0.8603\n",
      "Epoch 126/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7746 - mae: 0.6633 - mse: 0.7746 - val_loss: 1.0477 - val_mae: 0.7839 - val_mse: 1.0477\n",
      "Epoch 127/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7981 - mae: 0.6849 - mse: 0.7981 - val_loss: 1.1702 - val_mae: 0.8641 - val_mse: 1.1702\n",
      "Epoch 128/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7503 - mae: 0.6688 - mse: 0.7503 - val_loss: 1.3946 - val_mae: 0.9633 - val_mse: 1.3946\n",
      "Epoch 129/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8026 - mae: 0.6924 - mse: 0.8026 - val_loss: 0.8920 - val_mae: 0.7213 - val_mse: 0.8920\n",
      "Epoch 130/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7836 - mae: 0.6820 - mse: 0.7836 - val_loss: 1.1689 - val_mae: 0.8684 - val_mse: 1.1689\n",
      "Epoch 131/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7992 - mae: 0.7000 - mse: 0.7992 - val_loss: 1.0537 - val_mae: 0.8014 - val_mse: 1.0537\n",
      "Epoch 132/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7799 - mae: 0.6697 - mse: 0.7799 - val_loss: 1.4274 - val_mae: 0.9764 - val_mse: 1.4274\n",
      "Epoch 133/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7629 - mae: 0.6753 - mse: 0.7629 - val_loss: 1.2398 - val_mae: 0.8877 - val_mse: 1.2398\n",
      "Epoch 134/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7405 - mae: 0.6649 - mse: 0.7405 - val_loss: 1.2257 - val_mae: 0.8809 - val_mse: 1.2257\n",
      "Epoch 135/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7399 - mae: 0.6595 - mse: 0.7399 - val_loss: 0.9442 - val_mae: 0.7419 - val_mse: 0.9442\n",
      "Epoch 136/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7759 - mae: 0.6790 - mse: 0.7759 - val_loss: 0.8847 - val_mae: 0.7103 - val_mse: 0.8847\n",
      "Epoch 137/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7317 - mae: 0.6676 - mse: 0.7317 - val_loss: 1.2488 - val_mae: 0.8990 - val_mse: 1.2488\n",
      "Epoch 138/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7714 - mae: 0.6809 - mse: 0.7714 - val_loss: 0.8674 - val_mae: 0.7120 - val_mse: 0.8674\n",
      "Epoch 139/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7881 - mae: 0.6828 - mse: 0.7881 - val_loss: 0.9073 - val_mae: 0.7491 - val_mse: 0.9073\n",
      "Epoch 140/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7755 - mae: 0.6763 - mse: 0.7755 - val_loss: 0.8183 - val_mae: 0.6842 - val_mse: 0.8183\n",
      "Epoch 141/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7450 - mae: 0.6632 - mse: 0.7450 - val_loss: 0.9494 - val_mae: 0.7587 - val_mse: 0.9494\n",
      "Epoch 142/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7078 - mae: 0.6525 - mse: 0.7078 - val_loss: 1.4724 - val_mae: 0.9919 - val_mse: 1.4724\n",
      "Epoch 143/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7465 - mae: 0.6640 - mse: 0.7465 - val_loss: 0.8945 - val_mae: 0.7212 - val_mse: 0.8945\n",
      "Epoch 144/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6619 - mae: 0.6227 - mse: 0.6619 - val_loss: 0.9141 - val_mae: 0.7166 - val_mse: 0.9141\n",
      "Epoch 145/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7406 - mae: 0.6576 - mse: 0.7406 - val_loss: 0.8966 - val_mae: 0.7076 - val_mse: 0.8966\n",
      "Epoch 146/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6736 - mae: 0.6339 - mse: 0.6736 - val_loss: 0.8688 - val_mae: 0.7165 - val_mse: 0.8688\n",
      "Epoch 147/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6935 - mae: 0.6415 - mse: 0.6935 - val_loss: 0.8637 - val_mae: 0.7038 - val_mse: 0.8637\n",
      "Epoch 148/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7507 - mae: 0.6659 - mse: 0.7507 - val_loss: 0.8363 - val_mae: 0.6878 - val_mse: 0.8363\n",
      "Epoch 149/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7001 - mae: 0.6434 - mse: 0.7001 - val_loss: 1.0362 - val_mae: 0.7854 - val_mse: 1.0362\n",
      "Epoch 150/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7106 - mae: 0.6536 - mse: 0.7106 - val_loss: 0.9266 - val_mae: 0.7241 - val_mse: 0.9266\n",
      "Epoch 151/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6572 - mae: 0.6192 - mse: 0.6572 - val_loss: 1.0075 - val_mae: 0.7585 - val_mse: 1.0075\n",
      "Epoch 152/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7155 - mae: 0.6488 - mse: 0.7155 - val_loss: 1.5221 - val_mae: 1.0184 - val_mse: 1.5221\n",
      "Epoch 153/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7404 - mae: 0.6662 - mse: 0.7404 - val_loss: 0.9936 - val_mae: 0.7787 - val_mse: 0.9936\n",
      "Epoch 154/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7126 - mae: 0.6516 - mse: 0.7126 - val_loss: 0.9874 - val_mae: 0.7718 - val_mse: 0.9874\n",
      "Epoch 155/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6597 - mae: 0.6242 - mse: 0.6597 - val_loss: 1.3376 - val_mae: 0.9320 - val_mse: 1.3376\n",
      "Epoch 156/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7156 - mae: 0.6582 - mse: 0.7156 - val_loss: 0.8290 - val_mae: 0.7014 - val_mse: 0.8290\n",
      "Epoch 157/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6642 - mae: 0.6323 - mse: 0.6642 - val_loss: 0.8418 - val_mae: 0.7090 - val_mse: 0.8418\n",
      "Epoch 158/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7020 - mae: 0.6364 - mse: 0.7020 - val_loss: 0.8880 - val_mae: 0.7264 - val_mse: 0.8880\n",
      "Epoch 159/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6780 - mae: 0.6391 - mse: 0.6780 - val_loss: 1.6952 - val_mae: 1.0564 - val_mse: 1.6952\n",
      "Epoch 160/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6833 - mae: 0.6349 - mse: 0.6833 - val_loss: 1.0252 - val_mae: 0.7756 - val_mse: 1.0252\n",
      "Epoch 161/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6951 - mae: 0.6382 - mse: 0.6951 - val_loss: 1.0599 - val_mae: 0.7864 - val_mse: 1.0599\n",
      "Epoch 162/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7222 - mae: 0.6616 - mse: 0.7222 - val_loss: 1.0218 - val_mae: 0.7906 - val_mse: 1.0218\n",
      "Epoch 163/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6369 - mae: 0.6095 - mse: 0.6369 - val_loss: 1.1782 - val_mae: 0.8557 - val_mse: 1.1782\n",
      "Epoch 164/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6945 - mae: 0.6367 - mse: 0.6945 - val_loss: 1.1464 - val_mae: 0.8332 - val_mse: 1.1464\n",
      "Epoch 165/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6484 - mae: 0.6167 - mse: 0.6484 - val_loss: 1.0967 - val_mae: 0.8050 - val_mse: 1.0967\n",
      "Epoch 166/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6784 - mae: 0.6313 - mse: 0.6784 - val_loss: 0.8450 - val_mae: 0.6977 - val_mse: 0.8450\n",
      "Epoch 167/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6666 - mae: 0.6282 - mse: 0.6666 - val_loss: 0.9088 - val_mae: 0.7215 - val_mse: 0.9088\n",
      "Epoch 168/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6513 - mae: 0.6248 - mse: 0.6513 - val_loss: 1.0825 - val_mae: 0.7958 - val_mse: 1.0825\n",
      "Epoch 169/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6475 - mae: 0.6205 - mse: 0.6475 - val_loss: 0.9431 - val_mae: 0.7321 - val_mse: 0.9431\n",
      "Epoch 170/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6543 - mae: 0.6225 - mse: 0.6543 - val_loss: 1.8749 - val_mae: 1.1552 - val_mse: 1.8749\n",
      "Epoch 171/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6721 - mae: 0.6363 - mse: 0.6721 - val_loss: 1.4706 - val_mae: 0.9754 - val_mse: 1.4706\n",
      "Epoch 172/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6544 - mae: 0.6199 - mse: 0.6544 - val_loss: 0.8621 - val_mae: 0.7122 - val_mse: 0.8621\n",
      "Epoch 173/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6295 - mae: 0.6105 - mse: 0.6295 - val_loss: 0.9278 - val_mae: 0.7356 - val_mse: 0.9278\n",
      "Epoch 174/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6454 - mae: 0.6224 - mse: 0.6454 - val_loss: 0.9568 - val_mae: 0.7551 - val_mse: 0.9568\n",
      "Epoch 175/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6488 - mae: 0.6115 - mse: 0.6488 - val_loss: 1.1440 - val_mae: 0.8546 - val_mse: 1.1440\n",
      "Epoch 176/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6545 - mae: 0.6109 - mse: 0.6545 - val_loss: 0.8459 - val_mae: 0.7026 - val_mse: 0.8459\n",
      "Epoch 177/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5549 - mae: 0.5230 - mse: 0.554 - 0s 1ms/step - loss: 0.5982 - mae: 0.5972 - mse: 0.5982 - val_loss: 0.9939 - val_mae: 0.7758 - val_mse: 0.9939\n",
      "Epoch 178/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6626 - mae: 0.6281 - mse: 0.6626 - val_loss: 0.8765 - val_mae: 0.7234 - val_mse: 0.8765\n",
      "Epoch 179/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6510 - mae: 0.6244 - mse: 0.6510 - val_loss: 1.0089 - val_mae: 0.7818 - val_mse: 1.0089\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6240 - mae: 0.6022 - mse: 0.6240 - val_loss: 0.9530 - val_mae: 0.7517 - val_mse: 0.9530\n",
      "Epoch 181/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5868 - mae: 0.5833 - mse: 0.5868 - val_loss: 0.8960 - val_mae: 0.7134 - val_mse: 0.8960\n",
      "Epoch 182/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6067 - mae: 0.5925 - mse: 0.6067 - val_loss: 0.9709 - val_mae: 0.7794 - val_mse: 0.9709\n",
      "Epoch 183/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6322 - mae: 0.6110 - mse: 0.6322 - val_loss: 1.8024 - val_mae: 1.1234 - val_mse: 1.8024\n",
      "Epoch 184/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6520 - mae: 0.6160 - mse: 0.6520 - val_loss: 0.8543 - val_mae: 0.7147 - val_mse: 0.8543\n",
      "Epoch 185/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5912 - mae: 0.5865 - mse: 0.5912 - val_loss: 0.9195 - val_mae: 0.7324 - val_mse: 0.9195\n",
      "Epoch 186/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5946 - mae: 0.6012 - mse: 0.5946 - val_loss: 0.8391 - val_mae: 0.6989 - val_mse: 0.8391\n",
      "Epoch 187/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6528 - mae: 0.6258 - mse: 0.6528 - val_loss: 1.1437 - val_mae: 0.8478 - val_mse: 1.1437\n",
      "Epoch 188/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5707 - mae: 0.5745 - mse: 0.5707 - val_loss: 0.8471 - val_mae: 0.6974 - val_mse: 0.8471\n",
      "Epoch 189/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6666 - mae: 0.6335 - mse: 0.6666 - val_loss: 0.8821 - val_mae: 0.7144 - val_mse: 0.8821\n",
      "Epoch 190/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5833 - mae: 0.5807 - mse: 0.5833 - val_loss: 0.8981 - val_mae: 0.7236 - val_mse: 0.8981\n",
      "Epoch 191/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5827 - mae: 0.5852 - mse: 0.5827 - val_loss: 0.8632 - val_mae: 0.7007 - val_mse: 0.8632\n",
      "Epoch 192/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6121 - mae: 0.6036 - mse: 0.6121 - val_loss: 0.9005 - val_mae: 0.7060 - val_mse: 0.9005\n",
      "Epoch 193/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5771 - mae: 0.5730 - mse: 0.5771 - val_loss: 0.9104 - val_mae: 0.7251 - val_mse: 0.9104\n",
      "Epoch 194/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6019 - mae: 0.5953 - mse: 0.6019 - val_loss: 0.8751 - val_mae: 0.7230 - val_mse: 0.8751\n",
      "Epoch 195/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5637 - mae: 0.5761 - mse: 0.5637 - val_loss: 1.0950 - val_mae: 0.8181 - val_mse: 1.0950\n",
      "Epoch 196/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6112 - mae: 0.5933 - mse: 0.6112 - val_loss: 1.1459 - val_mae: 0.8578 - val_mse: 1.1459\n",
      "Epoch 197/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5895 - mae: 0.5933 - mse: 0.5895 - val_loss: 0.9200 - val_mae: 0.7329 - val_mse: 0.9200\n",
      "Epoch 198/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5798 - mae: 0.5721 - mse: 0.5798 - val_loss: 0.9167 - val_mae: 0.7274 - val_mse: 0.9167\n",
      "Epoch 199/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5668 - mae: 0.5763 - mse: 0.5668 - val_loss: 0.8460 - val_mae: 0.6974 - val_mse: 0.8460\n",
      "Epoch 200/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5728 - mae: 0.5840 - mse: 0.5728 - val_loss: 0.9774 - val_mae: 0.7516 - val_mse: 0.9774\n",
      "Epoch 201/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5774 - mae: 0.5746 - mse: 0.5774 - val_loss: 1.3209 - val_mae: 0.9003 - val_mse: 1.3209\n",
      "Epoch 202/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5641 - mae: 0.5783 - mse: 0.5641 - val_loss: 0.8739 - val_mae: 0.6935 - val_mse: 0.8739\n",
      "Epoch 203/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5504 - mae: 0.5783 - mse: 0.5504 - val_loss: 1.5577 - val_mae: 1.0030 - val_mse: 1.5577\n",
      "Epoch 204/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5994 - mae: 0.5977 - mse: 0.5994 - val_loss: 0.9316 - val_mae: 0.7348 - val_mse: 0.9316\n",
      "Epoch 205/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5567 - mae: 0.5658 - mse: 0.5567 - val_loss: 1.1341 - val_mae: 0.8176 - val_mse: 1.1341\n",
      "Epoch 206/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5493 - mae: 0.5748 - mse: 0.5493 - val_loss: 0.9481 - val_mae: 0.7415 - val_mse: 0.9481\n",
      "Epoch 207/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5747 - mae: 0.5840 - mse: 0.5747 - val_loss: 1.3020 - val_mae: 0.9222 - val_mse: 1.3020\n",
      "Epoch 208/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5002 - mae: 0.5400 - mse: 0.5002 - val_loss: 0.9463 - val_mae: 0.7404 - val_mse: 0.9463\n",
      "Epoch 209/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5600 - mae: 0.5695 - mse: 0.5600 - val_loss: 1.3810 - val_mae: 0.9159 - val_mse: 1.3810\n",
      "Epoch 210/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5696 - mae: 0.5759 - mse: 0.5696 - val_loss: 0.9278 - val_mae: 0.7377 - val_mse: 0.9278\n",
      "Epoch 211/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5384 - mae: 0.5557 - mse: 0.5384 - val_loss: 0.9151 - val_mae: 0.7244 - val_mse: 0.9151\n",
      "Epoch 212/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5619 - mae: 0.5765 - mse: 0.5619 - val_loss: 0.9432 - val_mae: 0.7500 - val_mse: 0.9432\n",
      "Epoch 213/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5079 - mae: 0.5427 - mse: 0.5079 - val_loss: 1.0021 - val_mae: 0.7615 - val_mse: 1.0021\n",
      "Epoch 214/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5311 - mae: 0.5557 - mse: 0.5311 - val_loss: 0.9683 - val_mae: 0.7535 - val_mse: 0.9683\n",
      "Epoch 215/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5119 - mae: 0.5427 - mse: 0.5119 - val_loss: 0.8792 - val_mae: 0.7098 - val_mse: 0.8792\n",
      "Epoch 216/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5312 - mae: 0.5547 - mse: 0.5312 - val_loss: 0.8828 - val_mae: 0.7141 - val_mse: 0.8828\n",
      "Epoch 217/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5688 - mae: 0.5820 - mse: 0.5688 - val_loss: 0.9551 - val_mae: 0.7478 - val_mse: 0.9551\n",
      "Epoch 218/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4955 - mae: 0.5404 - mse: 0.4955 - val_loss: 1.0412 - val_mae: 0.7726 - val_mse: 1.0412\n",
      "Epoch 219/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4891 - mae: 0.5280 - mse: 0.4891 - val_loss: 1.6553 - val_mae: 1.0322 - val_mse: 1.6553\n",
      "Epoch 220/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5389 - mae: 0.5664 - mse: 0.5389 - val_loss: 1.2196 - val_mae: 0.8741 - val_mse: 1.2196\n",
      "Epoch 221/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5380 - mae: 0.5603 - mse: 0.5380 - val_loss: 0.9325 - val_mae: 0.7208 - val_mse: 0.9325\n",
      "Epoch 222/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4835 - mae: 0.5386 - mse: 0.4835 - val_loss: 0.9813 - val_mae: 0.7690 - val_mse: 0.9813\n",
      "Epoch 223/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4877 - mae: 0.5308 - mse: 0.4877 - val_loss: 0.9676 - val_mae: 0.7639 - val_mse: 0.9676\n",
      "Epoch 224/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5347 - mae: 0.5650 - mse: 0.5347 - val_loss: 1.0528 - val_mae: 0.8061 - val_mse: 1.0528\n",
      "Epoch 225/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5036 - mae: 0.5480 - mse: 0.5036 - val_loss: 0.9508 - val_mae: 0.7355 - val_mse: 0.9508\n",
      "Epoch 226/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4659 - mae: 0.5314 - mse: 0.4659 - val_loss: 0.9007 - val_mae: 0.7164 - val_mse: 0.9007\n",
      "Epoch 227/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4826 - mae: 0.5272 - mse: 0.4826 - val_loss: 1.2343 - val_mae: 0.9045 - val_mse: 1.2343\n",
      "Epoch 228/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5176 - mae: 0.5547 - mse: 0.5176 - val_loss: 0.8797 - val_mae: 0.7180 - val_mse: 0.8797\n",
      "Epoch 229/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4684 - mae: 0.5152 - mse: 0.4684 - val_loss: 1.2120 - val_mae: 0.8677 - val_mse: 1.2120\n",
      "Epoch 230/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5430 - mae: 0.5699 - mse: 0.5430 - val_loss: 0.9164 - val_mae: 0.7261 - val_mse: 0.9164\n",
      "Epoch 231/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4944 - mae: 0.5339 - mse: 0.4944 - val_loss: 0.9842 - val_mae: 0.7738 - val_mse: 0.9842\n",
      "Epoch 232/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4479 - mae: 0.5117 - mse: 0.4479 - val_loss: 1.0464 - val_mae: 0.8039 - val_mse: 1.0464\n",
      "Epoch 233/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4764 - mae: 0.5253 - mse: 0.4764 - val_loss: 0.9808 - val_mae: 0.7572 - val_mse: 0.9808\n",
      "Epoch 234/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4966 - mae: 0.5433 - mse: 0.4966 - val_loss: 0.9891 - val_mae: 0.7702 - val_mse: 0.9891\n",
      "Epoch 235/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5022 - mae: 0.5408 - mse: 0.5022 - val_loss: 1.1349 - val_mae: 0.8563 - val_mse: 1.1349\n",
      "Epoch 236/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4401 - mae: 0.5052 - mse: 0.4401 - val_loss: 0.9015 - val_mae: 0.7318 - val_mse: 0.9015\n",
      "Epoch 237/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4489 - mae: 0.5159 - mse: 0.4489 - val_loss: 0.9170 - val_mae: 0.7401 - val_mse: 0.9170\n",
      "Epoch 238/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4390 - mae: 0.5060 - mse: 0.4390 - val_loss: 1.0292 - val_mae: 0.7876 - val_mse: 1.0292\n",
      "Epoch 239/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4396 - mae: 0.5134 - mse: 0.4396 - val_loss: 0.8736 - val_mae: 0.7211 - val_mse: 0.8736\n",
      "Epoch 240/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.4802 - mae: 0.5345 - mse: 0.4802 - val_loss: 1.1548 - val_mae: 0.8227 - val_mse: 1.1548\n",
      "Kappa Score: 0.7125233949060135\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 222.7007 - mae: 7.2171 - mse: 222.7007 - val_loss: 58.9996 - val_mae: 7.1064 - val_mse: 58.9996\n",
      "Epoch 2/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 50.3519 - mae: 5.5973 - mse: 50.3519 - val_loss: 8.6123 - val_mae: 2.7540 - val_mse: 8.6123\n",
      "Epoch 3/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 21.5126 - mae: 3.9205 - mse: 21.5126 - val_loss: 5.7347 - val_mae: 1.9921 - val_mse: 5.7347\n",
      "Epoch 4/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 14.2874 - mae: 3.0021 - mse: 14.2874 - val_loss: 2.6383 - val_mae: 1.2672 - val_mse: 2.6383\n",
      "Epoch 5/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 5.6161 - mae: 1.8493 - mse: 5.6161 - val_loss: 1.9736 - val_mae: 1.1518 - val_mse: 1.9736\n",
      "Epoch 6/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 4.7687 - mae: 1.7700 - mse: 4.7687 - val_loss: 3.0995 - val_mae: 1.3641 - val_mse: 3.0995\n",
      "Epoch 7/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.4711 - mae: 1.4878 - mse: 3.4711 - val_loss: 1.3085 - val_mae: 0.9014 - val_mse: 1.3085\n",
      "Epoch 8/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.8799 - mae: 1.3645 - mse: 2.8799 - val_loss: 8.7220 - val_mae: 2.7777 - val_mse: 8.7220\n",
      "Epoch 9/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 3.0662 - mae: 1.3611 - mse: 3.0662 - val_loss: 1.2155 - val_mae: 0.8439 - val_mse: 1.2155\n",
      "Epoch 10/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.6404 - mae: 1.2769 - mse: 2.6404 - val_loss: 4.0882 - val_mae: 1.7171 - val_mse: 4.0882\n",
      "Epoch 11/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.3043 - mae: 1.2104 - mse: 2.3043 - val_loss: 3.2505 - val_mae: 1.5721 - val_mse: 3.2505\n",
      "Epoch 12/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.3543 - mae: 1.2052 - mse: 2.3543 - val_loss: 4.2897 - val_mae: 1.8616 - val_mse: 4.2897\n",
      "Epoch 13/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.2306 - mae: 1.1868 - mse: 2.2306 - val_loss: 2.2833 - val_mae: 1.2179 - val_mse: 2.2833\n",
      "Epoch 14/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.9868 - mae: 1.1076 - mse: 1.9868 - val_loss: 1.3587 - val_mae: 0.9121 - val_mse: 1.3587\n",
      "Epoch 15/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.0128 - mae: 1.0983 - mse: 2.0128 - val_loss: 1.4508 - val_mae: 0.9419 - val_mse: 1.4508\n",
      "Epoch 16/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7515 - mae: 1.0393 - mse: 1.7515 - val_loss: 2.0582 - val_mae: 1.1637 - val_mse: 2.0582\n",
      "Epoch 17/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 2.0896 - mae: 1.1169 - mse: 2.0896 - val_loss: 2.6744 - val_mae: 1.3981 - val_mse: 2.6744\n",
      "Epoch 18/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7843 - mae: 1.0457 - mse: 1.7843 - val_loss: 2.1913 - val_mae: 1.2226 - val_mse: 2.1913\n",
      "Epoch 19/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.8644 - mae: 1.0775 - mse: 1.8644 - val_loss: 1.5936 - val_mae: 1.0074 - val_mse: 1.5936\n",
      "Epoch 20/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7084 - mae: 1.0147 - mse: 1.7084 - val_loss: 2.0439 - val_mae: 1.1844 - val_mse: 2.0439\n",
      "Epoch 21/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5481 - mae: 0.9940 - mse: 1.5481 - val_loss: 1.0139 - val_mae: 0.7805 - val_mse: 1.0139\n",
      "Epoch 22/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.7419 - mae: 1.0492 - mse: 1.7419 - val_loss: 1.1005 - val_mae: 0.8076 - val_mse: 1.1005\n",
      "Epoch 23/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6223 - mae: 0.9969 - mse: 1.6223 - val_loss: 1.0358 - val_mae: 0.7851 - val_mse: 1.0358\n",
      "Epoch 24/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.6358 - mae: 1.0031 - mse: 1.6358 - val_loss: 1.6911 - val_mae: 1.0460 - val_mse: 1.6911\n",
      "Epoch 25/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5915 - mae: 1.0037 - mse: 1.5915 - val_loss: 1.2846 - val_mae: 0.8770 - val_mse: 1.2846\n",
      "Epoch 26/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5709 - mae: 0.9759 - mse: 1.5709 - val_loss: 1.0199 - val_mae: 0.7822 - val_mse: 1.0199\n",
      "Epoch 27/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4630 - mae: 0.9576 - mse: 1.4630 - val_loss: 1.4300 - val_mae: 0.9452 - val_mse: 1.4300\n",
      "Epoch 28/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4775 - mae: 0.9486 - mse: 1.4775 - val_loss: 1.0555 - val_mae: 0.7885 - val_mse: 1.0555\n",
      "Epoch 29/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5962 - mae: 0.9980 - mse: 1.5962 - val_loss: 1.3977 - val_mae: 0.9374 - val_mse: 1.3977\n",
      "Epoch 30/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.5277 - mae: 0.9679 - mse: 1.5277 - val_loss: 1.3768 - val_mae: 0.9215 - val_mse: 1.3768\n",
      "Epoch 31/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4835 - mae: 0.9431 - mse: 1.4835 - val_loss: 1.8215 - val_mae: 1.0992 - val_mse: 1.8215\n",
      "Epoch 32/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4223 - mae: 0.9326 - mse: 1.4223 - val_loss: 1.2664 - val_mae: 0.8750 - val_mse: 1.2664\n",
      "Epoch 33/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4380 - mae: 0.9358 - mse: 1.4380 - val_loss: 1.8819 - val_mae: 1.0806 - val_mse: 1.8819\n",
      "Epoch 34/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4068 - mae: 0.9270 - mse: 1.4068 - val_loss: 1.6076 - val_mae: 1.0117 - val_mse: 1.6076\n",
      "Epoch 35/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4986 - mae: 0.9632 - mse: 1.4986 - val_loss: 2.4449 - val_mae: 1.3172 - val_mse: 2.4449\n",
      "Epoch 36/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3288 - mae: 0.9048 - mse: 1.3288 - val_loss: 1.3095 - val_mae: 0.8793 - val_mse: 1.3095\n",
      "Epoch 37/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4721 - mae: 0.9375 - mse: 1.4721 - val_loss: 1.0571 - val_mae: 0.7878 - val_mse: 1.0571\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4270 - mae: 0.9332 - mse: 1.4270 - val_loss: 2.1077 - val_mae: 1.1984 - val_mse: 2.1077\n",
      "Epoch 39/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2531 - mae: 0.8828 - mse: 1.2531 - val_loss: 0.9653 - val_mae: 0.7572 - val_mse: 0.9653\n",
      "Epoch 40/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3385 - mae: 0.9171 - mse: 1.3385 - val_loss: 0.9518 - val_mae: 0.7493 - val_mse: 0.9518\n",
      "Epoch 41/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.4214 - mae: 0.9182 - mse: 1.4214 - val_loss: 1.1725 - val_mae: 0.8439 - val_mse: 1.1725\n",
      "Epoch 42/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1914 - mae: 0.8561 - mse: 1.1914 - val_loss: 0.9287 - val_mae: 0.7422 - val_mse: 0.9287\n",
      "Epoch 43/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3111 - mae: 0.8835 - mse: 1.3111 - val_loss: 0.9080 - val_mae: 0.7336 - val_mse: 0.9080\n",
      "Epoch 44/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2876 - mae: 0.8903 - mse: 1.2876 - val_loss: 1.0219 - val_mae: 0.7726 - val_mse: 1.0219\n",
      "Epoch 45/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2703 - mae: 0.8766 - mse: 1.2703 - val_loss: 1.3448 - val_mae: 0.9234 - val_mse: 1.3448\n",
      "Epoch 46/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2794 - mae: 0.8847 - mse: 1.2794 - val_loss: 0.9475 - val_mae: 0.7539 - val_mse: 0.9475\n",
      "Epoch 47/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2915 - mae: 0.8897 - mse: 1.2915 - val_loss: 0.9742 - val_mae: 0.7592 - val_mse: 0.9742\n",
      "Epoch 48/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1942 - mae: 0.8464 - mse: 1.1942 - val_loss: 1.6920 - val_mae: 1.0447 - val_mse: 1.6920\n",
      "Epoch 49/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.3428 - mae: 0.8987 - mse: 1.3428 - val_loss: 1.3616 - val_mae: 0.9180 - val_mse: 1.3616\n",
      "Epoch 50/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2008 - mae: 0.8590 - mse: 1.2008 - val_loss: 1.1783 - val_mae: 0.8354 - val_mse: 1.1783\n",
      "Epoch 51/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2334 - mae: 0.8653 - mse: 1.2334 - val_loss: 1.0600 - val_mae: 0.7868 - val_mse: 1.0600\n",
      "Epoch 52/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2026 - mae: 0.8484 - mse: 1.2026 - val_loss: 1.1668 - val_mae: 0.8410 - val_mse: 1.1668\n",
      "Epoch 53/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2380 - mae: 0.8706 - mse: 1.2380 - val_loss: 1.2086 - val_mae: 0.8588 - val_mse: 1.2086\n",
      "Epoch 54/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1878 - mae: 0.8621 - mse: 1.1878 - val_loss: 1.1902 - val_mae: 0.8611 - val_mse: 1.1902\n",
      "Epoch 55/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1970 - mae: 0.8725 - mse: 1.1970 - val_loss: 1.2204 - val_mae: 0.8623 - val_mse: 1.2204\n",
      "Epoch 56/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1531 - mae: 0.8354 - mse: 1.1531 - val_loss: 0.8902 - val_mae: 0.7230 - val_mse: 0.8902\n",
      "Epoch 57/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2315 - mae: 0.8685 - mse: 1.2315 - val_loss: 0.9545 - val_mae: 0.7562 - val_mse: 0.9545\n",
      "Epoch 58/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1833 - mae: 0.8479 - mse: 1.1833 - val_loss: 1.0002 - val_mae: 0.7882 - val_mse: 1.0002\n",
      "Epoch 59/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2005 - mae: 0.8383 - mse: 1.2005 - val_loss: 0.8811 - val_mae: 0.7159 - val_mse: 0.8811\n",
      "Epoch 60/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0953 - mae: 0.8178 - mse: 1.0953 - val_loss: 1.0552 - val_mae: 0.8037 - val_mse: 1.0552\n",
      "Epoch 61/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2056 - mae: 0.8609 - mse: 1.2056 - val_loss: 1.2012 - val_mae: 0.8779 - val_mse: 1.2012\n",
      "Epoch 62/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1238 - mae: 0.8225 - mse: 1.1238 - val_loss: 0.9433 - val_mae: 0.7359 - val_mse: 0.9433\n",
      "Epoch 63/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.2123 - mae: 0.8587 - mse: 1.2123 - val_loss: 0.8899 - val_mae: 0.7268 - val_mse: 0.8899\n",
      "Epoch 64/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1375 - mae: 0.8164 - mse: 1.1375 - val_loss: 1.1590 - val_mae: 0.8356 - val_mse: 1.1590\n",
      "Epoch 65/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0827 - mae: 0.8045 - mse: 1.0827 - val_loss: 0.9775 - val_mae: 0.7646 - val_mse: 0.9775\n",
      "Epoch 66/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1857 - mae: 0.8487 - mse: 1.1857 - val_loss: 1.0441 - val_mae: 0.7854 - val_mse: 1.0441\n",
      "Epoch 67/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1405 - mae: 0.8297 - mse: 1.1405 - val_loss: 1.3336 - val_mae: 0.9163 - val_mse: 1.3336\n",
      "Epoch 68/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0970 - mae: 0.8202 - mse: 1.0970 - val_loss: 1.2686 - val_mae: 0.8873 - val_mse: 1.2686\n",
      "Epoch 69/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1539 - mae: 0.8370 - mse: 1.1539 - val_loss: 1.1864 - val_mae: 0.8770 - val_mse: 1.1864\n",
      "Epoch 70/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0732 - mae: 0.8018 - mse: 1.0732 - val_loss: 1.2482 - val_mae: 0.8646 - val_mse: 1.2482\n",
      "Epoch 71/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1457 - mae: 0.8373 - mse: 1.1457 - val_loss: 0.8451 - val_mae: 0.6988 - val_mse: 0.8451\n",
      "Epoch 72/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0829 - mae: 0.8047 - mse: 1.0829 - val_loss: 1.1324 - val_mae: 0.8203 - val_mse: 1.1324\n",
      "Epoch 73/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.1162 - mae: 0.8172 - mse: 1.1162 - val_loss: 1.1066 - val_mae: 0.8107 - val_mse: 1.1066\n",
      "Epoch 74/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0715 - mae: 0.8087 - mse: 1.0715 - val_loss: 0.8404 - val_mae: 0.6982 - val_mse: 0.8404\n",
      "Epoch 75/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0403 - mae: 0.7855 - mse: 1.0403 - val_loss: 2.0136 - val_mae: 1.1678 - val_mse: 2.0136\n",
      "Epoch 76/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0617 - mae: 0.7972 - mse: 1.0617 - val_loss: 0.9407 - val_mae: 0.7566 - val_mse: 0.9407\n",
      "Epoch 77/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0990 - mae: 0.8197 - mse: 1.0990 - val_loss: 0.8817 - val_mae: 0.7255 - val_mse: 0.8817\n",
      "Epoch 78/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0615 - mae: 0.7997 - mse: 1.0615 - val_loss: 0.8783 - val_mae: 0.7143 - val_mse: 0.8783\n",
      "Epoch 79/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0337 - mae: 0.7783 - mse: 1.0337 - val_loss: 1.1129 - val_mae: 0.8264 - val_mse: 1.1129\n",
      "Epoch 80/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0211 - mae: 0.7826 - mse: 1.0211 - val_loss: 2.7352 - val_mae: 1.4041 - val_mse: 2.7352\n",
      "Epoch 81/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9867 - mae: 0.7741 - mse: 0.9867 - val_loss: 0.8727 - val_mae: 0.7123 - val_mse: 0.8727\n",
      "Epoch 82/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0516 - mae: 0.7919 - mse: 1.0516 - val_loss: 1.1745 - val_mae: 0.8341 - val_mse: 1.1745\n",
      "Epoch 83/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0388 - mae: 0.7849 - mse: 1.0388 - val_loss: 0.9262 - val_mae: 0.7577 - val_mse: 0.9262\n",
      "Epoch 84/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0128 - mae: 0.7730 - mse: 1.0128 - val_loss: 0.8445 - val_mae: 0.7064 - val_mse: 0.8445\n",
      "Epoch 85/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0410 - mae: 0.7888 - mse: 1.0410 - val_loss: 1.2948 - val_mae: 0.9016 - val_mse: 1.2948\n",
      "Epoch 86/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0518 - mae: 0.7867 - mse: 1.0518 - val_loss: 0.9245 - val_mae: 0.7330 - val_mse: 0.9245\n",
      "Epoch 87/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9832 - mae: 0.7665 - mse: 0.9832 - val_loss: 1.1660 - val_mae: 0.8577 - val_mse: 1.1660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9897 - mae: 0.7626 - mse: 0.9897 - val_loss: 1.3080 - val_mae: 0.8995 - val_mse: 1.3080\n",
      "Epoch 89/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0259 - mae: 0.7924 - mse: 1.0259 - val_loss: 1.0148 - val_mae: 0.7846 - val_mse: 1.0148\n",
      "Epoch 90/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9425 - mae: 0.7410 - mse: 0.9425 - val_loss: 2.1372 - val_mae: 1.1812 - val_mse: 2.1372\n",
      "Epoch 91/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0824 - mae: 0.8085 - mse: 1.0824 - val_loss: 0.9642 - val_mae: 0.7559 - val_mse: 0.9642\n",
      "Epoch 92/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0066 - mae: 0.7768 - mse: 1.0066 - val_loss: 0.9218 - val_mae: 0.7371 - val_mse: 0.9218\n",
      "Epoch 93/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9804 - mae: 0.7620 - mse: 0.9804 - val_loss: 1.6682 - val_mae: 1.0526 - val_mse: 1.6682\n",
      "Epoch 94/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9631 - mae: 0.7514 - mse: 0.9631 - val_loss: 1.0822 - val_mae: 0.8183 - val_mse: 1.0822\n",
      "Epoch 95/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0489 - mae: 0.7843 - mse: 1.0489 - val_loss: 1.1413 - val_mae: 0.8340 - val_mse: 1.1413\n",
      "Epoch 96/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9249 - mae: 0.7323 - mse: 0.9249 - val_loss: 0.8782 - val_mae: 0.7257 - val_mse: 0.8782\n",
      "Epoch 97/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 1.0334 - mae: 0.7846 - mse: 1.0334 - val_loss: 1.0993 - val_mae: 0.8355 - val_mse: 1.0993\n",
      "Epoch 98/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9858 - mae: 0.7756 - mse: 0.9858 - val_loss: 0.8912 - val_mae: 0.7218 - val_mse: 0.8912\n",
      "Epoch 99/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9399 - mae: 0.7482 - mse: 0.9399 - val_loss: 0.9101 - val_mae: 0.7273 - val_mse: 0.9101\n",
      "Epoch 100/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9353 - mae: 0.7452 - mse: 0.9353 - val_loss: 0.9364 - val_mae: 0.7437 - val_mse: 0.9364\n",
      "Epoch 101/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9467 - mae: 0.7558 - mse: 0.9467 - val_loss: 0.8613 - val_mae: 0.7180 - val_mse: 0.8613\n",
      "Epoch 102/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8786 - mae: 0.7214 - mse: 0.8786 - val_loss: 1.1631 - val_mae: 0.8334 - val_mse: 1.1631\n",
      "Epoch 103/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9541 - mae: 0.7579 - mse: 0.9541 - val_loss: 1.1970 - val_mae: 0.8514 - val_mse: 1.1970\n",
      "Epoch 104/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9545 - mae: 0.7605 - mse: 0.9545 - val_loss: 0.8545 - val_mae: 0.7105 - val_mse: 0.8545\n",
      "Epoch 105/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8909 - mae: 0.7152 - mse: 0.8909 - val_loss: 1.3506 - val_mae: 0.9260 - val_mse: 1.3506\n",
      "Epoch 106/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9345 - mae: 0.7484 - mse: 0.9345 - val_loss: 1.1514 - val_mae: 0.8366 - val_mse: 1.1514\n",
      "Epoch 107/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9040 - mae: 0.7398 - mse: 0.9040 - val_loss: 0.9163 - val_mae: 0.7321 - val_mse: 0.9163\n",
      "Epoch 108/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8567 - mae: 0.7100 - mse: 0.8567 - val_loss: 0.8406 - val_mae: 0.7017 - val_mse: 0.8406\n",
      "Epoch 109/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9060 - mae: 0.7309 - mse: 0.9060 - val_loss: 0.9255 - val_mae: 0.7399 - val_mse: 0.9255\n",
      "Epoch 110/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8822 - mae: 0.7177 - mse: 0.8822 - val_loss: 0.9265 - val_mae: 0.7306 - val_mse: 0.9265\n",
      "Epoch 111/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8641 - mae: 0.7174 - mse: 0.8641 - val_loss: 0.9266 - val_mae: 0.7323 - val_mse: 0.9266\n",
      "Epoch 112/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9113 - mae: 0.7314 - mse: 0.9113 - val_loss: 0.8799 - val_mae: 0.7235 - val_mse: 0.8799\n",
      "Epoch 113/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8614 - mae: 0.7233 - mse: 0.8614 - val_loss: 1.6816 - val_mae: 1.0762 - val_mse: 1.6816\n",
      "Epoch 114/1000\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9142 - mae: 0.7350 - mse: 0.9142 - val_loss: 1.1632 - val_mae: 0.8443 - val_mse: 1.1632\n",
      "Epoch 115/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8851 - mae: 0.7249 - mse: 0.8851 - val_loss: 2.2932 - val_mae: 1.2845 - val_mse: 2.2932\n",
      "Epoch 116/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8557 - mae: 0.7022 - mse: 0.8557 - val_loss: 1.4667 - val_mae: 0.9637 - val_mse: 1.4667\n",
      "Epoch 117/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8389 - mae: 0.7103 - mse: 0.8389 - val_loss: 0.9754 - val_mae: 0.7829 - val_mse: 0.9754\n",
      "Epoch 118/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.9493 - mae: 0.7615 - mse: 0.9493 - val_loss: 0.8475 - val_mae: 0.7107 - val_mse: 0.8475\n",
      "Epoch 119/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.0889 - mae: 0.8148 - mse: 1.088 - 0s 1ms/step - loss: 0.8991 - mae: 0.7325 - mse: 0.8991 - val_loss: 0.8334 - val_mae: 0.6984 - val_mse: 0.8334\n",
      "Epoch 120/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8832 - mae: 0.7301 - mse: 0.8832 - val_loss: 0.8745 - val_mae: 0.7162 - val_mse: 0.8745\n",
      "Epoch 121/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8346 - mae: 0.7037 - mse: 0.8346 - val_loss: 0.8898 - val_mae: 0.7176 - val_mse: 0.8898\n",
      "Epoch 122/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8607 - mae: 0.7124 - mse: 0.8607 - val_loss: 1.0093 - val_mae: 0.7781 - val_mse: 1.0093\n",
      "Epoch 123/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8059 - mae: 0.6895 - mse: 0.8059 - val_loss: 0.8324 - val_mae: 0.7035 - val_mse: 0.8324\n",
      "Epoch 124/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8400 - mae: 0.6999 - mse: 0.8400 - val_loss: 0.8393 - val_mae: 0.7034 - val_mse: 0.8393\n",
      "Epoch 125/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8407 - mae: 0.7015 - mse: 0.8407 - val_loss: 0.8534 - val_mae: 0.7089 - val_mse: 0.8534\n",
      "Epoch 126/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8465 - mae: 0.7151 - mse: 0.8465 - val_loss: 0.8414 - val_mae: 0.7053 - val_mse: 0.8414\n",
      "Epoch 127/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8282 - mae: 0.6916 - mse: 0.8282 - val_loss: 0.9118 - val_mae: 0.7317 - val_mse: 0.9118\n",
      "Epoch 128/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7442 - mae: 0.6579 - mse: 0.7442 - val_loss: 1.0451 - val_mae: 0.7882 - val_mse: 1.0451\n",
      "Epoch 129/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8324 - mae: 0.6963 - mse: 0.8324 - val_loss: 0.8916 - val_mae: 0.7291 - val_mse: 0.8916\n",
      "Epoch 130/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8032 - mae: 0.6921 - mse: 0.8032 - val_loss: 1.0663 - val_mae: 0.7972 - val_mse: 1.0663\n",
      "Epoch 131/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8130 - mae: 0.6799 - mse: 0.8130 - val_loss: 1.2389 - val_mae: 0.8722 - val_mse: 1.2389\n",
      "Epoch 132/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8458 - mae: 0.7032 - mse: 0.8458 - val_loss: 0.9193 - val_mae: 0.7475 - val_mse: 0.9193\n",
      "Epoch 133/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8167 - mae: 0.6872 - mse: 0.8167 - val_loss: 0.8417 - val_mae: 0.7046 - val_mse: 0.8417\n",
      "Epoch 134/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7819 - mae: 0.6788 - mse: 0.7819 - val_loss: 0.8936 - val_mae: 0.7296 - val_mse: 0.8936\n",
      "Epoch 135/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8112 - mae: 0.6905 - mse: 0.8112 - val_loss: 1.7347 - val_mae: 1.0878 - val_mse: 1.7347\n",
      "Epoch 136/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8143 - mae: 0.6940 - mse: 0.8143 - val_loss: 1.1195 - val_mae: 0.8170 - val_mse: 1.1195\n",
      "Epoch 137/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8346 - mae: 0.6996 - mse: 0.8346 - val_loss: 1.2255 - val_mae: 0.8686 - val_mse: 1.2255\n",
      "Epoch 138/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7390 - mae: 0.6607 - mse: 0.7390 - val_loss: 1.1555 - val_mae: 0.8437 - val_mse: 1.1555\n",
      "Epoch 139/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7656 - mae: 0.6669 - mse: 0.7656 - val_loss: 0.9793 - val_mae: 0.7674 - val_mse: 0.9793\n",
      "Epoch 140/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8718 - mae: 0.7129 - mse: 0.8718 - val_loss: 0.8686 - val_mae: 0.7151 - val_mse: 0.8686\n",
      "Epoch 141/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8029 - mae: 0.6774 - mse: 0.8029 - val_loss: 0.9190 - val_mae: 0.7296 - val_mse: 0.9190\n",
      "Epoch 142/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7602 - mae: 0.6591 - mse: 0.7602 - val_loss: 0.8351 - val_mae: 0.7048 - val_mse: 0.8351\n",
      "Epoch 143/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8104 - mae: 0.6880 - mse: 0.8104 - val_loss: 1.0542 - val_mae: 0.7930 - val_mse: 1.0542\n",
      "Epoch 144/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7542 - mae: 0.6572 - mse: 0.7542 - val_loss: 1.4696 - val_mae: 0.9787 - val_mse: 1.4696\n",
      "Epoch 145/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7279 - mae: 0.6419 - mse: 0.7279 - val_loss: 1.0454 - val_mae: 0.7924 - val_mse: 1.0454\n",
      "Epoch 146/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7580 - mae: 0.6620 - mse: 0.7580 - val_loss: 2.0624 - val_mae: 1.2178 - val_mse: 2.0624\n",
      "Epoch 147/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8118 - mae: 0.6842 - mse: 0.8118 - val_loss: 1.2578 - val_mae: 0.8798 - val_mse: 1.2578\n",
      "Epoch 148/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7560 - mae: 0.6584 - mse: 0.7560 - val_loss: 0.8757 - val_mae: 0.7307 - val_mse: 0.8757\n",
      "Epoch 149/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7622 - mae: 0.6716 - mse: 0.7622 - val_loss: 1.0086 - val_mae: 0.7784 - val_mse: 1.0086\n",
      "Epoch 150/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7941 - mae: 0.6848 - mse: 0.7941 - val_loss: 1.3832 - val_mae: 0.9356 - val_mse: 1.3832\n",
      "Epoch 151/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.8068 - mae: 0.6831 - mse: 0.8068 - val_loss: 0.9833 - val_mae: 0.7575 - val_mse: 0.9833\n",
      "Epoch 152/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7393 - mae: 0.6585 - mse: 0.7393 - val_loss: 1.1494 - val_mae: 0.8347 - val_mse: 1.1494\n",
      "Epoch 153/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7577 - mae: 0.6615 - mse: 0.7577 - val_loss: 1.1931 - val_mae: 0.8581 - val_mse: 1.1931\n",
      "Epoch 154/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7399 - mae: 0.6544 - mse: 0.7399 - val_loss: 0.8786 - val_mae: 0.7156 - val_mse: 0.8786\n",
      "Epoch 155/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6949 - mae: 0.6325 - mse: 0.6949 - val_loss: 0.9248 - val_mae: 0.7326 - val_mse: 0.9248\n",
      "Epoch 156/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7517 - mae: 0.6684 - mse: 0.7517 - val_loss: 1.2278 - val_mae: 0.8678 - val_mse: 1.2278\n",
      "Epoch 157/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7558 - mae: 0.6679 - mse: 0.7558 - val_loss: 1.0207 - val_mae: 0.7768 - val_mse: 1.0207\n",
      "Epoch 158/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7274 - mae: 0.6442 - mse: 0.7274 - val_loss: 1.2009 - val_mae: 0.8689 - val_mse: 1.2009\n",
      "Epoch 159/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7494 - mae: 0.6578 - mse: 0.7494 - val_loss: 0.8595 - val_mae: 0.7152 - val_mse: 0.8595\n",
      "Epoch 160/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7373 - mae: 0.6608 - mse: 0.7373 - val_loss: 1.0199 - val_mae: 0.7849 - val_mse: 1.0199\n",
      "Epoch 161/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6883 - mae: 0.6348 - mse: 0.6883 - val_loss: 1.4168 - val_mae: 0.9411 - val_mse: 1.4168\n",
      "Epoch 162/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7667 - mae: 0.6645 - mse: 0.7667 - val_loss: 1.0959 - val_mae: 0.8084 - val_mse: 1.0959\n",
      "Epoch 163/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6767 - mae: 0.6320 - mse: 0.6767 - val_loss: 1.1919 - val_mae: 0.8600 - val_mse: 1.1919\n",
      "Epoch 164/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7152 - mae: 0.6373 - mse: 0.7152 - val_loss: 0.8906 - val_mae: 0.7231 - val_mse: 0.8906\n",
      "Epoch 165/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7002 - mae: 0.6472 - mse: 0.7002 - val_loss: 0.9404 - val_mae: 0.7389 - val_mse: 0.9404\n",
      "Epoch 166/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7081 - mae: 0.6382 - mse: 0.7081 - val_loss: 1.2788 - val_mae: 0.8929 - val_mse: 1.2788\n",
      "Epoch 167/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6883 - mae: 0.6411 - mse: 0.6883 - val_loss: 1.3828 - val_mae: 0.9331 - val_mse: 1.3828\n",
      "Epoch 168/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7113 - mae: 0.6494 - mse: 0.7113 - val_loss: 0.8582 - val_mae: 0.7125 - val_mse: 0.8582\n",
      "Epoch 169/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6921 - mae: 0.6347 - mse: 0.6921 - val_loss: 1.5818 - val_mae: 1.0255 - val_mse: 1.5818\n",
      "Epoch 170/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6626 - mae: 0.6213 - mse: 0.6626 - val_loss: 0.8908 - val_mae: 0.7218 - val_mse: 0.8908\n",
      "Epoch 171/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6800 - mae: 0.6239 - mse: 0.6800 - val_loss: 0.9006 - val_mae: 0.7326 - val_mse: 0.9006\n",
      "Epoch 172/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6921 - mae: 0.6325 - mse: 0.6921 - val_loss: 1.5649 - val_mae: 1.0008 - val_mse: 1.5649\n",
      "Epoch 173/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6680 - mae: 0.6260 - mse: 0.6680 - val_loss: 0.9566 - val_mae: 0.7544 - val_mse: 0.9566\n",
      "Epoch 174/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6878 - mae: 0.6312 - mse: 0.6878 - val_loss: 0.9286 - val_mae: 0.7377 - val_mse: 0.9286\n",
      "Epoch 175/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6640 - mae: 0.6166 - mse: 0.6640 - val_loss: 0.8492 - val_mae: 0.7090 - val_mse: 0.8492\n",
      "Epoch 176/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7200 - mae: 0.6417 - mse: 0.7200 - val_loss: 0.9437 - val_mae: 0.7408 - val_mse: 0.9437\n",
      "Epoch 177/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6676 - mae: 0.6191 - mse: 0.6676 - val_loss: 1.1014 - val_mae: 0.8177 - val_mse: 1.1014\n",
      "Epoch 178/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6445 - mae: 0.6080 - mse: 0.6445 - val_loss: 0.9262 - val_mae: 0.7414 - val_mse: 0.9262\n",
      "Epoch 179/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6977 - mae: 0.6340 - mse: 0.6977 - val_loss: 1.0614 - val_mae: 0.8082 - val_mse: 1.0614\n",
      "Epoch 180/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6595 - mae: 0.6226 - mse: 0.6595 - val_loss: 1.3580 - val_mae: 0.9267 - val_mse: 1.3580\n",
      "Epoch 181/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6928 - mae: 0.6358 - mse: 0.6928 - val_loss: 0.9643 - val_mae: 0.7557 - val_mse: 0.9643\n",
      "Epoch 182/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6761 - mae: 0.6228 - mse: 0.6761 - val_loss: 0.9883 - val_mae: 0.7640 - val_mse: 0.9883\n",
      "Epoch 183/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6699 - mae: 0.6255 - mse: 0.6699 - val_loss: 0.9044 - val_mae: 0.7349 - val_mse: 0.9044\n",
      "Epoch 184/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6218 - mae: 0.5936 - mse: 0.6218 - val_loss: 1.4094 - val_mae: 0.9388 - val_mse: 1.4094\n",
      "Epoch 185/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6690 - mae: 0.6181 - mse: 0.6690 - val_loss: 1.2866 - val_mae: 0.8953 - val_mse: 1.2866\n",
      "Epoch 186/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6495 - mae: 0.6153 - mse: 0.6495 - val_loss: 1.1320 - val_mae: 0.8290 - val_mse: 1.1320\n",
      "Epoch 187/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6359 - mae: 0.6133 - mse: 0.6359 - val_loss: 2.2519 - val_mae: 1.2581 - val_mse: 2.2519\n",
      "Epoch 188/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6352 - mae: 0.6012 - mse: 0.6352 - val_loss: 1.3688 - val_mae: 0.9247 - val_mse: 1.3688\n",
      "Epoch 189/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6433 - mae: 0.6148 - mse: 0.6433 - val_loss: 0.8733 - val_mae: 0.7087 - val_mse: 0.8733\n",
      "Epoch 190/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.7063 - mae: 0.6394 - mse: 0.7063 - val_loss: 0.8533 - val_mae: 0.7067 - val_mse: 0.8533\n",
      "Epoch 191/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6347 - mae: 0.5973 - mse: 0.6347 - val_loss: 0.9054 - val_mae: 0.7328 - val_mse: 0.9054\n",
      "Epoch 192/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6373 - mae: 0.6090 - mse: 0.6373 - val_loss: 0.8793 - val_mae: 0.7232 - val_mse: 0.8793\n",
      "Epoch 193/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6775 - mae: 0.6209 - mse: 0.6775 - val_loss: 1.0971 - val_mae: 0.8102 - val_mse: 1.0971\n",
      "Epoch 194/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6149 - mae: 0.6022 - mse: 0.6149 - val_loss: 1.1150 - val_mae: 0.8148 - val_mse: 1.1150\n",
      "Epoch 195/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6064 - mae: 0.5892 - mse: 0.6064 - val_loss: 1.0645 - val_mae: 0.7916 - val_mse: 1.0645\n",
      "Epoch 196/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5959 - mae: 0.5875 - mse: 0.5959 - val_loss: 0.9495 - val_mae: 0.7475 - val_mse: 0.9495\n",
      "Epoch 197/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6218 - mae: 0.5991 - mse: 0.6218 - val_loss: 0.9097 - val_mae: 0.7233 - val_mse: 0.9097\n",
      "Epoch 198/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5886 - mae: 0.5751 - mse: 0.5886 - val_loss: 1.1154 - val_mae: 0.8130 - val_mse: 1.1154\n",
      "Epoch 199/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6347 - mae: 0.6027 - mse: 0.6347 - val_loss: 1.0100 - val_mae: 0.7677 - val_mse: 1.0100\n",
      "Epoch 200/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6311 - mae: 0.5958 - mse: 0.6311 - val_loss: 1.1920 - val_mae: 0.8388 - val_mse: 1.1920\n",
      "Epoch 201/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6283 - mae: 0.6051 - mse: 0.6283 - val_loss: 0.8909 - val_mae: 0.7300 - val_mse: 0.8909\n",
      "Epoch 202/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6299 - mae: 0.6031 - mse: 0.6299 - val_loss: 1.0105 - val_mae: 0.7683 - val_mse: 1.0105\n",
      "Epoch 203/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6199 - mae: 0.5946 - mse: 0.6199 - val_loss: 1.0022 - val_mae: 0.7617 - val_mse: 1.0022\n",
      "Epoch 204/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5671 - mae: 0.5767 - mse: 0.5671 - val_loss: 0.8934 - val_mae: 0.7319 - val_mse: 0.8934\n",
      "Epoch 205/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6368 - mae: 0.6074 - mse: 0.6368 - val_loss: 0.8834 - val_mae: 0.7189 - val_mse: 0.8834\n",
      "Epoch 206/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5911 - mae: 0.5816 - mse: 0.5911 - val_loss: 0.9413 - val_mae: 0.7435 - val_mse: 0.9413\n",
      "Epoch 207/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6025 - mae: 0.5972 - mse: 0.6025 - val_loss: 0.9058 - val_mae: 0.7340 - val_mse: 0.9058\n",
      "Epoch 208/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6251 - mae: 0.5982 - mse: 0.6251 - val_loss: 0.8928 - val_mae: 0.7188 - val_mse: 0.8928\n",
      "Epoch 209/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5811 - mae: 0.5807 - mse: 0.5811 - val_loss: 0.8900 - val_mae: 0.7235 - val_mse: 0.8900\n",
      "Epoch 210/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.6258 - mae: 0.5957 - mse: 0.6258 - val_loss: 0.9541 - val_mae: 0.7427 - val_mse: 0.9541\n",
      "Epoch 211/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5889 - mae: 0.5903 - mse: 0.5889 - val_loss: 1.0643 - val_mae: 0.7985 - val_mse: 1.0643\n",
      "Epoch 212/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5893 - mae: 0.5795 - mse: 0.5893 - val_loss: 0.9273 - val_mae: 0.7315 - val_mse: 0.9273\n",
      "Epoch 213/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5744 - mae: 0.5714 - mse: 0.5744 - val_loss: 0.9404 - val_mae: 0.7385 - val_mse: 0.9404\n",
      "Epoch 214/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5673 - mae: 0.5764 - mse: 0.5673 - val_loss: 1.0369 - val_mae: 0.7770 - val_mse: 1.0369\n",
      "Epoch 215/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5905 - mae: 0.5831 - mse: 0.5905 - val_loss: 0.9119 - val_mae: 0.7312 - val_mse: 0.9119\n",
      "Epoch 216/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5943 - mae: 0.5787 - mse: 0.5943 - val_loss: 0.9598 - val_mae: 0.7479 - val_mse: 0.9598\n",
      "Epoch 217/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5601 - mae: 0.5704 - mse: 0.5601 - val_loss: 0.8630 - val_mae: 0.7130 - val_mse: 0.8630\n",
      "Epoch 218/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5613 - mae: 0.5564 - mse: 0.5613 - val_loss: 0.8909 - val_mae: 0.7253 - val_mse: 0.8909\n",
      "Epoch 219/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5809 - mae: 0.5826 - mse: 0.5809 - val_loss: 0.8787 - val_mae: 0.7190 - val_mse: 0.8787\n",
      "Epoch 220/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5453 - mae: 0.5625 - mse: 0.5453 - val_loss: 0.8936 - val_mae: 0.7288 - val_mse: 0.8936\n",
      "Epoch 221/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5546 - mae: 0.5688 - mse: 0.5546 - val_loss: 0.9651 - val_mae: 0.7548 - val_mse: 0.9651\n",
      "Epoch 222/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5468 - mae: 0.5705 - mse: 0.5468 - val_loss: 1.5881 - val_mae: 0.9852 - val_mse: 1.5881\n",
      "Epoch 223/1000\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.5976 - mae: 0.5705 - mse: 0.5976 - val_loss: 0.9132 - val_mae: 0.7374 - val_mse: 0.9132\n",
      "Kappa Score: 0.7387166103776481\n",
      "\n",
      "###########Set-4###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 64.8901 - mae: 4.1018 - mse: 64.8901 - val_loss: 17.9041 - val_mae: 3.6857 - val_mse: 17.9041\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 15.1784 - mae: 3.2666 - mse: 15.1784 - val_loss: 1.4335 - val_mae: 0.9106 - val_mse: 1.4335\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 7.2508 - mae: 2.0962 - mse: 7.2508 - val_loss: 2.2679 - val_mae: 1.2361 - val_mse: 2.2679\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.0846 - mae: 1.5638 - mse: 4.0846 - val_loss: 1.2939 - val_mae: 0.8879 - val_mse: 1.2939\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.3353 - mae: 1.4342 - mse: 3.3353 - val_loss: 1.5291 - val_mae: 0.9703 - val_mse: 1.5291\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7501 - mae: 1.2946 - mse: 2.7501 - val_loss: 2.1041 - val_mae: 1.0977 - val_mse: 2.1041\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5255 - mae: 1.2756 - mse: 2.5255 - val_loss: 1.2280 - val_mae: 0.8623 - val_mse: 1.2280\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4725 - mae: 1.2481 - mse: 2.4725 - val_loss: 1.3195 - val_mae: 0.9087 - val_mse: 1.3195\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0403 - mae: 1.1132 - mse: 2.0403 - val_loss: 1.3051 - val_mae: 0.8855 - val_mse: 1.3051\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0260 - mae: 1.1083 - mse: 2.0260 - val_loss: 1.1747 - val_mae: 0.8493 - val_mse: 1.1747\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9178 - mae: 1.0911 - mse: 1.9178 - val_loss: 1.6667 - val_mae: 0.9911 - val_mse: 1.6667\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9461 - mae: 1.0807 - mse: 1.9461 - val_loss: 1.1294 - val_mae: 0.8249 - val_mse: 1.1294\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7443 - mae: 1.0555 - mse: 1.7443 - val_loss: 2.2006 - val_mae: 1.1487 - val_mse: 2.2006\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7611 - mae: 1.0489 - mse: 1.7611 - val_loss: 1.1604 - val_mae: 0.8448 - val_mse: 1.1604\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6682 - mae: 1.0180 - mse: 1.6682 - val_loss: 2.0909 - val_mae: 1.1344 - val_mse: 2.0909\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7273 - mae: 1.0301 - mse: 1.7273 - val_loss: 3.6193 - val_mae: 1.5715 - val_mse: 3.6193\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6325 - mae: 1.0046 - mse: 1.6325 - val_loss: 1.2570 - val_mae: 0.8721 - val_mse: 1.2570\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6128 - mae: 1.0035 - mse: 1.6128 - val_loss: 3.1502 - val_mae: 1.5256 - val_mse: 3.1502\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6005 - mae: 0.9797 - mse: 1.6005 - val_loss: 1.0941 - val_mae: 0.8166 - val_mse: 1.0941\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5837 - mae: 0.9860 - mse: 1.5837 - val_loss: 1.1678 - val_mae: 0.8451 - val_mse: 1.1678\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5509 - mae: 0.9820 - mse: 1.5509 - val_loss: 5.4359 - val_mae: 2.0899 - val_mse: 5.4359\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5802 - mae: 0.9822 - mse: 1.5802 - val_loss: 1.3685 - val_mae: 0.9087 - val_mse: 1.3685\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4699 - mae: 0.9452 - mse: 1.4699 - val_loss: 2.5650 - val_mae: 1.3003 - val_mse: 2.5650\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5586 - mae: 0.9854 - mse: 1.5586 - val_loss: 3.3012 - val_mae: 1.5570 - val_mse: 3.3012\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5161 - mae: 0.9664 - mse: 1.5161 - val_loss: 1.0667 - val_mae: 0.8043 - val_mse: 1.0667\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5392 - mae: 0.9702 - mse: 1.5392 - val_loss: 1.0916 - val_mae: 0.8137 - val_mse: 1.0916\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4213 - mae: 0.9339 - mse: 1.4213 - val_loss: 1.3250 - val_mae: 0.8897 - val_mse: 1.3250\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3592 - mae: 0.9119 - mse: 1.3592 - val_loss: 1.1462 - val_mae: 0.8305 - val_mse: 1.1462\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4588 - mae: 0.9439 - mse: 1.4588 - val_loss: 1.0369 - val_mae: 0.7955 - val_mse: 1.0369\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3598 - mae: 0.9171 - mse: 1.3598 - val_loss: 1.2641 - val_mae: 0.8762 - val_mse: 1.2641\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4978 - mae: 0.9544 - mse: 1.4978 - val_loss: 1.1088 - val_mae: 0.8173 - val_mse: 1.1088\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4099 - mae: 0.9320 - mse: 1.4099 - val_loss: 1.0386 - val_mae: 0.7996 - val_mse: 1.0386\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3384 - mae: 0.9025 - mse: 1.3384 - val_loss: 1.5476 - val_mae: 0.9757 - val_mse: 1.5476\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3601 - mae: 0.9076 - mse: 1.3601 - val_loss: 1.1873 - val_mae: 0.8347 - val_mse: 1.1873\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3978 - mae: 0.9290 - mse: 1.3978 - val_loss: 1.0607 - val_mae: 0.8025 - val_mse: 1.0607\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3435 - mae: 0.9051 - mse: 1.3435 - val_loss: 1.3865 - val_mae: 0.9158 - val_mse: 1.3865\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2998 - mae: 0.8936 - mse: 1.2998 - val_loss: 1.1025 - val_mae: 0.8200 - val_mse: 1.1025\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3951 - mae: 0.9269 - mse: 1.3951 - val_loss: 1.3456 - val_mae: 0.9066 - val_mse: 1.3456\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3062 - mae: 0.8906 - mse: 1.3062 - val_loss: 3.0933 - val_mae: 1.5069 - val_mse: 3.0933\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3056 - mae: 0.8813 - mse: 1.3056 - val_loss: 1.6322 - val_mae: 1.0156 - val_mse: 1.6322\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2540 - mae: 0.8861 - mse: 1.2540 - val_loss: 1.7224 - val_mae: 1.0547 - val_mse: 1.7224\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2686 - mae: 0.8680 - mse: 1.2686 - val_loss: 2.1389 - val_mae: 1.1871 - val_mse: 2.1389\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2624 - mae: 0.8738 - mse: 1.2624 - val_loss: 1.7733 - val_mae: 1.0587 - val_mse: 1.7733\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2336 - mae: 0.8529 - mse: 1.2336 - val_loss: 1.2692 - val_mae: 0.8883 - val_mse: 1.2692\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2274 - mae: 0.8558 - mse: 1.2274 - val_loss: 2.2225 - val_mae: 1.2289 - val_mse: 2.2225\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2694 - mae: 0.8820 - mse: 1.2694 - val_loss: 0.9779 - val_mae: 0.7671 - val_mse: 0.9779\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1847 - mae: 0.8520 - mse: 1.1847 - val_loss: 1.1576 - val_mae: 0.8383 - val_mse: 1.1576\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2846 - mae: 0.8778 - mse: 1.2846 - val_loss: 0.9841 - val_mae: 0.7725 - val_mse: 0.9841\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2123 - mae: 0.8556 - mse: 1.2123 - val_loss: 0.9918 - val_mae: 0.7840 - val_mse: 0.9918\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2319 - mae: 0.8728 - mse: 1.2319 - val_loss: 1.2432 - val_mae: 0.8815 - val_mse: 1.2432\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2760 - mae: 0.8791 - mse: 1.2760 - val_loss: 1.0297 - val_mae: 0.7886 - val_mse: 1.0297\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2069 - mae: 0.8485 - mse: 1.2069 - val_loss: 1.7767 - val_mae: 1.0552 - val_mse: 1.7767\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2577 - mae: 0.8747 - mse: 1.2577 - val_loss: 0.9531 - val_mae: 0.7558 - val_mse: 0.9531\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1164 - mae: 0.8215 - mse: 1.1164 - val_loss: 1.3739 - val_mae: 0.9306 - val_mse: 1.3739\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1787 - mae: 0.8392 - mse: 1.1787 - val_loss: 1.3425 - val_mae: 0.9057 - val_mse: 1.3425\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2454 - mae: 0.8742 - mse: 1.2454 - val_loss: 1.8040 - val_mae: 1.0834 - val_mse: 1.8040\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1318 - mae: 0.8211 - mse: 1.1318 - val_loss: 1.4741 - val_mae: 0.9549 - val_mse: 1.4741\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2323 - mae: 0.8685 - mse: 1.2323 - val_loss: 1.7043 - val_mae: 1.0461 - val_mse: 1.7043\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1453 - mae: 0.8300 - mse: 1.1453 - val_loss: 0.9323 - val_mae: 0.7461 - val_mse: 0.9323\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2002 - mae: 0.8512 - mse: 1.2002 - val_loss: 0.9439 - val_mae: 0.7486 - val_mse: 0.9439\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1768 - mae: 0.8392 - mse: 1.1768 - val_loss: 1.0593 - val_mae: 0.7902 - val_mse: 1.0593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1487 - mae: 0.8342 - mse: 1.1487 - val_loss: 2.6128 - val_mae: 1.3589 - val_mse: 2.6128\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2063 - mae: 0.8447 - mse: 1.2063 - val_loss: 0.9801 - val_mae: 0.7636 - val_mse: 0.9801\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0959 - mae: 0.8021 - mse: 1.0959 - val_loss: 1.1442 - val_mae: 0.8504 - val_mse: 1.1442\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1114 - mae: 0.8212 - mse: 1.1114 - val_loss: 0.9569 - val_mae: 0.7585 - val_mse: 0.9569\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1252 - mae: 0.8219 - mse: 1.1252 - val_loss: 0.9114 - val_mae: 0.7397 - val_mse: 0.9114\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1649 - mae: 0.8304 - mse: 1.1649 - val_loss: 0.9085 - val_mae: 0.7432 - val_mse: 0.9085\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0755 - mae: 0.7871 - mse: 1.0755 - val_loss: 1.4071 - val_mae: 0.9628 - val_mse: 1.4071\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1085 - mae: 0.8103 - mse: 1.1085 - val_loss: 1.0661 - val_mae: 0.8000 - val_mse: 1.0661\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0999 - mae: 0.8108 - mse: 1.0999 - val_loss: 0.9009 - val_mae: 0.7395 - val_mse: 0.9009\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1063 - mae: 0.8163 - mse: 1.1063 - val_loss: 1.7008 - val_mae: 1.0443 - val_mse: 1.7008\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0451 - mae: 0.7919 - mse: 1.0451 - val_loss: 0.9518 - val_mae: 0.7607 - val_mse: 0.9518\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1708 - mae: 0.8312 - mse: 1.1708 - val_loss: 0.9499 - val_mae: 0.7534 - val_mse: 0.9499\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1112 - mae: 0.8159 - mse: 1.1112 - val_loss: 1.2249 - val_mae: 0.8910 - val_mse: 1.2249\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0811 - mae: 0.7971 - mse: 1.0811 - val_loss: 1.0598 - val_mae: 0.7922 - val_mse: 1.0598\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0692 - mae: 0.7970 - mse: 1.0692 - val_loss: 0.9508 - val_mae: 0.7644 - val_mse: 0.9508\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0231 - mae: 0.7966 - mse: 1.0231 - val_loss: 1.1701 - val_mae: 0.8702 - val_mse: 1.1701\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0370 - mae: 0.7830 - mse: 1.0370 - val_loss: 1.7479 - val_mae: 1.0634 - val_mse: 1.7479\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0099 - mae: 0.7820 - mse: 1.0099 - val_loss: 0.8887 - val_mae: 0.7381 - val_mse: 0.8887\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0461 - mae: 0.7844 - mse: 1.0461 - val_loss: 1.0615 - val_mae: 0.8167 - val_mse: 1.0615\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0988 - mae: 0.8185 - mse: 1.0988 - val_loss: 0.9357 - val_mae: 0.7437 - val_mse: 0.9357\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0406 - mae: 0.7950 - mse: 1.0406 - val_loss: 2.0599 - val_mae: 1.1754 - val_mse: 2.0599\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0222 - mae: 0.7745 - mse: 1.0222 - val_loss: 1.0624 - val_mae: 0.8089 - val_mse: 1.0624\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0471 - mae: 0.7914 - mse: 1.0471 - val_loss: 1.1345 - val_mae: 0.8123 - val_mse: 1.1345\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1147 - mae: 0.8226 - mse: 1.1147 - val_loss: 1.1836 - val_mae: 0.8375 - val_mse: 1.1836\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0465 - mae: 0.7826 - mse: 1.0465 - val_loss: 1.3544 - val_mae: 0.9347 - val_mse: 1.3544\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0262 - mae: 0.7852 - mse: 1.0262 - val_loss: 0.8587 - val_mae: 0.7270 - val_mse: 0.8587\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0359 - mae: 0.7709 - mse: 1.0359 - val_loss: 1.0756 - val_mae: 0.8161 - val_mse: 1.0756\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0639 - mae: 0.8015 - mse: 1.0639 - val_loss: 0.9313 - val_mae: 0.7631 - val_mse: 0.9313\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9803 - mae: 0.7660 - mse: 0.9803 - val_loss: 0.8613 - val_mae: 0.7291 - val_mse: 0.8613\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9784 - mae: 0.7607 - mse: 0.9784 - val_loss: 0.9983 - val_mae: 0.7921 - val_mse: 0.9983\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0112 - mae: 0.7785 - mse: 1.0112 - val_loss: 0.8772 - val_mae: 0.7329 - val_mse: 0.8772\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0161 - mae: 0.7818 - mse: 1.0161 - val_loss: 1.5064 - val_mae: 0.9647 - val_mse: 1.5064\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9765 - mae: 0.7634 - mse: 0.9765 - val_loss: 0.9368 - val_mae: 0.7641 - val_mse: 0.9368\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9792 - mae: 0.7654 - mse: 0.9792 - val_loss: 1.3676 - val_mae: 0.9138 - val_mse: 1.3676\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9949 - mae: 0.7601 - mse: 0.9949 - val_loss: 0.9368 - val_mae: 0.7430 - val_mse: 0.9368\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9366 - mae: 0.7461 - mse: 0.9366 - val_loss: 0.8650 - val_mae: 0.7349 - val_mse: 0.8650\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9632 - mae: 0.7571 - mse: 0.9632 - val_loss: 0.9332 - val_mae: 0.7848 - val_mse: 0.9332\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9893 - mae: 0.7693 - mse: 0.9893 - val_loss: 1.0648 - val_mae: 0.7821 - val_mse: 1.0648\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9784 - mae: 0.7507 - mse: 0.9784 - val_loss: 1.1195 - val_mae: 0.8460 - val_mse: 1.1195\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9360 - mae: 0.7433 - mse: 0.9360 - val_loss: 1.0536 - val_mae: 0.7860 - val_mse: 1.0536\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9987 - mae: 0.7655 - mse: 0.9987 - val_loss: 0.9747 - val_mae: 0.7963 - val_mse: 0.9747\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9690 - mae: 0.7398 - mse: 0.9690 - val_loss: 1.7012 - val_mae: 1.0729 - val_mse: 1.7012\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9401 - mae: 0.7442 - mse: 0.9401 - val_loss: 0.8710 - val_mae: 0.7483 - val_mse: 0.8710\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9654 - mae: 0.7490 - mse: 0.9654 - val_loss: 0.9229 - val_mae: 0.7402 - val_mse: 0.9229\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9549 - mae: 0.7612 - mse: 0.9549 - val_loss: 0.8306 - val_mae: 0.7172 - val_mse: 0.8306\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9316 - mae: 0.7401 - mse: 0.9316 - val_loss: 1.2203 - val_mae: 0.8610 - val_mse: 1.2203\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9563 - mae: 0.7334 - mse: 0.9563 - val_loss: 0.8663 - val_mae: 0.7265 - val_mse: 0.8663\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9441 - mae: 0.7426 - mse: 0.9441 - val_loss: 1.0798 - val_mae: 0.8100 - val_mse: 1.0798\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9124 - mae: 0.7340 - mse: 0.9124 - val_loss: 1.2508 - val_mae: 0.8680 - val_mse: 1.2508\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9617 - mae: 0.7572 - mse: 0.9617 - val_loss: 0.8549 - val_mae: 0.7205 - val_mse: 0.8549\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9681 - mae: 0.7533 - mse: 0.9681 - val_loss: 0.8319 - val_mae: 0.7134 - val_mse: 0.8319\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9352 - mae: 0.7332 - mse: 0.9352 - val_loss: 0.8664 - val_mae: 0.7209 - val_mse: 0.8664\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9551 - mae: 0.7559 - mse: 0.9551 - val_loss: 1.3014 - val_mae: 0.8964 - val_mse: 1.3014\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9071 - mae: 0.7313 - mse: 0.9071 - val_loss: 1.1801 - val_mae: 0.8317 - val_mse: 1.1801\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9227 - mae: 0.7298 - mse: 0.9227 - val_loss: 0.8715 - val_mae: 0.7363 - val_mse: 0.8715\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9125 - mae: 0.7377 - mse: 0.9125 - val_loss: 2.9125 - val_mae: 1.4451 - val_mse: 2.9125\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0011 - mae: 0.7663 - mse: 1.0011 - val_loss: 1.1537 - val_mae: 0.8386 - val_mse: 1.1537\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8774 - mae: 0.7124 - mse: 0.8774 - val_loss: 0.9008 - val_mae: 0.7615 - val_mse: 0.9008\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9469 - mae: 0.7443 - mse: 0.9469 - val_loss: 1.1585 - val_mae: 0.8720 - val_mse: 1.1585\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8817 - mae: 0.7151 - mse: 0.8817 - val_loss: 1.1685 - val_mae: 0.8457 - val_mse: 1.1685\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9137 - mae: 0.7250 - mse: 0.9137 - val_loss: 0.8028 - val_mae: 0.7044 - val_mse: 0.8028\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9200 - mae: 0.7258 - mse: 0.9200 - val_loss: 0.8601 - val_mae: 0.7111 - val_mse: 0.8601\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8450 - mae: 0.7058 - mse: 0.8450 - val_loss: 0.8257 - val_mae: 0.7186 - val_mse: 0.8257\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9236 - mae: 0.7360 - mse: 0.9236 - val_loss: 0.8077 - val_mae: 0.7056 - val_mse: 0.8077\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8597 - mae: 0.6997 - mse: 0.8597 - val_loss: 1.1103 - val_mae: 0.8144 - val_mse: 1.1103\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9124 - mae: 0.7194 - mse: 0.9124 - val_loss: 1.7349 - val_mae: 1.0508 - val_mse: 1.7349\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9006 - mae: 0.7258 - mse: 0.9006 - val_loss: 0.8278 - val_mae: 0.7131 - val_mse: 0.8278\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8717 - mae: 0.7216 - mse: 0.8717 - val_loss: 1.1813 - val_mae: 0.8522 - val_mse: 1.1813\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9102 - mae: 0.7222 - mse: 0.9102 - val_loss: 0.9213 - val_mae: 0.7407 - val_mse: 0.9213\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8793 - mae: 0.7104 - mse: 0.8793 - val_loss: 0.9984 - val_mae: 0.8058 - val_mse: 0.9984\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9153 - mae: 0.7385 - mse: 0.9153 - val_loss: 0.9063 - val_mae: 0.7406 - val_mse: 0.9063\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8287 - mae: 0.6888 - mse: 0.8287 - val_loss: 0.8772 - val_mae: 0.7261 - val_mse: 0.8772\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8660 - mae: 0.7134 - mse: 0.8660 - val_loss: 1.0797 - val_mae: 0.8370 - val_mse: 1.0797\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8373 - mae: 0.6857 - mse: 0.8373 - val_loss: 0.8771 - val_mae: 0.7418 - val_mse: 0.8771\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8186 - mae: 0.6864 - mse: 0.8186 - val_loss: 1.1370 - val_mae: 0.8516 - val_mse: 1.1370\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8468 - mae: 0.7054 - mse: 0.8468 - val_loss: 0.9499 - val_mae: 0.7948 - val_mse: 0.9499\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8802 - mae: 0.7018 - mse: 0.8802 - val_loss: 1.2575 - val_mae: 0.8818 - val_mse: 1.2575\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9028 - mae: 0.7129 - mse: 0.9028 - val_loss: 0.8676 - val_mae: 0.7249 - val_mse: 0.8676\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7979 - mae: 0.6837 - mse: 0.7979 - val_loss: 0.8846 - val_mae: 0.7301 - val_mse: 0.8846\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8763 - mae: 0.7112 - mse: 0.8763 - val_loss: 0.8246 - val_mae: 0.7090 - val_mse: 0.8246\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8434 - mae: 0.6946 - mse: 0.8434 - val_loss: 1.0381 - val_mae: 0.7867 - val_mse: 1.0381\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7676 - mae: 0.6668 - mse: 0.7676 - val_loss: 1.0301 - val_mae: 0.7733 - val_mse: 1.0301\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8873 - mae: 0.7115 - mse: 0.8873 - val_loss: 0.8907 - val_mae: 0.7578 - val_mse: 0.8907\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8335 - mae: 0.6844 - mse: 0.8335 - val_loss: 0.9851 - val_mae: 0.7748 - val_mse: 0.9851\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8543 - mae: 0.6970 - mse: 0.8543 - val_loss: 0.8069 - val_mae: 0.7078 - val_mse: 0.8069\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7937 - mae: 0.6736 - mse: 0.7937 - val_loss: 1.5934 - val_mae: 1.0074 - val_mse: 1.5934\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8360 - mae: 0.6991 - mse: 0.8360 - val_loss: 0.9315 - val_mae: 0.7362 - val_mse: 0.9315\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8565 - mae: 0.7010 - mse: 0.8565 - val_loss: 1.4600 - val_mae: 0.9560 - val_mse: 1.4600\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8223 - mae: 0.6775 - mse: 0.8223 - val_loss: 1.4731 - val_mae: 0.9726 - val_mse: 1.4731\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8892 - mae: 0.7124 - mse: 0.8892 - val_loss: 0.9973 - val_mae: 0.7712 - val_mse: 0.9973\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7625 - mae: 0.6638 - mse: 0.7625 - val_loss: 0.8762 - val_mae: 0.7245 - val_mse: 0.8762\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7918 - mae: 0.6690 - mse: 0.7918 - val_loss: 0.8283 - val_mae: 0.7135 - val_mse: 0.8283\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8136 - mae: 0.6718 - mse: 0.8136 - val_loss: 1.4230 - val_mae: 0.9547 - val_mse: 1.4230\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7615 - mae: 0.6642 - mse: 0.7615 - val_loss: 1.0042 - val_mae: 0.7746 - val_mse: 1.0042\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8050 - mae: 0.6771 - mse: 0.8050 - val_loss: 0.9905 - val_mae: 0.7606 - val_mse: 0.9905\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7747 - mae: 0.6738 - mse: 0.7747 - val_loss: 0.9797 - val_mae: 0.7648 - val_mse: 0.9797\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7869 - mae: 0.6769 - mse: 0.7869 - val_loss: 0.9566 - val_mae: 0.7561 - val_mse: 0.9566\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7569 - mae: 0.6588 - mse: 0.7569 - val_loss: 1.0119 - val_mae: 0.7772 - val_mse: 1.0119\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7779 - mae: 0.6591 - mse: 0.7779 - val_loss: 1.1689 - val_mae: 0.8621 - val_mse: 1.1689\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7774 - mae: 0.6621 - mse: 0.7774 - val_loss: 0.9576 - val_mae: 0.7815 - val_mse: 0.9576\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7735 - mae: 0.6616 - mse: 0.7735 - val_loss: 1.1202 - val_mae: 0.8090 - val_mse: 1.1202\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7997 - mae: 0.6782 - mse: 0.7997 - val_loss: 1.1137 - val_mae: 0.8207 - val_mse: 1.1137\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7587 - mae: 0.6630 - mse: 0.7587 - val_loss: 0.8064 - val_mae: 0.7154 - val_mse: 0.8064\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7866 - mae: 0.6664 - mse: 0.7866 - val_loss: 0.7912 - val_mae: 0.6881 - val_mse: 0.7912\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7824 - mae: 0.6725 - mse: 0.7824 - val_loss: 1.0989 - val_mae: 0.8206 - val_mse: 1.0989\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7616 - mae: 0.6650 - mse: 0.7616 - val_loss: 1.0583 - val_mae: 0.7944 - val_mse: 1.0583\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7285 - mae: 0.6433 - mse: 0.7285 - val_loss: 1.5820 - val_mae: 1.0267 - val_mse: 1.5820\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7879 - mae: 0.6857 - mse: 0.7879 - val_loss: 0.8342 - val_mae: 0.7054 - val_mse: 0.8342\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7380 - mae: 0.6486 - mse: 0.7380 - val_loss: 0.9310 - val_mae: 0.7466 - val_mse: 0.9310\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7584 - mae: 0.6553 - mse: 0.7584 - val_loss: 1.2806 - val_mae: 0.8894 - val_mse: 1.2806\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7254 - mae: 0.6331 - mse: 0.7254 - val_loss: 1.7547 - val_mae: 1.0663 - val_mse: 1.7547\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7461 - mae: 0.6587 - mse: 0.7461 - val_loss: 0.9490 - val_mae: 0.7518 - val_mse: 0.9490\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7465 - mae: 0.6471 - mse: 0.7465 - val_loss: 0.8271 - val_mae: 0.7231 - val_mse: 0.8271\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7402 - mae: 0.6516 - mse: 0.7402 - val_loss: 1.1102 - val_mae: 0.7903 - val_mse: 1.1102\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7315 - mae: 0.6380 - mse: 0.7315 - val_loss: 0.7950 - val_mae: 0.6971 - val_mse: 0.7950\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7317 - mae: 0.6463 - mse: 0.7317 - val_loss: 0.8893 - val_mae: 0.7419 - val_mse: 0.8893\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7278 - mae: 0.6448 - mse: 0.7278 - val_loss: 1.5308 - val_mae: 1.0006 - val_mse: 1.5308\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7276 - mae: 0.6541 - mse: 0.7276 - val_loss: 0.8401 - val_mae: 0.7175 - val_mse: 0.8401\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6923 - mae: 0.6159 - mse: 0.6923 - val_loss: 0.7825 - val_mae: 0.6867 - val_mse: 0.7825\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7099 - mae: 0.6372 - mse: 0.7099 - val_loss: 1.1955 - val_mae: 0.8735 - val_mse: 1.1955\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6805 - mae: 0.6187 - mse: 0.6805 - val_loss: 1.4405 - val_mae: 0.9666 - val_mse: 1.4405\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7509 - mae: 0.6548 - mse: 0.7509 - val_loss: 0.8491 - val_mae: 0.7272 - val_mse: 0.8491\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7157 - mae: 0.6327 - mse: 0.7157 - val_loss: 0.9749 - val_mae: 0.7486 - val_mse: 0.9749\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7052 - mae: 0.6330 - mse: 0.7052 - val_loss: 0.8227 - val_mae: 0.7039 - val_mse: 0.8227\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7021 - mae: 0.6272 - mse: 0.7021 - val_loss: 1.2746 - val_mae: 0.9184 - val_mse: 1.2746\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6999 - mae: 0.6241 - mse: 0.6999 - val_loss: 0.8669 - val_mae: 0.7279 - val_mse: 0.8669\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7015 - mae: 0.6302 - mse: 0.7015 - val_loss: 0.8363 - val_mae: 0.7171 - val_mse: 0.8363\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6841 - mae: 0.6296 - mse: 0.6841 - val_loss: 1.4043 - val_mae: 0.9487 - val_mse: 1.4043\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7661 - mae: 0.6450 - mse: 0.7661 - val_loss: 0.8792 - val_mae: 0.7373 - val_mse: 0.8792\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6665 - mae: 0.6127 - mse: 0.6665 - val_loss: 0.8403 - val_mae: 0.7138 - val_mse: 0.8403\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6857 - mae: 0.6196 - mse: 0.6857 - val_loss: 1.0710 - val_mae: 0.7806 - val_mse: 1.0710\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6473 - mae: 0.6123 - mse: 0.6473 - val_loss: 0.9003 - val_mae: 0.7282 - val_mse: 0.9003\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6972 - mae: 0.6277 - mse: 0.6972 - val_loss: 0.7661 - val_mae: 0.6881 - val_mse: 0.7661\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6986 - mae: 0.6344 - mse: 0.6986 - val_loss: 1.0782 - val_mae: 0.8022 - val_mse: 1.0782\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6578 - mae: 0.6104 - mse: 0.6578 - val_loss: 1.0790 - val_mae: 0.8080 - val_mse: 1.0790\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6977 - mae: 0.6223 - mse: 0.6977 - val_loss: 0.8591 - val_mae: 0.7345 - val_mse: 0.8591\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6625 - mae: 0.6139 - mse: 0.6625 - val_loss: 0.8611 - val_mae: 0.7374 - val_mse: 0.8611\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6771 - mae: 0.6238 - mse: 0.6771 - val_loss: 1.4620 - val_mae: 0.9731 - val_mse: 1.4620\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6522 - mae: 0.6017 - mse: 0.6522 - val_loss: 0.9102 - val_mae: 0.7432 - val_mse: 0.9102\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6567 - mae: 0.6002 - mse: 0.6567 - val_loss: 0.8148 - val_mae: 0.7018 - val_mse: 0.8148\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6724 - mae: 0.6125 - mse: 0.6724 - val_loss: 1.0266 - val_mae: 0.7933 - val_mse: 1.0266\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6749 - mae: 0.6137 - mse: 0.6749 - val_loss: 0.9255 - val_mae: 0.7466 - val_mse: 0.9255\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6533 - mae: 0.6022 - mse: 0.6533 - val_loss: 0.9470 - val_mae: 0.7648 - val_mse: 0.9470\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6950 - mae: 0.6190 - mse: 0.6950 - val_loss: 0.8167 - val_mae: 0.7021 - val_mse: 0.8167\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6484 - mae: 0.6040 - mse: 0.6484 - val_loss: 0.8539 - val_mae: 0.7222 - val_mse: 0.8539\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6280 - mae: 0.5980 - mse: 0.6280 - val_loss: 0.7757 - val_mae: 0.6928 - val_mse: 0.7757\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6338 - mae: 0.5904 - mse: 0.6338 - val_loss: 1.0020 - val_mae: 0.7762 - val_mse: 1.0020\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6353 - mae: 0.5945 - mse: 0.6353 - val_loss: 1.1034 - val_mae: 0.8204 - val_mse: 1.1034\n",
      "Epoch 210/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6029 - mae: 0.5791 - mse: 0.6029 - val_loss: 1.2820 - val_mae: 0.8855 - val_mse: 1.2820\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6639 - mae: 0.6225 - mse: 0.6639 - val_loss: 1.2329 - val_mae: 0.8884 - val_mse: 1.2329\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6170 - mae: 0.5778 - mse: 0.6170 - val_loss: 0.9905 - val_mae: 0.7710 - val_mse: 0.9905\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6255 - mae: 0.5848 - mse: 0.6255 - val_loss: 0.8542 - val_mae: 0.7225 - val_mse: 0.8542\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6248 - mae: 0.5910 - mse: 0.6248 - val_loss: 1.4427 - val_mae: 0.9532 - val_mse: 1.4427\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5937 - mae: 0.5732 - mse: 0.5937 - val_loss: 0.7992 - val_mae: 0.6977 - val_mse: 0.7992\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6522 - mae: 0.5943 - mse: 0.6522 - val_loss: 0.8046 - val_mae: 0.7087 - val_mse: 0.8046\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5973 - mae: 0.5839 - mse: 0.5973 - val_loss: 0.8304 - val_mae: 0.7025 - val_mse: 0.8304\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6237 - mae: 0.5886 - mse: 0.6237 - val_loss: 1.1566 - val_mae: 0.8173 - val_mse: 1.1566\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5616 - mae: 0.5604 - mse: 0.5616 - val_loss: 0.9376 - val_mae: 0.7377 - val_mse: 0.9376\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6307 - mae: 0.5986 - mse: 0.6307 - val_loss: 1.0463 - val_mae: 0.8120 - val_mse: 1.0463\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6113 - mae: 0.5818 - mse: 0.6113 - val_loss: 0.8648 - val_mae: 0.7384 - val_mse: 0.8648\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5867 - mae: 0.5742 - mse: 0.5867 - val_loss: 0.9826 - val_mae: 0.7687 - val_mse: 0.9826\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6190 - mae: 0.5898 - mse: 0.6190 - val_loss: 0.8668 - val_mae: 0.7190 - val_mse: 0.8668\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5719 - mae: 0.5568 - mse: 0.5719 - val_loss: 1.0228 - val_mae: 0.7878 - val_mse: 1.0228\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5893 - mae: 0.5755 - mse: 0.5893 - val_loss: 1.0663 - val_mae: 0.8026 - val_mse: 1.0663\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5942 - mae: 0.5791 - mse: 0.5942 - val_loss: 0.8072 - val_mae: 0.7041 - val_mse: 0.8072\n",
      "Epoch 227/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5840 - mae: 0.5703 - mse: 0.5840 - val_loss: 0.9255 - val_mae: 0.7521 - val_mse: 0.9255\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6289 - mae: 0.5892 - mse: 0.6289 - val_loss: 1.1328 - val_mae: 0.8094 - val_mse: 1.1328\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5735 - mae: 0.5716 - mse: 0.5735 - val_loss: 0.9700 - val_mae: 0.7584 - val_mse: 0.9700\n",
      "Epoch 230/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5887 - mae: 0.5750 - mse: 0.5887 - val_loss: 0.9292 - val_mae: 0.7513 - val_mse: 0.9292\n",
      "Epoch 231/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6059 - mae: 0.5687 - mse: 0.6059 - val_loss: 0.9716 - val_mae: 0.7758 - val_mse: 0.9716\n",
      "Epoch 232/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5754 - mae: 0.5769 - mse: 0.5754 - val_loss: 0.9171 - val_mae: 0.7429 - val_mse: 0.9171\n",
      "Epoch 233/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5800 - mae: 0.5621 - mse: 0.5800 - val_loss: 1.0198 - val_mae: 0.7931 - val_mse: 1.0198\n",
      "Epoch 234/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5694 - mae: 0.5579 - mse: 0.5694 - val_loss: 0.8263 - val_mae: 0.7064 - val_mse: 0.8263\n",
      "Epoch 235/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5664 - mae: 0.5586 - mse: 0.5664 - val_loss: 1.5288 - val_mae: 1.0008 - val_mse: 1.5288\n",
      "Epoch 236/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5601 - mae: 0.5542 - mse: 0.5601 - val_loss: 1.0846 - val_mae: 0.7951 - val_mse: 1.0846\n",
      "Epoch 237/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5862 - mae: 0.5750 - mse: 0.5862 - val_loss: 1.0236 - val_mae: 0.7866 - val_mse: 1.0236\n",
      "Epoch 238/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5714 - mae: 0.5538 - mse: 0.5714 - val_loss: 0.8936 - val_mae: 0.7330 - val_mse: 0.8936\n",
      "Epoch 239/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5710 - mae: 0.5676 - mse: 0.5710 - val_loss: 1.4322 - val_mae: 0.9435 - val_mse: 1.4322\n",
      "Epoch 240/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5729 - mae: 0.5637 - mse: 0.5729 - val_loss: 1.3047 - val_mae: 0.9027 - val_mse: 1.3047\n",
      "Epoch 241/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5651 - mae: 0.5656 - mse: 0.5651 - val_loss: 0.9723 - val_mae: 0.7589 - val_mse: 0.9723\n",
      "Epoch 242/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5523 - mae: 0.5403 - mse: 0.5523 - val_loss: 0.9886 - val_mae: 0.7754 - val_mse: 0.9886\n",
      "Epoch 243/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5639 - mae: 0.5654 - mse: 0.5639 - val_loss: 0.9433 - val_mae: 0.7608 - val_mse: 0.9433\n",
      "Epoch 244/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5469 - mae: 0.5416 - mse: 0.5469 - val_loss: 0.9784 - val_mae: 0.7656 - val_mse: 0.9784\n",
      "Epoch 245/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5540 - mae: 0.5617 - mse: 0.5540 - val_loss: 0.8859 - val_mae: 0.7358 - val_mse: 0.8859\n",
      "Epoch 246/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5221 - mae: 0.5292 - mse: 0.5221 - val_loss: 0.9155 - val_mae: 0.7413 - val_mse: 0.9155\n",
      "Epoch 247/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5578 - mae: 0.5521 - mse: 0.5578 - val_loss: 0.9021 - val_mae: 0.7430 - val_mse: 0.9021\n",
      "Epoch 248/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5251 - mae: 0.5322 - mse: 0.5251 - val_loss: 1.0526 - val_mae: 0.8008 - val_mse: 1.0526\n",
      "Epoch 249/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5692 - mae: 0.5601 - mse: 0.5692 - val_loss: 0.9890 - val_mae: 0.7880 - val_mse: 0.9890\n",
      "Epoch 250/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5176 - mae: 0.5305 - mse: 0.5176 - val_loss: 0.9781 - val_mae: 0.7729 - val_mse: 0.9781\n",
      "Epoch 251/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5646 - mae: 0.5504 - mse: 0.5646 - val_loss: 0.9721 - val_mae: 0.7744 - val_mse: 0.9721\n",
      "Epoch 252/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5485 - mae: 0.5541 - mse: 0.5485 - val_loss: 0.9378 - val_mae: 0.7529 - val_mse: 0.9378\n",
      "Epoch 253/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5257 - mae: 0.5316 - mse: 0.5257 - val_loss: 0.9512 - val_mae: 0.7625 - val_mse: 0.9512\n",
      "Epoch 254/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5188 - mae: 0.5343 - mse: 0.5188 - val_loss: 1.3452 - val_mae: 0.8943 - val_mse: 1.3452\n",
      "Epoch 255/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5522 - mae: 0.5415 - mse: 0.5522 - val_loss: 0.9853 - val_mae: 0.7800 - val_mse: 0.9853\n",
      "Epoch 256/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5236 - mae: 0.5336 - mse: 0.5236 - val_loss: 0.8405 - val_mae: 0.7193 - val_mse: 0.8405\n",
      "Epoch 257/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5256 - mae: 0.5326 - mse: 0.5256 - val_loss: 1.2808 - val_mae: 0.9075 - val_mse: 1.2808\n",
      "Epoch 258/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5301 - mae: 0.5300 - mse: 0.5301 - val_loss: 1.0769 - val_mae: 0.8075 - val_mse: 1.0769\n",
      "Epoch 259/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5301 - mae: 0.5345 - mse: 0.5301 - val_loss: 0.9016 - val_mae: 0.7393 - val_mse: 0.9016\n",
      "Epoch 260/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5145 - mae: 0.5299 - mse: 0.5145 - val_loss: 1.2909 - val_mae: 0.8973 - val_mse: 1.2909\n",
      "Epoch 261/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5313 - mae: 0.5360 - mse: 0.5313 - val_loss: 0.8937 - val_mae: 0.7462 - val_mse: 0.8937\n",
      "Epoch 262/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5343 - mae: 0.5443 - mse: 0.5343 - val_loss: 0.9836 - val_mae: 0.7689 - val_mse: 0.9836\n",
      "Epoch 263/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5209 - mae: 0.5307 - mse: 0.5209 - val_loss: 1.4643 - val_mae: 0.9385 - val_mse: 1.4643\n",
      "Epoch 264/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5165 - mae: 0.5310 - mse: 0.5165 - val_loss: 1.1094 - val_mae: 0.8258 - val_mse: 1.1094\n",
      "Epoch 265/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5125 - mae: 0.5345 - mse: 0.5125 - val_loss: 0.9295 - val_mae: 0.7599 - val_mse: 0.9295\n",
      "Epoch 266/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5478 - mae: 0.5428 - mse: 0.5478 - val_loss: 1.0000 - val_mae: 0.7823 - val_mse: 1.0000\n",
      "Epoch 267/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4918 - mae: 0.5151 - mse: 0.4918 - val_loss: 0.9688 - val_mae: 0.7670 - val_mse: 0.9688\n",
      "Epoch 268/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5137 - mae: 0.5320 - mse: 0.5137 - val_loss: 1.1284 - val_mae: 0.8313 - val_mse: 1.1284\n",
      "Epoch 269/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5075 - mae: 0.5202 - mse: 0.5075 - val_loss: 1.0276 - val_mae: 0.7864 - val_mse: 1.0276\n",
      "Epoch 270/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5120 - mae: 0.5286 - mse: 0.5120 - val_loss: 0.8456 - val_mae: 0.7171 - val_mse: 0.8456\n",
      "Epoch 271/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5078 - mae: 0.5226 - mse: 0.5078 - val_loss: 1.0839 - val_mae: 0.8053 - val_mse: 1.0839\n",
      "Epoch 272/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4969 - mae: 0.5161 - mse: 0.4969 - val_loss: 0.9136 - val_mae: 0.7455 - val_mse: 0.9136\n",
      "Epoch 273/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5047 - mae: 0.5199 - mse: 0.5047 - val_loss: 1.1846 - val_mae: 0.8679 - val_mse: 1.1846\n",
      "Epoch 274/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5134 - mae: 0.5226 - mse: 0.5134 - val_loss: 1.0045 - val_mae: 0.7831 - val_mse: 1.0045\n",
      "Epoch 275/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5134 - mae: 0.5232 - mse: 0.5134 - val_loss: 1.0801 - val_mae: 0.8122 - val_mse: 1.0801\n",
      "Epoch 276/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4761 - mae: 0.5120 - mse: 0.4761 - val_loss: 0.8770 - val_mae: 0.7264 - val_mse: 0.8770\n",
      "Epoch 277/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5191 - mae: 0.5273 - mse: 0.5191 - val_loss: 1.0261 - val_mae: 0.7902 - val_mse: 1.0261\n",
      "Epoch 278/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4690 - mae: 0.5014 - mse: 0.4690 - val_loss: 1.0033 - val_mae: 0.7855 - val_mse: 1.0033\n",
      "Epoch 279/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4802 - mae: 0.5075 - mse: 0.4802 - val_loss: 0.9518 - val_mae: 0.7551 - val_mse: 0.9518\n",
      "Epoch 280/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4899 - mae: 0.5136 - mse: 0.4899 - val_loss: 1.3384 - val_mae: 0.9197 - val_mse: 1.3384\n",
      "Epoch 281/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4925 - mae: 0.5167 - mse: 0.4925 - val_loss: 0.8953 - val_mae: 0.7352 - val_mse: 0.8953\n",
      "Epoch 282/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5029 - mae: 0.5221 - mse: 0.5029 - val_loss: 0.9092 - val_mae: 0.7432 - val_mse: 0.9092\n",
      "Epoch 283/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4693 - mae: 0.4993 - mse: 0.4693 - val_loss: 1.2961 - val_mae: 0.8988 - val_mse: 1.2961\n",
      "Epoch 284/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4918 - mae: 0.5168 - mse: 0.4918 - val_loss: 0.9258 - val_mae: 0.7520 - val_mse: 0.9258\n",
      "Epoch 285/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4571 - mae: 0.4962 - mse: 0.4571 - val_loss: 1.9356 - val_mae: 1.0625 - val_mse: 1.9356\n",
      "Epoch 286/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5156 - mae: 0.5299 - mse: 0.5156 - val_loss: 0.9582 - val_mae: 0.7611 - val_mse: 0.9582\n",
      "Epoch 287/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4642 - mae: 0.5004 - mse: 0.4642 - val_loss: 1.0082 - val_mae: 0.7809 - val_mse: 1.0082\n",
      "Epoch 288/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4863 - mae: 0.5138 - mse: 0.4863 - val_loss: 1.2510 - val_mae: 0.8605 - val_mse: 1.2510\n",
      "Epoch 289/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5182 - mae: 0.5304 - mse: 0.5182 - val_loss: 0.9926 - val_mae: 0.7836 - val_mse: 0.9926\n",
      "Epoch 290/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4653 - mae: 0.4937 - mse: 0.4653 - val_loss: 0.9466 - val_mae: 0.7482 - val_mse: 0.9466\n",
      "Epoch 291/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4565 - mae: 0.4966 - mse: 0.4565 - val_loss: 1.2361 - val_mae: 0.8647 - val_mse: 1.2361\n",
      "Epoch 292/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4987 - mae: 0.5174 - mse: 0.4987 - val_loss: 0.8821 - val_mae: 0.7253 - val_mse: 0.8821\n",
      "Epoch 293/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4465 - mae: 0.4876 - mse: 0.4465 - val_loss: 1.3427 - val_mae: 0.9008 - val_mse: 1.3427\n",
      "Epoch 294/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4840 - mae: 0.5166 - mse: 0.4840 - val_loss: 1.0560 - val_mae: 0.7930 - val_mse: 1.0560\n",
      "Kappa Score: 0.7081477826435576\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 74.0455 - mae: 4.8094 - mse: 74.0455 - val_loss: 54.0339 - val_mae: 6.6689 - val_mse: 54.0339\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 27.2708 - mae: 4.2779 - mse: 27.2708 - val_loss: 17.5861 - val_mae: 3.5277 - val_mse: 17.5861\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 12.0077 - mae: 2.5420 - mse: 12.0077 - val_loss: 4.4245 - val_mae: 1.5847 - val_mse: 4.4245\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.1082 - mae: 1.9885 - mse: 6.1082 - val_loss: 2.5297 - val_mae: 1.2580 - val_mse: 2.5297\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.3280 - mae: 1.7236 - mse: 4.3280 - val_loss: 2.3860 - val_mae: 1.1885 - val_mse: 2.3860\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.0661 - mae: 1.6360 - mse: 4.0661 - val_loss: 1.6150 - val_mae: 0.9729 - val_mse: 1.6150\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.9244 - mae: 1.3508 - mse: 2.9244 - val_loss: 2.7542 - val_mae: 1.3929 - val_mse: 2.7542\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6398 - mae: 1.2903 - mse: 2.6398 - val_loss: 1.2420 - val_mae: 0.8518 - val_mse: 1.2420\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8271 - mae: 1.3081 - mse: 2.8271 - val_loss: 2.3199 - val_mae: 1.2192 - val_mse: 2.3199\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3461 - mae: 1.2211 - mse: 2.3461 - val_loss: 1.2518 - val_mae: 0.8655 - val_mse: 1.2518\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1974 - mae: 1.1849 - mse: 2.1974 - val_loss: 1.1966 - val_mae: 0.8475 - val_mse: 1.1966\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0108 - mae: 1.1248 - mse: 2.0108 - val_loss: 2.5217 - val_mae: 1.3215 - val_mse: 2.5217\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0205 - mae: 1.1281 - mse: 2.0205 - val_loss: 1.9137 - val_mae: 1.0831 - val_mse: 1.9137\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9411 - mae: 1.0974 - mse: 1.9411 - val_loss: 1.1970 - val_mae: 0.8413 - val_mse: 1.1970\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0062 - mae: 1.1142 - mse: 2.0062 - val_loss: 1.2734 - val_mae: 0.8677 - val_mse: 1.2734\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8324 - mae: 1.0491 - mse: 1.8324 - val_loss: 1.1740 - val_mae: 0.8298 - val_mse: 1.1740\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8190 - mae: 1.0508 - mse: 1.8190 - val_loss: 1.2491 - val_mae: 0.8573 - val_mse: 1.2491\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8148 - mae: 1.0504 - mse: 1.8148 - val_loss: 1.1878 - val_mae: 0.8410 - val_mse: 1.1878\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8194 - mae: 1.0640 - mse: 1.8194 - val_loss: 1.2943 - val_mae: 0.8837 - val_mse: 1.2943\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5698 - mae: 0.9879 - mse: 1.5698 - val_loss: 1.1699 - val_mae: 0.8307 - val_mse: 1.1699\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5665 - mae: 0.9934 - mse: 1.5665 - val_loss: 1.1405 - val_mae: 0.8221 - val_mse: 1.1405\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7400 - mae: 1.0363 - mse: 1.7400 - val_loss: 1.1276 - val_mae: 0.8169 - val_mse: 1.1276\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6528 - mae: 1.0162 - mse: 1.6528 - val_loss: 1.4027 - val_mae: 0.9180 - val_mse: 1.4027\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5615 - mae: 0.9780 - mse: 1.5615 - val_loss: 1.1493 - val_mae: 0.8211 - val_mse: 1.1493\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6385 - mae: 0.9941 - mse: 1.6385 - val_loss: 2.5265 - val_mae: 1.2873 - val_mse: 2.5265\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6303 - mae: 0.9979 - mse: 1.6303 - val_loss: 1.7695 - val_mae: 1.0476 - val_mse: 1.7695\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6058 - mae: 0.9965 - mse: 1.6058 - val_loss: 1.3185 - val_mae: 0.8760 - val_mse: 1.3185\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5503 - mae: 0.9744 - mse: 1.5503 - val_loss: 2.0733 - val_mae: 1.1637 - val_mse: 2.0733\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5868 - mae: 0.9902 - mse: 1.5868 - val_loss: 1.3503 - val_mae: 0.8845 - val_mse: 1.3503\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3721 - mae: 0.9166 - mse: 1.3721 - val_loss: 2.0291 - val_mae: 1.1578 - val_mse: 2.0291\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5342 - mae: 0.9694 - mse: 1.5342 - val_loss: 2.9212 - val_mae: 1.4492 - val_mse: 2.9212\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5173 - mae: 0.9608 - mse: 1.5173 - val_loss: 1.2156 - val_mae: 0.8212 - val_mse: 1.2156\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5745 - mae: 0.9759 - mse: 1.5745 - val_loss: 1.3383 - val_mae: 0.8830 - val_mse: 1.3383\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3669 - mae: 0.9139 - mse: 1.3669 - val_loss: 1.1779 - val_mae: 0.8186 - val_mse: 1.1779\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4265 - mae: 0.9300 - mse: 1.4265 - val_loss: 1.8879 - val_mae: 1.0995 - val_mse: 1.8879\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3806 - mae: 0.9163 - mse: 1.3806 - val_loss: 1.1293 - val_mae: 0.8095 - val_mse: 1.1293\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4221 - mae: 0.9363 - mse: 1.4221 - val_loss: 1.2809 - val_mae: 0.8462 - val_mse: 1.2809\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3646 - mae: 0.9117 - mse: 1.3646 - val_loss: 1.1358 - val_mae: 0.8226 - val_mse: 1.1358\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3203 - mae: 0.8989 - mse: 1.3203 - val_loss: 1.1537 - val_mae: 0.8089 - val_mse: 1.1537\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4294 - mae: 0.9375 - mse: 1.4294 - val_loss: 1.1396 - val_mae: 0.8024 - val_mse: 1.1396\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3806 - mae: 0.9224 - mse: 1.3806 - val_loss: 1.0872 - val_mae: 0.7912 - val_mse: 1.0872\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3479 - mae: 0.9112 - mse: 1.3479 - val_loss: 1.0961 - val_mae: 0.7963 - val_mse: 1.0961\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3439 - mae: 0.9139 - mse: 1.3439 - val_loss: 1.2777 - val_mae: 0.8594 - val_mse: 1.2777\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3166 - mae: 0.8822 - mse: 1.3166 - val_loss: 1.4928 - val_mae: 0.9702 - val_mse: 1.4928\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2596 - mae: 0.8913 - mse: 1.2596 - val_loss: 1.1616 - val_mae: 0.8299 - val_mse: 1.1616\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3482 - mae: 0.8998 - mse: 1.3482 - val_loss: 1.1022 - val_mae: 0.8110 - val_mse: 1.1022\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2600 - mae: 0.8738 - mse: 1.2600 - val_loss: 1.5281 - val_mae: 0.9897 - val_mse: 1.5281\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2555 - mae: 0.8716 - mse: 1.2555 - val_loss: 1.0551 - val_mae: 0.7899 - val_mse: 1.0551\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2530 - mae: 0.8729 - mse: 1.2530 - val_loss: 1.0727 - val_mae: 0.7881 - val_mse: 1.0727\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2464 - mae: 0.8686 - mse: 1.2464 - val_loss: 2.0702 - val_mae: 1.1565 - val_mse: 2.0702\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2832 - mae: 0.8805 - mse: 1.2832 - val_loss: 1.0577 - val_mae: 0.7966 - val_mse: 1.0577\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0356 - mae: 0.8354 - mse: 1.035 - 0s 1ms/step - loss: 1.2465 - mae: 0.8813 - mse: 1.2465 - val_loss: 1.0595 - val_mae: 0.7793 - val_mse: 1.0595\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2548 - mae: 0.8778 - mse: 1.2548 - val_loss: 1.1262 - val_mae: 0.8043 - val_mse: 1.1262\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2744 - mae: 0.8714 - mse: 1.2744 - val_loss: 1.1009 - val_mae: 0.8214 - val_mse: 1.1009\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1919 - mae: 0.8602 - mse: 1.1919 - val_loss: 1.1350 - val_mae: 0.8138 - val_mse: 1.1350\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1969 - mae: 0.8583 - mse: 1.1969 - val_loss: 2.3134 - val_mae: 1.2619 - val_mse: 2.3134\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2283 - mae: 0.8628 - mse: 1.2283 - val_loss: 1.0072 - val_mae: 0.7713 - val_mse: 1.0072\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2021 - mae: 0.8595 - mse: 1.2021 - val_loss: 1.1744 - val_mae: 0.8508 - val_mse: 1.1744\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2152 - mae: 0.8573 - mse: 1.2152 - val_loss: 1.9077 - val_mae: 1.1246 - val_mse: 1.9077\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1690 - mae: 0.8333 - mse: 1.1690 - val_loss: 1.1927 - val_mae: 0.8441 - val_mse: 1.1927\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1759 - mae: 0.8416 - mse: 1.1759 - val_loss: 1.0193 - val_mae: 0.7777 - val_mse: 1.0193\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2373 - mae: 0.8593 - mse: 1.2373 - val_loss: 0.9780 - val_mae: 0.7740 - val_mse: 0.9780\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1217 - mae: 0.8272 - mse: 1.1217 - val_loss: 1.0198 - val_mae: 0.7881 - val_mse: 1.0198\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1756 - mae: 0.8409 - mse: 1.1756 - val_loss: 1.0678 - val_mae: 0.8095 - val_mse: 1.0678\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0996 - mae: 0.8139 - mse: 1.0996 - val_loss: 1.6979 - val_mae: 1.0286 - val_mse: 1.6979\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2349 - mae: 0.8838 - mse: 1.2349 - val_loss: 1.5002 - val_mae: 0.9359 - val_mse: 1.5002\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1177 - mae: 0.8201 - mse: 1.1177 - val_loss: 1.8180 - val_mae: 1.0489 - val_mse: 1.8180\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1589 - mae: 0.8407 - mse: 1.1589 - val_loss: 0.9876 - val_mae: 0.7590 - val_mse: 0.9876\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1195 - mae: 0.8179 - mse: 1.1195 - val_loss: 1.2562 - val_mae: 0.8567 - val_mse: 1.2562\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1561 - mae: 0.8426 - mse: 1.1561 - val_loss: 0.9472 - val_mae: 0.7655 - val_mse: 0.9472\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2015 - mae: 0.8411 - mse: 1.2015 - val_loss: 1.3256 - val_mae: 0.9070 - val_mse: 1.3256\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0712 - mae: 0.8030 - mse: 1.0712 - val_loss: 1.2505 - val_mae: 0.8835 - val_mse: 1.2505\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1307 - mae: 0.8268 - mse: 1.1307 - val_loss: 1.0115 - val_mae: 0.7686 - val_mse: 1.0115\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1986 - mae: 0.8474 - mse: 1.1986 - val_loss: 0.9917 - val_mae: 0.7586 - val_mse: 0.9917\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0565 - mae: 0.7899 - mse: 1.0565 - val_loss: 1.6628 - val_mae: 1.0145 - val_mse: 1.6628\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1815 - mae: 0.8492 - mse: 1.1815 - val_loss: 0.9925 - val_mae: 0.7693 - val_mse: 0.9925\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0332 - mae: 0.7777 - mse: 1.0332 - val_loss: 0.9624 - val_mae: 0.7748 - val_mse: 0.9624\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0797 - mae: 0.7934 - mse: 1.0797 - val_loss: 1.0184 - val_mae: 0.7812 - val_mse: 1.0184\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0257 - mae: 0.7852 - mse: 1.0257 - val_loss: 1.7076 - val_mae: 1.0499 - val_mse: 1.7076\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1524 - mae: 0.8320 - mse: 1.1524 - val_loss: 1.0101 - val_mae: 0.7667 - val_mse: 1.0101\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0500 - mae: 0.7882 - mse: 1.0500 - val_loss: 1.1090 - val_mae: 0.8110 - val_mse: 1.1090\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0797 - mae: 0.8126 - mse: 1.0797 - val_loss: 0.9768 - val_mae: 0.7548 - val_mse: 0.9768\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0750 - mae: 0.8021 - mse: 1.0750 - val_loss: 0.9416 - val_mae: 0.7499 - val_mse: 0.9416\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9973 - mae: 0.7737 - mse: 0.9973 - val_loss: 0.9575 - val_mae: 0.7752 - val_mse: 0.9575\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0300 - mae: 0.7794 - mse: 1.0300 - val_loss: 1.2972 - val_mae: 0.9053 - val_mse: 1.2972\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0669 - mae: 0.8008 - mse: 1.0669 - val_loss: 1.2656 - val_mae: 0.8673 - val_mse: 1.2656\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9965 - mae: 0.7795 - mse: 0.9965 - val_loss: 1.2782 - val_mae: 0.8642 - val_mse: 1.2782\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0218 - mae: 0.7767 - mse: 1.0218 - val_loss: 2.7374 - val_mae: 1.3981 - val_mse: 2.7374\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0216 - mae: 0.7816 - mse: 1.0216 - val_loss: 1.4458 - val_mae: 0.9564 - val_mse: 1.4458\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0449 - mae: 0.8053 - mse: 1.0449 - val_loss: 1.3182 - val_mae: 0.9172 - val_mse: 1.3182\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9915 - mae: 0.7682 - mse: 0.9915 - val_loss: 0.9276 - val_mae: 0.7593 - val_mse: 0.9276\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0289 - mae: 0.7862 - mse: 1.0289 - val_loss: 0.9668 - val_mae: 0.7511 - val_mse: 0.9668\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9740 - mae: 0.7706 - mse: 0.9740 - val_loss: 1.2641 - val_mae: 0.8625 - val_mse: 1.2641\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0604 - mae: 0.7911 - mse: 1.0604 - val_loss: 2.0517 - val_mae: 1.1417 - val_mse: 2.0517\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9822 - mae: 0.7736 - mse: 0.9822 - val_loss: 1.4136 - val_mae: 0.9522 - val_mse: 1.4136\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0190 - mae: 0.7740 - mse: 1.0190 - val_loss: 1.0763 - val_mae: 0.7918 - val_mse: 1.0763\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9862 - mae: 0.7631 - mse: 0.9862 - val_loss: 0.9221 - val_mae: 0.7471 - val_mse: 0.9221\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0303 - mae: 0.7868 - mse: 1.0303 - val_loss: 1.1935 - val_mae: 0.8293 - val_mse: 1.1935\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9799 - mae: 0.7490 - mse: 0.9799 - val_loss: 0.9380 - val_mae: 0.7703 - val_mse: 0.9380\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9980 - mae: 0.7684 - mse: 0.9980 - val_loss: 1.3727 - val_mae: 0.9092 - val_mse: 1.3727\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9678 - mae: 0.7584 - mse: 0.9678 - val_loss: 0.9192 - val_mae: 0.7426 - val_mse: 0.9192\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9386 - mae: 0.7363 - mse: 0.9386 - val_loss: 2.1604 - val_mae: 1.1803 - val_mse: 2.1604\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9855 - mae: 0.7589 - mse: 0.9855 - val_loss: 2.0870 - val_mae: 1.1534 - val_mse: 2.0870\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0000 - mae: 0.7700 - mse: 1.0000 - val_loss: 0.9142 - val_mae: 0.7396 - val_mse: 0.9142\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9103 - mae: 0.7372 - mse: 0.9103 - val_loss: 1.1116 - val_mae: 0.8086 - val_mse: 1.1116\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9850 - mae: 0.7586 - mse: 0.9850 - val_loss: 0.9589 - val_mae: 0.7601 - val_mse: 0.9589\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9454 - mae: 0.7494 - mse: 0.9454 - val_loss: 1.0482 - val_mae: 0.8118 - val_mse: 1.0482\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9397 - mae: 0.7408 - mse: 0.9397 - val_loss: 1.0122 - val_mae: 0.8046 - val_mse: 1.0122\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8679 - mae: 0.7247 - mse: 0.8679 - val_loss: 1.7508 - val_mae: 1.0585 - val_mse: 1.7508\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0022 - mae: 0.7651 - mse: 1.0022 - val_loss: 0.9283 - val_mae: 0.7570 - val_mse: 0.9283\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9470 - mae: 0.7470 - mse: 0.9470 - val_loss: 1.3666 - val_mae: 0.8885 - val_mse: 1.3666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9838 - mae: 0.7610 - mse: 0.9838 - val_loss: 1.0152 - val_mae: 0.7931 - val_mse: 1.0152\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9681 - mae: 0.7493 - mse: 0.9681 - val_loss: 1.3093 - val_mae: 0.8830 - val_mse: 1.3093\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8914 - mae: 0.7322 - mse: 0.8914 - val_loss: 1.6214 - val_mae: 1.0197 - val_mse: 1.6214\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9351 - mae: 0.7398 - mse: 0.9351 - val_loss: 1.1839 - val_mae: 0.8366 - val_mse: 1.1839\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9451 - mae: 0.7473 - mse: 0.9451 - val_loss: 0.9745 - val_mae: 0.7901 - val_mse: 0.9745\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9024 - mae: 0.7246 - mse: 0.9024 - val_loss: 1.5909 - val_mae: 0.9971 - val_mse: 1.5909\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9968 - mae: 0.7529 - mse: 0.9968 - val_loss: 0.9631 - val_mae: 0.7638 - val_mse: 0.9631\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8828 - mae: 0.7307 - mse: 0.8828 - val_loss: 0.9246 - val_mae: 0.7455 - val_mse: 0.9246\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9098 - mae: 0.7347 - mse: 0.9098 - val_loss: 1.1302 - val_mae: 0.8242 - val_mse: 1.1302\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9476 - mae: 0.7450 - mse: 0.9476 - val_loss: 1.4467 - val_mae: 0.9301 - val_mse: 1.4467\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9310 - mae: 0.7421 - mse: 0.9310 - val_loss: 0.9230 - val_mae: 0.7574 - val_mse: 0.9230\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9235 - mae: 0.7332 - mse: 0.9235 - val_loss: 1.5524 - val_mae: 0.9594 - val_mse: 1.5524\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9274 - mae: 0.7379 - mse: 0.9274 - val_loss: 0.9541 - val_mae: 0.7584 - val_mse: 0.9541\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8954 - mae: 0.7309 - mse: 0.8954 - val_loss: 1.0343 - val_mae: 0.8032 - val_mse: 1.0343\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8831 - mae: 0.7208 - mse: 0.8831 - val_loss: 1.0152 - val_mae: 0.7854 - val_mse: 1.0152\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8946 - mae: 0.7350 - mse: 0.8946 - val_loss: 0.9834 - val_mae: 0.7565 - val_mse: 0.9834\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9368 - mae: 0.7305 - mse: 0.9368 - val_loss: 0.9259 - val_mae: 0.7469 - val_mse: 0.9259\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8620 - mae: 0.7083 - mse: 0.8620 - val_loss: 0.9436 - val_mae: 0.7421 - val_mse: 0.9436\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9034 - mae: 0.7283 - mse: 0.9034 - val_loss: 1.0185 - val_mae: 0.7979 - val_mse: 1.0185\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8652 - mae: 0.7110 - mse: 0.8652 - val_loss: 1.0727 - val_mae: 0.7962 - val_mse: 1.0727\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8799 - mae: 0.7279 - mse: 0.8799 - val_loss: 0.9565 - val_mae: 0.7680 - val_mse: 0.9565\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8758 - mae: 0.7133 - mse: 0.8758 - val_loss: 1.2193 - val_mae: 0.8836 - val_mse: 1.2193\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8730 - mae: 0.7182 - mse: 0.8730 - val_loss: 1.0461 - val_mae: 0.7843 - val_mse: 1.0461\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8952 - mae: 0.7218 - mse: 0.8952 - val_loss: 0.9150 - val_mae: 0.7538 - val_mse: 0.9150\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8325 - mae: 0.6960 - mse: 0.8325 - val_loss: 1.3561 - val_mae: 0.8654 - val_mse: 1.3561\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9196 - mae: 0.7231 - mse: 0.9196 - val_loss: 1.2617 - val_mae: 0.8936 - val_mse: 1.2617\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8025 - mae: 0.6840 - mse: 0.8025 - val_loss: 1.1348 - val_mae: 0.8267 - val_mse: 1.1348\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9041 - mae: 0.7361 - mse: 0.9041 - val_loss: 0.9562 - val_mae: 0.7650 - val_mse: 0.9562\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8428 - mae: 0.6921 - mse: 0.8428 - val_loss: 1.9135 - val_mae: 1.0957 - val_mse: 1.9135\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9193 - mae: 0.7333 - mse: 0.9193 - val_loss: 0.9402 - val_mae: 0.7581 - val_mse: 0.9402\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8584 - mae: 0.7031 - mse: 0.8584 - val_loss: 0.9729 - val_mae: 0.7768 - val_mse: 0.9729\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8096 - mae: 0.6904 - mse: 0.8096 - val_loss: 1.3634 - val_mae: 0.9171 - val_mse: 1.3634\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8547 - mae: 0.6960 - mse: 0.8547 - val_loss: 0.9491 - val_mae: 0.7619 - val_mse: 0.9491\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8038 - mae: 0.6841 - mse: 0.8038 - val_loss: 1.6915 - val_mae: 1.0253 - val_mse: 1.6915\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8567 - mae: 0.6982 - mse: 0.8567 - val_loss: 1.1820 - val_mae: 0.8287 - val_mse: 1.1820\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7775 - mae: 0.6736 - mse: 0.7775 - val_loss: 1.5968 - val_mae: 0.9917 - val_mse: 1.5968\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8906 - mae: 0.7302 - mse: 0.8906 - val_loss: 0.8873 - val_mae: 0.7362 - val_mse: 0.8873\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7632 - mae: 0.6661 - mse: 0.7632 - val_loss: 3.2304 - val_mae: 1.4432 - val_mse: 3.2304\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9070 - mae: 0.7268 - mse: 0.9070 - val_loss: 1.0651 - val_mae: 0.8047 - val_mse: 1.0651\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8571 - mae: 0.6876 - mse: 0.8571 - val_loss: 1.1784 - val_mae: 0.8697 - val_mse: 1.1784\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7735 - mae: 0.6734 - mse: 0.7735 - val_loss: 1.5849 - val_mae: 0.9806 - val_mse: 1.5849\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8129 - mae: 0.6839 - mse: 0.8129 - val_loss: 1.2610 - val_mae: 0.9173 - val_mse: 1.2610\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8264 - mae: 0.6959 - mse: 0.8264 - val_loss: 0.9544 - val_mae: 0.7719 - val_mse: 0.9544\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8177 - mae: 0.6830 - mse: 0.8177 - val_loss: 0.9356 - val_mae: 0.7498 - val_mse: 0.9356\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7542 - mae: 0.6609 - mse: 0.7542 - val_loss: 1.2034 - val_mae: 0.8606 - val_mse: 1.2034\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8071 - mae: 0.6807 - mse: 0.8071 - val_loss: 0.9063 - val_mae: 0.7356 - val_mse: 0.9063\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7548 - mae: 0.6634 - mse: 0.7548 - val_loss: 2.1077 - val_mae: 1.1158 - val_mse: 2.1077\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7782 - mae: 0.6713 - mse: 0.7782 - val_loss: 0.9794 - val_mae: 0.7639 - val_mse: 0.9794\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8228 - mae: 0.6951 - mse: 0.8228 - val_loss: 1.5063 - val_mae: 0.9667 - val_mse: 1.5063\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7979 - mae: 0.6726 - mse: 0.7979 - val_loss: 1.4490 - val_mae: 0.9322 - val_mse: 1.4490\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8379 - mae: 0.6911 - mse: 0.8379 - val_loss: 1.0165 - val_mae: 0.7800 - val_mse: 1.0165\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7790 - mae: 0.6714 - mse: 0.7790 - val_loss: 1.1385 - val_mae: 0.8139 - val_mse: 1.1385\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7544 - mae: 0.6594 - mse: 0.7544 - val_loss: 1.0018 - val_mae: 0.7765 - val_mse: 1.0018\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8001 - mae: 0.6736 - mse: 0.8001 - val_loss: 1.0535 - val_mae: 0.7796 - val_mse: 1.0535\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7596 - mae: 0.6641 - mse: 0.7596 - val_loss: 0.8927 - val_mae: 0.7463 - val_mse: 0.8927\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7466 - mae: 0.6602 - mse: 0.7466 - val_loss: 1.2490 - val_mae: 0.8601 - val_mse: 1.2490\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7843 - mae: 0.6733 - mse: 0.7843 - val_loss: 1.0334 - val_mae: 0.8092 - val_mse: 1.0334\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8002 - mae: 0.6883 - mse: 0.8002 - val_loss: 1.4182 - val_mae: 0.9137 - val_mse: 1.4182\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7518 - mae: 0.6547 - mse: 0.7518 - val_loss: 0.9651 - val_mae: 0.7706 - val_mse: 0.9651\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7842 - mae: 0.6743 - mse: 0.7842 - val_loss: 1.0475 - val_mae: 0.8055 - val_mse: 1.0475\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7102 - mae: 0.6425 - mse: 0.7102 - val_loss: 1.6323 - val_mae: 0.9751 - val_mse: 1.6323\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8057 - mae: 0.6843 - mse: 0.8057 - val_loss: 1.0258 - val_mae: 0.8037 - val_mse: 1.0258\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7795 - mae: 0.6749 - mse: 0.7795 - val_loss: 0.9583 - val_mae: 0.7665 - val_mse: 0.9583\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7398 - mae: 0.6485 - mse: 0.7398 - val_loss: 1.2785 - val_mae: 0.8706 - val_mse: 1.2785\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8148 - mae: 0.6909 - mse: 0.8148 - val_loss: 1.3334 - val_mae: 0.8799 - val_mse: 1.3334\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7365 - mae: 0.6479 - mse: 0.7365 - val_loss: 0.9982 - val_mae: 0.7778 - val_mse: 0.9982\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7674 - mae: 0.6620 - mse: 0.7674 - val_loss: 1.0309 - val_mae: 0.8055 - val_mse: 1.0309\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6849 - mae: 0.6224 - mse: 0.6849 - val_loss: 1.0579 - val_mae: 0.8041 - val_mse: 1.0579\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7822 - mae: 0.6674 - mse: 0.7822 - val_loss: 1.0233 - val_mae: 0.7961 - val_mse: 1.0233\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7485 - mae: 0.6601 - mse: 0.7485 - val_loss: 0.9702 - val_mae: 0.7535 - val_mse: 0.9702\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7076 - mae: 0.6368 - mse: 0.7076 - val_loss: 1.0053 - val_mae: 0.7743 - val_mse: 1.0053\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7611 - mae: 0.6630 - mse: 0.7611 - val_loss: 0.9063 - val_mae: 0.7411 - val_mse: 0.9063\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6909 - mae: 0.6284 - mse: 0.6909 - val_loss: 0.9690 - val_mae: 0.7656 - val_mse: 0.9690\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7203 - mae: 0.6419 - mse: 0.7203 - val_loss: 1.5754 - val_mae: 0.9205 - val_mse: 1.5754\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6917 - mae: 0.6320 - mse: 0.6917 - val_loss: 1.1375 - val_mae: 0.8146 - val_mse: 1.1375\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7093 - mae: 0.6297 - mse: 0.7093 - val_loss: 1.2044 - val_mae: 0.8157 - val_mse: 1.2044\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7377 - mae: 0.6621 - mse: 0.7377 - val_loss: 1.0336 - val_mae: 0.7643 - val_mse: 1.0336\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7303 - mae: 0.6405 - mse: 0.7303 - val_loss: 1.2115 - val_mae: 0.8566 - val_mse: 1.2115\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6787 - mae: 0.6265 - mse: 0.6787 - val_loss: 2.3027 - val_mae: 1.1804 - val_mse: 2.3027\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7230 - mae: 0.6483 - mse: 0.7230 - val_loss: 1.1158 - val_mae: 0.8274 - val_mse: 1.1158\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6541 - mae: 0.6126 - mse: 0.6541 - val_loss: 0.9929 - val_mae: 0.7837 - val_mse: 0.9929\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6800 - mae: 0.6236 - mse: 0.6800 - val_loss: 1.3060 - val_mae: 0.8908 - val_mse: 1.3060\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6861 - mae: 0.6294 - mse: 0.6861 - val_loss: 0.9935 - val_mae: 0.7588 - val_mse: 0.9935\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7161 - mae: 0.6324 - mse: 0.7161 - val_loss: 0.9758 - val_mae: 0.7670 - val_mse: 0.9758\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6991 - mae: 0.6320 - mse: 0.6991 - val_loss: 1.6607 - val_mae: 1.0022 - val_mse: 1.6607\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7121 - mae: 0.6312 - mse: 0.7121 - val_loss: 0.9455 - val_mae: 0.7498 - val_mse: 0.9455\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6562 - mae: 0.6223 - mse: 0.6562 - val_loss: 0.9258 - val_mae: 0.7526 - val_mse: 0.9258\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7161 - mae: 0.6365 - mse: 0.7161 - val_loss: 1.0795 - val_mae: 0.8215 - val_mse: 1.0795\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6005 - mae: 0.5752 - mse: 0.6005 - val_loss: 1.0775 - val_mae: 0.8163 - val_mse: 1.0775\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6198 - mae: 0.5953 - mse: 0.6198 - val_loss: 1.1093 - val_mae: 0.8227 - val_mse: 1.1093\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7013 - mae: 0.6369 - mse: 0.7013 - val_loss: 1.0180 - val_mae: 0.7902 - val_mse: 1.0180\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6011 - mae: 0.5860 - mse: 0.6011 - val_loss: 0.9671 - val_mae: 0.7617 - val_mse: 0.9671\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6405 - mae: 0.6033 - mse: 0.6405 - val_loss: 1.1780 - val_mae: 0.8732 - val_mse: 1.1780\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6744 - mae: 0.6145 - mse: 0.6744 - val_loss: 1.0169 - val_mae: 0.7660 - val_mse: 1.0169\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6455 - mae: 0.6064 - mse: 0.6455 - val_loss: 0.9764 - val_mae: 0.7687 - val_mse: 0.9764\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6014 - mae: 0.5807 - mse: 0.6014 - val_loss: 1.0731 - val_mae: 0.8040 - val_mse: 1.0731\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6642 - mae: 0.6117 - mse: 0.6642 - val_loss: 1.3855 - val_mae: 0.9094 - val_mse: 1.3855\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6504 - mae: 0.6080 - mse: 0.6504 - val_loss: 0.9296 - val_mae: 0.7493 - val_mse: 0.9296\n",
      "Epoch 210/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6649 - mae: 0.6207 - mse: 0.6649 - val_loss: 1.1185 - val_mae: 0.8255 - val_mse: 1.1185\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6309 - mae: 0.6058 - mse: 0.6309 - val_loss: 1.0507 - val_mae: 0.7874 - val_mse: 1.0507\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6459 - mae: 0.6101 - mse: 0.6459 - val_loss: 1.3427 - val_mae: 0.9228 - val_mse: 1.3427\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6129 - mae: 0.5790 - mse: 0.6129 - val_loss: 1.2722 - val_mae: 0.8715 - val_mse: 1.2722\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6168 - mae: 0.5893 - mse: 0.6168 - val_loss: 0.9958 - val_mae: 0.7807 - val_mse: 0.9958\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6680 - mae: 0.6095 - mse: 0.6680 - val_loss: 0.9879 - val_mae: 0.7824 - val_mse: 0.9879\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6127 - mae: 0.5938 - mse: 0.6127 - val_loss: 0.9680 - val_mae: 0.7586 - val_mse: 0.9680\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6147 - mae: 0.5853 - mse: 0.6147 - val_loss: 1.0261 - val_mae: 0.7755 - val_mse: 1.0261\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6472 - mae: 0.5979 - mse: 0.6472 - val_loss: 1.1800 - val_mae: 0.8498 - val_mse: 1.1800\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6180 - mae: 0.5903 - mse: 0.6180 - val_loss: 1.0199 - val_mae: 0.7805 - val_mse: 1.0199\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6028 - mae: 0.5921 - mse: 0.6028 - val_loss: 1.1823 - val_mae: 0.8595 - val_mse: 1.1823\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6033 - mae: 0.5853 - mse: 0.6033 - val_loss: 1.2343 - val_mae: 0.8854 - val_mse: 1.2343\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6319 - mae: 0.6005 - mse: 0.6319 - val_loss: 1.0092 - val_mae: 0.7775 - val_mse: 1.0092\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5766 - mae: 0.5692 - mse: 0.5766 - val_loss: 1.1970 - val_mae: 0.8543 - val_mse: 1.1970\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6539 - mae: 0.6055 - mse: 0.6539 - val_loss: 0.9944 - val_mae: 0.7689 - val_mse: 0.9944\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5686 - mae: 0.5665 - mse: 0.5686 - val_loss: 1.0073 - val_mae: 0.7903 - val_mse: 1.0073\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5798 - mae: 0.5621 - mse: 0.5798 - val_loss: 1.0208 - val_mae: 0.7783 - val_mse: 1.0208\n",
      "Epoch 227/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6394 - mae: 0.6039 - mse: 0.6394 - val_loss: 1.1723 - val_mae: 0.8393 - val_mse: 1.1723\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5925 - mae: 0.5781 - mse: 0.5925 - val_loss: 1.2084 - val_mae: 0.8198 - val_mse: 1.2084\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5692 - mae: 0.5657 - mse: 0.5692 - val_loss: 1.0091 - val_mae: 0.7819 - val_mse: 1.0091\n",
      "Epoch 230/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6035 - mae: 0.5803 - mse: 0.6035 - val_loss: 1.1576 - val_mae: 0.8542 - val_mse: 1.1576\n",
      "Epoch 231/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6090 - mae: 0.5923 - mse: 0.6090 - val_loss: 1.0533 - val_mae: 0.7938 - val_mse: 1.0533\n",
      "Epoch 232/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5697 - mae: 0.5682 - mse: 0.5697 - val_loss: 1.1433 - val_mae: 0.8294 - val_mse: 1.1433\n",
      "Epoch 233/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5891 - mae: 0.5739 - mse: 0.5891 - val_loss: 1.0472 - val_mae: 0.7892 - val_mse: 1.0472\n",
      "Epoch 234/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5756 - mae: 0.5715 - mse: 0.5756 - val_loss: 1.2358 - val_mae: 0.8761 - val_mse: 1.2358\n",
      "Epoch 235/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6364 - mae: 0.6014 - mse: 0.6364 - val_loss: 1.0218 - val_mae: 0.7831 - val_mse: 1.0218\n",
      "Epoch 236/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5597 - mae: 0.5567 - mse: 0.5597 - val_loss: 1.0708 - val_mae: 0.8133 - val_mse: 1.0708\n",
      "Epoch 237/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5490 - mae: 0.5455 - mse: 0.5490 - val_loss: 1.4561 - val_mae: 0.9322 - val_mse: 1.4561\n",
      "Epoch 238/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6007 - mae: 0.5772 - mse: 0.6007 - val_loss: 1.0859 - val_mae: 0.8222 - val_mse: 1.0859\n",
      "Epoch 239/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5309 - mae: 0.5442 - mse: 0.5309 - val_loss: 1.7746 - val_mae: 1.0086 - val_mse: 1.7746\n",
      "Epoch 240/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5797 - mae: 0.5591 - mse: 0.5797 - val_loss: 1.5509 - val_mae: 0.9781 - val_mse: 1.5509\n",
      "Epoch 241/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6068 - mae: 0.5842 - mse: 0.6068 - val_loss: 1.1884 - val_mae: 0.8176 - val_mse: 1.1884\n",
      "Epoch 242/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5543 - mae: 0.5541 - mse: 0.5543 - val_loss: 1.0191 - val_mae: 0.7836 - val_mse: 1.0191\n",
      "Epoch 243/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5392 - mae: 0.5529 - mse: 0.5392 - val_loss: 1.6627 - val_mae: 1.0004 - val_mse: 1.6627\n",
      "Epoch 244/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5504 - mae: 0.5580 - mse: 0.5504 - val_loss: 1.5411 - val_mae: 0.9658 - val_mse: 1.5411\n",
      "Epoch 245/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5583 - mae: 0.5635 - mse: 0.5583 - val_loss: 1.1072 - val_mae: 0.7950 - val_mse: 1.1072\n",
      "Epoch 246/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5380 - mae: 0.5427 - mse: 0.5380 - val_loss: 1.2795 - val_mae: 0.8728 - val_mse: 1.2795\n",
      "Epoch 247/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5614 - mae: 0.5639 - mse: 0.5614 - val_loss: 1.3468 - val_mae: 0.9249 - val_mse: 1.3468\n",
      "Epoch 248/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5106 - mae: 0.5331 - mse: 0.5106 - val_loss: 1.3359 - val_mae: 0.9094 - val_mse: 1.3359\n",
      "Kappa Score: 0.7247689961424598\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 140.2399 - mae: 5.3416 - mse: 140.2399 - val_loss: 1.9721 - val_mae: 1.0293 - val_mse: 1.9721\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 38.8704 - mae: 4.4905 - mse: 38.8704 - val_loss: 4.8101 - val_mae: 1.6941 - val_mse: 4.8101\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 24.0998 - mae: 3.6548 - mse: 24.0998 - val_loss: 1.4065 - val_mae: 0.9082 - val_mse: 1.4065\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 13.9344 - mae: 2.7093 - mse: 13.9344 - val_loss: 8.5074 - val_mae: 2.3720 - val_mse: 8.5074\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.0501 - mae: 1.9330 - mse: 6.0501 - val_loss: 24.7063 - val_mae: 4.7816 - val_mse: 24.7063\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 5.1049 - mae: 1.6689 - mse: 5.1049 - val_loss: 5.0327 - val_mae: 1.7661 - val_mse: 5.0327\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.2718 - mae: 1.6535 - mse: 4.2718 - val_loss: 1.5526 - val_mae: 0.9286 - val_mse: 1.5526\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8215 - mae: 1.3452 - mse: 2.8215 - val_loss: 3.7572 - val_mae: 1.7052 - val_mse: 3.7572\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5649 - mae: 1.2860 - mse: 2.5649 - val_loss: 1.3497 - val_mae: 0.8849 - val_mse: 1.3497\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2935 - mae: 1.1868 - mse: 2.2935 - val_loss: 2.8143 - val_mae: 1.3192 - val_mse: 2.8143\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9447 - mae: 1.1049 - mse: 1.9447 - val_loss: 1.2217 - val_mae: 0.8640 - val_mse: 1.2217\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0663 - mae: 1.1356 - mse: 2.0663 - val_loss: 1.3725 - val_mae: 0.8954 - val_mse: 1.3725\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7739 - mae: 1.0536 - mse: 1.7739 - val_loss: 1.2708 - val_mae: 0.8549 - val_mse: 1.2708\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0697 - mae: 1.1114 - mse: 2.0697 - val_loss: 1.4339 - val_mae: 0.9169 - val_mse: 1.4339\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7718 - mae: 1.0554 - mse: 1.7718 - val_loss: 1.4189 - val_mae: 0.9282 - val_mse: 1.4189\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7589 - mae: 1.0465 - mse: 1.7589 - val_loss: 1.1098 - val_mae: 0.8280 - val_mse: 1.1098\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6363 - mae: 1.0137 - mse: 1.6363 - val_loss: 1.5417 - val_mae: 0.9703 - val_mse: 1.5417\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6143 - mae: 0.9945 - mse: 1.6143 - val_loss: 1.0344 - val_mae: 0.7907 - val_mse: 1.0344\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1915 - mae: 1.0933 - mse: 2.1915 - val_loss: 1.1045 - val_mae: 0.8131 - val_mse: 1.1045\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4139 - mae: 0.9205 - mse: 1.4139 - val_loss: 2.6006 - val_mae: 1.2306 - val_mse: 2.6006\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5955 - mae: 1.0018 - mse: 1.5955 - val_loss: 1.0355 - val_mae: 0.7760 - val_mse: 1.0355\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6089 - mae: 1.0009 - mse: 1.6089 - val_loss: 1.4411 - val_mae: 0.9414 - val_mse: 1.4411\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4827 - mae: 0.9626 - mse: 1.4827 - val_loss: 1.3057 - val_mae: 0.8779 - val_mse: 1.3057\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4375 - mae: 0.9365 - mse: 1.4375 - val_loss: 1.1132 - val_mae: 0.7960 - val_mse: 1.1132\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4295 - mae: 0.9353 - mse: 1.4295 - val_loss: 1.2806 - val_mae: 0.8597 - val_mse: 1.2806\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5757 - mae: 0.9694 - mse: 1.5757 - val_loss: 1.2536 - val_mae: 0.8520 - val_mse: 1.2536\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4533 - mae: 0.9551 - mse: 1.4533 - val_loss: 1.0071 - val_mae: 0.7736 - val_mse: 1.0071\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3392 - mae: 0.9135 - mse: 1.3392 - val_loss: 1.2878 - val_mae: 0.8756 - val_mse: 1.2878\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2874 - mae: 0.8914 - mse: 1.2874 - val_loss: 1.6361 - val_mae: 1.0035 - val_mse: 1.6361\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4912 - mae: 0.9560 - mse: 1.4912 - val_loss: 0.9494 - val_mae: 0.7547 - val_mse: 0.9494\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3895 - mae: 0.9271 - mse: 1.3895 - val_loss: 1.0373 - val_mae: 0.7774 - val_mse: 1.0373\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3260 - mae: 0.9074 - mse: 1.3260 - val_loss: 1.0447 - val_mae: 0.8074 - val_mse: 1.0447\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3417 - mae: 0.9070 - mse: 1.3417 - val_loss: 0.9304 - val_mae: 0.7436 - val_mse: 0.9304\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3655 - mae: 0.9252 - mse: 1.3655 - val_loss: 1.0350 - val_mae: 0.7746 - val_mse: 1.0350\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2805 - mae: 0.8834 - mse: 1.2805 - val_loss: 0.9429 - val_mae: 0.7424 - val_mse: 0.9429\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2460 - mae: 0.8792 - mse: 1.2460 - val_loss: 1.4431 - val_mae: 0.9366 - val_mse: 1.4431\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2921 - mae: 0.8906 - mse: 1.2921 - val_loss: 0.9165 - val_mae: 0.7411 - val_mse: 0.9165\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2789 - mae: 0.8787 - mse: 1.2789 - val_loss: 0.9087 - val_mae: 0.7340 - val_mse: 0.9087\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3648 - mae: 0.9007 - mse: 1.3648 - val_loss: 1.0178 - val_mae: 0.7635 - val_mse: 1.0178\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1689 - mae: 0.8561 - mse: 1.1689 - val_loss: 1.0139 - val_mae: 0.7675 - val_mse: 1.0139\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1539 - mae: 0.8428 - mse: 1.1539 - val_loss: 1.6715 - val_mae: 1.0496 - val_mse: 1.6715\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2655 - mae: 0.8801 - mse: 1.2655 - val_loss: 1.4321 - val_mae: 0.9665 - val_mse: 1.4321\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2224 - mae: 0.8605 - mse: 1.2224 - val_loss: 1.6871 - val_mae: 1.0321 - val_mse: 1.6871\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2047 - mae: 0.8593 - mse: 1.2047 - val_loss: 1.1442 - val_mae: 0.8552 - val_mse: 1.1442\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1967 - mae: 0.8530 - mse: 1.1967 - val_loss: 1.6941 - val_mae: 1.0275 - val_mse: 1.6941\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2037 - mae: 0.8629 - mse: 1.2037 - val_loss: 1.2404 - val_mae: 0.8610 - val_mse: 1.2404\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1656 - mae: 0.8447 - mse: 1.1656 - val_loss: 1.1574 - val_mae: 0.8309 - val_mse: 1.1574\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1794 - mae: 0.8497 - mse: 1.1794 - val_loss: 1.3497 - val_mae: 0.9217 - val_mse: 1.3497\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2717 - mae: 0.8785 - mse: 1.2717 - val_loss: 0.9981 - val_mae: 0.7580 - val_mse: 0.9981\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2117 - mae: 0.8618 - mse: 1.2117 - val_loss: 0.9109 - val_mae: 0.7498 - val_mse: 0.9109\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1670 - mae: 0.8281 - mse: 1.1670 - val_loss: 0.9016 - val_mae: 0.7474 - val_mse: 0.9016\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2285 - mae: 0.8627 - mse: 1.2285 - val_loss: 0.8608 - val_mae: 0.7198 - val_mse: 0.8608\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1097 - mae: 0.8169 - mse: 1.1097 - val_loss: 1.0219 - val_mae: 0.7741 - val_mse: 1.0219\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1790 - mae: 0.8470 - mse: 1.1790 - val_loss: 1.6925 - val_mae: 1.0342 - val_mse: 1.6925\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1604 - mae: 0.8472 - mse: 1.1604 - val_loss: 1.2360 - val_mae: 0.8946 - val_mse: 1.2360\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2099 - mae: 0.8692 - mse: 1.2099 - val_loss: 1.2079 - val_mae: 0.8490 - val_mse: 1.2079\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1978 - mae: 0.8474 - mse: 1.1978 - val_loss: 1.2787 - val_mae: 0.9053 - val_mse: 1.2787\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1404 - mae: 0.8379 - mse: 1.1404 - val_loss: 1.8176 - val_mae: 1.0626 - val_mse: 1.8176\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1635 - mae: 0.8338 - mse: 1.1635 - val_loss: 1.0588 - val_mae: 0.8215 - val_mse: 1.0588\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0940 - mae: 0.8174 - mse: 1.0940 - val_loss: 1.0832 - val_mae: 0.8021 - val_mse: 1.0832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1083 - mae: 0.8231 - mse: 1.1083 - val_loss: 0.9777 - val_mae: 0.7889 - val_mse: 0.9777\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0494 - mae: 0.8030 - mse: 1.0494 - val_loss: 1.4164 - val_mae: 0.9426 - val_mse: 1.4164\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1058 - mae: 0.8285 - mse: 1.1058 - val_loss: 1.0529 - val_mae: 0.7931 - val_mse: 1.0529\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1084 - mae: 0.8193 - mse: 1.1084 - val_loss: 0.8515 - val_mae: 0.7115 - val_mse: 0.8515\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1052 - mae: 0.8128 - mse: 1.1052 - val_loss: 0.8735 - val_mae: 0.7161 - val_mse: 0.8735\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1194 - mae: 0.8260 - mse: 1.1194 - val_loss: 0.8445 - val_mae: 0.7257 - val_mse: 0.8445\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0598 - mae: 0.8047 - mse: 1.0598 - val_loss: 0.8262 - val_mae: 0.7073 - val_mse: 0.8262\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0829 - mae: 0.8133 - mse: 1.0829 - val_loss: 0.8274 - val_mae: 0.7142 - val_mse: 0.8274\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0356 - mae: 0.7928 - mse: 1.0356 - val_loss: 1.3855 - val_mae: 0.9455 - val_mse: 1.3855\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1431 - mae: 0.8462 - mse: 1.1431 - val_loss: 0.8177 - val_mae: 0.7065 - val_mse: 0.8177\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0185 - mae: 0.7877 - mse: 1.0185 - val_loss: 0.9781 - val_mae: 0.7824 - val_mse: 0.9781\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0322 - mae: 0.7939 - mse: 1.0322 - val_loss: 1.4064 - val_mae: 0.9461 - val_mse: 1.4064\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1255 - mae: 0.8278 - mse: 1.1255 - val_loss: 1.5959 - val_mae: 1.0060 - val_mse: 1.5959\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0290 - mae: 0.7899 - mse: 1.0290 - val_loss: 1.8560 - val_mae: 1.1190 - val_mse: 1.8560\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0434 - mae: 0.7983 - mse: 1.0434 - val_loss: 1.3429 - val_mae: 0.9151 - val_mse: 1.3429\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0787 - mae: 0.8200 - mse: 1.0787 - val_loss: 0.8293 - val_mae: 0.7068 - val_mse: 0.8293\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0229 - mae: 0.7940 - mse: 1.0229 - val_loss: 1.3934 - val_mae: 0.9360 - val_mse: 1.3934\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0259 - mae: 0.7901 - mse: 1.0259 - val_loss: 0.8159 - val_mae: 0.7074 - val_mse: 0.8159\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0190 - mae: 0.7894 - mse: 1.0190 - val_loss: 1.8513 - val_mae: 1.1227 - val_mse: 1.8513\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0295 - mae: 0.7788 - mse: 1.0295 - val_loss: 1.3615 - val_mae: 0.9173 - val_mse: 1.3615\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0306 - mae: 0.7904 - mse: 1.0306 - val_loss: 0.8214 - val_mae: 0.7163 - val_mse: 0.8214\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9681 - mae: 0.7673 - mse: 0.9681 - val_loss: 1.4514 - val_mae: 0.9646 - val_mse: 1.4514\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0591 - mae: 0.8030 - mse: 1.0591 - val_loss: 1.1419 - val_mae: 0.8534 - val_mse: 1.1419\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0112 - mae: 0.7890 - mse: 1.0112 - val_loss: 0.8056 - val_mae: 0.6938 - val_mse: 0.8056\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9833 - mae: 0.7739 - mse: 0.9833 - val_loss: 1.6691 - val_mae: 1.0399 - val_mse: 1.6691\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0378 - mae: 0.7846 - mse: 1.0378 - val_loss: 0.9339 - val_mae: 0.7670 - val_mse: 0.9339\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0200 - mae: 0.7817 - mse: 1.0200 - val_loss: 1.2105 - val_mae: 0.8863 - val_mse: 1.2105\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9855 - mae: 0.7689 - mse: 0.9855 - val_loss: 0.9707 - val_mae: 0.7655 - val_mse: 0.9707\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9784 - mae: 0.7743 - mse: 0.9784 - val_loss: 0.9776 - val_mae: 0.7738 - val_mse: 0.9776\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9714 - mae: 0.7545 - mse: 0.9714 - val_loss: 0.8505 - val_mae: 0.7288 - val_mse: 0.8505\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0364 - mae: 0.7997 - mse: 1.0364 - val_loss: 0.8057 - val_mae: 0.6957 - val_mse: 0.8057\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9402 - mae: 0.7522 - mse: 0.9402 - val_loss: 0.8171 - val_mae: 0.7117 - val_mse: 0.8171\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9619 - mae: 0.7747 - mse: 0.9619 - val_loss: 1.0275 - val_mae: 0.8031 - val_mse: 1.0275\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9854 - mae: 0.7716 - mse: 0.9854 - val_loss: 1.0681 - val_mae: 0.8217 - val_mse: 1.0681\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9347 - mae: 0.7584 - mse: 0.9347 - val_loss: 1.0816 - val_mae: 0.8091 - val_mse: 1.0816\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9801 - mae: 0.7759 - mse: 0.9801 - val_loss: 0.9343 - val_mae: 0.7627 - val_mse: 0.9343\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0286 - mae: 0.7874 - mse: 1.0286 - val_loss: 0.8337 - val_mae: 0.7022 - val_mse: 0.8337\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9425 - mae: 0.7494 - mse: 0.9425 - val_loss: 1.0173 - val_mae: 0.8010 - val_mse: 1.0173\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9538 - mae: 0.7598 - mse: 0.9538 - val_loss: 1.4501 - val_mae: 0.9789 - val_mse: 1.4501\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9483 - mae: 0.7531 - mse: 0.9483 - val_loss: 0.8676 - val_mae: 0.7152 - val_mse: 0.8676\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9487 - mae: 0.7564 - mse: 0.9487 - val_loss: 0.8116 - val_mae: 0.7061 - val_mse: 0.8116\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9220 - mae: 0.7489 - mse: 0.9220 - val_loss: 0.7874 - val_mae: 0.6943 - val_mse: 0.7874\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9295 - mae: 0.7510 - mse: 0.9295 - val_loss: 1.0589 - val_mae: 0.8029 - val_mse: 1.0589\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9169 - mae: 0.7493 - mse: 0.9169 - val_loss: 0.8425 - val_mae: 0.7035 - val_mse: 0.8425\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9197 - mae: 0.7402 - mse: 0.9197 - val_loss: 1.3305 - val_mae: 0.9155 - val_mse: 1.3305\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8854 - mae: 0.7349 - mse: 0.8854 - val_loss: 0.7889 - val_mae: 0.6908 - val_mse: 0.7889\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9551 - mae: 0.7599 - mse: 0.9551 - val_loss: 1.0418 - val_mae: 0.7925 - val_mse: 1.0418\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8721 - mae: 0.7288 - mse: 0.8721 - val_loss: 1.0502 - val_mae: 0.8152 - val_mse: 1.0502\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8779 - mae: 0.7251 - mse: 0.8779 - val_loss: 0.7832 - val_mae: 0.6920 - val_mse: 0.7832\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9114 - mae: 0.7309 - mse: 0.9114 - val_loss: 1.0884 - val_mae: 0.8108 - val_mse: 1.0884\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9085 - mae: 0.7485 - mse: 0.9085 - val_loss: 1.2633 - val_mae: 0.8951 - val_mse: 1.2633\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9085 - mae: 0.7407 - mse: 0.9085 - val_loss: 0.8114 - val_mae: 0.6974 - val_mse: 0.8114\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9020 - mae: 0.7325 - mse: 0.9020 - val_loss: 0.9131 - val_mae: 0.7380 - val_mse: 0.9131\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8687 - mae: 0.7217 - mse: 0.8687 - val_loss: 1.1116 - val_mae: 0.8223 - val_mse: 1.1116\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9757 - mae: 0.7618 - mse: 0.9757 - val_loss: 0.8405 - val_mae: 0.7289 - val_mse: 0.8405\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8471 - mae: 0.7163 - mse: 0.8471 - val_loss: 0.8087 - val_mae: 0.7088 - val_mse: 0.8087\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8772 - mae: 0.7253 - mse: 0.8772 - val_loss: 1.5181 - val_mae: 0.9925 - val_mse: 1.5181\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8459 - mae: 0.7193 - mse: 0.8459 - val_loss: 0.9779 - val_mae: 0.7994 - val_mse: 0.9779\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8769 - mae: 0.7325 - mse: 0.8769 - val_loss: 0.8175 - val_mae: 0.6958 - val_mse: 0.8175\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8923 - mae: 0.7367 - mse: 0.8923 - val_loss: 1.1310 - val_mae: 0.8529 - val_mse: 1.1310\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8738 - mae: 0.7221 - mse: 0.8738 - val_loss: 0.8025 - val_mae: 0.6890 - val_mse: 0.8025\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8944 - mae: 0.7232 - mse: 0.8944 - val_loss: 0.7975 - val_mae: 0.7023 - val_mse: 0.7975\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8912 - mae: 0.7396 - mse: 0.8912 - val_loss: 1.2303 - val_mae: 0.8925 - val_mse: 1.2303\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8811 - mae: 0.7296 - mse: 0.8811 - val_loss: 0.8164 - val_mae: 0.7172 - val_mse: 0.8164\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8522 - mae: 0.7092 - mse: 0.8522 - val_loss: 1.1036 - val_mae: 0.8573 - val_mse: 1.1036\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8404 - mae: 0.7133 - mse: 0.8404 - val_loss: 1.5072 - val_mae: 0.9985 - val_mse: 1.5072\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8784 - mae: 0.7295 - mse: 0.8784 - val_loss: 0.8632 - val_mae: 0.7386 - val_mse: 0.8632\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8795 - mae: 0.7268 - mse: 0.8795 - val_loss: 1.5412 - val_mae: 1.0070 - val_mse: 1.5412\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8843 - mae: 0.7283 - mse: 0.8843 - val_loss: 0.8403 - val_mae: 0.7297 - val_mse: 0.8403\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8244 - mae: 0.7081 - mse: 0.8244 - val_loss: 0.7815 - val_mae: 0.6855 - val_mse: 0.7815\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8830 - mae: 0.7351 - mse: 0.8830 - val_loss: 1.1302 - val_mae: 0.8623 - val_mse: 1.1302\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8876 - mae: 0.7334 - mse: 0.8876 - val_loss: 1.3710 - val_mae: 0.9665 - val_mse: 1.3710\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8530 - mae: 0.7149 - mse: 0.8530 - val_loss: 0.7916 - val_mae: 0.6996 - val_mse: 0.7916\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8206 - mae: 0.6911 - mse: 0.8206 - val_loss: 0.9661 - val_mae: 0.7588 - val_mse: 0.9661\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9002 - mae: 0.7198 - mse: 0.9002 - val_loss: 0.8041 - val_mae: 0.7015 - val_mse: 0.8041\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8391 - mae: 0.7057 - mse: 0.8391 - val_loss: 0.9824 - val_mae: 0.7888 - val_mse: 0.9824\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8645 - mae: 0.7173 - mse: 0.8645 - val_loss: 1.4966 - val_mae: 0.9880 - val_mse: 1.4966\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7616 - mae: 0.6735 - mse: 0.7616 - val_loss: 0.8177 - val_mae: 0.7134 - val_mse: 0.8177\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8310 - mae: 0.6977 - mse: 0.8310 - val_loss: 0.8716 - val_mae: 0.7432 - val_mse: 0.8716\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7931 - mae: 0.6865 - mse: 0.7931 - val_loss: 1.0884 - val_mae: 0.8407 - val_mse: 1.0884\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8181 - mae: 0.6956 - mse: 0.8181 - val_loss: 1.5291 - val_mae: 0.9944 - val_mse: 1.5291\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8587 - mae: 0.7124 - mse: 0.8587 - val_loss: 0.8329 - val_mae: 0.7218 - val_mse: 0.8329\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8179 - mae: 0.6944 - mse: 0.8179 - val_loss: 0.8894 - val_mae: 0.7258 - val_mse: 0.8894\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7621 - mae: 0.6786 - mse: 0.7621 - val_loss: 1.3671 - val_mae: 0.9595 - val_mse: 1.3671\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8209 - mae: 0.7055 - mse: 0.8209 - val_loss: 0.8408 - val_mae: 0.7254 - val_mse: 0.8408\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7400 - mae: 0.6629 - mse: 0.7400 - val_loss: 0.8653 - val_mae: 0.7377 - val_mse: 0.8653\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7992 - mae: 0.6876 - mse: 0.7992 - val_loss: 2.0856 - val_mae: 1.2086 - val_mse: 2.0856\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8075 - mae: 0.6919 - mse: 0.8075 - val_loss: 1.3647 - val_mae: 0.9265 - val_mse: 1.3647\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7853 - mae: 0.6825 - mse: 0.7853 - val_loss: 0.8504 - val_mae: 0.7264 - val_mse: 0.8504\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8054 - mae: 0.7009 - mse: 0.8054 - val_loss: 0.8275 - val_mae: 0.6965 - val_mse: 0.8275\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7871 - mae: 0.6769 - mse: 0.7871 - val_loss: 0.9769 - val_mae: 0.7605 - val_mse: 0.9769\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7917 - mae: 0.6898 - mse: 0.7917 - val_loss: 2.0346 - val_mae: 1.1883 - val_mse: 2.0346\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7848 - mae: 0.6745 - mse: 0.7848 - val_loss: 0.8893 - val_mae: 0.7260 - val_mse: 0.8893\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7812 - mae: 0.6898 - mse: 0.7812 - val_loss: 0.9943 - val_mae: 0.7843 - val_mse: 0.9943\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7877 - mae: 0.6749 - mse: 0.7877 - val_loss: 1.5454 - val_mae: 1.0327 - val_mse: 1.5454\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7853 - mae: 0.6751 - mse: 0.7853 - val_loss: 0.9504 - val_mae: 0.7727 - val_mse: 0.9504\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7767 - mae: 0.6838 - mse: 0.7767 - val_loss: 0.8885 - val_mae: 0.7383 - val_mse: 0.8885\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7758 - mae: 0.6778 - mse: 0.7758 - val_loss: 0.8685 - val_mae: 0.7280 - val_mse: 0.8685\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7077 - mae: 0.6417 - mse: 0.7077 - val_loss: 1.6369 - val_mae: 1.0442 - val_mse: 1.6369\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7712 - mae: 0.6858 - mse: 0.7712 - val_loss: 1.1594 - val_mae: 0.8422 - val_mse: 1.1594\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7666 - mae: 0.6859 - mse: 0.7666 - val_loss: 0.8962 - val_mae: 0.7157 - val_mse: 0.8962\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7030 - mae: 0.6381 - mse: 0.7030 - val_loss: 0.8969 - val_mae: 0.7317 - val_mse: 0.8969\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7724 - mae: 0.6789 - mse: 0.7724 - val_loss: 0.9756 - val_mae: 0.7566 - val_mse: 0.9756\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7490 - mae: 0.6641 - mse: 0.7490 - val_loss: 1.0317 - val_mae: 0.7868 - val_mse: 1.0317\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6746 - mae: 0.6301 - mse: 0.6746 - val_loss: 1.1743 - val_mae: 0.8669 - val_mse: 1.1743\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7508 - mae: 0.6701 - mse: 0.7508 - val_loss: 0.8805 - val_mae: 0.7343 - val_mse: 0.8805\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7395 - mae: 0.6611 - mse: 0.7395 - val_loss: 1.0468 - val_mae: 0.8187 - val_mse: 1.0468\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7223 - mae: 0.6521 - mse: 0.7223 - val_loss: 1.2559 - val_mae: 0.9011 - val_mse: 1.2559\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7062 - mae: 0.6378 - mse: 0.7062 - val_loss: 0.8434 - val_mae: 0.7233 - val_mse: 0.8434\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7122 - mae: 0.6445 - mse: 0.7122 - val_loss: 0.8785 - val_mae: 0.7334 - val_mse: 0.8785\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7614 - mae: 0.6801 - mse: 0.7614 - val_loss: 0.8453 - val_mae: 0.7154 - val_mse: 0.8453\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7082 - mae: 0.6482 - mse: 0.7082 - val_loss: 1.3882 - val_mae: 0.9364 - val_mse: 1.3882\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8264 - mae: 0.6986 - mse: 0.8264 - val_loss: 0.8196 - val_mae: 0.7078 - val_mse: 0.8196\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7047 - mae: 0.6499 - mse: 0.7047 - val_loss: 0.7992 - val_mae: 0.6875 - val_mse: 0.7992\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6953 - mae: 0.6433 - mse: 0.6953 - val_loss: 1.5599 - val_mae: 1.0000 - val_mse: 1.5599\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7032 - mae: 0.6464 - mse: 0.7032 - val_loss: 1.0127 - val_mae: 0.8025 - val_mse: 1.0127\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7603 - mae: 0.6674 - mse: 0.7603 - val_loss: 0.8072 - val_mae: 0.6948 - val_mse: 0.8072\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6745 - mae: 0.6225 - mse: 0.6745 - val_loss: 1.3058 - val_mae: 0.9366 - val_mse: 1.3058\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6913 - mae: 0.6436 - mse: 0.6913 - val_loss: 0.8396 - val_mae: 0.7009 - val_mse: 0.8396\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7504 - mae: 0.6642 - mse: 0.7504 - val_loss: 1.2251 - val_mae: 0.8817 - val_mse: 1.2251\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6785 - mae: 0.6338 - mse: 0.6785 - val_loss: 2.0227 - val_mae: 1.1823 - val_mse: 2.0227\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7193 - mae: 0.6494 - mse: 0.7193 - val_loss: 0.8396 - val_mae: 0.7091 - val_mse: 0.8396\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7196 - mae: 0.6585 - mse: 0.7196 - val_loss: 0.9087 - val_mae: 0.7529 - val_mse: 0.9087\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6780 - mae: 0.6337 - mse: 0.6780 - val_loss: 0.8469 - val_mae: 0.7188 - val_mse: 0.8469\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7147 - mae: 0.6505 - mse: 0.7147 - val_loss: 0.9228 - val_mae: 0.7590 - val_mse: 0.9228\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6938 - mae: 0.6353 - mse: 0.6938 - val_loss: 0.8845 - val_mae: 0.7320 - val_mse: 0.8845\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6802 - mae: 0.6331 - mse: 0.6802 - val_loss: 1.2409 - val_mae: 0.8603 - val_mse: 1.2409\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6958 - mae: 0.6357 - mse: 0.6958 - val_loss: 0.9149 - val_mae: 0.7313 - val_mse: 0.9149\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6711 - mae: 0.6291 - mse: 0.6711 - val_loss: 1.4340 - val_mae: 0.9499 - val_mse: 1.4340\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6667 - mae: 0.6175 - mse: 0.6667 - val_loss: 0.8379 - val_mae: 0.7133 - val_mse: 0.8379\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7309 - mae: 0.6623 - mse: 0.7309 - val_loss: 1.7610 - val_mae: 1.0845 - val_mse: 1.7610\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7056 - mae: 0.6272 - mse: 0.7056 - val_loss: 0.8555 - val_mae: 0.7239 - val_mse: 0.8555\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6645 - mae: 0.6228 - mse: 0.6645 - val_loss: 1.2251 - val_mae: 0.8686 - val_mse: 1.2251\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6342 - mae: 0.6099 - mse: 0.6342 - val_loss: 1.9174 - val_mae: 1.1468 - val_mse: 1.9174\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6979 - mae: 0.6410 - mse: 0.6979 - val_loss: 1.0102 - val_mae: 0.7841 - val_mse: 1.0102\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6496 - mae: 0.6247 - mse: 0.6496 - val_loss: 0.8374 - val_mae: 0.7068 - val_mse: 0.8374\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7325 - mae: 0.6548 - mse: 0.7325 - val_loss: 0.8614 - val_mae: 0.7105 - val_mse: 0.8614\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6333 - mae: 0.6145 - mse: 0.6333 - val_loss: 1.0104 - val_mae: 0.7732 - val_mse: 1.0104\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6595 - mae: 0.6284 - mse: 0.6595 - val_loss: 0.8720 - val_mae: 0.7192 - val_mse: 0.8720\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6505 - mae: 0.6096 - mse: 0.6505 - val_loss: 0.9838 - val_mae: 0.7721 - val_mse: 0.9838\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6606 - mae: 0.6283 - mse: 0.6606 - val_loss: 0.9263 - val_mae: 0.7441 - val_mse: 0.9263\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6340 - mae: 0.6076 - mse: 0.6340 - val_loss: 1.1326 - val_mae: 0.8208 - val_mse: 1.1326\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6351 - mae: 0.6094 - mse: 0.6351 - val_loss: 1.1248 - val_mae: 0.8313 - val_mse: 1.1248\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5989 - mae: 0.5867 - mse: 0.5989 - val_loss: 1.5075 - val_mae: 0.9838 - val_mse: 1.5075\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6592 - mae: 0.6189 - mse: 0.6592 - val_loss: 0.8961 - val_mae: 0.7329 - val_mse: 0.8961\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6233 - mae: 0.5986 - mse: 0.6233 - val_loss: 0.8452 - val_mae: 0.6992 - val_mse: 0.8452\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6406 - mae: 0.6114 - mse: 0.6406 - val_loss: 0.9682 - val_mae: 0.7629 - val_mse: 0.9682\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6209 - mae: 0.6011 - mse: 0.6209 - val_loss: 0.8663 - val_mae: 0.7173 - val_mse: 0.8663\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6112 - mae: 0.5989 - mse: 0.6112 - val_loss: 1.2302 - val_mae: 0.8655 - val_mse: 1.2302\n",
      "Epoch 210/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6356 - mae: 0.6104 - mse: 0.6356 - val_loss: 1.2730 - val_mae: 0.8900 - val_mse: 1.2730\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7019 - mae: 0.6374 - mse: 0.7019 - val_loss: 0.8680 - val_mae: 0.7047 - val_mse: 0.8680\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6126 - mae: 0.5876 - mse: 0.6126 - val_loss: 0.9576 - val_mae: 0.7620 - val_mse: 0.9576\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5966 - mae: 0.5824 - mse: 0.5966 - val_loss: 0.8714 - val_mae: 0.7134 - val_mse: 0.8714\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5984 - mae: 0.5869 - mse: 0.5984 - val_loss: 0.9251 - val_mae: 0.7372 - val_mse: 0.9251\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6024 - mae: 0.5887 - mse: 0.6024 - val_loss: 0.9053 - val_mae: 0.7372 - val_mse: 0.9053\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6026 - mae: 0.5885 - mse: 0.6026 - val_loss: 1.1101 - val_mae: 0.8289 - val_mse: 1.1101\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5990 - mae: 0.5913 - mse: 0.5990 - val_loss: 0.9672 - val_mae: 0.7657 - val_mse: 0.9672\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6101 - mae: 0.6028 - mse: 0.6101 - val_loss: 0.8904 - val_mae: 0.7143 - val_mse: 0.8904\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5902 - mae: 0.5802 - mse: 0.5902 - val_loss: 0.9188 - val_mae: 0.7300 - val_mse: 0.9188\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6174 - mae: 0.6024 - mse: 0.6174 - val_loss: 0.8984 - val_mae: 0.7233 - val_mse: 0.8984\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6304 - mae: 0.5967 - mse: 0.6304 - val_loss: 1.0248 - val_mae: 0.7976 - val_mse: 1.0248\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5844 - mae: 0.5693 - mse: 0.5844 - val_loss: 1.0949 - val_mae: 0.7971 - val_mse: 1.0949\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5787 - mae: 0.5789 - mse: 0.5787 - val_loss: 0.8972 - val_mae: 0.7192 - val_mse: 0.8972\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5615 - mae: 0.5748 - mse: 0.5615 - val_loss: 0.8775 - val_mae: 0.7096 - val_mse: 0.8775\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5919 - mae: 0.5914 - mse: 0.5919 - val_loss: 0.8967 - val_mae: 0.7229 - val_mse: 0.8967\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6045 - mae: 0.5929 - mse: 0.6045 - val_loss: 0.9765 - val_mae: 0.7467 - val_mse: 0.9765\n",
      "Epoch 227/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6707 - mae: 0.6051 - mse: 0.6707 - val_loss: 0.8859 - val_mae: 0.7144 - val_mse: 0.8859\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5904 - mae: 0.5800 - mse: 0.5904 - val_loss: 0.9977 - val_mae: 0.7657 - val_mse: 0.9977\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5867 - mae: 0.5750 - mse: 0.5867 - val_loss: 1.2006 - val_mae: 0.8712 - val_mse: 1.2006\n",
      "Epoch 230/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5241 - mae: 0.5447 - mse: 0.5241 - val_loss: 1.3875 - val_mae: 0.9305 - val_mse: 1.3875\n",
      "Kappa Score: 0.6673815797536613\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 131.5738 - mae: 7.3405 - mse: 131.5738 - val_loss: 23.4515 - val_mae: 4.0802 - val_mse: 23.4515\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 40.2747 - mae: 5.0967 - mse: 40.2747 - val_loss: 25.8215 - val_mae: 4.3827 - val_mse: 25.8215\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 19.0680 - mae: 3.5210 - mse: 19.0680 - val_loss: 4.5108 - val_mae: 1.6483 - val_mse: 4.5108\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 10.9498 - mae: 2.5308 - mse: 10.9498 - val_loss: 11.6196 - val_mae: 2.9955 - val_mse: 11.6196\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.5383 - mae: 2.0266 - mse: 6.5383 - val_loss: 14.9139 - val_mae: 3.6992 - val_mse: 14.9139\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.8028 - mae: 1.5750 - mse: 3.8028 - val_loss: 4.9117 - val_mae: 1.8004 - val_mse: 4.9117\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.3955 - mae: 1.4640 - mse: 3.3955 - val_loss: 4.7610 - val_mae: 1.7529 - val_mse: 4.7610\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6460 - mae: 1.2975 - mse: 2.6460 - val_loss: 3.2585 - val_mae: 1.5471 - val_mse: 3.2585\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3907 - mae: 1.2392 - mse: 2.3907 - val_loss: 1.2384 - val_mae: 0.8424 - val_mse: 1.2384\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3903 - mae: 1.2037 - mse: 2.3903 - val_loss: 1.1604 - val_mae: 0.8479 - val_mse: 1.1604\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2755 - mae: 1.1875 - mse: 2.2755 - val_loss: 1.5742 - val_mae: 0.9958 - val_mse: 1.5742\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8915 - mae: 1.0780 - mse: 1.8915 - val_loss: 2.3918 - val_mae: 1.2805 - val_mse: 2.3918\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1068 - mae: 1.1392 - mse: 2.1068 - val_loss: 2.3676 - val_mae: 1.2746 - val_mse: 2.3676\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7737 - mae: 1.0527 - mse: 1.7737 - val_loss: 1.1288 - val_mae: 0.8144 - val_mse: 1.1288\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7279 - mae: 1.0231 - mse: 1.7279 - val_loss: 2.3236 - val_mae: 1.2264 - val_mse: 2.3236\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6025 - mae: 0.9934 - mse: 1.6025 - val_loss: 1.9885 - val_mae: 1.1377 - val_mse: 1.9885\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6058 - mae: 1.0068 - mse: 1.6058 - val_loss: 1.5485 - val_mae: 0.9865 - val_mse: 1.5485\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7692 - mae: 1.0373 - mse: 1.7692 - val_loss: 1.0774 - val_mae: 0.8026 - val_mse: 1.0774\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5918 - mae: 0.9868 - mse: 1.5918 - val_loss: 1.0500 - val_mae: 0.8061 - val_mse: 1.0500\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6995 - mae: 1.0228 - mse: 1.6995 - val_loss: 1.6300 - val_mae: 1.0118 - val_mse: 1.6300\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6417 - mae: 0.9934 - mse: 1.6417 - val_loss: 1.2047 - val_mae: 0.8416 - val_mse: 1.2047\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4671 - mae: 0.9398 - mse: 1.4671 - val_loss: 1.7260 - val_mae: 1.0210 - val_mse: 1.7260\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5262 - mae: 0.9687 - mse: 1.5262 - val_loss: 2.8859 - val_mae: 1.4377 - val_mse: 2.8859\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5998 - mae: 0.9866 - mse: 1.5998 - val_loss: 1.0783 - val_mae: 0.8222 - val_mse: 1.0783\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4418 - mae: 0.9424 - mse: 1.4418 - val_loss: 2.9584 - val_mae: 1.4582 - val_mse: 2.9584\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5020 - mae: 0.9505 - mse: 1.5020 - val_loss: 1.0006 - val_mae: 0.7811 - val_mse: 1.0006\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4562 - mae: 0.9177 - mse: 1.4562 - val_loss: 2.8328 - val_mae: 1.3868 - val_mse: 2.8328\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5191 - mae: 0.9601 - mse: 1.5191 - val_loss: 3.3321 - val_mae: 1.5810 - val_mse: 3.3321\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4928 - mae: 0.9594 - mse: 1.4928 - val_loss: 1.1620 - val_mae: 0.8208 - val_mse: 1.1620\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3313 - mae: 0.8859 - mse: 1.3313 - val_loss: 3.0807 - val_mae: 1.4906 - val_mse: 3.0807\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4565 - mae: 0.9433 - mse: 1.4565 - val_loss: 1.6353 - val_mae: 0.9928 - val_mse: 1.6353\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3394 - mae: 0.9088 - mse: 1.3394 - val_loss: 1.6422 - val_mae: 1.0121 - val_mse: 1.6422\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4560 - mae: 0.9495 - mse: 1.4560 - val_loss: 1.1347 - val_mae: 0.8103 - val_mse: 1.1347\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4095 - mae: 0.9267 - mse: 1.4095 - val_loss: 1.1259 - val_mae: 0.8442 - val_mse: 1.1259\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3537 - mae: 0.9091 - mse: 1.3537 - val_loss: 0.9996 - val_mae: 0.7674 - val_mse: 0.9996\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3123 - mae: 0.8953 - mse: 1.3123 - val_loss: 1.2193 - val_mae: 0.8464 - val_mse: 1.2193\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3582 - mae: 0.9042 - mse: 1.3582 - val_loss: 1.5898 - val_mae: 0.9891 - val_mse: 1.5898\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3357 - mae: 0.9033 - mse: 1.3357 - val_loss: 0.9663 - val_mae: 0.7649 - val_mse: 0.9663\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3393 - mae: 0.8882 - mse: 1.3393 - val_loss: 0.9618 - val_mae: 0.7645 - val_mse: 0.9618\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3816 - mae: 0.9181 - mse: 1.3816 - val_loss: 1.0170 - val_mae: 0.7970 - val_mse: 1.0170\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3013 - mae: 0.8921 - mse: 1.3013 - val_loss: 1.0278 - val_mae: 0.7837 - val_mse: 1.0278\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2970 - mae: 0.8811 - mse: 1.2970 - val_loss: 0.9605 - val_mae: 0.7618 - val_mse: 0.9605\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3248 - mae: 0.8973 - mse: 1.3248 - val_loss: 2.0924 - val_mae: 1.1771 - val_mse: 2.0924\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3066 - mae: 0.8904 - mse: 1.3066 - val_loss: 1.3930 - val_mae: 0.9454 - val_mse: 1.3930\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3118 - mae: 0.8971 - mse: 1.3118 - val_loss: 0.9475 - val_mae: 0.7532 - val_mse: 0.9475\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2355 - mae: 0.8636 - mse: 1.2355 - val_loss: 1.6740 - val_mae: 1.0476 - val_mse: 1.6740\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2368 - mae: 0.8663 - mse: 1.2368 - val_loss: 0.9824 - val_mae: 0.7576 - val_mse: 0.9824\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2968 - mae: 0.8866 - mse: 1.2968 - val_loss: 1.1829 - val_mae: 0.8640 - val_mse: 1.1829\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1524 - mae: 0.8295 - mse: 1.1524 - val_loss: 1.4358 - val_mae: 0.9594 - val_mse: 1.4358\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2296 - mae: 0.8688 - mse: 1.2296 - val_loss: 1.0347 - val_mae: 0.7757 - val_mse: 1.0347\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2329 - mae: 0.8629 - mse: 1.2329 - val_loss: 0.9490 - val_mae: 0.7621 - val_mse: 0.9490\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1704 - mae: 0.8279 - mse: 1.1704 - val_loss: 1.2655 - val_mae: 0.8708 - val_mse: 1.2655\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2618 - mae: 0.8722 - mse: 1.2618 - val_loss: 1.0075 - val_mae: 0.7945 - val_mse: 1.0075\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2124 - mae: 0.8561 - mse: 1.2124 - val_loss: 1.5623 - val_mae: 1.0063 - val_mse: 1.5623\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2264 - mae: 0.8520 - mse: 1.2264 - val_loss: 1.7987 - val_mae: 1.0760 - val_mse: 1.7987\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1947 - mae: 0.8523 - mse: 1.1947 - val_loss: 0.9263 - val_mae: 0.7474 - val_mse: 0.9263\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1793 - mae: 0.8341 - mse: 1.1793 - val_loss: 2.2199 - val_mae: 1.2223 - val_mse: 2.2199\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1808 - mae: 0.8392 - mse: 1.1808 - val_loss: 1.0030 - val_mae: 0.7905 - val_mse: 1.0030\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1549 - mae: 0.8417 - mse: 1.1549 - val_loss: 0.9927 - val_mae: 0.7581 - val_mse: 0.9927\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2173 - mae: 0.8546 - mse: 1.2173 - val_loss: 1.0229 - val_mae: 0.7656 - val_mse: 1.0229\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1382 - mae: 0.8253 - mse: 1.1382 - val_loss: 1.0841 - val_mae: 0.7941 - val_mse: 1.0841\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1028 - mae: 0.8154 - mse: 1.1028 - val_loss: 0.9168 - val_mae: 0.7391 - val_mse: 0.9168\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1610 - mae: 0.8492 - mse: 1.1610 - val_loss: 0.9855 - val_mae: 0.7525 - val_mse: 0.9855\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1653 - mae: 0.8393 - mse: 1.1653 - val_loss: 0.9277 - val_mae: 0.7498 - val_mse: 0.9277\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1069 - mae: 0.8180 - mse: 1.1069 - val_loss: 1.3569 - val_mae: 0.9348 - val_mse: 1.3569\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1067 - mae: 0.8162 - mse: 1.1067 - val_loss: 1.0208 - val_mae: 0.7637 - val_mse: 1.0208\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1486 - mae: 0.8304 - mse: 1.1486 - val_loss: 1.3684 - val_mae: 0.9016 - val_mse: 1.3684\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1461 - mae: 0.8307 - mse: 1.1461 - val_loss: 2.0096 - val_mae: 1.1461 - val_mse: 2.0096\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0959 - mae: 0.8178 - mse: 1.0959 - val_loss: 0.9093 - val_mae: 0.7370 - val_mse: 0.9093\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0984 - mae: 0.8134 - mse: 1.0984 - val_loss: 0.9785 - val_mae: 0.7517 - val_mse: 0.9785\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0781 - mae: 0.8229 - mse: 1.0781 - val_loss: 0.9314 - val_mae: 0.7531 - val_mse: 0.9314\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1343 - mae: 0.8217 - mse: 1.1343 - val_loss: 0.8989 - val_mae: 0.7229 - val_mse: 0.8989\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1077 - mae: 0.8208 - mse: 1.1077 - val_loss: 0.9789 - val_mae: 0.7502 - val_mse: 0.9789\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0932 - mae: 0.8120 - mse: 1.0932 - val_loss: 2.3324 - val_mae: 1.2653 - val_mse: 2.3324\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0460 - mae: 0.7788 - mse: 1.0460 - val_loss: 1.1480 - val_mae: 0.8138 - val_mse: 1.1480\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1154 - mae: 0.8258 - mse: 1.1154 - val_loss: 1.3140 - val_mae: 0.9236 - val_mse: 1.3140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0135 - mae: 0.7779 - mse: 1.0135 - val_loss: 0.9955 - val_mae: 0.7951 - val_mse: 0.9955\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1218 - mae: 0.8182 - mse: 1.1218 - val_loss: 1.4211 - val_mae: 0.9671 - val_mse: 1.4211\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0519 - mae: 0.7949 - mse: 1.0519 - val_loss: 0.8981 - val_mae: 0.7356 - val_mse: 0.8981\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1245 - mae: 0.8073 - mse: 1.1245 - val_loss: 0.8882 - val_mae: 0.7198 - val_mse: 0.8882\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0454 - mae: 0.7896 - mse: 1.0454 - val_loss: 1.0190 - val_mae: 0.7695 - val_mse: 1.0190\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0552 - mae: 0.7917 - mse: 1.0552 - val_loss: 0.9221 - val_mae: 0.7251 - val_mse: 0.9221\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0788 - mae: 0.8089 - mse: 1.0788 - val_loss: 0.8969 - val_mae: 0.7388 - val_mse: 0.8969\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0602 - mae: 0.7896 - mse: 1.0602 - val_loss: 0.8794 - val_mae: 0.7232 - val_mse: 0.8794\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0415 - mae: 0.7917 - mse: 1.0415 - val_loss: 1.6567 - val_mae: 1.0649 - val_mse: 1.6567\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0778 - mae: 0.7959 - mse: 1.0778 - val_loss: 0.8852 - val_mae: 0.7106 - val_mse: 0.8852\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0031 - mae: 0.7822 - mse: 1.0031 - val_loss: 0.9413 - val_mae: 0.7333 - val_mse: 0.9413\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0176 - mae: 0.7881 - mse: 1.0176 - val_loss: 1.0800 - val_mae: 0.7953 - val_mse: 1.0800\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0111 - mae: 0.7771 - mse: 1.0111 - val_loss: 0.9230 - val_mae: 0.7522 - val_mse: 0.9230\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0546 - mae: 0.7880 - mse: 1.0546 - val_loss: 1.9779 - val_mae: 1.1467 - val_mse: 1.9779\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0289 - mae: 0.7831 - mse: 1.0289 - val_loss: 1.4526 - val_mae: 0.9862 - val_mse: 1.4526\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9922 - mae: 0.7733 - mse: 0.9922 - val_loss: 2.0811 - val_mae: 1.1702 - val_mse: 2.0811\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0104 - mae: 0.7675 - mse: 1.0104 - val_loss: 0.8967 - val_mae: 0.7397 - val_mse: 0.8967\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9857 - mae: 0.7672 - mse: 0.9857 - val_loss: 1.8612 - val_mae: 1.0991 - val_mse: 1.8612\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0035 - mae: 0.7647 - mse: 1.0035 - val_loss: 1.2436 - val_mae: 0.8649 - val_mse: 1.2436\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0163 - mae: 0.7665 - mse: 1.0163 - val_loss: 1.1990 - val_mae: 0.8594 - val_mse: 1.1990\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9979 - mae: 0.7665 - mse: 0.9979 - val_loss: 1.6596 - val_mae: 1.0510 - val_mse: 1.6596\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9798 - mae: 0.7652 - mse: 0.9798 - val_loss: 0.8870 - val_mae: 0.7218 - val_mse: 0.8870\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9577 - mae: 0.7607 - mse: 0.9577 - val_loss: 0.8881 - val_mae: 0.7296 - val_mse: 0.8881\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9755 - mae: 0.7551 - mse: 0.9755 - val_loss: 1.1407 - val_mae: 0.8545 - val_mse: 1.1407\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0267 - mae: 0.7655 - mse: 1.0267 - val_loss: 0.8951 - val_mae: 0.7144 - val_mse: 0.8951\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9754 - mae: 0.7640 - mse: 0.9754 - val_loss: 1.3546 - val_mae: 0.9476 - val_mse: 1.3546\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0099 - mae: 0.7700 - mse: 1.0099 - val_loss: 0.8675 - val_mae: 0.7078 - val_mse: 0.8675\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0013 - mae: 0.7742 - mse: 1.0013 - val_loss: 0.9214 - val_mae: 0.7172 - val_mse: 0.9214\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9587 - mae: 0.7485 - mse: 0.9587 - val_loss: 1.7419 - val_mae: 1.0564 - val_mse: 1.7419\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0066 - mae: 0.7763 - mse: 1.0066 - val_loss: 0.8703 - val_mae: 0.7389 - val_mse: 0.8703\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9638 - mae: 0.7561 - mse: 0.9638 - val_loss: 0.8575 - val_mae: 0.7199 - val_mse: 0.8575\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9549 - mae: 0.7441 - mse: 0.9549 - val_loss: 1.2468 - val_mae: 0.9036 - val_mse: 1.2468\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9595 - mae: 0.7577 - mse: 0.9595 - val_loss: 0.8570 - val_mae: 0.7056 - val_mse: 0.8570\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9206 - mae: 0.7372 - mse: 0.9206 - val_loss: 1.8027 - val_mae: 1.0877 - val_mse: 1.8027\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9502 - mae: 0.7441 - mse: 0.9502 - val_loss: 0.9199 - val_mae: 0.7228 - val_mse: 0.9199\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9372 - mae: 0.7475 - mse: 0.9372 - val_loss: 1.5817 - val_mae: 0.9956 - val_mse: 1.5817\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9638 - mae: 0.7538 - mse: 0.9638 - val_loss: 1.1790 - val_mae: 0.8338 - val_mse: 1.1790\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9428 - mae: 0.7488 - mse: 0.9428 - val_loss: 2.0595 - val_mae: 1.2077 - val_mse: 2.0595\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9512 - mae: 0.7527 - mse: 0.9512 - val_loss: 1.8651 - val_mae: 1.1200 - val_mse: 1.8651\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9524 - mae: 0.7483 - mse: 0.9524 - val_loss: 0.9027 - val_mae: 0.7407 - val_mse: 0.9027\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9128 - mae: 0.7364 - mse: 0.9128 - val_loss: 1.0140 - val_mae: 0.8053 - val_mse: 1.0140\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9239 - mae: 0.7404 - mse: 0.9239 - val_loss: 0.9004 - val_mae: 0.7174 - val_mse: 0.9004\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8962 - mae: 0.7205 - mse: 0.8962 - val_loss: 1.6961 - val_mae: 1.0501 - val_mse: 1.6961\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9556 - mae: 0.7512 - mse: 0.9556 - val_loss: 0.9165 - val_mae: 0.7518 - val_mse: 0.9165\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9166 - mae: 0.7446 - mse: 0.9166 - val_loss: 0.9959 - val_mae: 0.7527 - val_mse: 0.9959\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9495 - mae: 0.7404 - mse: 0.9495 - val_loss: 0.8796 - val_mae: 0.7439 - val_mse: 0.8796\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9193 - mae: 0.7295 - mse: 0.9193 - val_loss: 1.0574 - val_mae: 0.8239 - val_mse: 1.0574\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9071 - mae: 0.7352 - mse: 0.9071 - val_loss: 0.9051 - val_mae: 0.7176 - val_mse: 0.9051\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9286 - mae: 0.7397 - mse: 0.9286 - val_loss: 0.8673 - val_mae: 0.7407 - val_mse: 0.8673\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8841 - mae: 0.7311 - mse: 0.8841 - val_loss: 0.9795 - val_mae: 0.7893 - val_mse: 0.9795\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8586 - mae: 0.7134 - mse: 0.8586 - val_loss: 0.8518 - val_mae: 0.7258 - val_mse: 0.8518\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8600 - mae: 0.7128 - mse: 0.8600 - val_loss: 1.0926 - val_mae: 0.8081 - val_mse: 1.0926\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9309 - mae: 0.7423 - mse: 0.9309 - val_loss: 0.8268 - val_mae: 0.6936 - val_mse: 0.8268\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8706 - mae: 0.7126 - mse: 0.8706 - val_loss: 1.1959 - val_mae: 0.8566 - val_mse: 1.1959\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8960 - mae: 0.7246 - mse: 0.8960 - val_loss: 0.9254 - val_mae: 0.7251 - val_mse: 0.9254\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8936 - mae: 0.7249 - mse: 0.8936 - val_loss: 0.9479 - val_mae: 0.7663 - val_mse: 0.9479\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8501 - mae: 0.7161 - mse: 0.8501 - val_loss: 1.2861 - val_mae: 0.9315 - val_mse: 1.2861\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8914 - mae: 0.7202 - mse: 0.8914 - val_loss: 0.9370 - val_mae: 0.7343 - val_mse: 0.9370\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8407 - mae: 0.6997 - mse: 0.8407 - val_loss: 1.4257 - val_mae: 0.9127 - val_mse: 1.4257\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8949 - mae: 0.7127 - mse: 0.8949 - val_loss: 1.3426 - val_mae: 0.9346 - val_mse: 1.3426\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8858 - mae: 0.7304 - mse: 0.8858 - val_loss: 0.9074 - val_mae: 0.7545 - val_mse: 0.9074\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8558 - mae: 0.6989 - mse: 0.8558 - val_loss: 1.8749 - val_mae: 1.1257 - val_mse: 1.8749\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8940 - mae: 0.7237 - mse: 0.8940 - val_loss: 0.8351 - val_mae: 0.7186 - val_mse: 0.8351\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8152 - mae: 0.6824 - mse: 0.8152 - val_loss: 0.9122 - val_mae: 0.7641 - val_mse: 0.9122\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8224 - mae: 0.6928 - mse: 0.8224 - val_loss: 0.9407 - val_mae: 0.7710 - val_mse: 0.9407\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8616 - mae: 0.7054 - mse: 0.8616 - val_loss: 1.1394 - val_mae: 0.8563 - val_mse: 1.1394\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8297 - mae: 0.6900 - mse: 0.8297 - val_loss: 0.8485 - val_mae: 0.6970 - val_mse: 0.8485\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8466 - mae: 0.7084 - mse: 0.8466 - val_loss: 1.0348 - val_mae: 0.7912 - val_mse: 1.0348\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8162 - mae: 0.6990 - mse: 0.8162 - val_loss: 0.9198 - val_mae: 0.7619 - val_mse: 0.9198\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7742 - mae: 0.6750 - mse: 0.7742 - val_loss: 1.4803 - val_mae: 0.9893 - val_mse: 1.4803\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8201 - mae: 0.6942 - mse: 0.8201 - val_loss: 1.0905 - val_mae: 0.8074 - val_mse: 1.0905\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8237 - mae: 0.6889 - mse: 0.8237 - val_loss: 1.3136 - val_mae: 0.8921 - val_mse: 1.3136\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8129 - mae: 0.6769 - mse: 0.8129 - val_loss: 0.8613 - val_mae: 0.7232 - val_mse: 0.8613\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8364 - mae: 0.6941 - mse: 0.8364 - val_loss: 1.6430 - val_mae: 1.0299 - val_mse: 1.6430\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8126 - mae: 0.6920 - mse: 0.8126 - val_loss: 0.8664 - val_mae: 0.7259 - val_mse: 0.8664\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8024 - mae: 0.6804 - mse: 0.8024 - val_loss: 0.8553 - val_mae: 0.7223 - val_mse: 0.8553\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8069 - mae: 0.6736 - mse: 0.8069 - val_loss: 2.0501 - val_mae: 1.1917 - val_mse: 2.0501\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8428 - mae: 0.7019 - mse: 0.8428 - val_loss: 0.9666 - val_mae: 0.7722 - val_mse: 0.9666\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8283 - mae: 0.6914 - mse: 0.8283 - val_loss: 1.0481 - val_mae: 0.7935 - val_mse: 1.0481\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7773 - mae: 0.6748 - mse: 0.7773 - val_loss: 1.0058 - val_mae: 0.7679 - val_mse: 1.0058\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7894 - mae: 0.6765 - mse: 0.7894 - val_loss: 1.0213 - val_mae: 0.7780 - val_mse: 1.0213\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8313 - mae: 0.6896 - mse: 0.8313 - val_loss: 0.9927 - val_mae: 0.7834 - val_mse: 0.9927\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8333 - mae: 0.6979 - mse: 0.8333 - val_loss: 0.8541 - val_mae: 0.7079 - val_mse: 0.8541\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7664 - mae: 0.6704 - mse: 0.7664 - val_loss: 0.9706 - val_mae: 0.7838 - val_mse: 0.9706\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7607 - mae: 0.6686 - mse: 0.7607 - val_loss: 0.9980 - val_mae: 0.7817 - val_mse: 0.9980\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7829 - mae: 0.6709 - mse: 0.7829 - val_loss: 0.9261 - val_mae: 0.7526 - val_mse: 0.9261\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7607 - mae: 0.6635 - mse: 0.7607 - val_loss: 0.8709 - val_mae: 0.7238 - val_mse: 0.8709\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7926 - mae: 0.6817 - mse: 0.7926 - val_loss: 1.2995 - val_mae: 0.9034 - val_mse: 1.2995\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7618 - mae: 0.6629 - mse: 0.7618 - val_loss: 1.3010 - val_mae: 0.9180 - val_mse: 1.3010\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7876 - mae: 0.6714 - mse: 0.7876 - val_loss: 0.8371 - val_mae: 0.7062 - val_mse: 0.8371\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7961 - mae: 0.6810 - mse: 0.7961 - val_loss: 1.0930 - val_mae: 0.8090 - val_mse: 1.0930\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7368 - mae: 0.6474 - mse: 0.7368 - val_loss: 0.8398 - val_mae: 0.7008 - val_mse: 0.8398\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7324 - mae: 0.6485 - mse: 0.7324 - val_loss: 1.1218 - val_mae: 0.8273 - val_mse: 1.1218\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7695 - mae: 0.6640 - mse: 0.7695 - val_loss: 0.9353 - val_mae: 0.7390 - val_mse: 0.9353\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7653 - mae: 0.6664 - mse: 0.7653 - val_loss: 1.1674 - val_mae: 0.8401 - val_mse: 1.1674\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7588 - mae: 0.6659 - mse: 0.7588 - val_loss: 1.0091 - val_mae: 0.7734 - val_mse: 1.0091\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7574 - mae: 0.6647 - mse: 0.7574 - val_loss: 0.9575 - val_mae: 0.7539 - val_mse: 0.9575\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7215 - mae: 0.6450 - mse: 0.7215 - val_loss: 0.9838 - val_mae: 0.7651 - val_mse: 0.9838\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7647 - mae: 0.6673 - mse: 0.7647 - val_loss: 1.0351 - val_mae: 0.8091 - val_mse: 1.0351\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7501 - mae: 0.6607 - mse: 0.7501 - val_loss: 0.8377 - val_mae: 0.7101 - val_mse: 0.8377\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7133 - mae: 0.6364 - mse: 0.7133 - val_loss: 1.0022 - val_mae: 0.7698 - val_mse: 1.0022\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7331 - mae: 0.6568 - mse: 0.7331 - val_loss: 1.2451 - val_mae: 0.8719 - val_mse: 1.2451\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7424 - mae: 0.6497 - mse: 0.7424 - val_loss: 0.9038 - val_mae: 0.7282 - val_mse: 0.9038\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7369 - mae: 0.6465 - mse: 0.7369 - val_loss: 0.8797 - val_mae: 0.7252 - val_mse: 0.8797\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7262 - mae: 0.6357 - mse: 0.7262 - val_loss: 0.8999 - val_mae: 0.7243 - val_mse: 0.8999\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6874 - mae: 0.6337 - mse: 0.6874 - val_loss: 1.3934 - val_mae: 0.9249 - val_mse: 1.3934\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7397 - mae: 0.6477 - mse: 0.7397 - val_loss: 1.0009 - val_mae: 0.7720 - val_mse: 1.0009\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7197 - mae: 0.6488 - mse: 0.7197 - val_loss: 1.0008 - val_mae: 0.7919 - val_mse: 1.0008\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6895 - mae: 0.6275 - mse: 0.6895 - val_loss: 1.0209 - val_mae: 0.7840 - val_mse: 1.0209\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7461 - mae: 0.6419 - mse: 0.7461 - val_loss: 1.1768 - val_mae: 0.8356 - val_mse: 1.1768\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7482 - mae: 0.6556 - mse: 0.7482 - val_loss: 0.8646 - val_mae: 0.7223 - val_mse: 0.8646\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7110 - mae: 0.6349 - mse: 0.7110 - val_loss: 1.2077 - val_mae: 0.8898 - val_mse: 1.2077\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6757 - mae: 0.6158 - mse: 0.6757 - val_loss: 0.9278 - val_mae: 0.7701 - val_mse: 0.9278\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6884 - mae: 0.6256 - mse: 0.6884 - val_loss: 0.9547 - val_mae: 0.7555 - val_mse: 0.9547\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6736 - mae: 0.6193 - mse: 0.6736 - val_loss: 1.3081 - val_mae: 0.9197 - val_mse: 1.3081\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7012 - mae: 0.6305 - mse: 0.7012 - val_loss: 1.2886 - val_mae: 0.8916 - val_mse: 1.2886\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6869 - mae: 0.6290 - mse: 0.6869 - val_loss: 1.7659 - val_mae: 1.0667 - val_mse: 1.7659\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6800 - mae: 0.6159 - mse: 0.6800 - val_loss: 1.0117 - val_mae: 0.7851 - val_mse: 1.0117\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6841 - mae: 0.6232 - mse: 0.6841 - val_loss: 0.8798 - val_mae: 0.7288 - val_mse: 0.8798\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6825 - mae: 0.6169 - mse: 0.6825 - val_loss: 0.9495 - val_mae: 0.7715 - val_mse: 0.9495\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6938 - mae: 0.6240 - mse: 0.6938 - val_loss: 0.8649 - val_mae: 0.7171 - val_mse: 0.8649\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6428 - mae: 0.5982 - mse: 0.6428 - val_loss: 1.0553 - val_mae: 0.8072 - val_mse: 1.0553\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6825 - mae: 0.6142 - mse: 0.6825 - val_loss: 0.9113 - val_mae: 0.7458 - val_mse: 0.9113\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6891 - mae: 0.6267 - mse: 0.6891 - val_loss: 0.8825 - val_mae: 0.7227 - val_mse: 0.8825\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6394 - mae: 0.6040 - mse: 0.6394 - val_loss: 1.0482 - val_mae: 0.7938 - val_mse: 1.0482\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6838 - mae: 0.6281 - mse: 0.6838 - val_loss: 1.5113 - val_mae: 0.9851 - val_mse: 1.5113\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6651 - mae: 0.6085 - mse: 0.6651 - val_loss: 1.1672 - val_mae: 0.8301 - val_mse: 1.1672\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6598 - mae: 0.6153 - mse: 0.6598 - val_loss: 1.0464 - val_mae: 0.8109 - val_mse: 1.0464\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6846 - mae: 0.6294 - mse: 0.6846 - val_loss: 0.8833 - val_mae: 0.7342 - val_mse: 0.8833\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5983 - mae: 0.5767 - mse: 0.5983 - val_loss: 1.2667 - val_mae: 0.8892 - val_mse: 1.2667\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6794 - mae: 0.6262 - mse: 0.6794 - val_loss: 0.9152 - val_mae: 0.7307 - val_mse: 0.9152\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6826 - mae: 0.6209 - mse: 0.6826 - val_loss: 0.9461 - val_mae: 0.7613 - val_mse: 0.9461\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6684 - mae: 0.6190 - mse: 0.6684 - val_loss: 1.0519 - val_mae: 0.8156 - val_mse: 1.0519\n",
      "Epoch 210/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6041 - mae: 0.5897 - mse: 0.6041 - val_loss: 1.7594 - val_mae: 1.0481 - val_mse: 1.7594\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6381 - mae: 0.6043 - mse: 0.6381 - val_loss: 1.0642 - val_mae: 0.8078 - val_mse: 1.0642\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6256 - mae: 0.5979 - mse: 0.6256 - val_loss: 0.9612 - val_mae: 0.7701 - val_mse: 0.9612\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6312 - mae: 0.6005 - mse: 0.6312 - val_loss: 0.9124 - val_mae: 0.7355 - val_mse: 0.9124\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6283 - mae: 0.6002 - mse: 0.6283 - val_loss: 0.8804 - val_mae: 0.7360 - val_mse: 0.8804\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6169 - mae: 0.5826 - mse: 0.6169 - val_loss: 1.3050 - val_mae: 0.8877 - val_mse: 1.3050\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6745 - mae: 0.6193 - mse: 0.6745 - val_loss: 1.0028 - val_mae: 0.7943 - val_mse: 1.0028\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6660 - mae: 0.6227 - mse: 0.6660 - val_loss: 1.1306 - val_mae: 0.8271 - val_mse: 1.1306\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6025 - mae: 0.5825 - mse: 0.6025 - val_loss: 1.6196 - val_mae: 1.0055 - val_mse: 1.6196\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6208 - mae: 0.5971 - mse: 0.6208 - val_loss: 0.9409 - val_mae: 0.7455 - val_mse: 0.9409\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6025 - mae: 0.5868 - mse: 0.6025 - val_loss: 1.0588 - val_mae: 0.7901 - val_mse: 1.0588\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6224 - mae: 0.5921 - mse: 0.6224 - val_loss: 1.0948 - val_mae: 0.8102 - val_mse: 1.0948\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5874 - mae: 0.5733 - mse: 0.5874 - val_loss: 1.0338 - val_mae: 0.7872 - val_mse: 1.0338\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6303 - mae: 0.5977 - mse: 0.6303 - val_loss: 0.9627 - val_mae: 0.7702 - val_mse: 0.9627\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5883 - mae: 0.5778 - mse: 0.5883 - val_loss: 0.8829 - val_mae: 0.7377 - val_mse: 0.8829\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5915 - mae: 0.5797 - mse: 0.5915 - val_loss: 0.9491 - val_mae: 0.7530 - val_mse: 0.9491\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5754 - mae: 0.5677 - mse: 0.5754 - val_loss: 1.4920 - val_mae: 0.9957 - val_mse: 1.4920\n",
      "Epoch 227/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6109 - mae: 0.5837 - mse: 0.6109 - val_loss: 0.8899 - val_mae: 0.7271 - val_mse: 0.8899\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5988 - mae: 0.5774 - mse: 0.5988 - val_loss: 0.9876 - val_mae: 0.7733 - val_mse: 0.9876\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5939 - mae: 0.5799 - mse: 0.5939 - val_loss: 1.1456 - val_mae: 0.8417 - val_mse: 1.1456\n",
      "Kappa Score: 0.7112743498805527\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 67.4092 - mae: 4.9177 - mse: 67.4092 - val_loss: 104.0620 - val_mae: 9.4384 - val_mse: 104.0620\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 20.9028 - mae: 3.1992 - mse: 20.9028 - val_loss: 2.9286 - val_mae: 1.4904 - val_mse: 2.9286\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 10.8346 - mae: 2.6314 - mse: 10.8346 - val_loss: 3.0318 - val_mae: 1.3154 - val_mse: 3.0318\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.9113 - mae: 1.6690 - mse: 4.9113 - val_loss: 1.1613 - val_mae: 0.8357 - val_mse: 1.1613\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.1168 - mae: 1.6208 - mse: 4.1168 - val_loss: 1.5684 - val_mae: 0.9969 - val_mse: 1.5684\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5269 - mae: 1.2275 - mse: 2.5269 - val_loss: 1.6236 - val_mae: 0.9469 - val_mse: 1.6236\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7209 - mae: 1.2915 - mse: 2.7209 - val_loss: 1.5922 - val_mae: 1.0029 - val_mse: 1.5922\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1681 - mae: 1.1541 - mse: 2.1681 - val_loss: 1.2546 - val_mae: 0.8774 - val_mse: 1.2546\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9710 - mae: 1.0966 - mse: 1.9710 - val_loss: 3.1049 - val_mae: 1.3253 - val_mse: 3.1049\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0205 - mae: 1.1178 - mse: 2.0205 - val_loss: 1.1134 - val_mae: 0.8307 - val_mse: 1.1134\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.7422 - mae: 1.0404 - mse: 1.7422 - val_loss: 4.6320 - val_mae: 1.9458 - val_mse: 4.6320\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7618 - mae: 1.0607 - mse: 1.7618 - val_loss: 0.9655 - val_mae: 0.7759 - val_mse: 0.9655\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7697 - mae: 1.0471 - mse: 1.7697 - val_loss: 2.0923 - val_mae: 1.1947 - val_mse: 2.0923\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5559 - mae: 0.9762 - mse: 1.5559 - val_loss: 1.3507 - val_mae: 0.9409 - val_mse: 1.3507\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6089 - mae: 0.9917 - mse: 1.6089 - val_loss: 1.3129 - val_mae: 0.8925 - val_mse: 1.3129\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5903 - mae: 0.9823 - mse: 1.5903 - val_loss: 1.0062 - val_mae: 0.7927 - val_mse: 1.0062\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4849 - mae: 0.9525 - mse: 1.4849 - val_loss: 1.0973 - val_mae: 0.8246 - val_mse: 1.0973\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4245 - mae: 0.9360 - mse: 1.4245 - val_loss: 1.7434 - val_mae: 1.0664 - val_mse: 1.7434\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5622 - mae: 0.9727 - mse: 1.5622 - val_loss: 0.9772 - val_mae: 0.7943 - val_mse: 0.9772\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3360 - mae: 0.9017 - mse: 1.3360 - val_loss: 2.1095 - val_mae: 1.1686 - val_mse: 2.1095\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4019 - mae: 0.9198 - mse: 1.4019 - val_loss: 2.6368 - val_mae: 1.3755 - val_mse: 2.6368\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4070 - mae: 0.9387 - mse: 1.4070 - val_loss: 1.5415 - val_mae: 1.0140 - val_mse: 1.5415\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3878 - mae: 0.9187 - mse: 1.3878 - val_loss: 1.4821 - val_mae: 0.9943 - val_mse: 1.4821\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3379 - mae: 0.8928 - mse: 1.3379 - val_loss: 1.2886 - val_mae: 0.8631 - val_mse: 1.2886\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3849 - mae: 0.9147 - mse: 1.3849 - val_loss: 0.9595 - val_mae: 0.7859 - val_mse: 0.9595\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4104 - mae: 0.9372 - mse: 1.4104 - val_loss: 2.0000 - val_mae: 1.1380 - val_mse: 2.0000\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3375 - mae: 0.8977 - mse: 1.3375 - val_loss: 0.9321 - val_mae: 0.7620 - val_mse: 0.9321\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2929 - mae: 0.8847 - mse: 1.2929 - val_loss: 0.9381 - val_mae: 0.7779 - val_mse: 0.9381\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2512 - mae: 0.8832 - mse: 1.2512 - val_loss: 2.0183 - val_mae: 1.1259 - val_mse: 2.0183\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2806 - mae: 0.8878 - mse: 1.2806 - val_loss: 1.0209 - val_mae: 0.8023 - val_mse: 1.0209\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2036 - mae: 0.8579 - mse: 1.2036 - val_loss: 1.1785 - val_mae: 0.8661 - val_mse: 1.1785\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2989 - mae: 0.8857 - mse: 1.2989 - val_loss: 1.3572 - val_mae: 0.9149 - val_mse: 1.3572\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2136 - mae: 0.8573 - mse: 1.2136 - val_loss: 1.3221 - val_mae: 0.8899 - val_mse: 1.3221\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2642 - mae: 0.8952 - mse: 1.2642 - val_loss: 0.9986 - val_mae: 0.8028 - val_mse: 0.9986\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2162 - mae: 0.8618 - mse: 1.2162 - val_loss: 1.2323 - val_mae: 0.8577 - val_mse: 1.2323\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2091 - mae: 0.8418 - mse: 1.2091 - val_loss: 1.0777 - val_mae: 0.8334 - val_mse: 1.0777\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1965 - mae: 0.8628 - mse: 1.1965 - val_loss: 0.9443 - val_mae: 0.7754 - val_mse: 0.9443\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2821 - mae: 0.8799 - mse: 1.2821 - val_loss: 1.9305 - val_mae: 1.1085 - val_mse: 1.9305\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2093 - mae: 0.8636 - mse: 1.2093 - val_loss: 0.9018 - val_mae: 0.7406 - val_mse: 0.9018\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1851 - mae: 0.8455 - mse: 1.1851 - val_loss: 1.0942 - val_mae: 0.8078 - val_mse: 1.0942\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1937 - mae: 0.8513 - mse: 1.1937 - val_loss: 1.7490 - val_mae: 1.0622 - val_mse: 1.7490\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1734 - mae: 0.8387 - mse: 1.1734 - val_loss: 1.6313 - val_mae: 0.9924 - val_mse: 1.6313\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1410 - mae: 0.8297 - mse: 1.1410 - val_loss: 0.8870 - val_mae: 0.7517 - val_mse: 0.8870\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2165 - mae: 0.8557 - mse: 1.2165 - val_loss: 0.9680 - val_mae: 0.7545 - val_mse: 0.9680\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1081 - mae: 0.8232 - mse: 1.1081 - val_loss: 1.9982 - val_mae: 1.1734 - val_mse: 1.9982\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1296 - mae: 0.8229 - mse: 1.1296 - val_loss: 1.1429 - val_mae: 0.8509 - val_mse: 1.1429\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1355 - mae: 0.8347 - mse: 1.1355 - val_loss: 1.0801 - val_mae: 0.8255 - val_mse: 1.0801\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0960 - mae: 0.8041 - mse: 1.0960 - val_loss: 0.9281 - val_mae: 0.7371 - val_mse: 0.9281\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1044 - mae: 0.8133 - mse: 1.1044 - val_loss: 1.1262 - val_mae: 0.8096 - val_mse: 1.1262\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0836 - mae: 0.8061 - mse: 1.0836 - val_loss: 1.6271 - val_mae: 1.0094 - val_mse: 1.6271\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1367 - mae: 0.8211 - mse: 1.1367 - val_loss: 0.9041 - val_mae: 0.7356 - val_mse: 0.9041\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0953 - mae: 0.8004 - mse: 1.0953 - val_loss: 0.9494 - val_mae: 0.7433 - val_mse: 0.9494\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1069 - mae: 0.8172 - mse: 1.1069 - val_loss: 0.9404 - val_mae: 0.7330 - val_mse: 0.9404\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0681 - mae: 0.7981 - mse: 1.0681 - val_loss: 0.9201 - val_mae: 0.7482 - val_mse: 0.9201\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1242 - mae: 0.8191 - mse: 1.1242 - val_loss: 0.8977 - val_mae: 0.7373 - val_mse: 0.8977\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0300 - mae: 0.7845 - mse: 1.0300 - val_loss: 0.8713 - val_mae: 0.7319 - val_mse: 0.8713\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0874 - mae: 0.8116 - mse: 1.0874 - val_loss: 1.3006 - val_mae: 0.8720 - val_mse: 1.3006\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0641 - mae: 0.7905 - mse: 1.0641 - val_loss: 1.9651 - val_mae: 1.1261 - val_mse: 1.9651\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0865 - mae: 0.8076 - mse: 1.0865 - val_loss: 0.9743 - val_mae: 0.7566 - val_mse: 0.9743\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0755 - mae: 0.8030 - mse: 1.0755 - val_loss: 0.9488 - val_mae: 0.7710 - val_mse: 0.9488\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0435 - mae: 0.7921 - mse: 1.0435 - val_loss: 1.0385 - val_mae: 0.7894 - val_mse: 1.0385\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0213 - mae: 0.7823 - mse: 1.0213 - val_loss: 1.2144 - val_mae: 0.8524 - val_mse: 1.2144\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0327 - mae: 0.7930 - mse: 1.0327 - val_loss: 1.0043 - val_mae: 0.7708 - val_mse: 1.0043\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9920 - mae: 0.7624 - mse: 0.9920 - val_loss: 0.9838 - val_mae: 0.7596 - val_mse: 0.9838\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0383 - mae: 0.7859 - mse: 1.0383 - val_loss: 0.9826 - val_mae: 0.7873 - val_mse: 0.9826\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0135 - mae: 0.7890 - mse: 1.0135 - val_loss: 1.6226 - val_mae: 1.0266 - val_mse: 1.6226\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0354 - mae: 0.7868 - mse: 1.0354 - val_loss: 1.4182 - val_mae: 0.9648 - val_mse: 1.4182\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0444 - mae: 0.7874 - mse: 1.0444 - val_loss: 1.0947 - val_mae: 0.8392 - val_mse: 1.0947\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0107 - mae: 0.7834 - mse: 1.0107 - val_loss: 0.9445 - val_mae: 0.7476 - val_mse: 0.9445\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0329 - mae: 0.7801 - mse: 1.0329 - val_loss: 1.1699 - val_mae: 0.8299 - val_mse: 1.1699\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0017 - mae: 0.7771 - mse: 1.0017 - val_loss: 1.1683 - val_mae: 0.8199 - val_mse: 1.1683\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9964 - mae: 0.7686 - mse: 0.9964 - val_loss: 1.6748 - val_mae: 1.0183 - val_mse: 1.6748\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0058 - mae: 0.7757 - mse: 1.0058 - val_loss: 0.9558 - val_mae: 0.7511 - val_mse: 0.9558\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0169 - mae: 0.7716 - mse: 1.0169 - val_loss: 0.8600 - val_mae: 0.7478 - val_mse: 0.8600\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0162 - mae: 0.7872 - mse: 1.0162 - val_loss: 1.5933 - val_mae: 1.0442 - val_mse: 1.5933\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0107 - mae: 0.7668 - mse: 1.0107 - val_loss: 0.9731 - val_mae: 0.7637 - val_mse: 0.9731\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9903 - mae: 0.7648 - mse: 0.9903 - val_loss: 0.8199 - val_mae: 0.7220 - val_mse: 0.8199\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9223 - mae: 0.7288 - mse: 0.9223 - val_loss: 0.7990 - val_mae: 0.7058 - val_mse: 0.7990\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0119 - mae: 0.7717 - mse: 1.0119 - val_loss: 1.1253 - val_mae: 0.8186 - val_mse: 1.1253\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9831 - mae: 0.7596 - mse: 0.9831 - val_loss: 1.0141 - val_mae: 0.8131 - val_mse: 1.0141\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9641 - mae: 0.7560 - mse: 0.9641 - val_loss: 0.8695 - val_mae: 0.7401 - val_mse: 0.8695\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9308 - mae: 0.7387 - mse: 0.9308 - val_loss: 0.8267 - val_mae: 0.7048 - val_mse: 0.8267\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9435 - mae: 0.7431 - mse: 0.9435 - val_loss: 1.0127 - val_mae: 0.7743 - val_mse: 1.0127\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9476 - mae: 0.7378 - mse: 0.9476 - val_loss: 1.0844 - val_mae: 0.7980 - val_mse: 1.0844\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9711 - mae: 0.7530 - mse: 0.9711 - val_loss: 0.8037 - val_mae: 0.7019 - val_mse: 0.8037\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9204 - mae: 0.7373 - mse: 0.9204 - val_loss: 1.1368 - val_mae: 0.8187 - val_mse: 1.1368\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0077 - mae: 0.7655 - mse: 1.0077 - val_loss: 0.8278 - val_mae: 0.7204 - val_mse: 0.8278\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9508 - mae: 0.7421 - mse: 0.9508 - val_loss: 0.8686 - val_mae: 0.7265 - val_mse: 0.8686\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9275 - mae: 0.7349 - mse: 0.9275 - val_loss: 1.1334 - val_mae: 0.8253 - val_mse: 1.1334\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9013 - mae: 0.7263 - mse: 0.9013 - val_loss: 0.9646 - val_mae: 0.7987 - val_mse: 0.9646\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9528 - mae: 0.7482 - mse: 0.9528 - val_loss: 0.8511 - val_mae: 0.7466 - val_mse: 0.8511\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8778 - mae: 0.7162 - mse: 0.8778 - val_loss: 0.7974 - val_mae: 0.7035 - val_mse: 0.7974\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9041 - mae: 0.7287 - mse: 0.9041 - val_loss: 0.7941 - val_mae: 0.7149 - val_mse: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9038 - mae: 0.7331 - mse: 0.9038 - val_loss: 1.3577 - val_mae: 0.9653 - val_mse: 1.3577\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9157 - mae: 0.7339 - mse: 0.9157 - val_loss: 0.8927 - val_mae: 0.7610 - val_mse: 0.8927\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9001 - mae: 0.7231 - mse: 0.9001 - val_loss: 1.0771 - val_mae: 0.8550 - val_mse: 1.0771\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9228 - mae: 0.7245 - mse: 0.9228 - val_loss: 0.8463 - val_mae: 0.7169 - val_mse: 0.8463\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9119 - mae: 0.7229 - mse: 0.9119 - val_loss: 1.1262 - val_mae: 0.8212 - val_mse: 1.1262\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8569 - mae: 0.7099 - mse: 0.8569 - val_loss: 0.9923 - val_mae: 0.7601 - val_mse: 0.9923\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8550 - mae: 0.7038 - mse: 0.8550 - val_loss: 1.3541 - val_mae: 0.9058 - val_mse: 1.3541\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9195 - mae: 0.7286 - mse: 0.9195 - val_loss: 0.8395 - val_mae: 0.7379 - val_mse: 0.8395\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8926 - mae: 0.7316 - mse: 0.8926 - val_loss: 1.1366 - val_mae: 0.8162 - val_mse: 1.1366\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8608 - mae: 0.7060 - mse: 0.8608 - val_loss: 0.9514 - val_mae: 0.7493 - val_mse: 0.9514\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8523 - mae: 0.7005 - mse: 0.8523 - val_loss: 0.8568 - val_mae: 0.7255 - val_mse: 0.8568\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8671 - mae: 0.7153 - mse: 0.8671 - val_loss: 1.0152 - val_mae: 0.7988 - val_mse: 1.0152\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8528 - mae: 0.7045 - mse: 0.8528 - val_loss: 0.8482 - val_mae: 0.7450 - val_mse: 0.8482\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8493 - mae: 0.7024 - mse: 0.8493 - val_loss: 1.6295 - val_mae: 1.0561 - val_mse: 1.6295\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8984 - mae: 0.7266 - mse: 0.8984 - val_loss: 0.9147 - val_mae: 0.7841 - val_mse: 0.9147\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8435 - mae: 0.7009 - mse: 0.8435 - val_loss: 0.9135 - val_mae: 0.7373 - val_mse: 0.9135\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8308 - mae: 0.6951 - mse: 0.8308 - val_loss: 0.8464 - val_mae: 0.7394 - val_mse: 0.8464\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8915 - mae: 0.7102 - mse: 0.8915 - val_loss: 1.2995 - val_mae: 0.8940 - val_mse: 1.2995\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8701 - mae: 0.7050 - mse: 0.8701 - val_loss: 0.7832 - val_mae: 0.7044 - val_mse: 0.7832\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7854 - mae: 0.6780 - mse: 0.7854 - val_loss: 0.9409 - val_mae: 0.7952 - val_mse: 0.9409\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8617 - mae: 0.7018 - mse: 0.8617 - val_loss: 0.8608 - val_mae: 0.7186 - val_mse: 0.8608\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8380 - mae: 0.7007 - mse: 0.8380 - val_loss: 0.9803 - val_mae: 0.7974 - val_mse: 0.9803\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8290 - mae: 0.6964 - mse: 0.8290 - val_loss: 0.7877 - val_mae: 0.6936 - val_mse: 0.7877\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8217 - mae: 0.6996 - mse: 0.8217 - val_loss: 1.0502 - val_mae: 0.7760 - val_mse: 1.0502\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8589 - mae: 0.6903 - mse: 0.8589 - val_loss: 0.8577 - val_mae: 0.7134 - val_mse: 0.8577\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8255 - mae: 0.6824 - mse: 0.8255 - val_loss: 0.8712 - val_mae: 0.7238 - val_mse: 0.8712\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7763 - mae: 0.6709 - mse: 0.7763 - val_loss: 0.8036 - val_mae: 0.7133 - val_mse: 0.8036\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8270 - mae: 0.6914 - mse: 0.8270 - val_loss: 0.8173 - val_mae: 0.7210 - val_mse: 0.8173\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8107 - mae: 0.6854 - mse: 0.8107 - val_loss: 1.1538 - val_mae: 0.8363 - val_mse: 1.1538\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7955 - mae: 0.6636 - mse: 0.7955 - val_loss: 0.7941 - val_mae: 0.7116 - val_mse: 0.7941\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8133 - mae: 0.6912 - mse: 0.8133 - val_loss: 0.9571 - val_mae: 0.7555 - val_mse: 0.9571\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8148 - mae: 0.6925 - mse: 0.8148 - val_loss: 1.2419 - val_mae: 0.8627 - val_mse: 1.2419\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8138 - mae: 0.6846 - mse: 0.8138 - val_loss: 0.8074 - val_mae: 0.6983 - val_mse: 0.8074\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7745 - mae: 0.6617 - mse: 0.7745 - val_loss: 1.2489 - val_mae: 0.9111 - val_mse: 1.2489\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7658 - mae: 0.6633 - mse: 0.7658 - val_loss: 0.8946 - val_mae: 0.7254 - val_mse: 0.8946\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8268 - mae: 0.6941 - mse: 0.8268 - val_loss: 0.8227 - val_mae: 0.7111 - val_mse: 0.8227\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7883 - mae: 0.6722 - mse: 0.7883 - val_loss: 0.8197 - val_mae: 0.7239 - val_mse: 0.8197\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7457 - mae: 0.6579 - mse: 0.7457 - val_loss: 0.9743 - val_mae: 0.7475 - val_mse: 0.9743\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7527 - mae: 0.6580 - mse: 0.7527 - val_loss: 0.8641 - val_mae: 0.7172 - val_mse: 0.8641\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7863 - mae: 0.6640 - mse: 0.7863 - val_loss: 0.9193 - val_mae: 0.7323 - val_mse: 0.9193\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7571 - mae: 0.6630 - mse: 0.7571 - val_loss: 0.8796 - val_mae: 0.7637 - val_mse: 0.8796\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7761 - mae: 0.6661 - mse: 0.7761 - val_loss: 1.2270 - val_mae: 0.8604 - val_mse: 1.2270\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7660 - mae: 0.6633 - mse: 0.7660 - val_loss: 0.7959 - val_mae: 0.7111 - val_mse: 0.7959\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7969 - mae: 0.6673 - mse: 0.7969 - val_loss: 0.8612 - val_mae: 0.7374 - val_mse: 0.8612\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7564 - mae: 0.6576 - mse: 0.7564 - val_loss: 0.8055 - val_mae: 0.7063 - val_mse: 0.8055\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7707 - mae: 0.6669 - mse: 0.7707 - val_loss: 0.8797 - val_mae: 0.7362 - val_mse: 0.8797\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7621 - mae: 0.6559 - mse: 0.7621 - val_loss: 0.9021 - val_mae: 0.7786 - val_mse: 0.9021\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7752 - mae: 0.6642 - mse: 0.7752 - val_loss: 1.0906 - val_mae: 0.8110 - val_mse: 1.0906\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7307 - mae: 0.6503 - mse: 0.7307 - val_loss: 1.1561 - val_mae: 0.8616 - val_mse: 1.1561\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7296 - mae: 0.6442 - mse: 0.7296 - val_loss: 0.9470 - val_mae: 0.7420 - val_mse: 0.9470\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7742 - mae: 0.6635 - mse: 0.7742 - val_loss: 0.9609 - val_mae: 0.7661 - val_mse: 0.9609\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7282 - mae: 0.6469 - mse: 0.7282 - val_loss: 0.7924 - val_mae: 0.7043 - val_mse: 0.7924\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7519 - mae: 0.6570 - mse: 0.7519 - val_loss: 1.4445 - val_mae: 0.9440 - val_mse: 1.4445\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7420 - mae: 0.6498 - mse: 0.7420 - val_loss: 1.4734 - val_mae: 0.9808 - val_mse: 1.4734\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7235 - mae: 0.6389 - mse: 0.7235 - val_loss: 0.8193 - val_mae: 0.7192 - val_mse: 0.8193\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7107 - mae: 0.6347 - mse: 0.7107 - val_loss: 1.7958 - val_mae: 1.0852 - val_mse: 1.7958\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7477 - mae: 0.6443 - mse: 0.7477 - val_loss: 0.8118 - val_mae: 0.7056 - val_mse: 0.8118\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7448 - mae: 0.6535 - mse: 0.7448 - val_loss: 0.9226 - val_mae: 0.7442 - val_mse: 0.9226\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7056 - mae: 0.6245 - mse: 0.7056 - val_loss: 1.3158 - val_mae: 0.9059 - val_mse: 1.3158\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7319 - mae: 0.6477 - mse: 0.7319 - val_loss: 0.9192 - val_mae: 0.7662 - val_mse: 0.9192\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6752 - mae: 0.6141 - mse: 0.6752 - val_loss: 1.1125 - val_mae: 0.8082 - val_mse: 1.1125\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7406 - mae: 0.6464 - mse: 0.7406 - val_loss: 0.8802 - val_mae: 0.7609 - val_mse: 0.8802\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7061 - mae: 0.6324 - mse: 0.7061 - val_loss: 1.0144 - val_mae: 0.8275 - val_mse: 1.0144\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6798 - mae: 0.6219 - mse: 0.6798 - val_loss: 0.8554 - val_mae: 0.7295 - val_mse: 0.8554\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6943 - mae: 0.6251 - mse: 0.6943 - val_loss: 0.8095 - val_mae: 0.7079 - val_mse: 0.8095\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6842 - mae: 0.6110 - mse: 0.6842 - val_loss: 0.9714 - val_mae: 0.7537 - val_mse: 0.9714\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6439 - mae: 0.6020 - mse: 0.6439 - val_loss: 1.2474 - val_mae: 0.9079 - val_mse: 1.2474\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7274 - mae: 0.6420 - mse: 0.7274 - val_loss: 1.0234 - val_mae: 0.7836 - val_mse: 1.0234\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6946 - mae: 0.6206 - mse: 0.6946 - val_loss: 0.7990 - val_mae: 0.7220 - val_mse: 0.7990\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6842 - mae: 0.6182 - mse: 0.6842 - val_loss: 0.8201 - val_mae: 0.7036 - val_mse: 0.8201\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6945 - mae: 0.6352 - mse: 0.6945 - val_loss: 0.8348 - val_mae: 0.7042 - val_mse: 0.8348\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6543 - mae: 0.6108 - mse: 0.6543 - val_loss: 0.8709 - val_mae: 0.7273 - val_mse: 0.8709\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6855 - mae: 0.6171 - mse: 0.6855 - val_loss: 0.9631 - val_mae: 0.7925 - val_mse: 0.9631\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6613 - mae: 0.6089 - mse: 0.6613 - val_loss: 0.8579 - val_mae: 0.7236 - val_mse: 0.8579\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6685 - mae: 0.6018 - mse: 0.6685 - val_loss: 0.8658 - val_mae: 0.7291 - val_mse: 0.8658\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6518 - mae: 0.6002 - mse: 0.6518 - val_loss: 0.8665 - val_mae: 0.7292 - val_mse: 0.8665\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6441 - mae: 0.6055 - mse: 0.6441 - val_loss: 0.7806 - val_mae: 0.7075 - val_mse: 0.7806\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6348 - mae: 0.5975 - mse: 0.6348 - val_loss: 0.7853 - val_mae: 0.7113 - val_mse: 0.7853\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6258 - mae: 0.5793 - mse: 0.6258 - val_loss: 1.0649 - val_mae: 0.8129 - val_mse: 1.0649\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6030 - mae: 0.5735 - mse: 0.6030 - val_loss: 1.2061 - val_mae: 0.8449 - val_mse: 1.2061\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6681 - mae: 0.6104 - mse: 0.6681 - val_loss: 0.8675 - val_mae: 0.7474 - val_mse: 0.8675\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6525 - mae: 0.5979 - mse: 0.6525 - val_loss: 0.8109 - val_mae: 0.7175 - val_mse: 0.8109\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6589 - mae: 0.6041 - mse: 0.6589 - val_loss: 0.8156 - val_mae: 0.7186 - val_mse: 0.8156\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6268 - mae: 0.5913 - mse: 0.6268 - val_loss: 0.7900 - val_mae: 0.7070 - val_mse: 0.7900\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5952 - mae: 0.5688 - mse: 0.5952 - val_loss: 0.8221 - val_mae: 0.7205 - val_mse: 0.8221\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6288 - mae: 0.5956 - mse: 0.6288 - val_loss: 0.9190 - val_mae: 0.7309 - val_mse: 0.9190\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6285 - mae: 0.5951 - mse: 0.6285 - val_loss: 0.7880 - val_mae: 0.7027 - val_mse: 0.7880\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6130 - mae: 0.5876 - mse: 0.6130 - val_loss: 0.8040 - val_mae: 0.6990 - val_mse: 0.8040\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6182 - mae: 0.5770 - mse: 0.6182 - val_loss: 0.9392 - val_mae: 0.7649 - val_mse: 0.9392\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5935 - mae: 0.5726 - mse: 0.5935 - val_loss: 1.1826 - val_mae: 0.8551 - val_mse: 1.1826\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6063 - mae: 0.5805 - mse: 0.6063 - val_loss: 0.8133 - val_mae: 0.7212 - val_mse: 0.8133\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5911 - mae: 0.5771 - mse: 0.5911 - val_loss: 0.8342 - val_mae: 0.7165 - val_mse: 0.8342\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6427 - mae: 0.5886 - mse: 0.6427 - val_loss: 0.8781 - val_mae: 0.7558 - val_mse: 0.8781\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5982 - mae: 0.5728 - mse: 0.5982 - val_loss: 0.9095 - val_mae: 0.7617 - val_mse: 0.9095\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6102 - mae: 0.5805 - mse: 0.6102 - val_loss: 0.8810 - val_mae: 0.7284 - val_mse: 0.8810\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5641 - mae: 0.5452 - mse: 0.5641 - val_loss: 0.8320 - val_mae: 0.7250 - val_mse: 0.8320\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6215 - mae: 0.5847 - mse: 0.6215 - val_loss: 0.8267 - val_mae: 0.7281 - val_mse: 0.8267\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6070 - mae: 0.5849 - mse: 0.6070 - val_loss: 0.9809 - val_mae: 0.7975 - val_mse: 0.9809\n",
      "Epoch 192/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5904 - mae: 0.5712 - mse: 0.5904 - val_loss: 0.9297 - val_mae: 0.7701 - val_mse: 0.9297\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5727 - mae: 0.5680 - mse: 0.5727 - val_loss: 0.9765 - val_mae: 0.7713 - val_mse: 0.9765\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5880 - mae: 0.5670 - mse: 0.5880 - val_loss: 0.9887 - val_mae: 0.7901 - val_mse: 0.9887\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5964 - mae: 0.5741 - mse: 0.5964 - val_loss: 0.8549 - val_mae: 0.7261 - val_mse: 0.8549\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5646 - mae: 0.5654 - mse: 0.5646 - val_loss: 0.9386 - val_mae: 0.7848 - val_mse: 0.9386\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5547 - mae: 0.5451 - mse: 0.5547 - val_loss: 0.8073 - val_mae: 0.7230 - val_mse: 0.8073\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5658 - mae: 0.5563 - mse: 0.5658 - val_loss: 0.7953 - val_mae: 0.7109 - val_mse: 0.7953\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5735 - mae: 0.5602 - mse: 0.5735 - val_loss: 0.8657 - val_mae: 0.7300 - val_mse: 0.8657\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5514 - mae: 0.5451 - mse: 0.5514 - val_loss: 0.7983 - val_mae: 0.7117 - val_mse: 0.7983\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5753 - mae: 0.5654 - mse: 0.5753 - val_loss: 0.8401 - val_mae: 0.7400 - val_mse: 0.8401\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5957 - mae: 0.5629 - mse: 0.5957 - val_loss: 0.8181 - val_mae: 0.7297 - val_mse: 0.8181\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5460 - mae: 0.5455 - mse: 0.5460 - val_loss: 0.7933 - val_mae: 0.6953 - val_mse: 0.7933\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5257 - mae: 0.5352 - mse: 0.5257 - val_loss: 0.8249 - val_mae: 0.7139 - val_mse: 0.8249\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5899 - mae: 0.5740 - mse: 0.5899 - val_loss: 0.8704 - val_mae: 0.7525 - val_mse: 0.8704\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5446 - mae: 0.5426 - mse: 0.5446 - val_loss: 1.2283 - val_mae: 0.8391 - val_mse: 1.2283\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5417 - mae: 0.5400 - mse: 0.5417 - val_loss: 0.9015 - val_mae: 0.7687 - val_mse: 0.9015\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5844 - mae: 0.5568 - mse: 0.5844 - val_loss: 1.0746 - val_mae: 0.8037 - val_mse: 1.0746\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5476 - mae: 0.5495 - mse: 0.5476 - val_loss: 0.8564 - val_mae: 0.7259 - val_mse: 0.8564\n",
      "Epoch 210/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5446 - mae: 0.5383 - mse: 0.5446 - val_loss: 1.0152 - val_mae: 0.8084 - val_mse: 1.0152\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5464 - mae: 0.5501 - mse: 0.5464 - val_loss: 0.9097 - val_mae: 0.7559 - val_mse: 0.9097\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5281 - mae: 0.5382 - mse: 0.5281 - val_loss: 0.8295 - val_mae: 0.7294 - val_mse: 0.8295\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5144 - mae: 0.5216 - mse: 0.5144 - val_loss: 0.8515 - val_mae: 0.7434 - val_mse: 0.8515\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5597 - mae: 0.5563 - mse: 0.5597 - val_loss: 1.4235 - val_mae: 0.9443 - val_mse: 1.4235\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5539 - mae: 0.5479 - mse: 0.5539 - val_loss: 0.8452 - val_mae: 0.7289 - val_mse: 0.8452\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5326 - mae: 0.5441 - mse: 0.5326 - val_loss: 0.9307 - val_mae: 0.7590 - val_mse: 0.9307\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5238 - mae: 0.5401 - mse: 0.5238 - val_loss: 0.9189 - val_mae: 0.7513 - val_mse: 0.9189\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5310 - mae: 0.5318 - mse: 0.5310 - val_loss: 1.1140 - val_mae: 0.8233 - val_mse: 1.1140\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5237 - mae: 0.5246 - mse: 0.5237 - val_loss: 0.8353 - val_mae: 0.7151 - val_mse: 0.8353\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5776 - mae: 0.5553 - mse: 0.5776 - val_loss: 1.0071 - val_mae: 0.7904 - val_mse: 1.0071\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4870 - mae: 0.5064 - mse: 0.4870 - val_loss: 1.0725 - val_mae: 0.8207 - val_mse: 1.0725\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4892 - mae: 0.5026 - mse: 0.4892 - val_loss: 0.8725 - val_mae: 0.7450 - val_mse: 0.8725\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5317 - mae: 0.5344 - mse: 0.5317 - val_loss: 1.0968 - val_mae: 0.8144 - val_mse: 1.0968\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5072 - mae: 0.5175 - mse: 0.5072 - val_loss: 0.9940 - val_mae: 0.7838 - val_mse: 0.9940\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5085 - mae: 0.5261 - mse: 0.5085 - val_loss: 0.8674 - val_mae: 0.7436 - val_mse: 0.8674\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5127 - mae: 0.5260 - mse: 0.5127 - val_loss: 0.9101 - val_mae: 0.7574 - val_mse: 0.9101\n",
      "Epoch 227/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5118 - mae: 0.5185 - mse: 0.5118 - val_loss: 1.3789 - val_mae: 0.9323 - val_mse: 1.3789\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5175 - mae: 0.5372 - mse: 0.5175 - val_loss: 0.9158 - val_mae: 0.7656 - val_mse: 0.9158\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5041 - mae: 0.5203 - mse: 0.5041 - val_loss: 0.8173 - val_mae: 0.7160 - val_mse: 0.8173\n",
      "Epoch 230/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5264 - mae: 0.5207 - mse: 0.5264 - val_loss: 0.9126 - val_mae: 0.7493 - val_mse: 0.9126\n",
      "Epoch 231/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4912 - mae: 0.5107 - mse: 0.4912 - val_loss: 0.9206 - val_mae: 0.7638 - val_mse: 0.9206\n",
      "Epoch 232/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5129 - mae: 0.5238 - mse: 0.5129 - val_loss: 0.9638 - val_mae: 0.7757 - val_mse: 0.9638\n",
      "Epoch 233/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4982 - mae: 0.5219 - mse: 0.4982 - val_loss: 0.9633 - val_mae: 0.7729 - val_mse: 0.9633\n",
      "Epoch 234/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4805 - mae: 0.5014 - mse: 0.4805 - val_loss: 1.2381 - val_mae: 0.8512 - val_mse: 1.2381\n",
      "Epoch 235/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5035 - mae: 0.5178 - mse: 0.5035 - val_loss: 1.2761 - val_mae: 0.8798 - val_mse: 1.2761\n",
      "Epoch 236/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5032 - mae: 0.5177 - mse: 0.5032 - val_loss: 1.3478 - val_mae: 0.9042 - val_mse: 1.3478\n",
      "Epoch 237/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5020 - mae: 0.5223 - mse: 0.5020 - val_loss: 0.9684 - val_mae: 0.7657 - val_mse: 0.9684\n",
      "Epoch 238/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4662 - mae: 0.4961 - mse: 0.4662 - val_loss: 1.2155 - val_mae: 0.8676 - val_mse: 1.2155\n",
      "Epoch 239/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4742 - mae: 0.4985 - mse: 0.4742 - val_loss: 0.8610 - val_mae: 0.7301 - val_mse: 0.8610\n",
      "Epoch 240/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5094 - mae: 0.5156 - mse: 0.5094 - val_loss: 0.9430 - val_mae: 0.7695 - val_mse: 0.9430\n",
      "Epoch 241/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4973 - mae: 0.5117 - mse: 0.4973 - val_loss: 0.9247 - val_mae: 0.7534 - val_mse: 0.9247\n",
      "Epoch 242/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4564 - mae: 0.4949 - mse: 0.4564 - val_loss: 0.9164 - val_mae: 0.7726 - val_mse: 0.9164\n",
      "Epoch 243/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4876 - mae: 0.5070 - mse: 0.4876 - val_loss: 1.5796 - val_mae: 0.9629 - val_mse: 1.5796\n",
      "Epoch 244/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4945 - mae: 0.5040 - mse: 0.4945 - val_loss: 0.8755 - val_mae: 0.7382 - val_mse: 0.8755\n",
      "Epoch 245/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.4857 - mse: 0.4578 - val_loss: 0.9310 - val_mae: 0.7777 - val_mse: 0.9310\n",
      "Epoch 246/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4763 - mae: 0.5014 - mse: 0.4763 - val_loss: 0.9339 - val_mae: 0.7573 - val_mse: 0.9339\n",
      "Epoch 247/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4518 - mae: 0.4884 - mse: 0.4518 - val_loss: 1.4319 - val_mae: 0.9285 - val_mse: 1.4319\n",
      "Epoch 248/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4694 - mae: 0.5011 - mse: 0.4694 - val_loss: 0.9223 - val_mae: 0.7689 - val_mse: 0.9223\n",
      "Epoch 249/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4654 - mae: 0.4964 - mse: 0.4654 - val_loss: 0.9377 - val_mae: 0.7715 - val_mse: 0.9377\n",
      "Epoch 250/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4973 - mae: 0.5080 - mse: 0.4973 - val_loss: 0.8632 - val_mae: 0.7360 - val_mse: 0.8632\n",
      "Epoch 251/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4496 - mae: 0.4848 - mse: 0.4496 - val_loss: 0.8126 - val_mae: 0.7161 - val_mse: 0.8126\n",
      "Epoch 252/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4420 - mae: 0.4804 - mse: 0.4420 - val_loss: 0.9278 - val_mae: 0.7687 - val_mse: 0.9278\n",
      "Epoch 253/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4698 - mae: 0.5066 - mse: 0.4698 - val_loss: 0.8790 - val_mae: 0.7416 - val_mse: 0.8790\n",
      "Epoch 254/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4513 - mae: 0.4855 - mse: 0.4513 - val_loss: 0.9264 - val_mae: 0.7748 - val_mse: 0.9264\n",
      "Epoch 255/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4668 - mae: 0.4924 - mse: 0.4668 - val_loss: 0.9523 - val_mae: 0.7731 - val_mse: 0.9523\n",
      "Epoch 256/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4731 - mae: 0.4982 - mse: 0.4731 - val_loss: 0.8998 - val_mae: 0.7512 - val_mse: 0.8998\n",
      "Epoch 257/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4370 - mae: 0.4872 - mse: 0.4370 - val_loss: 1.5212 - val_mae: 0.9871 - val_mse: 1.5212\n",
      "Epoch 258/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4541 - mae: 0.4931 - mse: 0.4541 - val_loss: 1.0020 - val_mae: 0.7850 - val_mse: 1.0020\n",
      "Epoch 259/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4716 - mae: 0.5071 - mse: 0.4716 - val_loss: 0.9745 - val_mae: 0.7750 - val_mse: 0.9745\n",
      "Epoch 260/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4212 - mae: 0.4690 - mse: 0.4212 - val_loss: 1.2431 - val_mae: 0.8948 - val_mse: 1.2431\n",
      "Epoch 261/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4362 - mae: 0.4846 - mse: 0.4362 - val_loss: 1.0811 - val_mae: 0.8232 - val_mse: 1.0811\n",
      "Epoch 262/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4330 - mae: 0.4793 - mse: 0.4330 - val_loss: 0.9343 - val_mae: 0.7733 - val_mse: 0.9343\n",
      "Epoch 263/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4474 - mae: 0.4802 - mse: 0.4474 - val_loss: 0.8899 - val_mae: 0.7522 - val_mse: 0.8899\n",
      "Epoch 264/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4247 - mae: 0.4776 - mse: 0.4247 - val_loss: 0.9572 - val_mae: 0.7790 - val_mse: 0.9572\n",
      "Epoch 265/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4218 - mae: 0.4622 - mse: 0.4218 - val_loss: 1.1328 - val_mae: 0.8383 - val_mse: 1.1328\n",
      "Epoch 266/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4483 - mae: 0.4943 - mse: 0.4483 - val_loss: 0.8852 - val_mae: 0.7444 - val_mse: 0.8852\n",
      "Epoch 267/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4457 - mae: 0.4985 - mse: 0.4457 - val_loss: 0.9723 - val_mae: 0.7716 - val_mse: 0.9723\n",
      "Epoch 268/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4070 - mae: 0.4665 - mse: 0.4070 - val_loss: 1.0681 - val_mae: 0.8084 - val_mse: 1.0681\n",
      "Epoch 269/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4202 - mae: 0.4747 - mse: 0.4202 - val_loss: 0.8894 - val_mae: 0.7448 - val_mse: 0.8894\n",
      "Epoch 270/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4134 - mae: 0.4662 - mse: 0.4134 - val_loss: 0.9044 - val_mae: 0.7562 - val_mse: 0.9044\n",
      "Kappa Score: 0.7101899046366327\n",
      "\n",
      "###########Set-5###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 112.1956 - mae: 5.6440 - mse: 112.1956 - val_loss: 11.3946 - val_mae: 2.5564 - val_mse: 11.3946\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 32.3747 - mae: 4.6990 - mse: 32.3747 - val_loss: 5.9213 - val_mae: 1.5748 - val_mse: 5.9213\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 13.6897 - mae: 2.6257 - mse: 13.6897 - val_loss: 5.0698 - val_mae: 1.2029 - val_mse: 5.0698\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 7.1523 - mae: 2.1907 - mse: 7.1523 - val_loss: 5.8683 - val_mae: 1.6558 - val_mse: 5.8683\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 4.6081 - mae: 1.6852 - mse: 4.6081 - val_loss: 16.4017 - val_mae: 3.1348 - val_mse: 16.4017\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 4.7911 - mae: 1.6902 - mse: 4.7911 - val_loss: 6.2941 - val_mae: 1.3596 - val_mse: 6.2941\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.0411 - mae: 1.4042 - mse: 3.0411 - val_loss: 3.5016 - val_mae: 1.1913 - val_mse: 3.5016\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.1155 - mae: 1.3847 - mse: 3.1155 - val_loss: 19.9136 - val_mae: 3.5323 - val_mse: 19.9136\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.5930 - mae: 1.2410 - mse: 2.5930 - val_loss: 2.9583 - val_mae: 1.0795 - val_mse: 2.9583\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4649 - mae: 1.2082 - mse: 2.4649 - val_loss: 10.2832 - val_mae: 1.9256 - val_mse: 10.2832\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2076 - mae: 1.1715 - mse: 2.2076 - val_loss: 2.9501 - val_mae: 1.0590 - val_mse: 2.9501\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.1318 - mae: 1.1752 - mse: 2.1318 - val_loss: 5.8676 - val_mae: 1.2066 - val_mse: 5.8676\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0314 - mae: 1.1173 - mse: 2.0314 - val_loss: 3.3278 - val_mae: 1.4075 - val_mse: 3.3278\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8927 - mae: 1.0906 - mse: 1.8927 - val_loss: 13.6661 - val_mae: 3.1114 - val_mse: 13.6661\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0796 - mae: 1.1105 - mse: 2.0796 - val_loss: 6.2696 - val_mae: 2.2911 - val_mse: 6.2696\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7843 - mae: 1.0462 - mse: 1.7843 - val_loss: 5.9206 - val_mae: 1.5815 - val_mse: 5.9206\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7168 - mae: 1.0307 - mse: 1.7168 - val_loss: 3.9239 - val_mae: 1.3215 - val_mse: 3.9239\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7231 - mae: 1.0429 - mse: 1.7231 - val_loss: 7.5458 - val_mae: 1.9177 - val_mse: 7.5458\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9002 - mae: 1.0828 - mse: 1.9002 - val_loss: 2.6724 - val_mae: 1.0750 - val_mse: 2.6724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8118 - mae: 1.0542 - mse: 1.8118 - val_loss: 3.9380 - val_mae: 1.1827 - val_mse: 3.9380\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6299 - mae: 0.9908 - mse: 1.6299 - val_loss: 2.9680 - val_mae: 1.2040 - val_mse: 2.9680\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8943 - mae: 1.0605 - mse: 1.8943 - val_loss: 5.1181 - val_mae: 1.7199 - val_mse: 5.1181\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6802 - mae: 1.0165 - mse: 1.6802 - val_loss: 4.9058 - val_mae: 1.2705 - val_mse: 4.9058\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6870 - mae: 1.0124 - mse: 1.6870 - val_loss: 3.0312 - val_mae: 1.0844 - val_mse: 3.0312\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5018 - mae: 0.9476 - mse: 1.5018 - val_loss: 7.4783 - val_mae: 1.6577 - val_mse: 7.4783\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5875 - mae: 0.9742 - mse: 1.5875 - val_loss: 3.5591 - val_mae: 1.4223 - val_mse: 3.5591\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5217 - mae: 0.9659 - mse: 1.5217 - val_loss: 3.1862 - val_mae: 1.1910 - val_mse: 3.1862\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4204 - mae: 0.9307 - mse: 1.4204 - val_loss: 5.6942 - val_mae: 1.5460 - val_mse: 5.6942\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5407 - mae: 0.9871 - mse: 1.5407 - val_loss: 2.9192 - val_mae: 1.1186 - val_mse: 2.9192\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3967 - mae: 0.9180 - mse: 1.3967 - val_loss: 6.4183 - val_mae: 1.7444 - val_mse: 6.4183\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4114 - mae: 0.9409 - mse: 1.4114 - val_loss: 2.4565 - val_mae: 1.0085 - val_mse: 2.4565\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3601 - mae: 0.9122 - mse: 1.3601 - val_loss: 6.3887 - val_mae: 1.2994 - val_mse: 6.3887\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4115 - mae: 0.9379 - mse: 1.4115 - val_loss: 6.5735 - val_mae: 1.9113 - val_mse: 6.5735\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3510 - mae: 0.8973 - mse: 1.3510 - val_loss: 2.2273 - val_mae: 1.0081 - val_mse: 2.2273\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3468 - mae: 0.9009 - mse: 1.3468 - val_loss: 2.5971 - val_mae: 1.0498 - val_mse: 2.5971\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3326 - mae: 0.8900 - mse: 1.3326 - val_loss: 3.7723 - val_mae: 1.0674 - val_mse: 3.7723\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3779 - mae: 0.9190 - mse: 1.3779 - val_loss: 3.4801 - val_mae: 1.2610 - val_mse: 3.4801\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1953 - mae: 0.8445 - mse: 1.1953 - val_loss: 3.7666 - val_mae: 1.3305 - val_mse: 3.7666\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3409 - mae: 0.8895 - mse: 1.3409 - val_loss: 2.6725 - val_mae: 1.0212 - val_mse: 2.6725\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2422 - mae: 0.8648 - mse: 1.2422 - val_loss: 3.2385 - val_mae: 1.4448 - val_mse: 3.2385\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3868 - mae: 0.9248 - mse: 1.3868 - val_loss: 3.8330 - val_mae: 1.4125 - val_mse: 3.8330\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2913 - mae: 0.8852 - mse: 1.2913 - val_loss: 6.1566 - val_mae: 1.5266 - val_mse: 6.1566\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2547 - mae: 0.8819 - mse: 1.2547 - val_loss: 2.2523 - val_mae: 1.0010 - val_mse: 2.2523\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2551 - mae: 0.8824 - mse: 1.2551 - val_loss: 3.3010 - val_mae: 1.0726 - val_mse: 3.3010\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2264 - mae: 0.8704 - mse: 1.2264 - val_loss: 3.1455 - val_mae: 1.3720 - val_mse: 3.1455\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2437 - mae: 0.8729 - mse: 1.2437 - val_loss: 5.4370 - val_mae: 1.7334 - val_mse: 5.4370\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2758 - mae: 0.8700 - mse: 1.2758 - val_loss: 3.5916 - val_mae: 1.3462 - val_mse: 3.5916\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2076 - mae: 0.8560 - mse: 1.2076 - val_loss: 3.3469 - val_mae: 1.0436 - val_mse: 3.3469\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1835 - mae: 0.8507 - mse: 1.1835 - val_loss: 2.2634 - val_mae: 0.9640 - val_mse: 2.2634\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1916 - mae: 0.8510 - mse: 1.1916 - val_loss: 3.5902 - val_mae: 1.3254 - val_mse: 3.5902\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1892 - mae: 0.8573 - mse: 1.1892 - val_loss: 3.8139 - val_mae: 1.0684 - val_mse: 3.8139\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2722 - mae: 0.8769 - mse: 1.2722 - val_loss: 2.7579 - val_mae: 1.0256 - val_mse: 2.7579\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3156 - mae: 0.8626 - mse: 1.3156 - val_loss: 4.2266 - val_mae: 1.2147 - val_mse: 4.2266\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2330 - mae: 0.8623 - mse: 1.2330 - val_loss: 2.7484 - val_mae: 1.2213 - val_mse: 2.7484\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1917 - mae: 0.8575 - mse: 1.1917 - val_loss: 4.6202 - val_mae: 1.1751 - val_mse: 4.6202\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0865 - mae: 0.8166 - mse: 1.0865 - val_loss: 4.1924 - val_mae: 1.4481 - val_mse: 4.1924\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1820 - mae: 0.8379 - mse: 1.1820 - val_loss: 3.8490 - val_mae: 1.3352 - val_mse: 3.8490\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1370 - mae: 0.8308 - mse: 1.1370 - val_loss: 2.3430 - val_mae: 0.9753 - val_mse: 2.3430\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1519 - mae: 0.8371 - mse: 1.1519 - val_loss: 4.3996 - val_mae: 1.5680 - val_mse: 4.3996\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2029 - mae: 0.8537 - mse: 1.2029 - val_loss: 2.8898 - val_mae: 1.0639 - val_mse: 2.8898\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1253 - mae: 0.8207 - mse: 1.1253 - val_loss: 3.2609 - val_mae: 1.1070 - val_mse: 3.2609\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1506 - mae: 0.8457 - mse: 1.1506 - val_loss: 3.0421 - val_mae: 1.1128 - val_mse: 3.0421\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1815 - mae: 0.8296 - mse: 1.1815 - val_loss: 3.3751 - val_mae: 1.0728 - val_mse: 3.3751\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1025 - mae: 0.8170 - mse: 1.1025 - val_loss: 2.7021 - val_mae: 1.1434 - val_mse: 2.7021\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0800 - mae: 0.8075 - mse: 1.0800 - val_loss: 5.1779 - val_mae: 2.0015 - val_mse: 5.1779\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0880 - mae: 0.8054 - mse: 1.0880 - val_loss: 3.3774 - val_mae: 1.5053 - val_mse: 3.3774\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1820 - mae: 0.8472 - mse: 1.1820 - val_loss: 6.7273 - val_mae: 1.7365 - val_mse: 6.7273\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1107 - mae: 0.8142 - mse: 1.1107 - val_loss: 2.6328 - val_mae: 1.0190 - val_mse: 2.6328\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0788 - mae: 0.8127 - mse: 1.0788 - val_loss: 2.9333 - val_mae: 1.0448 - val_mse: 2.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0606 - mae: 0.8069 - mse: 1.0606 - val_loss: 3.7651 - val_mae: 1.2273 - val_mse: 3.7651\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1073 - mae: 0.8129 - mse: 1.1073 - val_loss: 3.1630 - val_mae: 1.2813 - val_mse: 3.1630\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0707 - mae: 0.7997 - mse: 1.0707 - val_loss: 2.5274 - val_mae: 1.0766 - val_mse: 2.5274\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0648 - mae: 0.8062 - mse: 1.0648 - val_loss: 3.1498 - val_mae: 1.0241 - val_mse: 3.1498\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0842 - mae: 0.8184 - mse: 1.0842 - val_loss: 3.2704 - val_mae: 1.4156 - val_mse: 3.2704\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1122 - mae: 0.8212 - mse: 1.1122 - val_loss: 2.8467 - val_mae: 0.9997 - val_mse: 2.8467\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0632 - mae: 0.7977 - mse: 1.0632 - val_loss: 2.9767 - val_mae: 1.1152 - val_mse: 2.9767\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9948 - mae: 0.7791 - mse: 0.9948 - val_loss: 2.9660 - val_mae: 1.0810 - val_mse: 2.9660\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0191 - mae: 0.7834 - mse: 1.0191 - val_loss: 2.8077 - val_mae: 1.0130 - val_mse: 2.8077\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0423 - mae: 0.7893 - mse: 1.0423 - val_loss: 3.1909 - val_mae: 1.0591 - val_mse: 3.1909\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0174 - mae: 0.7895 - mse: 1.0174 - val_loss: 3.9193 - val_mae: 1.3494 - val_mse: 3.9193\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0366 - mae: 0.7855 - mse: 1.0366 - val_loss: 2.6505 - val_mae: 1.0241 - val_mse: 2.6505\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9996 - mae: 0.7780 - mse: 0.9996 - val_loss: 4.5896 - val_mae: 1.4901 - val_mse: 4.5896\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0101 - mae: 0.7736 - mse: 1.0101 - val_loss: 3.8008 - val_mae: 1.2260 - val_mse: 3.8008\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9883 - mae: 0.7823 - mse: 0.9883 - val_loss: 4.6000 - val_mae: 1.3330 - val_mse: 4.6000\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9689 - mae: 0.7595 - mse: 0.9689 - val_loss: 2.7624 - val_mae: 1.0114 - val_mse: 2.7624\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0153 - mae: 0.7789 - mse: 1.0153 - val_loss: 2.2712 - val_mae: 0.9966 - val_mse: 2.2712\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9779 - mae: 0.7624 - mse: 0.9779 - val_loss: 2.7219 - val_mae: 0.9978 - val_mse: 2.7219\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9601 - mae: 0.7546 - mse: 0.9601 - val_loss: 5.7544 - val_mae: 1.7651 - val_mse: 5.7544\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9949 - mae: 0.7741 - mse: 0.9949 - val_loss: 2.9918 - val_mae: 1.0279 - val_mse: 2.9918\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9524 - mae: 0.7566 - mse: 0.9524 - val_loss: 4.8906 - val_mae: 1.6308 - val_mse: 4.8906\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0418 - mae: 0.7936 - mse: 1.0418 - val_loss: 7.0095 - val_mae: 1.9125 - val_mse: 7.0095\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9751 - mae: 0.7612 - mse: 0.9751 - val_loss: 3.2445 - val_mae: 1.1620 - val_mse: 3.2445\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9725 - mae: 0.7661 - mse: 0.9725 - val_loss: 2.9441 - val_mae: 0.9982 - val_mse: 2.9441\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9540 - mae: 0.7577 - mse: 0.9540 - val_loss: 4.7368 - val_mae: 1.5602 - val_mse: 4.7368\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0518 - mae: 0.7915 - mse: 1.0518 - val_loss: 3.8387 - val_mae: 1.1781 - val_mse: 3.8387\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9213 - mae: 0.7433 - mse: 0.9213 - val_loss: 2.6095 - val_mae: 1.0069 - val_mse: 2.6095\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8976 - mae: 0.7387 - mse: 0.8976 - val_loss: 3.1322 - val_mae: 1.0258 - val_mse: 3.1322\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9202 - mae: 0.7341 - mse: 0.9202 - val_loss: 2.4131 - val_mae: 0.9905 - val_mse: 2.4131\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9610 - mae: 0.7470 - mse: 0.9610 - val_loss: 3.2856 - val_mae: 1.0722 - val_mse: 3.2856\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8799 - mae: 0.7315 - mse: 0.8799 - val_loss: 3.9192 - val_mae: 1.2930 - val_mse: 3.9192\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9734 - mae: 0.7591 - mse: 0.9734 - val_loss: 5.7716 - val_mae: 1.7138 - val_mse: 5.7716\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9849 - mae: 0.7667 - mse: 0.9849 - val_loss: 2.6715 - val_mae: 0.9868 - val_mse: 2.6715\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9110 - mae: 0.7369 - mse: 0.9110 - val_loss: 3.5404 - val_mae: 1.1032 - val_mse: 3.5404\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8973 - mae: 0.7366 - mse: 0.8973 - val_loss: 3.7776 - val_mae: 1.4995 - val_mse: 3.7776\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9153 - mae: 0.7348 - mse: 0.9153 - val_loss: 2.7244 - val_mae: 1.1074 - val_mse: 2.7244\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9579 - mae: 0.7565 - mse: 0.9579 - val_loss: 3.2812 - val_mae: 1.0262 - val_mse: 3.2812\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8087 - mae: 0.6869 - mse: 0.8087 - val_loss: 2.8108 - val_mae: 1.1577 - val_mse: 2.8108\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9293 - mae: 0.7450 - mse: 0.9293 - val_loss: 3.4189 - val_mae: 1.1904 - val_mse: 3.4189\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8185 - mae: 0.7007 - mse: 0.8185 - val_loss: 4.5841 - val_mae: 1.3975 - val_mse: 4.5841\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9269 - mae: 0.7476 - mse: 0.9269 - val_loss: 3.7379 - val_mae: 1.2783 - val_mse: 3.7379\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8767 - mae: 0.7288 - mse: 0.8767 - val_loss: 3.5617 - val_mae: 1.4461 - val_mse: 3.5617\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8867 - mae: 0.7192 - mse: 0.8867 - val_loss: 2.9250 - val_mae: 0.9966 - val_mse: 2.9250\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8831 - mae: 0.7248 - mse: 0.8831 - val_loss: 3.6955 - val_mae: 1.2150 - val_mse: 3.6955\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8735 - mae: 0.7174 - mse: 0.8735 - val_loss: 2.9340 - val_mae: 1.1486 - val_mse: 2.9340\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8535 - mae: 0.7087 - mse: 0.8535 - val_loss: 2.8565 - val_mae: 1.1258 - val_mse: 2.8565\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7814 - mae: 0.6844 - mse: 0.7814 - val_loss: 3.2639 - val_mae: 1.0222 - val_mse: 3.2639\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9073 - mae: 0.7318 - mse: 0.9073 - val_loss: 4.8671 - val_mae: 1.4665 - val_mse: 4.8671\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7899 - mae: 0.6856 - mse: 0.7899 - val_loss: 3.8925 - val_mae: 1.1005 - val_mse: 3.8925\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8500 - mae: 0.7034 - mse: 0.8500 - val_loss: 3.1348 - val_mae: 1.0672 - val_mse: 3.1348\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8462 - mae: 0.7175 - mse: 0.8462 - val_loss: 4.7264 - val_mae: 1.5057 - val_mse: 4.7264\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8598 - mae: 0.7167 - mse: 0.8598 - val_loss: 3.3846 - val_mae: 1.1101 - val_mse: 3.3846\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8953 - mae: 0.7251 - mse: 0.8953 - val_loss: 2.7152 - val_mae: 0.9956 - val_mse: 2.7152\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8306 - mae: 0.7078 - mse: 0.8306 - val_loss: 5.3401 - val_mae: 1.6080 - val_mse: 5.3401\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8456 - mae: 0.7123 - mse: 0.8456 - val_loss: 6.4074 - val_mae: 1.8500 - val_mse: 6.4074\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8336 - mae: 0.6845 - mse: 0.8336 - val_loss: 4.3412 - val_mae: 1.3839 - val_mse: 4.3412\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8636 - mae: 0.7147 - mse: 0.8636 - val_loss: 2.7191 - val_mae: 1.0375 - val_mse: 2.7191\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8019 - mae: 0.6852 - mse: 0.8019 - val_loss: 3.4415 - val_mae: 1.0764 - val_mse: 3.4415\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8104 - mae: 0.6893 - mse: 0.8104 - val_loss: 3.8665 - val_mae: 1.3069 - val_mse: 3.8665\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8315 - mae: 0.7049 - mse: 0.8315 - val_loss: 3.0303 - val_mae: 1.0501 - val_mse: 3.0303\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8346 - mae: 0.6926 - mse: 0.8346 - val_loss: 3.2578 - val_mae: 1.0272 - val_mse: 3.2578\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8435 - mae: 0.7120 - mse: 0.8435 - val_loss: 2.9323 - val_mae: 1.0205 - val_mse: 2.9323\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7918 - mae: 0.6833 - mse: 0.7918 - val_loss: 2.6844 - val_mae: 0.9985 - val_mse: 2.6844\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8065 - mae: 0.6842 - mse: 0.8065 - val_loss: 4.1631 - val_mae: 1.2952 - val_mse: 4.1631\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7492 - mae: 0.6650 - mse: 0.7492 - val_loss: 3.2997 - val_mae: 1.0930 - val_mse: 3.2997\n",
      "Kappa Score: 0.6359703687792188\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 96.7777 - mae: 5.7093 - mse: 96.7777 - val_loss: 4.7185 - val_mae: 1.2780 - val_mse: 4.7185\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 29.5419 - mae: 4.3883 - mse: 29.5419 - val_loss: 3.7714 - val_mae: 1.3181 - val_mse: 3.7714\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 14.0637 - mae: 2.8105 - mse: 14.0637 - val_loss: 7.8118 - val_mae: 1.4982 - val_mse: 7.8118\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 7.8134 - mae: 2.1346 - mse: 7.8134 - val_loss: 7.1993 - val_mae: 1.7908 - val_mse: 7.1993\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 4.0137 - mae: 1.6246 - mse: 4.0137 - val_loss: 10.9668 - val_mae: 1.9562 - val_mse: 10.9668\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3.3914 - mae: 1.4909 - mse: 3.3914 - val_loss: 8.2722 - val_mae: 2.0778 - val_mse: 8.2722\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.9030 - mae: 1.3635 - mse: 2.9030 - val_loss: 18.2093 - val_mae: 3.2636 - val_mse: 18.2093\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.8837 - mae: 1.3667 - mse: 2.8837 - val_loss: 3.9353 - val_mae: 1.2033 - val_mse: 3.9353\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.6111 - mae: 1.2738 - mse: 2.6111 - val_loss: 6.2659 - val_mae: 1.3000 - val_mse: 6.2659\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9505 - mae: 1.0973 - mse: 1.9505 - val_loss: 7.7782 - val_mae: 2.0694 - val_mse: 7.7782\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0443 - mae: 1.1203 - mse: 2.0443 - val_loss: 3.3130 - val_mae: 1.3352 - val_mse: 3.3130\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9766 - mae: 1.1029 - mse: 1.9766 - val_loss: 4.6662 - val_mae: 1.2107 - val_mse: 4.6662\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9780 - mae: 1.1012 - mse: 1.9780 - val_loss: 6.8910 - val_mae: 1.9348 - val_mse: 6.8910\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8961 - mae: 1.0645 - mse: 1.8961 - val_loss: 4.2244 - val_mae: 1.2807 - val_mse: 4.2244\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8938 - mae: 1.0783 - mse: 1.8938 - val_loss: 3.9328 - val_mae: 1.2286 - val_mse: 3.9328\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9831 - mae: 1.0687 - mse: 1.9831 - val_loss: 6.4589 - val_mae: 1.8860 - val_mse: 6.4589\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7165 - mae: 1.0101 - mse: 1.7165 - val_loss: 3.0336 - val_mae: 1.1107 - val_mse: 3.0336\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7634 - mae: 1.0306 - mse: 1.7634 - val_loss: 5.3860 - val_mae: 1.2661 - val_mse: 5.3860\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5252 - mae: 0.9543 - mse: 1.5252 - val_loss: 4.1390 - val_mae: 1.2744 - val_mse: 4.1390\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5950 - mae: 0.9869 - mse: 1.5950 - val_loss: 3.5032 - val_mae: 1.0996 - val_mse: 3.5032\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4275 - mae: 0.9405 - mse: 1.4275 - val_loss: 2.8345 - val_mae: 1.0810 - val_mse: 2.8345\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5150 - mae: 0.9685 - mse: 1.5150 - val_loss: 6.9903 - val_mae: 1.2583 - val_mse: 6.9903\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5342 - mae: 0.9503 - mse: 1.5342 - val_loss: 3.0888 - val_mae: 1.0745 - val_mse: 3.0888\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4644 - mae: 0.9454 - mse: 1.4644 - val_loss: 6.1603 - val_mae: 1.3054 - val_mse: 6.1603\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2802 - mae: 0.8739 - mse: 1.2802 - val_loss: 11.7876 - val_mae: 2.6851 - val_mse: 11.7876\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.5682 - mae: 0.9432 - mse: 1.5682 - val_loss: 9.8448 - val_mae: 2.2039 - val_mse: 9.8448\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.4100 - mae: 0.9264 - mse: 1.4100 - val_loss: 4.3964 - val_mae: 1.7527 - val_mse: 4.3964\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4877 - mae: 0.9553 - mse: 1.4877 - val_loss: 4.8525 - val_mae: 1.1931 - val_mse: 4.8525\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2816 - mae: 0.8800 - mse: 1.2816 - val_loss: 2.9819 - val_mae: 1.1073 - val_mse: 2.9819\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3668 - mae: 0.9125 - mse: 1.3668 - val_loss: 8.3545 - val_mae: 1.7307 - val_mse: 8.3545\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5374 - mae: 0.9590 - mse: 1.5374 - val_loss: 3.2564 - val_mae: 1.0873 - val_mse: 3.2564\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3363 - mae: 0.8999 - mse: 1.3363 - val_loss: 9.9656 - val_mae: 2.2310 - val_mse: 9.9656\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5638 - mae: 0.9522 - mse: 1.5638 - val_loss: 3.1977 - val_mae: 1.0882 - val_mse: 3.1977\n",
      "Epoch 34/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4252 - mae: 0.9271 - mse: 1.4252 - val_loss: 6.7036 - val_mae: 1.7916 - val_mse: 6.7036\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3649 - mae: 0.9096 - mse: 1.3649 - val_loss: 6.6508 - val_mae: 1.8893 - val_mse: 6.6508\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3040 - mae: 0.8981 - mse: 1.3040 - val_loss: 4.3159 - val_mae: 1.2226 - val_mse: 4.3159\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3518 - mae: 0.9046 - mse: 1.3518 - val_loss: 2.8930 - val_mae: 1.0433 - val_mse: 2.8930\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3925 - mae: 0.9067 - mse: 1.3925 - val_loss: 4.7983 - val_mae: 1.5903 - val_mse: 4.7983\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2585 - mae: 0.8777 - mse: 1.2585 - val_loss: 5.1323 - val_mae: 1.5780 - val_mse: 5.1323\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3976 - mae: 0.9129 - mse: 1.3976 - val_loss: 5.6461 - val_mae: 2.1348 - val_mse: 5.6461\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3668 - mae: 0.8907 - mse: 1.3668 - val_loss: 4.9618 - val_mae: 1.6920 - val_mse: 4.9618\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2804 - mae: 0.8811 - mse: 1.2804 - val_loss: 4.0490 - val_mae: 1.2437 - val_mse: 4.0490\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1860 - mae: 0.8535 - mse: 1.1860 - val_loss: 4.2660 - val_mae: 1.3035 - val_mse: 4.2660\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2687 - mae: 0.8696 - mse: 1.2687 - val_loss: 3.6324 - val_mae: 1.1460 - val_mse: 3.6324\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2005 - mae: 0.8524 - mse: 1.2005 - val_loss: 6.0135 - val_mae: 1.2677 - val_mse: 6.0135\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2778 - mae: 0.8810 - mse: 1.2778 - val_loss: 4.0057 - val_mae: 1.2404 - val_mse: 4.0057\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2503 - mae: 0.8678 - mse: 1.2503 - val_loss: 8.1852 - val_mae: 2.0410 - val_mse: 8.1852\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2628 - mae: 0.8712 - mse: 1.2628 - val_loss: 3.6750 - val_mae: 1.3888 - val_mse: 3.6750\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1608 - mae: 0.8501 - mse: 1.1608 - val_loss: 5.2639 - val_mae: 1.3234 - val_mse: 5.2639\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2372 - mae: 0.8649 - mse: 1.2372 - val_loss: 7.0692 - val_mae: 1.7164 - val_mse: 7.0692\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1547 - mae: 0.8353 - mse: 1.1547 - val_loss: 3.9791 - val_mae: 1.1819 - val_mse: 3.9791\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2284 - mae: 0.8591 - mse: 1.2284 - val_loss: 3.2324 - val_mae: 1.0930 - val_mse: 3.2324\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2103 - mae: 0.8541 - mse: 1.2103 - val_loss: 4.1048 - val_mae: 1.1394 - val_mse: 4.1048\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1992 - mae: 0.8482 - mse: 1.1992 - val_loss: 4.0273 - val_mae: 1.1221 - val_mse: 4.0273\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1422 - mae: 0.8238 - mse: 1.1422 - val_loss: 7.5499 - val_mae: 2.0090 - val_mse: 7.5499\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2063 - mae: 0.8352 - mse: 1.2063 - val_loss: 4.2249 - val_mae: 1.7128 - val_mse: 4.2249\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1712 - mae: 0.8317 - mse: 1.1712 - val_loss: 5.0589 - val_mae: 1.3189 - val_mse: 5.0589\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1569 - mae: 0.8350 - mse: 1.1569 - val_loss: 6.3952 - val_mae: 1.7560 - val_mse: 6.3952\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1219 - mae: 0.8184 - mse: 1.1219 - val_loss: 3.9695 - val_mae: 1.1404 - val_mse: 3.9695\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1537 - mae: 0.8260 - mse: 1.1537 - val_loss: 3.6875 - val_mae: 1.0975 - val_mse: 3.6875\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1215 - mae: 0.8305 - mse: 1.1215 - val_loss: 3.0474 - val_mae: 1.2177 - val_mse: 3.0474\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1147 - mae: 0.8209 - mse: 1.1147 - val_loss: 3.8677 - val_mae: 1.1250 - val_mse: 3.8677\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1094 - mae: 0.8163 - mse: 1.1094 - val_loss: 4.2995 - val_mae: 1.3444 - val_mse: 4.2995\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1380 - mae: 0.8205 - mse: 1.1380 - val_loss: 3.8903 - val_mae: 1.1042 - val_mse: 3.8903\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1506 - mae: 0.8221 - mse: 1.1506 - val_loss: 3.0055 - val_mae: 1.1295 - val_mse: 3.0055\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1351 - mae: 0.8183 - mse: 1.1351 - val_loss: 2.9144 - val_mae: 1.1212 - val_mse: 2.9144\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0790 - mae: 0.8103 - mse: 1.0790 - val_loss: 6.4965 - val_mae: 2.1446 - val_mse: 6.4965\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1824 - mae: 0.8378 - mse: 1.1824 - val_loss: 5.5505 - val_mae: 1.6746 - val_mse: 5.5505\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1722 - mae: 0.8456 - mse: 1.1722 - val_loss: 4.0734 - val_mae: 1.5644 - val_mse: 4.0734\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2303 - mae: 0.8574 - mse: 1.2303 - val_loss: 4.4665 - val_mae: 1.3499 - val_mse: 4.4665\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0967 - mae: 0.8191 - mse: 1.0967 - val_loss: 3.9126 - val_mae: 1.1277 - val_mse: 3.9126\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1098 - mae: 0.8004 - mse: 1.1098 - val_loss: 5.6629 - val_mae: 1.6372 - val_mse: 5.6629\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1321 - mae: 0.8086 - mse: 1.1321 - val_loss: 4.2561 - val_mae: 1.4663 - val_mse: 4.2561\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0112 - mae: 0.7751 - mse: 1.0112 - val_loss: 3.2772 - val_mae: 1.1134 - val_mse: 3.2772\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0859 - mae: 0.8011 - mse: 1.0859 - val_loss: 4.6947 - val_mae: 1.6535 - val_mse: 4.6947\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0803 - mae: 0.7968 - mse: 1.0803 - val_loss: 3.3781 - val_mae: 1.1085 - val_mse: 3.3781\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1340 - mae: 0.8148 - mse: 1.1340 - val_loss: 3.0607 - val_mae: 1.1262 - val_mse: 3.0607\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0713 - mae: 0.7986 - mse: 1.0713 - val_loss: 3.5364 - val_mae: 1.1512 - val_mse: 3.5364\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1089 - mae: 0.8252 - mse: 1.1089 - val_loss: 5.6479 - val_mae: 1.6066 - val_mse: 5.6479\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0816 - mae: 0.8125 - mse: 1.0816 - val_loss: 5.6608 - val_mae: 1.4414 - val_mse: 5.6608\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0369 - mae: 0.7781 - mse: 1.0369 - val_loss: 3.9022 - val_mae: 1.1492 - val_mse: 3.9022\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0460 - mae: 0.7892 - mse: 1.0460 - val_loss: 3.7418 - val_mae: 1.1721 - val_mse: 3.7418\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0611 - mae: 0.7915 - mse: 1.0611 - val_loss: 6.3729 - val_mae: 1.7882 - val_mse: 6.3729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0535 - mae: 0.7862 - mse: 1.0535 - val_loss: 3.4904 - val_mae: 1.0988 - val_mse: 3.4904\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9935 - mae: 0.7570 - mse: 0.9935 - val_loss: 5.6330 - val_mae: 1.6285 - val_mse: 5.6330\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0302 - mae: 0.7893 - mse: 1.0302 - val_loss: 3.3229 - val_mae: 1.0826 - val_mse: 3.3229\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0401 - mae: 0.7932 - mse: 1.0401 - val_loss: 3.1463 - val_mae: 1.1371 - val_mse: 3.1463\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0508 - mae: 0.7755 - mse: 1.0508 - val_loss: 3.3473 - val_mae: 1.1459 - val_mse: 3.3473\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9828 - mae: 0.7701 - mse: 0.9828 - val_loss: 4.3495 - val_mae: 1.3336 - val_mse: 4.3495\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9962 - mae: 0.7686 - mse: 0.9962 - val_loss: 3.3037 - val_mae: 1.3115 - val_mse: 3.3037\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0578 - mae: 0.8000 - mse: 1.0578 - val_loss: 6.6101 - val_mae: 1.7828 - val_mse: 6.6101\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9764 - mae: 0.7650 - mse: 0.9764 - val_loss: 3.2193 - val_mae: 1.3317 - val_mse: 3.2193\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0533 - mae: 0.7895 - mse: 1.0533 - val_loss: 3.7731 - val_mae: 1.4517 - val_mse: 3.7731\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0329 - mae: 0.7861 - mse: 1.0329 - val_loss: 3.0456 - val_mae: 1.1080 - val_mse: 3.0456\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0144 - mae: 0.7753 - mse: 1.0144 - val_loss: 4.0276 - val_mae: 1.2077 - val_mse: 4.0276\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0258 - mae: 0.7806 - mse: 1.0258 - val_loss: 3.8146 - val_mae: 1.1625 - val_mse: 3.8146\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9913 - mae: 0.7580 - mse: 0.9913 - val_loss: 5.2754 - val_mae: 1.4767 - val_mse: 5.2754\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8941 - mae: 0.7201 - mse: 0.8941 - val_loss: 3.9675 - val_mae: 1.6233 - val_mse: 3.9675\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9995 - mae: 0.7725 - mse: 0.9995 - val_loss: 3.5668 - val_mae: 1.0894 - val_mse: 3.5668\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9414 - mae: 0.7571 - mse: 0.9414 - val_loss: 3.3640 - val_mae: 1.1077 - val_mse: 3.3640\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9342 - mae: 0.7431 - mse: 0.9342 - val_loss: 4.8143 - val_mae: 1.8619 - val_mse: 4.8143\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0414 - mae: 0.7811 - mse: 1.0414 - val_loss: 3.3637 - val_mae: 1.0732 - val_mse: 3.3637\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9833 - mae: 0.7626 - mse: 0.9833 - val_loss: 2.9168 - val_mae: 1.0727 - val_mse: 2.9168\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9634 - mae: 0.7489 - mse: 0.9634 - val_loss: 3.9269 - val_mae: 1.1825 - val_mse: 3.9269\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9556 - mae: 0.7454 - mse: 0.9556 - val_loss: 3.2363 - val_mae: 1.2579 - val_mse: 3.2363\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9312 - mae: 0.7505 - mse: 0.9312 - val_loss: 3.3226 - val_mae: 1.2456 - val_mse: 3.3226\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9957 - mae: 0.7737 - mse: 0.9957 - val_loss: 4.3486 - val_mae: 1.3064 - val_mse: 4.3486\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9567 - mae: 0.7565 - mse: 0.9567 - val_loss: 3.4830 - val_mae: 1.0852 - val_mse: 3.4830\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9035 - mae: 0.7253 - mse: 0.9035 - val_loss: 5.0849 - val_mae: 1.3818 - val_mse: 5.0849\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8869 - mae: 0.7208 - mse: 0.8869 - val_loss: 4.4965 - val_mae: 1.3528 - val_mse: 4.4965\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9549 - mae: 0.7597 - mse: 0.9549 - val_loss: 3.9601 - val_mae: 1.1202 - val_mse: 3.9601\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9313 - mae: 0.7407 - mse: 0.9313 - val_loss: 3.1241 - val_mae: 1.2028 - val_mse: 3.1241\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8260 - mae: 0.6964 - mse: 0.8260 - val_loss: 4.5696 - val_mae: 1.7355 - val_mse: 4.5696\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0288 - mae: 0.7731 - mse: 1.0288 - val_loss: 4.0255 - val_mae: 1.1559 - val_mse: 4.0255\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8791 - mae: 0.7150 - mse: 0.8791 - val_loss: 3.0422 - val_mae: 1.0790 - val_mse: 3.0422\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8708 - mae: 0.7133 - mse: 0.8708 - val_loss: 4.2594 - val_mae: 1.1966 - val_mse: 4.2594\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9184 - mae: 0.7390 - mse: 0.9184 - val_loss: 3.6288 - val_mae: 1.4342 - val_mse: 3.6288\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8823 - mae: 0.7243 - mse: 0.8823 - val_loss: 3.3977 - val_mae: 1.2137 - val_mse: 3.3977\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9210 - mae: 0.7355 - mse: 0.9210 - val_loss: 3.6437 - val_mae: 1.1385 - val_mse: 3.6437\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9080 - mae: 0.7284 - mse: 0.9080 - val_loss: 3.4434 - val_mae: 1.3418 - val_mse: 3.4434\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8680 - mae: 0.7053 - mse: 0.8680 - val_loss: 4.3378 - val_mae: 1.6267 - val_mse: 4.3378\n",
      "Kappa Score: 0.5441059876296115\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 123.3941 - mae: 7.1344 - mse: 123.3941 - val_loss: 39.8823 - val_mae: 5.3465 - val_mse: 39.8823\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 32.6298 - mae: 3.7613 - mse: 32.6298 - val_loss: 73.1957 - val_mae: 8.1480 - val_mse: 73.1957\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 22.8625 - mae: 3.8678 - mse: 22.8625 - val_loss: 4.4101 - val_mae: 1.2724 - val_mse: 4.4101\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 12.1923 - mae: 2.8361 - mse: 12.1923 - val_loss: 10.8900 - val_mae: 3.0488 - val_mse: 10.8900\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 7.8618 - mae: 2.2188 - mse: 7.8618 - val_loss: 11.7552 - val_mae: 2.1949 - val_mse: 11.7552\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 4.6016 - mae: 1.7033 - mse: 4.6016 - val_loss: 4.0780 - val_mae: 1.1194 - val_mse: 4.0780\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.2301 - mae: 1.4344 - mse: 3.2301 - val_loss: 5.0227 - val_mae: 1.4779 - val_mse: 5.0227\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.8173 - mae: 1.3235 - mse: 2.8173 - val_loss: 6.7445 - val_mae: 1.6338 - val_mse: 6.7445\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2761 - mae: 1.1935 - mse: 2.2761 - val_loss: 4.4351 - val_mae: 1.2957 - val_mse: 4.4351\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2593 - mae: 1.1971 - mse: 2.2593 - val_loss: 5.7168 - val_mae: 1.5269 - val_mse: 5.7168\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9671 - mae: 1.0966 - mse: 1.9671 - val_loss: 6.1956 - val_mae: 2.2634 - val_mse: 6.1956\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.1199 - mae: 1.1467 - mse: 2.1199 - val_loss: 3.3635 - val_mae: 1.0666 - val_mse: 3.3635\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8666 - mae: 1.0579 - mse: 1.8666 - val_loss: 2.8017 - val_mae: 1.0722 - val_mse: 2.8017\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9059 - mae: 1.0865 - mse: 1.9059 - val_loss: 5.0645 - val_mae: 1.1925 - val_mse: 5.0645\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9470 - mae: 1.0937 - mse: 1.9470 - val_loss: 2.8658 - val_mae: 1.0359 - val_mse: 2.8658\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6867 - mae: 1.0237 - mse: 1.6867 - val_loss: 3.9869 - val_mae: 1.1238 - val_mse: 3.9869\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7057 - mae: 1.0537 - mse: 1.7057 - val_loss: 4.4911 - val_mae: 1.4319 - val_mse: 4.4911\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8680 - mae: 1.0710 - mse: 1.8680 - val_loss: 4.7118 - val_mae: 1.1720 - val_mse: 4.7118\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5692 - mae: 0.9701 - mse: 1.5692 - val_loss: 6.0116 - val_mae: 1.7978 - val_mse: 6.0116\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5995 - mae: 0.9852 - mse: 1.5995 - val_loss: 3.9611 - val_mae: 1.1564 - val_mse: 3.9611\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4733 - mae: 0.9545 - mse: 1.4733 - val_loss: 3.7627 - val_mae: 1.3551 - val_mse: 3.7627\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6070 - mae: 1.0028 - mse: 1.6070 - val_loss: 3.6171 - val_mae: 1.0862 - val_mse: 3.6171\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4467 - mae: 0.9402 - mse: 1.4467 - val_loss: 2.6249 - val_mae: 0.9896 - val_mse: 2.6249\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7136 - mae: 1.0056 - mse: 1.7136 - val_loss: 4.6704 - val_mae: 1.2902 - val_mse: 4.6704\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4669 - mae: 0.9546 - mse: 1.4669 - val_loss: 2.8020 - val_mae: 1.0127 - val_mse: 2.8020\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3630 - mae: 0.9103 - mse: 1.3630 - val_loss: 3.6826 - val_mae: 1.1224 - val_mse: 3.6826\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4388 - mae: 0.9366 - mse: 1.4388 - val_loss: 4.4452 - val_mae: 1.4795 - val_mse: 4.4452\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4252 - mae: 0.9365 - mse: 1.4252 - val_loss: 5.2615 - val_mae: 1.3777 - val_mse: 5.2615\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3631 - mae: 0.9194 - mse: 1.3631 - val_loss: 2.6580 - val_mae: 1.1249 - val_mse: 2.6580\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3791 - mae: 0.9181 - mse: 1.3791 - val_loss: 6.8046 - val_mae: 2.2954 - val_mse: 6.8046\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5114 - mae: 0.9465 - mse: 1.5114 - val_loss: 2.5708 - val_mae: 1.0027 - val_mse: 2.5708\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3224 - mae: 0.8892 - mse: 1.3224 - val_loss: 4.0907 - val_mae: 1.5664 - val_mse: 4.0907\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2886 - mae: 0.8799 - mse: 1.2886 - val_loss: 5.5519 - val_mae: 1.7041 - val_mse: 5.5519\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3293 - mae: 0.8892 - mse: 1.3293 - val_loss: 3.4293 - val_mae: 1.1544 - val_mse: 3.4293\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2773 - mae: 0.8770 - mse: 1.2773 - val_loss: 3.5679 - val_mae: 1.2042 - val_mse: 3.5679\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3244 - mae: 0.8926 - mse: 1.3244 - val_loss: 3.7530 - val_mae: 1.0914 - val_mse: 3.7530\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3304 - mae: 0.8951 - mse: 1.3304 - val_loss: 2.6996 - val_mae: 0.9866 - val_mse: 2.6996\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2493 - mae: 0.8678 - mse: 1.2493 - val_loss: 5.2157 - val_mae: 1.4870 - val_mse: 5.2157\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2752 - mae: 0.8786 - mse: 1.2752 - val_loss: 2.4841 - val_mae: 1.0366 - val_mse: 2.4841\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2363 - mae: 0.8633 - mse: 1.2363 - val_loss: 4.5677 - val_mae: 1.3909 - val_mse: 4.5677\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2462 - mae: 0.8667 - mse: 1.2462 - val_loss: 2.7740 - val_mae: 0.9947 - val_mse: 2.7740\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2369 - mae: 0.8565 - mse: 1.2369 - val_loss: 3.2275 - val_mae: 1.0410 - val_mse: 3.2275\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2424 - mae: 0.8693 - mse: 1.2424 - val_loss: 2.5027 - val_mae: 0.9456 - val_mse: 2.5027\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1758 - mae: 0.8514 - mse: 1.1758 - val_loss: 2.9173 - val_mae: 1.0875 - val_mse: 2.9173\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2113 - mae: 0.8597 - mse: 1.2113 - val_loss: 3.7316 - val_mae: 1.6179 - val_mse: 3.7316\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2099 - mae: 0.8486 - mse: 1.2099 - val_loss: 2.7641 - val_mae: 1.0041 - val_mse: 2.7641\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2288 - mae: 0.8612 - mse: 1.2288 - val_loss: 2.4642 - val_mae: 0.9356 - val_mse: 2.4642\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1325 - mae: 0.8188 - mse: 1.1325 - val_loss: 4.5628 - val_mae: 1.4314 - val_mse: 4.5628\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2011 - mae: 0.8445 - mse: 1.2011 - val_loss: 3.4100 - val_mae: 1.4906 - val_mse: 3.4100\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1066 - mae: 0.8059 - mse: 1.1066 - val_loss: 6.5112 - val_mae: 1.8903 - val_mse: 6.5112\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1672 - mae: 0.8299 - mse: 1.1672 - val_loss: 2.4454 - val_mae: 0.9681 - val_mse: 2.4454\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1505 - mae: 0.8309 - mse: 1.1505 - val_loss: 4.9984 - val_mae: 1.9646 - val_mse: 4.9984\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2891 - mae: 0.8637 - mse: 1.2891 - val_loss: 3.7269 - val_mae: 1.2539 - val_mse: 3.7269\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1412 - mae: 0.8070 - mse: 1.1412 - val_loss: 2.8797 - val_mae: 1.0270 - val_mse: 2.8797\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1362 - mae: 0.8259 - mse: 1.1362 - val_loss: 2.4406 - val_mae: 0.9538 - val_mse: 2.4406\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1575 - mae: 0.8324 - mse: 1.1575 - val_loss: 2.7422 - val_mae: 1.0162 - val_mse: 2.7422\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2011 - mae: 0.8469 - mse: 1.2011 - val_loss: 2.6234 - val_mae: 1.1194 - val_mse: 2.6234\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1299 - mae: 0.8245 - mse: 1.1299 - val_loss: 7.6378 - val_mae: 2.0634 - val_mse: 7.6378\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0516 - mae: 0.7922 - mse: 1.0516 - val_loss: 3.5279 - val_mae: 1.2151 - val_mse: 3.5279\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2199 - mae: 0.8473 - mse: 1.2199 - val_loss: 4.3051 - val_mae: 1.7675 - val_mse: 4.3051\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1045 - mae: 0.8035 - mse: 1.1045 - val_loss: 2.5471 - val_mae: 0.9707 - val_mse: 2.5471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1497 - mae: 0.8285 - mse: 1.1497 - val_loss: 5.0614 - val_mae: 1.6034 - val_mse: 5.0614\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1243 - mae: 0.8168 - mse: 1.1243 - val_loss: 9.3309 - val_mae: 2.4759 - val_mse: 9.3309\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1665 - mae: 0.8141 - mse: 1.1665 - val_loss: 2.8036 - val_mae: 0.9706 - val_mse: 2.8036\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1659 - mae: 0.8235 - mse: 1.1659 - val_loss: 4.4566 - val_mae: 1.8309 - val_mse: 4.4566\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0169 - mae: 0.7769 - mse: 1.0169 - val_loss: 2.7869 - val_mae: 0.9608 - val_mse: 2.7869\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0490 - mae: 0.7868 - mse: 1.0490 - val_loss: 6.0462 - val_mae: 1.8661 - val_mse: 6.0462\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1013 - mae: 0.8043 - mse: 1.1013 - val_loss: 3.2848 - val_mae: 1.0672 - val_mse: 3.2848\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9971 - mae: 0.7735 - mse: 0.9971 - val_loss: 2.4899 - val_mae: 1.0407 - val_mse: 2.4899\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0290 - mae: 0.7769 - mse: 1.0290 - val_loss: 2.6867 - val_mae: 0.9525 - val_mse: 2.6867\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0798 - mae: 0.7972 - mse: 1.0798 - val_loss: 2.5888 - val_mae: 1.0542 - val_mse: 2.5888\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0328 - mae: 0.7836 - mse: 1.0328 - val_loss: 2.4089 - val_mae: 0.9377 - val_mse: 2.4089\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0270 - mae: 0.7897 - mse: 1.0270 - val_loss: 5.1187 - val_mae: 1.5907 - val_mse: 5.1187\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0657 - mae: 0.8063 - mse: 1.0657 - val_loss: 3.8819 - val_mae: 1.2417 - val_mse: 3.8819\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0587 - mae: 0.7843 - mse: 1.0587 - val_loss: 2.8246 - val_mae: 0.9851 - val_mse: 2.8246\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9668 - mae: 0.7555 - mse: 0.9668 - val_loss: 4.6234 - val_mae: 1.8855 - val_mse: 4.6234\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0788 - mae: 0.7945 - mse: 1.0788 - val_loss: 3.3925 - val_mae: 1.1326 - val_mse: 3.3925\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0042 - mae: 0.7663 - mse: 1.0042 - val_loss: 3.8160 - val_mae: 1.2810 - val_mse: 3.8160\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9854 - mae: 0.7672 - mse: 0.9854 - val_loss: 2.8046 - val_mae: 0.9663 - val_mse: 2.8046\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0363 - mae: 0.7727 - mse: 1.0363 - val_loss: 2.3983 - val_mae: 0.9262 - val_mse: 2.3983\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1103 - mae: 0.8189 - mse: 1.1103 - val_loss: 2.9830 - val_mae: 1.0418 - val_mse: 2.9830\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0215 - mae: 0.7765 - mse: 1.0215 - val_loss: 2.8386 - val_mae: 0.9627 - val_mse: 2.8386\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9587 - mae: 0.7596 - mse: 0.9587 - val_loss: 4.1556 - val_mae: 1.7550 - val_mse: 4.1556\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9905 - mae: 0.7636 - mse: 0.9905 - val_loss: 2.5504 - val_mae: 0.9318 - val_mse: 2.5504\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0353 - mae: 0.7743 - mse: 1.0353 - val_loss: 2.8084 - val_mae: 0.9600 - val_mse: 2.8084\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9996 - mae: 0.7633 - mse: 0.9996 - val_loss: 2.5818 - val_mae: 0.9343 - val_mse: 2.5818\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9952 - mae: 0.7618 - mse: 0.9952 - val_loss: 2.6417 - val_mae: 0.9441 - val_mse: 2.6417\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9809 - mae: 0.7576 - mse: 0.9809 - val_loss: 3.4538 - val_mae: 1.5232 - val_mse: 3.4538\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9407 - mae: 0.7465 - mse: 0.9407 - val_loss: 3.5024 - val_mae: 1.5006 - val_mse: 3.5024\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0062 - mae: 0.7630 - mse: 1.0062 - val_loss: 2.4684 - val_mae: 0.9378 - val_mse: 2.4684\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9292 - mae: 0.7337 - mse: 0.9292 - val_loss: 3.2796 - val_mae: 1.1180 - val_mse: 3.2796\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9233 - mae: 0.7298 - mse: 0.9233 - val_loss: 2.5006 - val_mae: 0.9210 - val_mse: 2.5006\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9428 - mae: 0.7502 - mse: 0.9428 - val_loss: 3.3753 - val_mae: 1.4880 - val_mse: 3.3753\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9437 - mae: 0.7458 - mse: 0.9437 - val_loss: 3.5826 - val_mae: 1.1985 - val_mse: 3.5826\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9389 - mae: 0.7425 - mse: 0.9389 - val_loss: 3.5143 - val_mae: 1.1944 - val_mse: 3.5143\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9408 - mae: 0.7477 - mse: 0.9408 - val_loss: 3.1909 - val_mae: 1.3467 - val_mse: 3.1909\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9745 - mae: 0.7546 - mse: 0.9745 - val_loss: 2.7373 - val_mae: 0.9695 - val_mse: 2.7373\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9456 - mae: 0.7399 - mse: 0.9456 - val_loss: 4.4095 - val_mae: 1.4068 - val_mse: 4.4095\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9033 - mae: 0.7261 - mse: 0.9033 - val_loss: 9.7909 - val_mae: 2.4916 - val_mse: 9.7909\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0164 - mae: 0.7522 - mse: 1.0164 - val_loss: 2.5692 - val_mae: 1.0083 - val_mse: 2.5692\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8955 - mae: 0.7249 - mse: 0.8955 - val_loss: 2.4576 - val_mae: 0.9346 - val_mse: 2.4576\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8791 - mae: 0.7153 - mse: 0.8791 - val_loss: 2.6352 - val_mae: 0.9803 - val_mse: 2.6352\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8881 - mae: 0.7211 - mse: 0.8881 - val_loss: 3.1148 - val_mae: 1.0402 - val_mse: 3.1148\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9087 - mae: 0.7196 - mse: 0.9087 - val_loss: 2.4762 - val_mae: 0.9996 - val_mse: 2.4762\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8863 - mae: 0.7274 - mse: 0.8863 - val_loss: 2.6546 - val_mae: 0.9437 - val_mse: 2.6546\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8989 - mae: 0.7280 - mse: 0.8989 - val_loss: 2.7573 - val_mae: 1.1955 - val_mse: 2.7573\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9076 - mae: 0.7270 - mse: 0.9076 - val_loss: 2.4722 - val_mae: 0.9897 - val_mse: 2.4722\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8663 - mae: 0.7159 - mse: 0.8663 - val_loss: 4.2337 - val_mae: 1.3824 - val_mse: 4.2337\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9337 - mae: 0.7413 - mse: 0.9337 - val_loss: 2.5838 - val_mae: 1.0987 - val_mse: 2.5838\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9237 - mae: 0.7270 - mse: 0.9237 - val_loss: 2.5543 - val_mae: 1.0641 - val_mse: 2.5543\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8471 - mae: 0.7010 - mse: 0.8471 - val_loss: 3.2751 - val_mae: 1.1027 - val_mse: 3.2751\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8494 - mae: 0.7018 - mse: 0.8494 - val_loss: 3.2469 - val_mae: 1.4388 - val_mse: 3.2469\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8897 - mae: 0.7115 - mse: 0.8897 - val_loss: 4.6947 - val_mae: 1.4867 - val_mse: 4.6947\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8867 - mae: 0.7088 - mse: 0.8867 - val_loss: 2.6430 - val_mae: 0.9367 - val_mse: 2.6430\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8346 - mae: 0.6883 - mse: 0.8346 - val_loss: 5.7374 - val_mae: 1.7304 - val_mse: 5.7374\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9101 - mae: 0.7217 - mse: 0.9101 - val_loss: 2.5723 - val_mae: 1.0856 - val_mse: 2.5723\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8370 - mae: 0.7064 - mse: 0.8370 - val_loss: 2.6258 - val_mae: 0.9515 - val_mse: 2.6258\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8598 - mae: 0.7060 - mse: 0.8598 - val_loss: 2.4810 - val_mae: 1.0327 - val_mse: 2.4810\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8531 - mae: 0.6941 - mse: 0.8531 - val_loss: 2.4180 - val_mae: 0.9118 - val_mse: 2.4180\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8757 - mae: 0.7072 - mse: 0.8757 - val_loss: 2.8107 - val_mae: 1.0350 - val_mse: 2.8107\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8570 - mae: 0.7034 - mse: 0.8570 - val_loss: 3.1023 - val_mae: 1.0453 - val_mse: 3.1023\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8470 - mae: 0.6996 - mse: 0.8470 - val_loss: 2.6539 - val_mae: 0.9314 - val_mse: 2.6539\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8320 - mae: 0.7007 - mse: 0.8320 - val_loss: 2.8074 - val_mae: 0.9755 - val_mse: 2.8074\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8175 - mae: 0.6963 - mse: 0.8175 - val_loss: 3.0316 - val_mae: 1.3501 - val_mse: 3.0316\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7940 - mae: 0.6763 - mse: 0.7940 - val_loss: 4.1621 - val_mae: 1.3502 - val_mse: 4.1621\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8387 - mae: 0.6983 - mse: 0.8387 - val_loss: 4.9266 - val_mae: 1.5587 - val_mse: 4.9266\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8641 - mae: 0.7098 - mse: 0.8641 - val_loss: 2.4231 - val_mae: 0.9898 - val_mse: 2.4231\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7953 - mae: 0.6752 - mse: 0.7953 - val_loss: 2.5207 - val_mae: 1.0660 - val_mse: 2.5207\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8416 - mae: 0.6974 - mse: 0.8416 - val_loss: 2.5616 - val_mae: 1.0962 - val_mse: 2.5616\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8397 - mae: 0.6934 - mse: 0.8397 - val_loss: 2.6125 - val_mae: 0.9241 - val_mse: 2.6125\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7786 - mae: 0.6783 - mse: 0.7786 - val_loss: 2.4557 - val_mae: 0.9040 - val_mse: 2.4557\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7869 - mae: 0.6774 - mse: 0.7869 - val_loss: 2.4780 - val_mae: 1.0001 - val_mse: 2.4780\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7703 - mae: 0.6573 - mse: 0.7703 - val_loss: 2.3917 - val_mae: 0.9196 - val_mse: 2.3917\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8174 - mae: 0.6766 - mse: 0.8174 - val_loss: 3.5563 - val_mae: 1.5606 - val_mse: 3.5563\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8345 - mae: 0.6898 - mse: 0.8345 - val_loss: 3.3388 - val_mae: 1.4773 - val_mse: 3.3388\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7790 - mae: 0.6759 - mse: 0.7790 - val_loss: 2.7271 - val_mae: 0.9517 - val_mse: 2.7271\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8425 - mae: 0.7096 - mse: 0.8425 - val_loss: 4.2502 - val_mae: 1.3937 - val_mse: 4.2502\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8156 - mae: 0.6863 - mse: 0.8156 - val_loss: 2.4452 - val_mae: 0.9782 - val_mse: 2.4452\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7426 - mae: 0.6568 - mse: 0.7426 - val_loss: 2.5816 - val_mae: 1.0820 - val_mse: 2.5816\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7844 - mae: 0.6644 - mse: 0.7844 - val_loss: 6.3141 - val_mae: 1.8957 - val_mse: 6.3141\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8015 - mae: 0.6653 - mse: 0.8015 - val_loss: 3.8042 - val_mae: 1.2551 - val_mse: 3.8042\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7775 - mae: 0.6746 - mse: 0.7775 - val_loss: 2.5050 - val_mae: 1.0303 - val_mse: 2.5050\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8163 - mae: 0.6828 - mse: 0.8163 - val_loss: 2.4310 - val_mae: 0.8948 - val_mse: 2.4310\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7192 - mae: 0.6451 - mse: 0.7192 - val_loss: 3.2517 - val_mae: 1.4395 - val_mse: 3.2517\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8197 - mae: 0.6765 - mse: 0.8197 - val_loss: 2.4292 - val_mae: 0.9678 - val_mse: 2.4292\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7819 - mae: 0.6672 - mse: 0.7819 - val_loss: 2.4479 - val_mae: 0.8953 - val_mse: 2.4479\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7419 - mae: 0.6502 - mse: 0.7419 - val_loss: 2.5848 - val_mae: 1.1024 - val_mse: 2.5848\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7590 - mae: 0.6649 - mse: 0.7590 - val_loss: 2.4440 - val_mae: 0.9654 - val_mse: 2.4440\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7536 - mae: 0.6626 - mse: 0.7536 - val_loss: 2.4586 - val_mae: 0.9306 - val_mse: 2.4586\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7214 - mae: 0.6388 - mse: 0.7214 - val_loss: 2.5509 - val_mae: 1.0710 - val_mse: 2.5509\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7429 - mae: 0.6508 - mse: 0.7429 - val_loss: 3.5187 - val_mae: 1.1548 - val_mse: 3.5187\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7637 - mae: 0.6582 - mse: 0.7637 - val_loss: 2.5204 - val_mae: 0.9215 - val_mse: 2.5204\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7561 - mae: 0.6636 - mse: 0.7561 - val_loss: 2.4042 - val_mae: 0.8963 - val_mse: 2.4042\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7547 - mae: 0.6580 - mse: 0.7547 - val_loss: 2.6416 - val_mae: 0.9384 - val_mse: 2.6416\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7518 - mae: 0.6537 - mse: 0.7518 - val_loss: 3.3471 - val_mae: 1.1364 - val_mse: 3.3471\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7466 - mae: 0.6653 - mse: 0.7466 - val_loss: 2.8560 - val_mae: 0.9761 - val_mse: 2.8560\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7700 - mae: 0.6709 - mse: 0.7700 - val_loss: 2.5540 - val_mae: 0.9067 - val_mse: 2.5540\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7036 - mae: 0.6383 - mse: 0.7036 - val_loss: 2.5922 - val_mae: 1.1000 - val_mse: 2.5922\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7504 - mae: 0.6621 - mse: 0.7504 - val_loss: 2.8724 - val_mae: 1.2750 - val_mse: 2.8724\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7791 - mae: 0.6764 - mse: 0.7791 - val_loss: 3.2713 - val_mae: 1.0846 - val_mse: 3.2713\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7109 - mae: 0.6384 - mse: 0.7109 - val_loss: 6.0732 - val_mae: 1.8240 - val_mse: 6.0732\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7600 - mae: 0.6535 - mse: 0.7600 - val_loss: 2.4446 - val_mae: 0.9193 - val_mse: 2.4446\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7348 - mae: 0.6512 - mse: 0.7348 - val_loss: 2.9814 - val_mae: 1.3074 - val_mse: 2.9814\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7077 - mae: 0.6337 - mse: 0.7077 - val_loss: 2.6206 - val_mae: 1.0364 - val_mse: 2.6206\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7525 - mae: 0.6546 - mse: 0.7525 - val_loss: 2.8508 - val_mae: 0.9919 - val_mse: 2.8508\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7295 - mae: 0.6483 - mse: 0.7295 - val_loss: 2.4819 - val_mae: 0.9654 - val_mse: 2.4819\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7057 - mae: 0.6252 - mse: 0.7057 - val_loss: 3.0599 - val_mae: 1.0298 - val_mse: 3.0599\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7207 - mae: 0.6481 - mse: 0.7207 - val_loss: 2.4589 - val_mae: 0.9495 - val_mse: 2.4589\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7344 - mae: 0.6525 - mse: 0.7344 - val_loss: 2.5042 - val_mae: 1.0125 - val_mse: 2.5042\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7168 - mae: 0.6352 - mse: 0.7168 - val_loss: 2.6285 - val_mae: 1.1290 - val_mse: 2.6285\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6943 - mae: 0.6370 - mse: 0.6943 - val_loss: 2.5861 - val_mae: 0.9699 - val_mse: 2.5861\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6615 - mae: 0.6090 - mse: 0.6615 - val_loss: 2.6025 - val_mae: 0.9436 - val_mse: 2.6025\n",
      "Epoch 173/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6968 - mae: 0.6295 - mse: 0.6968 - val_loss: 2.5761 - val_mae: 1.0751 - val_mse: 2.5761\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6881 - mae: 0.6307 - mse: 0.6881 - val_loss: 3.0297 - val_mae: 1.0357 - val_mse: 3.0297\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6979 - mae: 0.6399 - mse: 0.6979 - val_loss: 2.6354 - val_mae: 1.1249 - val_mse: 2.6354\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6848 - mae: 0.6256 - mse: 0.6848 - val_loss: 3.2570 - val_mae: 1.4343 - val_mse: 3.2570\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7477 - mae: 0.6452 - mse: 0.7477 - val_loss: 2.6420 - val_mae: 1.1212 - val_mse: 2.6420\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6806 - mae: 0.6161 - mse: 0.6806 - val_loss: 2.5937 - val_mae: 0.9305 - val_mse: 2.5937\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6678 - mae: 0.6170 - mse: 0.6678 - val_loss: 2.5051 - val_mae: 0.9898 - val_mse: 2.5051\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7060 - mae: 0.6344 - mse: 0.7060 - val_loss: 4.0595 - val_mae: 1.2981 - val_mse: 4.0595\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7006 - mae: 0.6313 - mse: 0.7006 - val_loss: 3.3909 - val_mae: 1.4879 - val_mse: 3.3909\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7114 - mae: 0.6395 - mse: 0.7114 - val_loss: 4.7165 - val_mae: 1.4650 - val_mse: 4.7165\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6938 - mae: 0.6334 - mse: 0.6938 - val_loss: 2.8590 - val_mae: 0.9778 - val_mse: 2.8590\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6585 - mae: 0.6164 - mse: 0.6585 - val_loss: 4.7856 - val_mae: 1.5198 - val_mse: 4.7856\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6702 - mae: 0.6257 - mse: 0.6702 - val_loss: 4.5043 - val_mae: 1.4340 - val_mse: 4.5043\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7200 - mae: 0.6482 - mse: 0.7200 - val_loss: 3.1837 - val_mae: 1.0725 - val_mse: 3.1837\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6765 - mae: 0.6220 - mse: 0.6765 - val_loss: 2.5090 - val_mae: 0.9748 - val_mse: 2.5090\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6550 - mae: 0.6079 - mse: 0.6550 - val_loss: 2.6133 - val_mae: 1.0496 - val_mse: 2.6133\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7082 - mae: 0.6414 - mse: 0.7082 - val_loss: 4.1272 - val_mae: 1.2936 - val_mse: 4.1272\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6880 - mae: 0.6222 - mse: 0.6880 - val_loss: 2.6387 - val_mae: 0.9246 - val_mse: 2.6387\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6231 - mae: 0.5996 - mse: 0.6231 - val_loss: 2.5201 - val_mae: 0.9222 - val_mse: 2.5201\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7071 - mae: 0.6335 - mse: 0.7071 - val_loss: 2.5998 - val_mae: 1.0220 - val_mse: 2.5998\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6305 - mae: 0.5965 - mse: 0.6305 - val_loss: 2.4667 - val_mae: 0.9969 - val_mse: 2.4667\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6448 - mae: 0.6027 - mse: 0.6448 - val_loss: 2.7838 - val_mae: 1.2064 - val_mse: 2.7838\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7089 - mae: 0.6364 - mse: 0.7089 - val_loss: 2.4676 - val_mae: 0.9952 - val_mse: 2.4676\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6168 - mae: 0.5961 - mse: 0.6168 - val_loss: 3.0774 - val_mae: 1.0197 - val_mse: 3.0774\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6301 - mae: 0.5962 - mse: 0.6301 - val_loss: 3.6594 - val_mae: 1.2276 - val_mse: 3.6594\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6314 - mae: 0.6058 - mse: 0.6314 - val_loss: 2.7898 - val_mae: 1.1693 - val_mse: 2.7898\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6623 - mae: 0.6155 - mse: 0.6623 - val_loss: 4.3800 - val_mae: 1.3757 - val_mse: 4.3800\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6639 - mae: 0.6137 - mse: 0.6639 - val_loss: 3.6375 - val_mae: 1.1795 - val_mse: 3.6375\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6463 - mae: 0.6042 - mse: 0.6463 - val_loss: 2.5195 - val_mae: 0.9949 - val_mse: 2.5195\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6381 - mae: 0.6130 - mse: 0.6381 - val_loss: 3.0917 - val_mae: 1.0302 - val_mse: 3.0917\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6068 - mae: 0.5900 - mse: 0.6068 - val_loss: 3.1381 - val_mae: 1.0628 - val_mse: 3.1381\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6798 - mae: 0.6253 - mse: 0.6798 - val_loss: 2.4868 - val_mae: 0.9709 - val_mse: 2.4868\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6045 - mae: 0.5903 - mse: 0.6045 - val_loss: 3.4930 - val_mae: 1.1746 - val_mse: 3.4930\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6289 - mae: 0.5991 - mse: 0.6289 - val_loss: 2.5407 - val_mae: 0.9327 - val_mse: 2.5407\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6440 - mae: 0.6092 - mse: 0.6440 - val_loss: 2.5343 - val_mae: 1.0288 - val_mse: 2.5343\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5882 - mae: 0.5800 - mse: 0.5882 - val_loss: 4.6874 - val_mae: 1.5029 - val_mse: 4.6874\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6056 - mae: 0.5854 - mse: 0.6056 - val_loss: 2.6842 - val_mae: 1.1424 - val_mse: 2.6842\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7007 - mae: 0.6362 - mse: 0.7007 - val_loss: 2.6529 - val_mae: 1.0405 - val_mse: 2.6529\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6304 - mae: 0.6002 - mse: 0.6304 - val_loss: 2.7904 - val_mae: 0.9825 - val_mse: 2.7904\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6020 - mae: 0.5936 - mse: 0.6020 - val_loss: 2.6637 - val_mae: 1.1274 - val_mse: 2.6637\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6213 - mae: 0.5936 - mse: 0.6213 - val_loss: 2.6062 - val_mae: 0.9443 - val_mse: 2.6062\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6065 - mae: 0.5861 - mse: 0.6065 - val_loss: 4.5084 - val_mae: 1.8340 - val_mse: 4.5084\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6523 - mae: 0.5989 - mse: 0.6523 - val_loss: 2.6608 - val_mae: 1.0071 - val_mse: 2.6608\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5755 - mae: 0.5768 - mse: 0.5755 - val_loss: 4.8988 - val_mae: 1.5040 - val_mse: 4.8988\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6227 - mae: 0.5923 - mse: 0.6227 - val_loss: 2.7582 - val_mae: 1.1656 - val_mse: 2.7582\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6187 - mae: 0.5825 - mse: 0.6187 - val_loss: 2.6393 - val_mae: 0.9471 - val_mse: 2.6393\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5873 - mae: 0.5877 - mse: 0.5873 - val_loss: 2.8594 - val_mae: 0.9976 - val_mse: 2.8594\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6070 - mae: 0.5896 - mse: 0.6070 - val_loss: 2.6033 - val_mae: 0.9801 - val_mse: 2.6033\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5968 - mae: 0.5790 - mse: 0.5968 - val_loss: 3.8967 - val_mae: 1.2609 - val_mse: 3.8967\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5914 - mae: 0.5748 - mse: 0.5914 - val_loss: 3.3791 - val_mae: 1.1316 - val_mse: 3.3791\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5961 - mae: 0.5877 - mse: 0.5961 - val_loss: 2.5635 - val_mae: 0.9609 - val_mse: 2.5635\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6097 - mae: 0.5847 - mse: 0.6097 - val_loss: 2.7069 - val_mae: 0.9649 - val_mse: 2.7069\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5546 - mae: 0.5587 - mse: 0.5546 - val_loss: 3.2749 - val_mae: 1.4450 - val_mse: 3.2749\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6192 - mae: 0.5936 - mse: 0.6192 - val_loss: 2.4710 - val_mae: 0.9523 - val_mse: 2.4710\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5869 - mae: 0.5832 - mse: 0.5869 - val_loss: 2.8219 - val_mae: 0.9475 - val_mse: 2.8219\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5757 - mae: 0.5706 - mse: 0.5757 - val_loss: 2.5269 - val_mae: 0.9945 - val_mse: 2.5269\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6216 - mae: 0.5955 - mse: 0.6216 - val_loss: 3.1609 - val_mae: 1.0677 - val_mse: 3.1609\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5890 - mae: 0.5802 - mse: 0.5890 - val_loss: 4.1495 - val_mae: 1.3362 - val_mse: 4.1495\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5563 - mae: 0.5597 - mse: 0.5563 - val_loss: 3.4702 - val_mae: 1.1841 - val_mse: 3.4702\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5869 - mae: 0.5726 - mse: 0.5869 - val_loss: 5.5285 - val_mae: 1.6105 - val_mse: 5.5285\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5986 - mae: 0.5757 - mse: 0.5986 - val_loss: 2.9209 - val_mae: 1.0073 - val_mse: 2.9209\n",
      "Kappa Score: 0.6834749552772809\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 212.0014 - mae: 7.6067 - mse: 212.0014 - val_loss: 189.9434 - val_mae: 12.2410 - val_mse: 189.9434\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 43.2867 - mae: 5.2653 - mse: 43.2867 - val_loss: 4.4901 - val_mae: 1.2487 - val_mse: 4.4901\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 23.3547 - mae: 3.2340 - mse: 23.3547 - val_loss: 6.4169 - val_mae: 2.0916 - val_mse: 6.4169\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 12.6859 - mae: 2.7007 - mse: 12.6859 - val_loss: 6.3174 - val_mae: 1.9620 - val_mse: 6.3174\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 6.8690 - mae: 2.0856 - mse: 6.8690 - val_loss: 4.7183 - val_mae: 1.1997 - val_mse: 4.7183\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 4.3190 - mae: 1.5762 - mse: 4.3190 - val_loss: 11.0027 - val_mae: 2.9955 - val_mse: 11.0027\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.4549 - mae: 1.4901 - mse: 3.4549 - val_loss: 4.5112 - val_mae: 1.1669 - val_mse: 4.5112\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7989 - mae: 1.3224 - mse: 2.7989 - val_loss: 11.0189 - val_mae: 2.2862 - val_mse: 11.0189\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4655 - mae: 1.2300 - mse: 2.4655 - val_loss: 9.8446 - val_mae: 2.1737 - val_mse: 9.8446\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4210 - mae: 1.2281 - mse: 2.4210 - val_loss: 7.3806 - val_mae: 1.6223 - val_mse: 7.3806\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0025 - mae: 1.1076 - mse: 2.0025 - val_loss: 6.2038 - val_mae: 1.3571 - val_mse: 6.2038\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.1912 - mae: 1.1686 - mse: 2.1912 - val_loss: 4.2653 - val_mae: 1.1380 - val_mse: 4.2653\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2659 - mae: 1.1773 - mse: 2.2659 - val_loss: 5.4236 - val_mae: 1.2716 - val_mse: 5.4236\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0160 - mae: 1.1297 - mse: 2.0160 - val_loss: 8.6955 - val_mae: 1.8434 - val_mse: 8.6955\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0421 - mae: 1.1177 - mse: 2.0421 - val_loss: 5.4101 - val_mae: 1.6407 - val_mse: 5.4101\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2070 - mae: 1.1705 - mse: 2.2070 - val_loss: 6.3332 - val_mae: 1.1409 - val_mse: 6.3332\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7102 - mae: 1.0118 - mse: 1.7102 - val_loss: 6.4707 - val_mae: 1.2321 - val_mse: 6.4707\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.1737 - mae: 1.1651 - mse: 2.1737 - val_loss: 4.7267 - val_mae: 1.4674 - val_mse: 4.7267\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7579 - mae: 1.0398 - mse: 1.7579 - val_loss: 5.8179 - val_mae: 1.5879 - val_mse: 5.8179\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7769 - mae: 1.0826 - mse: 1.7769 - val_loss: 4.0955 - val_mae: 1.0974 - val_mse: 4.0955\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6808 - mae: 1.0210 - mse: 1.6808 - val_loss: 18.0446 - val_mae: 3.2250 - val_mse: 18.0446\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.7346 - mae: 1.0193 - mse: 1.7346 - val_loss: 7.1349 - val_mae: 2.3279 - val_mse: 7.1349\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6844 - mae: 1.0110 - mse: 1.6844 - val_loss: 3.6460 - val_mae: 1.1344 - val_mse: 3.6460\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5859 - mae: 0.9861 - mse: 1.5859 - val_loss: 6.2624 - val_mae: 2.0524 - val_mse: 6.2624\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7573 - mae: 1.0451 - mse: 1.7573 - val_loss: 6.1049 - val_mae: 1.5695 - val_mse: 6.1049\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5943 - mae: 1.0065 - mse: 1.5943 - val_loss: 5.0730 - val_mae: 1.3025 - val_mse: 5.0730\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5553 - mae: 0.9825 - mse: 1.5553 - val_loss: 5.7712 - val_mae: 1.8559 - val_mse: 5.7712\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7645 - mae: 1.0263 - mse: 1.7645 - val_loss: 3.8603 - val_mae: 1.1117 - val_mse: 3.8603\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5630 - mae: 0.9780 - mse: 1.5630 - val_loss: 5.1591 - val_mae: 1.6384 - val_mse: 5.1591\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4126 - mae: 0.9454 - mse: 1.4126 - val_loss: 6.8271 - val_mae: 1.7170 - val_mse: 6.8271\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4974 - mae: 0.9747 - mse: 1.4974 - val_loss: 4.7357 - val_mae: 1.1022 - val_mse: 4.7357\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3916 - mae: 0.9246 - mse: 1.3916 - val_loss: 4.9314 - val_mae: 1.1344 - val_mse: 4.9314\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3632 - mae: 0.9149 - mse: 1.3632 - val_loss: 4.0003 - val_mae: 1.1143 - val_mse: 4.0003\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3986 - mae: 0.9348 - mse: 1.3986 - val_loss: 6.4939 - val_mae: 1.4707 - val_mse: 6.4939\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3227 - mae: 0.9071 - mse: 1.3227 - val_loss: 7.8744 - val_mae: 1.9193 - val_mse: 7.8744\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4307 - mae: 0.9305 - mse: 1.4307 - val_loss: 5.4438 - val_mae: 1.3425 - val_mse: 5.4438\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2732 - mae: 0.8809 - mse: 1.2732 - val_loss: 5.9454 - val_mae: 1.2382 - val_mse: 5.9454\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3715 - mae: 0.9166 - mse: 1.3715 - val_loss: 4.2376 - val_mae: 1.1330 - val_mse: 4.2376\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2919 - mae: 0.8991 - mse: 1.2919 - val_loss: 4.6518 - val_mae: 1.2401 - val_mse: 4.6518\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3147 - mae: 0.9139 - mse: 1.3147 - val_loss: 3.8985 - val_mae: 1.2396 - val_mse: 3.8985\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3460 - mae: 0.9099 - mse: 1.3460 - val_loss: 4.1423 - val_mae: 1.0810 - val_mse: 4.1423\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2206 - mae: 0.8761 - mse: 1.2206 - val_loss: 4.1537 - val_mae: 1.3396 - val_mse: 4.1537\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2271 - mae: 0.8539 - mse: 1.2271 - val_loss: 3.7900 - val_mae: 1.1365 - val_mse: 3.7900\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2794 - mae: 0.8876 - mse: 1.2794 - val_loss: 4.5431 - val_mae: 1.5669 - val_mse: 4.5431\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2589 - mae: 0.8835 - mse: 1.2589 - val_loss: 4.5275 - val_mae: 1.2249 - val_mse: 4.5275\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2121 - mae: 0.8671 - mse: 1.2121 - val_loss: 4.7704 - val_mae: 1.0766 - val_mse: 4.7704\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2125 - mae: 0.8513 - mse: 1.2125 - val_loss: 7.5198 - val_mae: 2.3878 - val_mse: 7.5198\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2813 - mae: 0.9003 - mse: 1.2813 - val_loss: 4.6202 - val_mae: 1.1348 - val_mse: 4.6202\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2030 - mae: 0.8566 - mse: 1.2030 - val_loss: 4.0937 - val_mae: 1.1463 - val_mse: 4.0937\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2076 - mae: 0.8528 - mse: 1.2076 - val_loss: 7.8522 - val_mae: 1.8441 - val_mse: 7.8522\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1956 - mae: 0.8378 - mse: 1.1956 - val_loss: 6.9709 - val_mae: 1.7932 - val_mse: 6.9709\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2182 - mae: 0.8625 - mse: 1.2182 - val_loss: 3.5088 - val_mae: 1.0924 - val_mse: 3.5088\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2586 - mae: 0.8877 - mse: 1.2586 - val_loss: 5.0825 - val_mae: 1.8551 - val_mse: 5.0825\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2195 - mae: 0.8546 - mse: 1.2195 - val_loss: 6.3590 - val_mae: 1.7748 - val_mse: 6.3590\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1928 - mae: 0.8505 - mse: 1.1928 - val_loss: 3.2300 - val_mae: 1.0759 - val_mse: 3.2300\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2119 - mae: 0.8598 - mse: 1.2119 - val_loss: 3.1713 - val_mae: 1.0459 - val_mse: 3.1713\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1801 - mae: 0.8469 - mse: 1.1801 - val_loss: 3.7445 - val_mae: 1.0292 - val_mse: 3.7445\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2166 - mae: 0.8758 - mse: 1.2166 - val_loss: 3.7245 - val_mae: 1.1046 - val_mse: 3.7245\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1404 - mae: 0.8359 - mse: 1.1404 - val_loss: 5.6882 - val_mae: 1.5756 - val_mse: 5.6882\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1384 - mae: 0.8397 - mse: 1.1384 - val_loss: 3.5312 - val_mae: 1.0080 - val_mse: 3.5312\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1421 - mae: 0.8384 - mse: 1.1421 - val_loss: 4.1235 - val_mae: 1.5770 - val_mse: 4.1235\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1492 - mae: 0.8424 - mse: 1.1492 - val_loss: 6.6555 - val_mae: 1.8273 - val_mse: 6.6555\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1862 - mae: 0.8544 - mse: 1.1862 - val_loss: 3.8500 - val_mae: 1.0183 - val_mse: 3.8500\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0591 - mae: 0.8158 - mse: 1.0591 - val_loss: 2.8864 - val_mae: 0.9875 - val_mse: 2.8864\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1129 - mae: 0.8243 - mse: 1.1129 - val_loss: 3.6113 - val_mae: 1.2645 - val_mse: 3.6113\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0548 - mae: 0.7975 - mse: 1.0548 - val_loss: 4.2289 - val_mae: 1.2891 - val_mse: 4.2289\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1395 - mae: 0.8217 - mse: 1.1395 - val_loss: 3.7752 - val_mae: 1.4012 - val_mse: 3.7752\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0904 - mae: 0.8175 - mse: 1.0904 - val_loss: 2.9252 - val_mae: 0.9847 - val_mse: 2.9252\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0852 - mae: 0.8139 - mse: 1.0852 - val_loss: 2.9769 - val_mae: 1.0140 - val_mse: 2.9769\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0895 - mae: 0.8181 - mse: 1.0895 - val_loss: 3.1823 - val_mae: 0.9912 - val_mse: 3.1823\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0354 - mae: 0.7976 - mse: 1.0354 - val_loss: 4.3562 - val_mae: 1.3614 - val_mse: 4.3562\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1046 - mae: 0.8295 - mse: 1.1046 - val_loss: 4.5156 - val_mae: 1.7454 - val_mse: 4.5156\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1460 - mae: 0.8367 - mse: 1.1460 - val_loss: 3.4615 - val_mae: 1.3253 - val_mse: 3.4615\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0604 - mae: 0.8058 - mse: 1.0604 - val_loss: 3.8287 - val_mae: 1.2451 - val_mse: 3.8287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1147 - mae: 0.8164 - mse: 1.1147 - val_loss: 6.3992 - val_mae: 1.7955 - val_mse: 6.3992\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0812 - mae: 0.8067 - mse: 1.0812 - val_loss: 3.0695 - val_mae: 0.9956 - val_mse: 3.0695\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0758 - mae: 0.8003 - mse: 1.0758 - val_loss: 3.1269 - val_mae: 1.0285 - val_mse: 3.1269\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0262 - mae: 0.7954 - mse: 1.0262 - val_loss: 3.6368 - val_mae: 1.0774 - val_mse: 3.6368\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0522 - mae: 0.8120 - mse: 1.0522 - val_loss: 3.1921 - val_mae: 1.0190 - val_mse: 3.1921\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1095 - mae: 0.8184 - mse: 1.1095 - val_loss: 3.6268 - val_mae: 1.1017 - val_mse: 3.6268\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0200 - mae: 0.7830 - mse: 1.0200 - val_loss: 4.4514 - val_mae: 1.2729 - val_mse: 4.4514\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0523 - mae: 0.8117 - mse: 1.0523 - val_loss: 4.6053 - val_mae: 1.2842 - val_mse: 4.6053\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0504 - mae: 0.7966 - mse: 1.0504 - val_loss: 3.0974 - val_mae: 0.9849 - val_mse: 3.0974\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0059 - mae: 0.7876 - mse: 1.0059 - val_loss: 5.0365 - val_mae: 1.4673 - val_mse: 5.0365\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0685 - mae: 0.8039 - mse: 1.0685 - val_loss: 3.1574 - val_mae: 0.9890 - val_mse: 3.1574\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0420 - mae: 0.7880 - mse: 1.0420 - val_loss: 3.1943 - val_mae: 1.0249 - val_mse: 3.1943\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1057 - mae: 0.8194 - mse: 1.1057 - val_loss: 5.2181 - val_mae: 1.2942 - val_mse: 5.2181\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0209 - mae: 0.7859 - mse: 1.0209 - val_loss: 5.4474 - val_mae: 1.5125 - val_mse: 5.4474\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9943 - mae: 0.7627 - mse: 0.9943 - val_loss: 3.2096 - val_mae: 1.0052 - val_mse: 3.2096\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9783 - mae: 0.7747 - mse: 0.9783 - val_loss: 3.9506 - val_mae: 1.1498 - val_mse: 3.9506\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0296 - mae: 0.7837 - mse: 1.0296 - val_loss: 4.0974 - val_mae: 1.4110 - val_mse: 4.0974\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.4615 - mae: 0.9979 - mse: 1.461 - 0s 1ms/step - loss: 0.9219 - mae: 0.7432 - mse: 0.9219 - val_loss: 4.5028 - val_mae: 1.6380 - val_mse: 4.5028\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0063 - mae: 0.7767 - mse: 1.0063 - val_loss: 3.1478 - val_mae: 0.9920 - val_mse: 3.1478\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9848 - mae: 0.7742 - mse: 0.9848 - val_loss: 6.1956 - val_mae: 1.6477 - val_mse: 6.1956\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9407 - mae: 0.7573 - mse: 0.9407 - val_loss: 3.8804 - val_mae: 1.4993 - val_mse: 3.8804\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9683 - mae: 0.7645 - mse: 0.9683 - val_loss: 3.0435 - val_mae: 1.1236 - val_mse: 3.0435\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9815 - mae: 0.7789 - mse: 0.9815 - val_loss: 5.3230 - val_mae: 1.8569 - val_mse: 5.3230\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9987 - mae: 0.7758 - mse: 0.9987 - val_loss: 4.1270 - val_mae: 1.1658 - val_mse: 4.1270\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9259 - mae: 0.7493 - mse: 0.9259 - val_loss: 3.1741 - val_mae: 1.0079 - val_mse: 3.1741\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9452 - mae: 0.7399 - mse: 0.9452 - val_loss: 3.0500 - val_mae: 1.0120 - val_mse: 3.0500\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0219 - mae: 0.7807 - mse: 1.0219 - val_loss: 3.0287 - val_mae: 1.0691 - val_mse: 3.0287\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9483 - mae: 0.7656 - mse: 0.9483 - val_loss: 3.1172 - val_mae: 1.0048 - val_mse: 3.1172\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9258 - mae: 0.7399 - mse: 0.9258 - val_loss: 3.8352 - val_mae: 1.2141 - val_mse: 3.8352\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8927 - mae: 0.7278 - mse: 0.8927 - val_loss: 3.2010 - val_mae: 0.9861 - val_mse: 3.2010\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9414 - mae: 0.7521 - mse: 0.9414 - val_loss: 4.4060 - val_mae: 1.2267 - val_mse: 4.4060\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9542 - mae: 0.7533 - mse: 0.9542 - val_loss: 2.9865 - val_mae: 1.0419 - val_mse: 2.9865\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9506 - mae: 0.7576 - mse: 0.9506 - val_loss: 3.8732 - val_mae: 1.1721 - val_mse: 3.8732\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8490 - mae: 0.7167 - mse: 0.8490 - val_loss: 5.9201 - val_mae: 1.6930 - val_mse: 5.9201\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9508 - mae: 0.7589 - mse: 0.9508 - val_loss: 4.6523 - val_mae: 1.4104 - val_mse: 4.6523\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9290 - mae: 0.7430 - mse: 0.9290 - val_loss: 3.5917 - val_mae: 1.0928 - val_mse: 3.5917\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8898 - mae: 0.7312 - mse: 0.8898 - val_loss: 4.1208 - val_mae: 1.6234 - val_mse: 4.1208\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8839 - mae: 0.7280 - mse: 0.8839 - val_loss: 3.1346 - val_mae: 1.0737 - val_mse: 3.1346\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9421 - mae: 0.7596 - mse: 0.9421 - val_loss: 3.0899 - val_mae: 0.9959 - val_mse: 3.0899\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8934 - mae: 0.7308 - mse: 0.8934 - val_loss: 4.3066 - val_mae: 1.3750 - val_mse: 4.3066\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9168 - mae: 0.7380 - mse: 0.9168 - val_loss: 3.7113 - val_mae: 1.1634 - val_mse: 3.7113\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8434 - mae: 0.7128 - mse: 0.8434 - val_loss: 3.6758 - val_mae: 1.1724 - val_mse: 3.6758\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8956 - mae: 0.7320 - mse: 0.8956 - val_loss: 2.9616 - val_mae: 0.9769 - val_mse: 2.9616\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8822 - mae: 0.7359 - mse: 0.8822 - val_loss: 3.1706 - val_mae: 1.0247 - val_mse: 3.1706\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8951 - mae: 0.7289 - mse: 0.8951 - val_loss: 3.3937 - val_mae: 1.0558 - val_mse: 3.3937\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9090 - mae: 0.7422 - mse: 0.9090 - val_loss: 5.3894 - val_mae: 1.5578 - val_mse: 5.3894\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8657 - mae: 0.7176 - mse: 0.8657 - val_loss: 4.1318 - val_mae: 1.2278 - val_mse: 4.1318\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9052 - mae: 0.7390 - mse: 0.9052 - val_loss: 3.1278 - val_mae: 1.0333 - val_mse: 3.1278\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8884 - mae: 0.7199 - mse: 0.8884 - val_loss: 4.5863 - val_mae: 1.4404 - val_mse: 4.5863\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8594 - mae: 0.7162 - mse: 0.8594 - val_loss: 3.1268 - val_mae: 0.9922 - val_mse: 3.1268\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8891 - mae: 0.7221 - mse: 0.8891 - val_loss: 3.5426 - val_mae: 1.1420 - val_mse: 3.5426\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8641 - mae: 0.7275 - mse: 0.8641 - val_loss: 2.8173 - val_mae: 1.0791 - val_mse: 2.8173\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8289 - mae: 0.7038 - mse: 0.8289 - val_loss: 3.5963 - val_mae: 1.4252 - val_mse: 3.5963\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8547 - mae: 0.7145 - mse: 0.8547 - val_loss: 3.3509 - val_mae: 1.1090 - val_mse: 3.3509\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8966 - mae: 0.7403 - mse: 0.8966 - val_loss: 3.8940 - val_mae: 1.2155 - val_mse: 3.8940\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8494 - mae: 0.7053 - mse: 0.8494 - val_loss: 3.1918 - val_mae: 1.1236 - val_mse: 3.1918\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8791 - mae: 0.7234 - mse: 0.8791 - val_loss: 2.7254 - val_mae: 1.0075 - val_mse: 2.7254\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8016 - mae: 0.7054 - mse: 0.8016 - val_loss: 3.7200 - val_mae: 1.2397 - val_mse: 3.7200\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9078 - mae: 0.7301 - mse: 0.9078 - val_loss: 2.5960 - val_mae: 0.9613 - val_mse: 2.5960\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8067 - mae: 0.6928 - mse: 0.8067 - val_loss: 2.9224 - val_mae: 1.0012 - val_mse: 2.9224\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7879 - mae: 0.6917 - mse: 0.7879 - val_loss: 2.7206 - val_mae: 0.9646 - val_mse: 2.7206\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9093 - mae: 0.7368 - mse: 0.9093 - val_loss: 3.2548 - val_mae: 1.0769 - val_mse: 3.2548\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8657 - mae: 0.7187 - mse: 0.8657 - val_loss: 2.9760 - val_mae: 1.0195 - val_mse: 2.9760\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7838 - mae: 0.6866 - mse: 0.7838 - val_loss: 4.9089 - val_mae: 1.4912 - val_mse: 4.9089\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8347 - mae: 0.7001 - mse: 0.8347 - val_loss: 2.9328 - val_mae: 0.9919 - val_mse: 2.9328\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8505 - mae: 0.7088 - mse: 0.8505 - val_loss: 2.9520 - val_mae: 0.9860 - val_mse: 2.9520\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8448 - mae: 0.7097 - mse: 0.8448 - val_loss: 2.7990 - val_mae: 1.1011 - val_mse: 2.7990\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7423 - mae: 0.6710 - mse: 0.7423 - val_loss: 3.1567 - val_mae: 1.3523 - val_mse: 3.1567\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8024 - mae: 0.6963 - mse: 0.8024 - val_loss: 4.3074 - val_mae: 1.7672 - val_mse: 4.3074\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9201 - mae: 0.7200 - mse: 0.9201 - val_loss: 2.7725 - val_mae: 0.9712 - val_mse: 2.7725\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7916 - mae: 0.6931 - mse: 0.7916 - val_loss: 2.7511 - val_mae: 1.0552 - val_mse: 2.7511\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7893 - mae: 0.6864 - mse: 0.7893 - val_loss: 2.9845 - val_mae: 1.0039 - val_mse: 2.9845\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7765 - mae: 0.6829 - mse: 0.7765 - val_loss: 3.7827 - val_mae: 1.2091 - val_mse: 3.7827\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8123 - mae: 0.6891 - mse: 0.8123 - val_loss: 2.7914 - val_mae: 1.0394 - val_mse: 2.7914\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8111 - mae: 0.6978 - mse: 0.8111 - val_loss: 3.4322 - val_mae: 1.0805 - val_mse: 3.4322\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7586 - mae: 0.6694 - mse: 0.7586 - val_loss: 3.5304 - val_mae: 1.1646 - val_mse: 3.5304\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7943 - mae: 0.6825 - mse: 0.7943 - val_loss: 4.0151 - val_mae: 1.2459 - val_mse: 4.0151\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7853 - mae: 0.6852 - mse: 0.7853 - val_loss: 3.3068 - val_mae: 1.3851 - val_mse: 3.3068\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8063 - mae: 0.7043 - mse: 0.8063 - val_loss: 2.8945 - val_mae: 1.2230 - val_mse: 2.8945\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7599 - mae: 0.6734 - mse: 0.7599 - val_loss: 4.8728 - val_mae: 1.4273 - val_mse: 4.8728\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7328 - mae: 0.6610 - mse: 0.7328 - val_loss: 2.8195 - val_mae: 1.0831 - val_mse: 2.8195\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7606 - mae: 0.6755 - mse: 0.7606 - val_loss: 2.9748 - val_mae: 1.0001 - val_mse: 2.9748\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7510 - mae: 0.6663 - mse: 0.7510 - val_loss: 3.1066 - val_mae: 1.0192 - val_mse: 3.1066\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7885 - mae: 0.6889 - mse: 0.7885 - val_loss: 4.1040 - val_mae: 1.2768 - val_mse: 4.1040\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7662 - mae: 0.6738 - mse: 0.7662 - val_loss: 2.9647 - val_mae: 1.0102 - val_mse: 2.9647\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6974 - mae: 0.6401 - mse: 0.6974 - val_loss: 4.4545 - val_mae: 1.3998 - val_mse: 4.4545\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8026 - mae: 0.6747 - mse: 0.8026 - val_loss: 3.6361 - val_mae: 1.1664 - val_mse: 3.6361\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7310 - mae: 0.6602 - mse: 0.7310 - val_loss: 2.7138 - val_mae: 1.0030 - val_mse: 2.7138\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7129 - mae: 0.6428 - mse: 0.7129 - val_loss: 3.2438 - val_mae: 1.3378 - val_mse: 3.2438\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7608 - mae: 0.6720 - mse: 0.7608 - val_loss: 3.2137 - val_mae: 1.0727 - val_mse: 3.2137\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7424 - mae: 0.6608 - mse: 0.7424 - val_loss: 4.7772 - val_mae: 1.4558 - val_mse: 4.7772\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7417 - mae: 0.6680 - mse: 0.7417 - val_loss: 3.0814 - val_mae: 1.0220 - val_mse: 3.0814\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7102 - mae: 0.6360 - mse: 0.7102 - val_loss: 3.2145 - val_mae: 1.2955 - val_mse: 3.2145\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7561 - mae: 0.6690 - mse: 0.7561 - val_loss: 2.9432 - val_mae: 0.9940 - val_mse: 2.9432\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7109 - mae: 0.6575 - mse: 0.7109 - val_loss: 3.1770 - val_mae: 1.3337 - val_mse: 3.1770\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7141 - mae: 0.6551 - mse: 0.7141 - val_loss: 3.2441 - val_mae: 1.0816 - val_mse: 3.2441\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7162 - mae: 0.6565 - mse: 0.7162 - val_loss: 3.5274 - val_mae: 1.1262 - val_mse: 3.5274\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7131 - mae: 0.6450 - mse: 0.7131 - val_loss: 3.7953 - val_mae: 1.1563 - val_mse: 3.7953\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6944 - mae: 0.6421 - mse: 0.6944 - val_loss: 3.0295 - val_mae: 0.9998 - val_mse: 3.0295\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7202 - mae: 0.6518 - mse: 0.7202 - val_loss: 2.8338 - val_mae: 1.1087 - val_mse: 2.8338\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7574 - mae: 0.6675 - mse: 0.7574 - val_loss: 3.1096 - val_mae: 1.0077 - val_mse: 3.1096\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6769 - mae: 0.6304 - mse: 0.6769 - val_loss: 3.5267 - val_mae: 1.0987 - val_mse: 3.5267\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7069 - mae: 0.6500 - mse: 0.7069 - val_loss: 2.9464 - val_mae: 0.9931 - val_mse: 2.9464\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6996 - mae: 0.6389 - mse: 0.6996 - val_loss: 3.0374 - val_mae: 0.9938 - val_mse: 3.0374\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7374 - mae: 0.6529 - mse: 0.7374 - val_loss: 3.7610 - val_mae: 1.1577 - val_mse: 3.7610\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6964 - mae: 0.6480 - mse: 0.6964 - val_loss: 4.3125 - val_mae: 1.2176 - val_mse: 4.3125\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6594 - mae: 0.6243 - mse: 0.6594 - val_loss: 3.6755 - val_mae: 1.4935 - val_mse: 3.6755\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7002 - mae: 0.6384 - mse: 0.7002 - val_loss: 3.2420 - val_mae: 1.2548 - val_mse: 3.2420\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6637 - mae: 0.6300 - mse: 0.6637 - val_loss: 4.0453 - val_mae: 1.2710 - val_mse: 4.0453\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7252 - mae: 0.6487 - mse: 0.7252 - val_loss: 3.2402 - val_mae: 1.2386 - val_mse: 3.2402\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7056 - mae: 0.6421 - mse: 0.7056 - val_loss: 4.0793 - val_mae: 1.2640 - val_mse: 4.0793\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6943 - mae: 0.6407 - mse: 0.6943 - val_loss: 3.0884 - val_mae: 1.0060 - val_mse: 3.0884\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6553 - mae: 0.6318 - mse: 0.6553 - val_loss: 3.0851 - val_mae: 1.0129 - val_mse: 3.0851\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6884 - mae: 0.6329 - mse: 0.6884 - val_loss: 2.9308 - val_mae: 1.0382 - val_mse: 2.9308\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6971 - mae: 0.6259 - mse: 0.6971 - val_loss: 4.8420 - val_mae: 1.3925 - val_mse: 4.8420\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6513 - mae: 0.6132 - mse: 0.6513 - val_loss: 4.2874 - val_mae: 1.3046 - val_mse: 4.2874\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6607 - mae: 0.6272 - mse: 0.6607 - val_loss: 3.1516 - val_mae: 1.2963 - val_mse: 3.1516\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7118 - mae: 0.6362 - mse: 0.7118 - val_loss: 5.5394 - val_mae: 1.6592 - val_mse: 5.5394\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6551 - mae: 0.6217 - mse: 0.6551 - val_loss: 3.0445 - val_mae: 1.2937 - val_mse: 3.0445\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6204 - mae: 0.5992 - mse: 0.6204 - val_loss: 5.3943 - val_mae: 1.6374 - val_mse: 5.3943\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7135 - mae: 0.6474 - mse: 0.7135 - val_loss: 2.9192 - val_mae: 1.0149 - val_mse: 2.9192\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6451 - mae: 0.6210 - mse: 0.6451 - val_loss: 4.2813 - val_mae: 1.2362 - val_mse: 4.2813\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6848 - mae: 0.6333 - mse: 0.6848 - val_loss: 4.1556 - val_mae: 1.3159 - val_mse: 4.1556\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6531 - mae: 0.6154 - mse: 0.6531 - val_loss: 5.1539 - val_mae: 1.5422 - val_mse: 5.1539\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6699 - mae: 0.6264 - mse: 0.6699 - val_loss: 2.8785 - val_mae: 1.0424 - val_mse: 2.8785\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6789 - mae: 0.6329 - mse: 0.6789 - val_loss: 3.0446 - val_mae: 0.9988 - val_mse: 3.0446\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6366 - mae: 0.6135 - mse: 0.6366 - val_loss: 2.8707 - val_mae: 1.0993 - val_mse: 2.8707\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6565 - mae: 0.6194 - mse: 0.6565 - val_loss: 2.8224 - val_mae: 0.9853 - val_mse: 2.8224\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6438 - mae: 0.6055 - mse: 0.6438 - val_loss: 2.8085 - val_mae: 1.0291 - val_mse: 2.8085\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6743 - mae: 0.6117 - mse: 0.6743 - val_loss: 2.9053 - val_mae: 1.1921 - val_mse: 2.9053\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6551 - mae: 0.6230 - mse: 0.6551 - val_loss: 4.4391 - val_mae: 1.4013 - val_mse: 4.4391\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6078 - mae: 0.5990 - mse: 0.6078 - val_loss: 5.3765 - val_mae: 1.6304 - val_mse: 5.3765\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6638 - mae: 0.6210 - mse: 0.6638 - val_loss: 2.7312 - val_mae: 0.9878 - val_mse: 2.7312\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6576 - mae: 0.6219 - mse: 0.6576 - val_loss: 2.8154 - val_mae: 0.9938 - val_mse: 2.8154\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6521 - mae: 0.6151 - mse: 0.6521 - val_loss: 4.1871 - val_mae: 1.3347 - val_mse: 4.1871\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6190 - mae: 0.6037 - mse: 0.6190 - val_loss: 2.8237 - val_mae: 0.9803 - val_mse: 2.8237\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6278 - mae: 0.6045 - mse: 0.6278 - val_loss: 2.8018 - val_mae: 1.0138 - val_mse: 2.8018\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6149 - mae: 0.5966 - mse: 0.6149 - val_loss: 2.6099 - val_mae: 0.9914 - val_mse: 2.6099\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6491 - mae: 0.6170 - mse: 0.6491 - val_loss: 2.8391 - val_mae: 1.0138 - val_mse: 2.8391\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6236 - mae: 0.6051 - mse: 0.6236 - val_loss: 3.0441 - val_mae: 1.0347 - val_mse: 3.0441\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6886 - mae: 0.6289 - mse: 0.6886 - val_loss: 2.6869 - val_mae: 1.1121 - val_mse: 2.6869\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6131 - mae: 0.6066 - mse: 0.6131 - val_loss: 3.0522 - val_mae: 1.0109 - val_mse: 3.0522\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6516 - mae: 0.6155 - mse: 0.6516 - val_loss: 2.9353 - val_mae: 1.1522 - val_mse: 2.9353\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5683 - mae: 0.5744 - mse: 0.5683 - val_loss: 3.0601 - val_mae: 1.2222 - val_mse: 3.0601\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6480 - mae: 0.6144 - mse: 0.6480 - val_loss: 2.7693 - val_mae: 0.9930 - val_mse: 2.7693\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5769 - mae: 0.5843 - mse: 0.5769 - val_loss: 3.1677 - val_mae: 1.2540 - val_mse: 3.1677\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6498 - mae: 0.6134 - mse: 0.6498 - val_loss: 2.9868 - val_mae: 1.0163 - val_mse: 2.9868\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6054 - mae: 0.5976 - mse: 0.6054 - val_loss: 3.0542 - val_mae: 1.0195 - val_mse: 3.0542\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6035 - mae: 0.5906 - mse: 0.6035 - val_loss: 3.5671 - val_mae: 1.1402 - val_mse: 3.5671\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6331 - mae: 0.6058 - mse: 0.6331 - val_loss: 2.9404 - val_mae: 1.0186 - val_mse: 2.9404\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5462 - mae: 0.5618 - mse: 0.5462 - val_loss: 4.4601 - val_mae: 1.4256 - val_mse: 4.4601\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6337 - mae: 0.6003 - mse: 0.6337 - val_loss: 4.9344 - val_mae: 1.5380 - val_mse: 4.9344\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6040 - mae: 0.6005 - mse: 0.6040 - val_loss: 2.8642 - val_mae: 1.0434 - val_mse: 2.8642\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5843 - mae: 0.5815 - mse: 0.5843 - val_loss: 2.9321 - val_mae: 1.0637 - val_mse: 2.9321\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5638 - mae: 0.5696 - mse: 0.5638 - val_loss: 3.6945 - val_mae: 1.2416 - val_mse: 3.6945\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5954 - mae: 0.5936 - mse: 0.5954 - val_loss: 2.5158 - val_mae: 0.9973 - val_mse: 2.5158\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5768 - mae: 0.5912 - mse: 0.5768 - val_loss: 2.8548 - val_mae: 1.0123 - val_mse: 2.8548\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6040 - mae: 0.5942 - mse: 0.6040 - val_loss: 2.7770 - val_mae: 1.0289 - val_mse: 2.7770\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5775 - mae: 0.5840 - mse: 0.5775 - val_loss: 3.1311 - val_mae: 1.0368 - val_mse: 3.1311\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5786 - mae: 0.5790 - mse: 0.5786 - val_loss: 4.0120 - val_mae: 1.2584 - val_mse: 4.0120\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5819 - mae: 0.5901 - mse: 0.5819 - val_loss: 2.8122 - val_mae: 1.0084 - val_mse: 2.8122\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5683 - mae: 0.5769 - mse: 0.5683 - val_loss: 2.7425 - val_mae: 1.1406 - val_mse: 2.7425\n",
      "Epoch 237/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5609 - mae: 0.5792 - mse: 0.5609 - val_loss: 3.5749 - val_mae: 1.1534 - val_mse: 3.5749\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5742 - mae: 0.5838 - mse: 0.5742 - val_loss: 2.8688 - val_mae: 1.0204 - val_mse: 2.8688\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5844 - mae: 0.5805 - mse: 0.5844 - val_loss: 3.1548 - val_mae: 1.0617 - val_mse: 3.1548\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5739 - mae: 0.5690 - mse: 0.5739 - val_loss: 2.8845 - val_mae: 1.0664 - val_mse: 2.8845\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5826 - mae: 0.5853 - mse: 0.5826 - val_loss: 3.4046 - val_mae: 1.1204 - val_mse: 3.4046\n",
      "Epoch 242/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5806 - mae: 0.5849 - mse: 0.5806 - val_loss: 3.3987 - val_mae: 1.0992 - val_mse: 3.3987\n",
      "Epoch 243/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5725 - mae: 0.5756 - mse: 0.5725 - val_loss: 2.9426 - val_mae: 1.0205 - val_mse: 2.9426\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5317 - mae: 0.5568 - mse: 0.5317 - val_loss: 2.9982 - val_mae: 1.2431 - val_mse: 2.9982\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5917 - mae: 0.5865 - mse: 0.5917 - val_loss: 2.8730 - val_mae: 1.1569 - val_mse: 2.8730\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5336 - mae: 0.5589 - mse: 0.5336 - val_loss: 2.8772 - val_mae: 1.2282 - val_mse: 2.8772\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5685 - mae: 0.5783 - mse: 0.5685 - val_loss: 3.3364 - val_mae: 1.1454 - val_mse: 3.3364\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5381 - mae: 0.5628 - mse: 0.5381 - val_loss: 4.7084 - val_mae: 1.5033 - val_mse: 4.7084\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5572 - mae: 0.5577 - mse: 0.5572 - val_loss: 2.8170 - val_mae: 1.0473 - val_mse: 2.8170\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5783 - mae: 0.5843 - mse: 0.5783 - val_loss: 2.9155 - val_mae: 1.1573 - val_mse: 2.9155\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5319 - mae: 0.5547 - mse: 0.5319 - val_loss: 5.5231 - val_mae: 1.5965 - val_mse: 5.5231\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5530 - mae: 0.5566 - mse: 0.5530 - val_loss: 3.9137 - val_mae: 1.5462 - val_mse: 3.9137\n",
      "Epoch 253/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6330 - mae: 0.5862 - mse: 0.6330 - val_loss: 2.6548 - val_mae: 0.9842 - val_mse: 2.6548\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5112 - mae: 0.5549 - mse: 0.5112 - val_loss: 3.2336 - val_mae: 1.1074 - val_mse: 3.2336\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5069 - mae: 0.5442 - mse: 0.5069 - val_loss: 3.4311 - val_mae: 1.4367 - val_mse: 3.4311\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5341 - mae: 0.5540 - mse: 0.5341 - val_loss: 2.9776 - val_mae: 1.2429 - val_mse: 2.9776\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5269 - mae: 0.5504 - mse: 0.5269 - val_loss: 4.1678 - val_mae: 1.3373 - val_mse: 4.1678\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5493 - mae: 0.5679 - mse: 0.5493 - val_loss: 2.7373 - val_mae: 1.0619 - val_mse: 2.7373\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5179 - mae: 0.5445 - mse: 0.5179 - val_loss: 3.1846 - val_mae: 1.1010 - val_mse: 3.1846\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5361 - mae: 0.5598 - mse: 0.5361 - val_loss: 2.6914 - val_mae: 0.9962 - val_mse: 2.6914\n",
      "Epoch 261/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4970 - mae: 0.5363 - mse: 0.4970 - val_loss: 2.9163 - val_mae: 1.1795 - val_mse: 2.9163\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5196 - mae: 0.5439 - mse: 0.5196 - val_loss: 4.1452 - val_mae: 1.3184 - val_mse: 4.1452\n",
      "Epoch 263/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5222 - mae: 0.5470 - mse: 0.5222 - val_loss: 2.9702 - val_mae: 1.1734 - val_mse: 2.9702\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4915 - mae: 0.5299 - mse: 0.4915 - val_loss: 2.9055 - val_mae: 1.0530 - val_mse: 2.9055\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4895 - mae: 0.5397 - mse: 0.4895 - val_loss: 3.3555 - val_mae: 1.1090 - val_mse: 3.3555\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5233 - mae: 0.5489 - mse: 0.5233 - val_loss: 2.8933 - val_mae: 1.0227 - val_mse: 2.8933\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4911 - mae: 0.5382 - mse: 0.4911 - val_loss: 2.6084 - val_mae: 0.9996 - val_mse: 2.6084\n",
      "Epoch 268/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5192 - mae: 0.5495 - mse: 0.5192 - val_loss: 4.4955 - val_mae: 1.4287 - val_mse: 4.4955\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4929 - mae: 0.5353 - mse: 0.4929 - val_loss: 3.1327 - val_mae: 1.0502 - val_mse: 3.1327\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4875 - mae: 0.5401 - mse: 0.4875 - val_loss: 2.9636 - val_mae: 1.0926 - val_mse: 2.9636\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5370 - mae: 0.5581 - mse: 0.5370 - val_loss: 2.6721 - val_mae: 1.0670 - val_mse: 2.6721\n",
      "Epoch 272/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4532 - mae: 0.5054 - mse: 0.4532 - val_loss: 3.3531 - val_mae: 1.1590 - val_mse: 3.3531\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4759 - mae: 0.5307 - mse: 0.4759 - val_loss: 4.1453 - val_mae: 1.3498 - val_mse: 4.1453\n",
      "Epoch 274/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5098 - mae: 0.5417 - mse: 0.5098 - val_loss: 2.7117 - val_mae: 1.0156 - val_mse: 2.7117\n",
      "Epoch 275/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4786 - mae: 0.5257 - mse: 0.4786 - val_loss: 3.4990 - val_mae: 1.2021 - val_mse: 3.4990\n",
      "Epoch 276/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5058 - mae: 0.5474 - mse: 0.5058 - val_loss: 3.7305 - val_mae: 1.1845 - val_mse: 3.7305\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4334 - mae: 0.5083 - mse: 0.4334 - val_loss: 2.7425 - val_mae: 0.9979 - val_mse: 2.7425\n",
      "Epoch 278/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4540 - mae: 0.5163 - mse: 0.4540 - val_loss: 2.8825 - val_mae: 1.2194 - val_mse: 2.8825\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4924 - mae: 0.5394 - mse: 0.4924 - val_loss: 6.0430 - val_mae: 1.6732 - val_mse: 6.0430\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5230 - mae: 0.5331 - mse: 0.5230 - val_loss: 2.6839 - val_mae: 1.0397 - val_mse: 2.6839\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4505 - mae: 0.5126 - mse: 0.4505 - val_loss: 2.7861 - val_mae: 1.0556 - val_mse: 2.7861\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4419 - mae: 0.5070 - mse: 0.4419 - val_loss: 2.8739 - val_mae: 1.0277 - val_mse: 2.8739\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4746 - mae: 0.5247 - mse: 0.4746 - val_loss: 3.5173 - val_mae: 1.1573 - val_mse: 3.5173\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4646 - mae: 0.5264 - mse: 0.4646 - val_loss: 2.6388 - val_mae: 1.0416 - val_mse: 2.6388\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5035 - mae: 0.5354 - mse: 0.5035 - val_loss: 2.7961 - val_mae: 1.0583 - val_mse: 2.7961\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4722 - mae: 0.5222 - mse: 0.4722 - val_loss: 2.8227 - val_mae: 1.0495 - val_mse: 2.8227\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4349 - mae: 0.5059 - mse: 0.4349 - val_loss: 3.3912 - val_mae: 1.3121 - val_mse: 3.3912\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4940 - mae: 0.5274 - mse: 0.4940 - val_loss: 2.8354 - val_mae: 1.0559 - val_mse: 2.8354\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4843 - mae: 0.5261 - mse: 0.4843 - val_loss: 2.8141 - val_mae: 1.0259 - val_mse: 2.8141\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4331 - mae: 0.5025 - mse: 0.4331 - val_loss: 3.7938 - val_mae: 1.1896 - val_mse: 3.7938\n",
      "Epoch 291/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4740 - mae: 0.5184 - mse: 0.4740 - val_loss: 2.8278 - val_mae: 1.0374 - val_mse: 2.8278\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4728 - mae: 0.5182 - mse: 0.4728 - val_loss: 3.3984 - val_mae: 1.4232 - val_mse: 3.3984\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4619 - mae: 0.5027 - mse: 0.4619 - val_loss: 3.1819 - val_mae: 1.0586 - val_mse: 3.1819\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4678 - mae: 0.5123 - mse: 0.4678 - val_loss: 3.3158 - val_mae: 1.0601 - val_mse: 3.3158\n",
      "Epoch 295/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4724 - mae: 0.5281 - mse: 0.4724 - val_loss: 2.7502 - val_mae: 1.0356 - val_mse: 2.7502\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4315 - mae: 0.5024 - mse: 0.4315 - val_loss: 3.5485 - val_mae: 1.1919 - val_mse: 3.5485\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4665 - mae: 0.5206 - mse: 0.4665 - val_loss: 2.9928 - val_mae: 1.0197 - val_mse: 2.9928\n",
      "Epoch 298/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4250 - mae: 0.4965 - mse: 0.4250 - val_loss: 2.7568 - val_mae: 1.0493 - val_mse: 2.7568\n",
      "Epoch 299/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4480 - mae: 0.5141 - mse: 0.4480 - val_loss: 2.9698 - val_mae: 1.1285 - val_mse: 2.9698\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4374 - mae: 0.5030 - mse: 0.4374 - val_loss: 3.5768 - val_mae: 1.1625 - val_mse: 3.5768\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4262 - mae: 0.4933 - mse: 0.4262 - val_loss: 4.4831 - val_mae: 1.4053 - val_mse: 4.4831\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4533 - mae: 0.5045 - mse: 0.4533 - val_loss: 2.8104 - val_mae: 1.0447 - val_mse: 2.8104\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4587 - mae: 0.5070 - mse: 0.4587 - val_loss: 3.1915 - val_mae: 1.0746 - val_mse: 3.1915\n",
      "Epoch 304/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4276 - mae: 0.4964 - mse: 0.4276 - val_loss: 2.9739 - val_mae: 1.1773 - val_mse: 2.9739\n",
      "Epoch 305/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4176 - mae: 0.4965 - mse: 0.4176 - val_loss: 2.7675 - val_mae: 1.1309 - val_mse: 2.7675\n",
      "Epoch 306/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4434 - mae: 0.5038 - mse: 0.4434 - val_loss: 3.0632 - val_mae: 1.0671 - val_mse: 3.0632\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4354 - mae: 0.5022 - mse: 0.4354 - val_loss: 2.8853 - val_mae: 1.0200 - val_mse: 2.8853\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4545 - mae: 0.5135 - mse: 0.4545 - val_loss: 3.9903 - val_mae: 1.2803 - val_mse: 3.9903\n",
      "Epoch 309/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3981 - mae: 0.4814 - mse: 0.3981 - val_loss: 2.7007 - val_mae: 1.0432 - val_mse: 2.7007\n",
      "Epoch 310/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4356 - mae: 0.4971 - mse: 0.4356 - val_loss: 2.7710 - val_mae: 1.0471 - val_mse: 2.7710\n",
      "Epoch 311/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4257 - mae: 0.4991 - mse: 0.4257 - val_loss: 3.0598 - val_mae: 1.0475 - val_mse: 3.0598\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4466 - mae: 0.5038 - mse: 0.4466 - val_loss: 2.8114 - val_mae: 1.0817 - val_mse: 2.8114\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4102 - mae: 0.4905 - mse: 0.4102 - val_loss: 4.2182 - val_mae: 1.3190 - val_mse: 4.2182\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4270 - mae: 0.4995 - mse: 0.4270 - val_loss: 3.2518 - val_mae: 1.1042 - val_mse: 3.2518\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4046 - mae: 0.4975 - mse: 0.4046 - val_loss: 3.8462 - val_mae: 1.2446 - val_mse: 3.8462\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4190 - mae: 0.4935 - mse: 0.4190 - val_loss: 3.0056 - val_mae: 1.2346 - val_mse: 3.0056\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4151 - mae: 0.4877 - mse: 0.4151 - val_loss: 2.8402 - val_mae: 1.0472 - val_mse: 2.8402\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3986 - mae: 0.4786 - mse: 0.3986 - val_loss: 3.1640 - val_mae: 1.0847 - val_mse: 3.1640\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4012 - mae: 0.4768 - mse: 0.4012 - val_loss: 3.9186 - val_mae: 1.2989 - val_mse: 3.9186\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4060 - mae: 0.4824 - mse: 0.4060 - val_loss: 3.0176 - val_mae: 1.1062 - val_mse: 3.0176\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3846 - mae: 0.4606 - mse: 0.3846 - val_loss: 3.0967 - val_mae: 1.3317 - val_mse: 3.0967\n",
      "Epoch 322/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4409 - mae: 0.4940 - mse: 0.4409 - val_loss: 3.5103 - val_mae: 1.1776 - val_mse: 3.5103\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4056 - mae: 0.4839 - mse: 0.4056 - val_loss: 2.8608 - val_mae: 1.0331 - val_mse: 2.8608\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4073 - mae: 0.4833 - mse: 0.4073 - val_loss: 3.6309 - val_mae: 1.2159 - val_mse: 3.6309\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3992 - mae: 0.4791 - mse: 0.3992 - val_loss: 3.0392 - val_mae: 1.0266 - val_mse: 3.0392\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4527 - mae: 0.5078 - mse: 0.4527 - val_loss: 2.7504 - val_mae: 1.0451 - val_mse: 2.7504\n",
      "Epoch 327/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3666 - mae: 0.4564 - mse: 0.3666 - val_loss: 2.7370 - val_mae: 1.0925 - val_mse: 2.7370\n",
      "Epoch 328/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3918 - mae: 0.4801 - mse: 0.3918 - val_loss: 3.6318 - val_mae: 1.1578 - val_mse: 3.6318\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5971 - mae: 0.6426 - mse: 0.597 - 0s 1ms/step - loss: 0.3985 - mae: 0.4810 - mse: 0.3985 - val_loss: 3.1844 - val_mae: 1.0812 - val_mse: 3.1844\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4002 - mae: 0.4792 - mse: 0.4002 - val_loss: 2.9193 - val_mae: 1.0307 - val_mse: 2.9193\n",
      "Kappa Score: 0.6131659206101683\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 95.9032 - mae: 4.6331 - mse: 95.9032 - val_loss: 17.0559 - val_mae: 3.8648 - val_mse: 17.0559\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 17.8588 - mae: 3.6842 - mse: 17.8588 - val_loss: 4.0442 - val_mae: 1.3569 - val_mse: 4.0442\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 12.2135 - mae: 2.2785 - mse: 12.2135 - val_loss: 4.1777 - val_mae: 1.2552 - val_mse: 4.1777\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 6.2299 - mae: 1.9471 - mse: 6.2299 - val_loss: 9.0565 - val_mae: 2.7871 - val_mse: 9.0565\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 5.3748 - mae: 1.8719 - mse: 5.3748 - val_loss: 4.5195 - val_mae: 1.1895 - val_mse: 4.5195\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.7400 - mae: 1.5234 - mse: 3.7400 - val_loss: 5.3981 - val_mae: 1.5080 - val_mse: 5.3981\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.1615 - mae: 1.4535 - mse: 3.1615 - val_loss: 10.3863 - val_mae: 2.4886 - val_mse: 10.3863\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7568 - mae: 1.2960 - mse: 2.7568 - val_loss: 7.5009 - val_mae: 2.0252 - val_mse: 7.5009\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4967 - mae: 1.2651 - mse: 2.4967 - val_loss: 3.8782 - val_mae: 1.1767 - val_mse: 3.8782\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2743 - mae: 1.2013 - mse: 2.2743 - val_loss: 8.2183 - val_mae: 1.9745 - val_mse: 8.2183\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0551 - mae: 1.1402 - mse: 2.0551 - val_loss: 5.5384 - val_mae: 1.6016 - val_mse: 5.5384\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.1227 - mae: 1.1537 - mse: 2.1227 - val_loss: 6.4404 - val_mae: 1.7707 - val_mse: 6.4404\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9027 - mae: 1.0604 - mse: 1.9027 - val_loss: 3.2588 - val_mae: 1.3607 - val_mse: 3.2588\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6733 - mae: 1.0173 - mse: 1.6733 - val_loss: 9.7773 - val_mae: 1.6918 - val_mse: 9.7773\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.8849 - mae: 1.0625 - mse: 1.8849 - val_loss: 3.3879 - val_mae: 1.4463 - val_mse: 3.3879\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.7322 - mae: 1.0419 - mse: 1.7322 - val_loss: 5.6436 - val_mae: 1.1594 - val_mse: 5.6436\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4987 - mae: 0.9612 - mse: 1.4987 - val_loss: 2.5926 - val_mae: 1.0639 - val_mse: 2.5926\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6104 - mae: 0.9942 - mse: 1.6104 - val_loss: 10.4566 - val_mae: 2.3233 - val_mse: 10.4566\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5683 - mae: 0.9793 - mse: 1.5683 - val_loss: 3.4376 - val_mae: 1.1866 - val_mse: 3.4376\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5252 - mae: 0.9750 - mse: 1.5252 - val_loss: 4.4134 - val_mae: 1.4540 - val_mse: 4.4134\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.5036 - mae: 0.9591 - mse: 1.5036 - val_loss: 7.0015 - val_mae: 1.8784 - val_mse: 7.0015\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.6156 - mae: 0.9923 - mse: 1.6156 - val_loss: 6.6142 - val_mae: 1.9673 - val_mse: 6.6142\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4831 - mae: 0.9445 - mse: 1.4831 - val_loss: 3.8000 - val_mae: 1.1996 - val_mse: 3.8000\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4504 - mae: 0.9427 - mse: 1.4504 - val_loss: 2.5869 - val_mae: 1.0323 - val_mse: 2.5869\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3882 - mae: 0.9201 - mse: 1.3882 - val_loss: 4.8245 - val_mae: 1.2507 - val_mse: 4.8245\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3835 - mae: 0.9202 - mse: 1.3835 - val_loss: 3.2901 - val_mae: 1.4021 - val_mse: 3.2901\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.4424 - mae: 0.9305 - mse: 1.4424 - val_loss: 3.8354 - val_mae: 1.2605 - val_mse: 3.8354\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3337 - mae: 0.9010 - mse: 1.3337 - val_loss: 6.1188 - val_mae: 1.8452 - val_mse: 6.1188\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3870 - mae: 0.9140 - mse: 1.3870 - val_loss: 4.8475 - val_mae: 1.3382 - val_mse: 4.8475\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3869 - mae: 0.9268 - mse: 1.3869 - val_loss: 2.7260 - val_mae: 1.1476 - val_mse: 2.7260\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3065 - mae: 0.9054 - mse: 1.3065 - val_loss: 5.7392 - val_mae: 1.2485 - val_mse: 5.7392\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2649 - mae: 0.8795 - mse: 1.2649 - val_loss: 5.2323 - val_mae: 1.6354 - val_mse: 5.2323\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2226 - mae: 0.8662 - mse: 1.2226 - val_loss: 4.6123 - val_mae: 1.6167 - val_mse: 4.6123\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3566 - mae: 0.9198 - mse: 1.3566 - val_loss: 4.9107 - val_mae: 1.9463 - val_mse: 4.9107\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3209 - mae: 0.8905 - mse: 1.3209 - val_loss: 3.5889 - val_mae: 1.2006 - val_mse: 3.5889\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2952 - mae: 0.8972 - mse: 1.2952 - val_loss: 3.4020 - val_mae: 1.4397 - val_mse: 3.4020\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2523 - mae: 0.8715 - mse: 1.2523 - val_loss: 3.9451 - val_mae: 1.1005 - val_mse: 3.9451\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2614 - mae: 0.8845 - mse: 1.2614 - val_loss: 6.5577 - val_mae: 1.8962 - val_mse: 6.5577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3351 - mae: 0.8971 - mse: 1.3351 - val_loss: 3.7046 - val_mae: 1.1814 - val_mse: 3.7046\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2157 - mae: 0.8565 - mse: 1.2157 - val_loss: 3.2244 - val_mae: 1.1778 - val_mse: 3.2244\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1895 - mae: 0.8557 - mse: 1.1895 - val_loss: 5.4928 - val_mae: 2.0340 - val_mse: 5.4928\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1861 - mae: 0.8380 - mse: 1.1861 - val_loss: 2.5243 - val_mae: 1.0676 - val_mse: 2.5243\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.3152 - mae: 0.9004 - mse: 1.3152 - val_loss: 5.4748 - val_mae: 1.5528 - val_mse: 5.4748\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1397 - mae: 0.8336 - mse: 1.1397 - val_loss: 3.6749 - val_mae: 1.2370 - val_mse: 3.6749\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1763 - mae: 0.8470 - mse: 1.1763 - val_loss: 3.6727 - val_mae: 1.5307 - val_mse: 3.6727\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1843 - mae: 0.8441 - mse: 1.1843 - val_loss: 2.9480 - val_mae: 1.1520 - val_mse: 2.9480\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1390 - mae: 0.8234 - mse: 1.1390 - val_loss: 6.9288 - val_mae: 2.0433 - val_mse: 6.9288\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.2301 - mae: 0.8457 - mse: 1.2301 - val_loss: 2.8845 - val_mae: 1.0331 - val_mse: 2.8845\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1809 - mae: 0.8463 - mse: 1.1809 - val_loss: 2.7655 - val_mae: 1.1145 - val_mse: 2.7655\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1472 - mae: 0.8258 - mse: 1.1472 - val_loss: 3.4067 - val_mae: 1.3375 - val_mse: 3.4067\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1253 - mae: 0.8204 - mse: 1.1253 - val_loss: 2.8706 - val_mae: 1.0847 - val_mse: 2.8706\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1498 - mae: 0.8383 - mse: 1.1498 - val_loss: 3.2827 - val_mae: 1.2723 - val_mse: 3.2827\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1947 - mae: 0.8468 - mse: 1.1947 - val_loss: 2.5707 - val_mae: 1.0916 - val_mse: 2.5707\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1544 - mae: 0.8385 - mse: 1.1544 - val_loss: 3.1279 - val_mae: 1.0528 - val_mse: 3.1279\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0600 - mae: 0.7965 - mse: 1.0600 - val_loss: 2.8368 - val_mae: 1.2307 - val_mse: 2.8368\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1637 - mae: 0.8467 - mse: 1.1637 - val_loss: 3.4638 - val_mae: 1.3234 - val_mse: 3.4638\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1432 - mae: 0.8308 - mse: 1.1432 - val_loss: 2.8969 - val_mae: 1.0477 - val_mse: 2.8969\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0992 - mae: 0.8239 - mse: 1.0992 - val_loss: 4.8924 - val_mae: 1.4893 - val_mse: 4.8924\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1075 - mae: 0.8110 - mse: 1.1075 - val_loss: 2.9336 - val_mae: 1.0708 - val_mse: 2.9336\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1003 - mae: 0.8175 - mse: 1.1003 - val_loss: 4.3318 - val_mae: 1.3337 - val_mse: 4.3318\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0636 - mae: 0.8005 - mse: 1.0636 - val_loss: 2.5081 - val_mae: 0.9964 - val_mse: 2.5081\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0215 - mae: 0.7805 - mse: 1.0215 - val_loss: 2.5821 - val_mae: 1.0825 - val_mse: 2.5821\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0792 - mae: 0.7977 - mse: 1.0792 - val_loss: 6.0736 - val_mae: 1.8203 - val_mse: 6.0736\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1306 - mae: 0.8170 - mse: 1.1306 - val_loss: 2.6021 - val_mae: 1.1174 - val_mse: 2.6021\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0553 - mae: 0.7840 - mse: 1.0553 - val_loss: 2.8099 - val_mae: 1.0344 - val_mse: 2.8099\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.1325 - mae: 0.8221 - mse: 1.1325 - val_loss: 2.8940 - val_mae: 1.0744 - val_mse: 2.8940\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9949 - mae: 0.7772 - mse: 0.9949 - val_loss: 2.6484 - val_mae: 1.0279 - val_mse: 2.6484\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0107 - mae: 0.7681 - mse: 1.0107 - val_loss: 4.8296 - val_mae: 1.5317 - val_mse: 4.8296\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0150 - mae: 0.7780 - mse: 1.0150 - val_loss: 3.3319 - val_mae: 1.2539 - val_mse: 3.3319\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9861 - mae: 0.7641 - mse: 0.9861 - val_loss: 3.3385 - val_mae: 1.2090 - val_mse: 3.3385\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0480 - mae: 0.7918 - mse: 1.0480 - val_loss: 2.8238 - val_mae: 1.0262 - val_mse: 2.8238\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9826 - mae: 0.7714 - mse: 0.9826 - val_loss: 2.8946 - val_mae: 1.0657 - val_mse: 2.8946\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9555 - mae: 0.7653 - mse: 0.9555 - val_loss: 3.4260 - val_mae: 1.4284 - val_mse: 3.4260\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0173 - mae: 0.7771 - mse: 1.0173 - val_loss: 4.7006 - val_mae: 1.8938 - val_mse: 4.7006\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0721 - mae: 0.7983 - mse: 1.0721 - val_loss: 2.7197 - val_mae: 1.1220 - val_mse: 2.7197\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9768 - mae: 0.7669 - mse: 0.9768 - val_loss: 3.5971 - val_mae: 1.5461 - val_mse: 3.5971\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9983 - mae: 0.7671 - mse: 0.9983 - val_loss: 2.5673 - val_mae: 1.0158 - val_mse: 2.5673\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9924 - mae: 0.7695 - mse: 0.9924 - val_loss: 5.2036 - val_mae: 1.6557 - val_mse: 5.2036\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0298 - mae: 0.7873 - mse: 1.0298 - val_loss: 2.8014 - val_mae: 1.1739 - val_mse: 2.8014\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9691 - mae: 0.7607 - mse: 0.9691 - val_loss: 4.4660 - val_mae: 1.4504 - val_mse: 4.4660\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9267 - mae: 0.7419 - mse: 0.9267 - val_loss: 2.6235 - val_mae: 1.0113 - val_mse: 2.6235\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0038 - mae: 0.7742 - mse: 1.0038 - val_loss: 3.8593 - val_mae: 1.3134 - val_mse: 3.8593\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9619 - mae: 0.7557 - mse: 0.9619 - val_loss: 4.3479 - val_mae: 1.4209 - val_mse: 4.3479\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9493 - mae: 0.7532 - mse: 0.9493 - val_loss: 2.9523 - val_mae: 1.2132 - val_mse: 2.9523\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9381 - mae: 0.7495 - mse: 0.9381 - val_loss: 3.4744 - val_mae: 1.2100 - val_mse: 3.4744\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9608 - mae: 0.7515 - mse: 0.9608 - val_loss: 3.6457 - val_mae: 1.5611 - val_mse: 3.6457\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.0591 - mae: 0.7949 - mse: 1.0591 - val_loss: 2.7347 - val_mae: 1.1772 - val_mse: 2.7347\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9792 - mae: 0.7519 - mse: 0.9792 - val_loss: 2.9273 - val_mae: 1.0469 - val_mse: 2.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9747 - mae: 0.7540 - mse: 0.9747 - val_loss: 3.9378 - val_mae: 1.3081 - val_mse: 3.9378\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9144 - mae: 0.7395 - mse: 0.9144 - val_loss: 5.7430 - val_mae: 1.7540 - val_mse: 5.7430\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9613 - mae: 0.7546 - mse: 0.9613 - val_loss: 3.4824 - val_mae: 1.1956 - val_mse: 3.4824\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9228 - mae: 0.7547 - mse: 0.9228 - val_loss: 2.9074 - val_mae: 1.0688 - val_mse: 2.9074\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9850 - mae: 0.7619 - mse: 0.9850 - val_loss: 2.9138 - val_mae: 1.0801 - val_mse: 2.9138\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9281 - mae: 0.7374 - mse: 0.9281 - val_loss: 2.5100 - val_mae: 1.0050 - val_mse: 2.5100\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9172 - mae: 0.7279 - mse: 0.9172 - val_loss: 2.9173 - val_mae: 1.2145 - val_mse: 2.9173\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9464 - mae: 0.7591 - mse: 0.9464 - val_loss: 3.2983 - val_mae: 1.1501 - val_mse: 3.2983\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8804 - mae: 0.7168 - mse: 0.8804 - val_loss: 3.1932 - val_mae: 1.3530 - val_mse: 3.1932\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9040 - mae: 0.7225 - mse: 0.9040 - val_loss: 6.9100 - val_mae: 1.9840 - val_mse: 6.9100\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9112 - mae: 0.7141 - mse: 0.9112 - val_loss: 3.9546 - val_mae: 1.6612 - val_mse: 3.9546\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9296 - mae: 0.7283 - mse: 0.9296 - val_loss: 2.7304 - val_mae: 1.0255 - val_mse: 2.7304\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8217 - mae: 0.6945 - mse: 0.8217 - val_loss: 4.4609 - val_mae: 1.5117 - val_mse: 4.4609\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9202 - mae: 0.7349 - mse: 0.9202 - val_loss: 3.4422 - val_mae: 1.4602 - val_mse: 3.4422\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8768 - mae: 0.7182 - mse: 0.8768 - val_loss: 2.6966 - val_mae: 1.0863 - val_mse: 2.6966\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8985 - mae: 0.7317 - mse: 0.8985 - val_loss: 2.6234 - val_mae: 1.0300 - val_mse: 2.6234\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8878 - mae: 0.7253 - mse: 0.8878 - val_loss: 2.7353 - val_mae: 1.1194 - val_mse: 2.7353\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.9589 - mae: 0.7417 - mse: 0.9589 - val_loss: 2.5452 - val_mae: 1.0310 - val_mse: 2.5452\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8741 - mae: 0.7181 - mse: 0.8741 - val_loss: 3.1253 - val_mae: 1.2999 - val_mse: 3.1253\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8633 - mae: 0.7156 - mse: 0.8633 - val_loss: 3.8818 - val_mae: 1.5564 - val_mse: 3.8818\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8653 - mae: 0.7140 - mse: 0.8653 - val_loss: 3.5860 - val_mae: 1.2547 - val_mse: 3.5860\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8583 - mae: 0.7103 - mse: 0.8583 - val_loss: 2.6900 - val_mae: 1.1326 - val_mse: 2.6900\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8886 - mae: 0.7260 - mse: 0.8886 - val_loss: 4.1577 - val_mae: 1.3650 - val_mse: 4.1577\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8680 - mae: 0.7148 - mse: 0.8680 - val_loss: 2.6301 - val_mae: 1.0274 - val_mse: 2.6301\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8782 - mae: 0.7221 - mse: 0.8782 - val_loss: 4.0025 - val_mae: 1.3537 - val_mse: 4.0025\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8378 - mae: 0.6987 - mse: 0.8378 - val_loss: 2.6141 - val_mae: 1.0596 - val_mse: 2.6141\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8614 - mae: 0.7142 - mse: 0.8614 - val_loss: 2.8074 - val_mae: 1.0688 - val_mse: 2.8074\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8798 - mae: 0.7180 - mse: 0.8798 - val_loss: 3.8124 - val_mae: 1.2831 - val_mse: 3.8124\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8219 - mae: 0.6982 - mse: 0.8219 - val_loss: 3.3307 - val_mae: 1.4237 - val_mse: 3.3307\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8337 - mae: 0.6959 - mse: 0.8337 - val_loss: 2.8711 - val_mae: 1.0517 - val_mse: 2.8711\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8424 - mae: 0.6993 - mse: 0.8424 - val_loss: 3.2996 - val_mae: 1.4335 - val_mse: 3.2996\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7998 - mae: 0.6880 - mse: 0.7998 - val_loss: 3.1912 - val_mae: 1.3650 - val_mse: 3.1912\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8338 - mae: 0.7073 - mse: 0.8338 - val_loss: 2.9363 - val_mae: 1.2803 - val_mse: 2.9363\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8508 - mae: 0.7063 - mse: 0.8508 - val_loss: 3.5490 - val_mae: 1.2437 - val_mse: 3.5490\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7796 - mae: 0.6810 - mse: 0.7796 - val_loss: 3.4412 - val_mae: 1.1922 - val_mse: 3.4412\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7984 - mae: 0.6863 - mse: 0.7984 - val_loss: 2.7709 - val_mae: 1.2113 - val_mse: 2.7709\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7883 - mae: 0.6746 - mse: 0.7883 - val_loss: 3.5227 - val_mae: 1.2092 - val_mse: 3.5227\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8288 - mae: 0.7083 - mse: 0.8288 - val_loss: 3.4589 - val_mae: 1.5129 - val_mse: 3.4589\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7826 - mae: 0.6697 - mse: 0.7826 - val_loss: 2.6317 - val_mae: 1.0778 - val_mse: 2.6317\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8622 - mae: 0.7112 - mse: 0.8622 - val_loss: 2.8376 - val_mae: 1.2073 - val_mse: 2.8376\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7549 - mae: 0.6716 - mse: 0.7549 - val_loss: 2.7692 - val_mae: 1.0197 - val_mse: 2.7692\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8033 - mae: 0.6969 - mse: 0.8033 - val_loss: 2.7381 - val_mae: 1.1451 - val_mse: 2.7381\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7699 - mae: 0.6660 - mse: 0.7699 - val_loss: 3.1596 - val_mae: 1.1151 - val_mse: 3.1596\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8366 - mae: 0.6991 - mse: 0.8366 - val_loss: 2.7675 - val_mae: 1.0544 - val_mse: 2.7675\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7912 - mae: 0.6827 - mse: 0.7912 - val_loss: 2.5208 - val_mae: 1.0547 - val_mse: 2.5208\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8058 - mae: 0.6850 - mse: 0.8058 - val_loss: 4.0751 - val_mae: 1.3902 - val_mse: 4.0751\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7427 - mae: 0.6675 - mse: 0.7427 - val_loss: 2.7734 - val_mae: 1.0171 - val_mse: 2.7734\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8027 - mae: 0.6871 - mse: 0.8027 - val_loss: 2.8197 - val_mae: 1.0445 - val_mse: 2.8197\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8068 - mae: 0.6849 - mse: 0.8068 - val_loss: 3.2738 - val_mae: 1.1270 - val_mse: 3.2738\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7556 - mae: 0.6700 - mse: 0.7556 - val_loss: 2.8578 - val_mae: 1.1670 - val_mse: 2.8578\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7327 - mae: 0.6597 - mse: 0.7327 - val_loss: 2.5028 - val_mae: 0.9821 - val_mse: 2.5028\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7221 - mae: 0.6640 - mse: 0.7221 - val_loss: 4.2912 - val_mae: 1.3572 - val_mse: 4.2912\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7875 - mae: 0.6746 - mse: 0.7875 - val_loss: 2.6570 - val_mae: 1.1446 - val_mse: 2.6570\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7460 - mae: 0.6598 - mse: 0.7460 - val_loss: 3.4445 - val_mae: 1.4085 - val_mse: 3.4445\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7620 - mae: 0.6714 - mse: 0.7620 - val_loss: 2.6912 - val_mae: 1.1179 - val_mse: 2.6912\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7203 - mae: 0.6549 - mse: 0.7203 - val_loss: 2.5796 - val_mae: 0.9878 - val_mse: 2.5796\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7152 - mae: 0.6493 - mse: 0.7152 - val_loss: 2.6625 - val_mae: 1.0505 - val_mse: 2.6625\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6825 - mae: 0.6423 - mse: 0.6825 - val_loss: 2.6371 - val_mae: 1.0671 - val_mse: 2.6371\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7561 - mae: 0.6617 - mse: 0.7561 - val_loss: 3.0315 - val_mae: 1.1105 - val_mse: 3.0315\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.8951 - mae: 0.7240 - mse: 0.8951 - val_loss: 4.1031 - val_mae: 1.3204 - val_mse: 4.1031\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7488 - mae: 0.6584 - mse: 0.7488 - val_loss: 2.9328 - val_mae: 1.3062 - val_mse: 2.9328\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7251 - mae: 0.6506 - mse: 0.7251 - val_loss: 4.1809 - val_mae: 1.3194 - val_mse: 4.1809\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7228 - mae: 0.6515 - mse: 0.7228 - val_loss: 2.7252 - val_mae: 1.1254 - val_mse: 2.7252\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7311 - mae: 0.6480 - mse: 0.7311 - val_loss: 2.5475 - val_mae: 0.9938 - val_mse: 2.5475\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7215 - mae: 0.6571 - mse: 0.7215 - val_loss: 2.6666 - val_mae: 1.0220 - val_mse: 2.6666\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6776 - mae: 0.6296 - mse: 0.6776 - val_loss: 2.7846 - val_mae: 1.0555 - val_mse: 2.7846\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7129 - mae: 0.6456 - mse: 0.7129 - val_loss: 2.6564 - val_mae: 1.1531 - val_mse: 2.6564\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7208 - mae: 0.6502 - mse: 0.7208 - val_loss: 2.5922 - val_mae: 1.0209 - val_mse: 2.5922\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7029 - mae: 0.6442 - mse: 0.7029 - val_loss: 5.1597 - val_mae: 1.5047 - val_mse: 5.1597\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6792 - mae: 0.6240 - mse: 0.6792 - val_loss: 3.5750 - val_mae: 1.2198 - val_mse: 3.5750\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7032 - mae: 0.6391 - mse: 0.7032 - val_loss: 3.1014 - val_mae: 1.0475 - val_mse: 3.1014\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6829 - mae: 0.6304 - mse: 0.6829 - val_loss: 2.5646 - val_mae: 1.0034 - val_mse: 2.5646\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6869 - mae: 0.6395 - mse: 0.6869 - val_loss: 2.6047 - val_mae: 1.0397 - val_mse: 2.6047\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6755 - mae: 0.6318 - mse: 0.6755 - val_loss: 2.9965 - val_mae: 1.0685 - val_mse: 2.9965\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6687 - mae: 0.6275 - mse: 0.6687 - val_loss: 2.6983 - val_mae: 1.0179 - val_mse: 2.6983\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.7039 - mae: 0.6430 - mse: 0.7039 - val_loss: 3.2896 - val_mae: 1.1350 - val_mse: 3.2896\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6866 - mae: 0.6334 - mse: 0.6866 - val_loss: 2.9261 - val_mae: 1.0578 - val_mse: 2.9261\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6677 - mae: 0.6301 - mse: 0.6677 - val_loss: 4.2529 - val_mae: 1.4441 - val_mse: 4.2529\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6933 - mae: 0.6409 - mse: 0.6933 - val_loss: 2.9968 - val_mae: 1.2917 - val_mse: 2.9968\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6636 - mae: 0.6275 - mse: 0.6636 - val_loss: 3.1125 - val_mae: 1.1123 - val_mse: 3.1125\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6371 - mae: 0.6067 - mse: 0.6371 - val_loss: 2.7336 - val_mae: 1.1197 - val_mse: 2.7336\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6556 - mae: 0.6192 - mse: 0.6556 - val_loss: 2.9226 - val_mae: 1.0647 - val_mse: 2.9226\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6401 - mae: 0.6086 - mse: 0.6401 - val_loss: 3.3166 - val_mae: 1.0795 - val_mse: 3.3166\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6214 - mae: 0.6067 - mse: 0.6214 - val_loss: 4.6982 - val_mae: 1.5244 - val_mse: 4.6982\n",
      "Epoch 173/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6691 - mae: 0.6186 - mse: 0.6691 - val_loss: 2.7669 - val_mae: 1.1139 - val_mse: 2.7669\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6516 - mae: 0.6148 - mse: 0.6516 - val_loss: 3.2208 - val_mae: 1.0714 - val_mse: 3.2208\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6695 - mae: 0.6273 - mse: 0.6695 - val_loss: 2.7350 - val_mae: 1.0301 - val_mse: 2.7350\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6085 - mae: 0.5951 - mse: 0.6085 - val_loss: 3.7331 - val_mae: 1.2144 - val_mse: 3.7331\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6601 - mae: 0.6188 - mse: 0.6601 - val_loss: 3.3742 - val_mae: 1.0935 - val_mse: 3.3742\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6414 - mae: 0.6225 - mse: 0.6414 - val_loss: 2.6127 - val_mae: 1.0566 - val_mse: 2.6127\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6422 - mae: 0.6225 - mse: 0.6422 - val_loss: 2.5174 - val_mae: 0.9830 - val_mse: 2.5174\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6403 - mae: 0.6130 - mse: 0.6403 - val_loss: 3.3438 - val_mae: 1.0651 - val_mse: 3.3438\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6537 - mae: 0.6166 - mse: 0.6537 - val_loss: 2.8938 - val_mae: 1.0647 - val_mse: 2.8938\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6217 - mae: 0.6021 - mse: 0.6217 - val_loss: 3.2108 - val_mae: 1.0877 - val_mse: 3.2108\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6113 - mae: 0.5881 - mse: 0.6113 - val_loss: 2.5445 - val_mae: 1.0876 - val_mse: 2.5445\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6401 - mae: 0.6170 - mse: 0.6401 - val_loss: 2.4961 - val_mae: 1.0042 - val_mse: 2.4961\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6328 - mae: 0.6139 - mse: 0.6328 - val_loss: 2.8864 - val_mae: 1.0287 - val_mse: 2.8864\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6149 - mae: 0.5979 - mse: 0.6149 - val_loss: 3.3051 - val_mae: 1.1836 - val_mse: 3.3051\n",
      "Epoch 187/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6274 - mae: 0.6115 - mse: 0.6274 - val_loss: 2.6706 - val_mae: 1.0557 - val_mse: 2.6706\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6065 - mae: 0.6005 - mse: 0.6065 - val_loss: 4.1648 - val_mae: 1.3389 - val_mse: 4.1648\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6182 - mae: 0.5972 - mse: 0.6182 - val_loss: 3.3270 - val_mae: 1.1693 - val_mse: 3.3270\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6142 - mae: 0.5944 - mse: 0.6142 - val_loss: 3.1520 - val_mae: 1.1044 - val_mse: 3.1520\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5828 - mae: 0.5919 - mse: 0.5828 - val_loss: 3.0467 - val_mae: 1.1381 - val_mse: 3.0467\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6268 - mae: 0.6003 - mse: 0.6268 - val_loss: 2.6558 - val_mae: 1.1460 - val_mse: 2.6558\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5860 - mae: 0.5857 - mse: 0.5860 - val_loss: 3.1574 - val_mae: 1.1119 - val_mse: 3.1574\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6013 - mae: 0.5925 - mse: 0.6013 - val_loss: 3.1720 - val_mae: 1.1893 - val_mse: 3.1720\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5770 - mae: 0.5732 - mse: 0.5770 - val_loss: 3.0872 - val_mae: 1.3527 - val_mse: 3.0872\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6223 - mae: 0.6124 - mse: 0.6223 - val_loss: 2.9411 - val_mae: 1.2221 - val_mse: 2.9411\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5969 - mae: 0.5968 - mse: 0.5969 - val_loss: 3.0256 - val_mae: 1.0958 - val_mse: 3.0256\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5953 - mae: 0.5902 - mse: 0.5953 - val_loss: 4.6933 - val_mae: 1.4289 - val_mse: 4.6933\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.6049 - mae: 0.5929 - mse: 0.6049 - val_loss: 2.6441 - val_mae: 1.0055 - val_mse: 2.6441\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5716 - mae: 0.5727 - mse: 0.5716 - val_loss: 3.0775 - val_mae: 1.2418 - val_mse: 3.0775\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5772 - mae: 0.5826 - mse: 0.5772 - val_loss: 2.6530 - val_mae: 1.1399 - val_mse: 2.6530\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5806 - mae: 0.5846 - mse: 0.5806 - val_loss: 2.6287 - val_mae: 1.1240 - val_mse: 2.6287\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5741 - mae: 0.5784 - mse: 0.5741 - val_loss: 2.8723 - val_mae: 1.0652 - val_mse: 2.8723\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5538 - mae: 0.5740 - mse: 0.5538 - val_loss: 2.7782 - val_mae: 1.0423 - val_mse: 2.7782\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5549 - mae: 0.5640 - mse: 0.5549 - val_loss: 3.2715 - val_mae: 1.1660 - val_mse: 3.2715\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5760 - mae: 0.5764 - mse: 0.5760 - val_loss: 3.0833 - val_mae: 1.0523 - val_mse: 3.0833\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5636 - mae: 0.5744 - mse: 0.5636 - val_loss: 3.3335 - val_mae: 1.1575 - val_mse: 3.3335\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5505 - mae: 0.5664 - mse: 0.5505 - val_loss: 6.3145 - val_mae: 1.6725 - val_mse: 6.3145\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5899 - mae: 0.5703 - mse: 0.5899 - val_loss: 3.1522 - val_mae: 1.1339 - val_mse: 3.1522\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5336 - mae: 0.5564 - mse: 0.5336 - val_loss: 3.1924 - val_mae: 1.0846 - val_mse: 3.1924\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5922 - mae: 0.5913 - mse: 0.5922 - val_loss: 4.8542 - val_mae: 1.5369 - val_mse: 4.8542\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5334 - mae: 0.5533 - mse: 0.5334 - val_loss: 4.2285 - val_mae: 1.2744 - val_mse: 4.2285\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5492 - mae: 0.5668 - mse: 0.5492 - val_loss: 2.5839 - val_mae: 1.0577 - val_mse: 2.5839\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5332 - mae: 0.5564 - mse: 0.5332 - val_loss: 3.1619 - val_mae: 1.0572 - val_mse: 3.1619\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5382 - mae: 0.5591 - mse: 0.5382 - val_loss: 3.2110 - val_mae: 1.3322 - val_mse: 3.2110\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5637 - mae: 0.5659 - mse: 0.5637 - val_loss: 2.5972 - val_mae: 1.0131 - val_mse: 2.5972\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5371 - mae: 0.5651 - mse: 0.5371 - val_loss: 3.2823 - val_mae: 1.1208 - val_mse: 3.2823\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5140 - mae: 0.5452 - mse: 0.5140 - val_loss: 3.1696 - val_mae: 1.0696 - val_mse: 3.1696\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5207 - mae: 0.5487 - mse: 0.5207 - val_loss: 2.9796 - val_mae: 1.0700 - val_mse: 2.9796\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5418 - mae: 0.5720 - mse: 0.5418 - val_loss: 3.3421 - val_mae: 1.2053 - val_mse: 3.3421\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5380 - mae: 0.5534 - mse: 0.5380 - val_loss: 3.2623 - val_mae: 1.0938 - val_mse: 3.2623\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5053 - mae: 0.5382 - mse: 0.5053 - val_loss: 3.7018 - val_mae: 1.5661 - val_mse: 3.7018\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5436 - mae: 0.5565 - mse: 0.5436 - val_loss: 2.8660 - val_mae: 1.2349 - val_mse: 2.8660\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5338 - mae: 0.5570 - mse: 0.5338 - val_loss: 2.7801 - val_mae: 1.0312 - val_mse: 2.7801\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5067 - mae: 0.5428 - mse: 0.5067 - val_loss: 3.2946 - val_mae: 1.0481 - val_mse: 3.2946\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5182 - mae: 0.5391 - mse: 0.5182 - val_loss: 3.1508 - val_mae: 1.1299 - val_mse: 3.1508\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5132 - mae: 0.5488 - mse: 0.5132 - val_loss: 2.7807 - val_mae: 1.0683 - val_mse: 2.7807\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4910 - mae: 0.5312 - mse: 0.4910 - val_loss: 3.0456 - val_mae: 1.0542 - val_mse: 3.0456\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5240 - mae: 0.5437 - mse: 0.5240 - val_loss: 2.7547 - val_mae: 1.0259 - val_mse: 2.7547\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5083 - mae: 0.5385 - mse: 0.5083 - val_loss: 3.3653 - val_mae: 1.0626 - val_mse: 3.3653\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4738 - mae: 0.5297 - mse: 0.4738 - val_loss: 2.5503 - val_mae: 1.0999 - val_mse: 2.5503\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5448 - mae: 0.5563 - mse: 0.5448 - val_loss: 3.5418 - val_mae: 1.3469 - val_mse: 3.5418\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5329 - mae: 0.5509 - mse: 0.5329 - val_loss: 2.6654 - val_mae: 1.0125 - val_mse: 2.6654\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4804 - mae: 0.5248 - mse: 0.4804 - val_loss: 3.2203 - val_mae: 1.0594 - val_mse: 3.2203\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4984 - mae: 0.5356 - mse: 0.4984 - val_loss: 2.8607 - val_mae: 1.0715 - val_mse: 2.8607\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5084 - mae: 0.5411 - mse: 0.5084 - val_loss: 2.8812 - val_mae: 1.0354 - val_mse: 2.8812\n",
      "Epoch 237/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4737 - mae: 0.5292 - mse: 0.4737 - val_loss: 2.5836 - val_mae: 1.0445 - val_mse: 2.5836\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.5181 - mae: 0.5482 - mse: 0.5181 - val_loss: 3.1925 - val_mae: 1.0447 - val_mse: 3.1925\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4997 - mae: 0.5416 - mse: 0.4997 - val_loss: 3.3171 - val_mae: 1.1899 - val_mse: 3.3171\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4650 - mae: 0.5098 - mse: 0.4650 - val_loss: 2.8315 - val_mae: 1.0585 - val_mse: 2.8315\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4978 - mae: 0.5423 - mse: 0.4978 - val_loss: 2.6451 - val_mae: 1.0101 - val_mse: 2.6451\n",
      "Epoch 242/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4977 - mae: 0.5375 - mse: 0.4977 - val_loss: 2.5902 - val_mae: 1.0138 - val_mse: 2.5902\n",
      "Epoch 243/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4861 - mae: 0.5323 - mse: 0.4861 - val_loss: 2.4399 - val_mae: 0.9714 - val_mse: 2.4399\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4761 - mae: 0.5296 - mse: 0.4761 - val_loss: 2.8536 - val_mae: 1.0770 - val_mse: 2.8536\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4938 - mae: 0.5327 - mse: 0.4938 - val_loss: 2.9241 - val_mae: 1.1201 - val_mse: 2.9241\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4806 - mae: 0.5264 - mse: 0.4806 - val_loss: 2.7008 - val_mae: 1.0072 - val_mse: 2.7008\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4669 - mae: 0.5154 - mse: 0.4669 - val_loss: 3.2677 - val_mae: 1.1196 - val_mse: 3.2677\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4784 - mae: 0.5243 - mse: 0.4784 - val_loss: 3.1698 - val_mae: 1.2787 - val_mse: 3.1698\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4593 - mae: 0.5101 - mse: 0.4593 - val_loss: 2.6418 - val_mae: 1.1244 - val_mse: 2.6418\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4654 - mae: 0.5157 - mse: 0.4654 - val_loss: 2.8256 - val_mae: 1.0294 - val_mse: 2.8256\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4813 - mae: 0.5294 - mse: 0.4813 - val_loss: 2.4198 - val_mae: 0.9862 - val_mse: 2.4198\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4567 - mae: 0.5104 - mse: 0.4567 - val_loss: 3.2801 - val_mae: 1.0649 - val_mse: 3.2801\n",
      "Epoch 253/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4344 - mae: 0.5080 - mse: 0.4344 - val_loss: 4.0081 - val_mae: 1.3509 - val_mse: 4.0081\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4942 - mae: 0.5270 - mse: 0.4942 - val_loss: 3.8314 - val_mae: 1.2726 - val_mse: 3.8314\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4424 - mae: 0.5044 - mse: 0.4424 - val_loss: 2.8254 - val_mae: 1.0376 - val_mse: 2.8254\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4851 - mae: 0.5243 - mse: 0.4851 - val_loss: 2.8777 - val_mae: 1.0247 - val_mse: 2.8777\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4471 - mae: 0.5023 - mse: 0.4471 - val_loss: 2.7100 - val_mae: 1.0073 - val_mse: 2.7100\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4732 - mae: 0.5178 - mse: 0.4732 - val_loss: 2.7464 - val_mae: 1.1631 - val_mse: 2.7464\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4381 - mae: 0.5024 - mse: 0.4381 - val_loss: 4.2877 - val_mae: 1.2725 - val_mse: 4.2877\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4622 - mae: 0.5089 - mse: 0.4622 - val_loss: 2.8104 - val_mae: 1.0373 - val_mse: 2.8104\n",
      "Epoch 261/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4671 - mae: 0.5170 - mse: 0.4671 - val_loss: 2.8660 - val_mae: 1.1512 - val_mse: 2.8660\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4399 - mae: 0.4991 - mse: 0.4399 - val_loss: 3.4146 - val_mae: 1.1807 - val_mse: 3.4146\n",
      "Epoch 263/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4790 - mae: 0.5280 - mse: 0.4790 - val_loss: 2.6372 - val_mae: 1.0975 - val_mse: 2.6372\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4456 - mae: 0.5039 - mse: 0.4456 - val_loss: 3.4465 - val_mae: 1.0681 - val_mse: 3.4465\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3869 - mae: 0.4798 - mse: 0.3869 - val_loss: 2.7878 - val_mae: 1.0164 - val_mse: 2.7878\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4385 - mae: 0.5014 - mse: 0.4385 - val_loss: 3.5579 - val_mae: 1.1053 - val_mse: 3.5579\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4406 - mae: 0.5026 - mse: 0.4406 - val_loss: 3.2627 - val_mae: 1.0999 - val_mse: 3.2627\n",
      "Epoch 268/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3904 - mae: 0.4718 - mse: 0.3904 - val_loss: 4.6847 - val_mae: 1.4987 - val_mse: 4.6847\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4442 - mae: 0.5027 - mse: 0.4442 - val_loss: 3.0517 - val_mae: 1.2706 - val_mse: 3.0517\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4540 - mae: 0.5079 - mse: 0.4540 - val_loss: 2.9517 - val_mae: 1.0721 - val_mse: 2.9517\n",
      "Epoch 271/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4361 - mae: 0.5063 - mse: 0.4361 - val_loss: 2.6735 - val_mae: 1.1232 - val_mse: 2.6735\n",
      "Epoch 272/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4435 - mae: 0.5062 - mse: 0.4435 - val_loss: 2.9088 - val_mae: 1.0662 - val_mse: 2.9088\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4109 - mae: 0.4865 - mse: 0.4109 - val_loss: 2.6560 - val_mae: 0.9957 - val_mse: 2.6560\n",
      "Epoch 274/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4258 - mae: 0.4970 - mse: 0.4258 - val_loss: 2.8040 - val_mae: 1.1383 - val_mse: 2.8040\n",
      "Epoch 275/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4139 - mae: 0.4827 - mse: 0.4139 - val_loss: 2.4590 - val_mae: 1.0335 - val_mse: 2.4590\n",
      "Epoch 276/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4169 - mae: 0.4922 - mse: 0.4169 - val_loss: 3.9668 - val_mae: 1.1820 - val_mse: 3.9668\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3999 - mae: 0.4785 - mse: 0.3999 - val_loss: 3.2200 - val_mae: 1.1576 - val_mse: 3.2200\n",
      "Epoch 278/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3935 - mae: 0.4773 - mse: 0.3935 - val_loss: 2.9578 - val_mae: 1.1235 - val_mse: 2.9578\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4374 - mae: 0.5049 - mse: 0.4374 - val_loss: 2.9207 - val_mae: 1.2754 - val_mse: 2.9207\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4011 - mae: 0.4741 - mse: 0.4011 - val_loss: 3.2986 - val_mae: 1.2121 - val_mse: 3.2986\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4300 - mae: 0.4956 - mse: 0.4300 - val_loss: 2.8685 - val_mae: 1.0833 - val_mse: 2.8685\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4478 - mae: 0.5125 - mse: 0.4478 - val_loss: 2.9329 - val_mae: 1.0341 - val_mse: 2.9329\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3870 - mae: 0.4701 - mse: 0.3870 - val_loss: 3.0720 - val_mae: 1.1049 - val_mse: 3.0720\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4056 - mae: 0.4837 - mse: 0.4056 - val_loss: 2.6068 - val_mae: 1.1452 - val_mse: 2.6068\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3787 - mae: 0.4727 - mse: 0.3787 - val_loss: 3.5962 - val_mae: 1.1295 - val_mse: 3.5962\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4236 - mae: 0.4978 - mse: 0.4236 - val_loss: 4.3925 - val_mae: 1.3775 - val_mse: 4.3925\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4171 - mae: 0.4853 - mse: 0.4171 - val_loss: 3.5988 - val_mae: 1.1044 - val_mse: 3.5988\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4075 - mae: 0.4825 - mse: 0.4075 - val_loss: 3.1140 - val_mae: 1.3109 - val_mse: 3.1140\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3872 - mae: 0.4730 - mse: 0.3872 - val_loss: 3.0219 - val_mae: 1.0808 - val_mse: 3.0219\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3866 - mae: 0.4745 - mse: 0.3866 - val_loss: 3.0200 - val_mae: 1.1354 - val_mse: 3.0200\n",
      "Epoch 291/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3714 - mae: 0.4595 - mse: 0.3714 - val_loss: 3.0243 - val_mae: 1.2484 - val_mse: 3.0243\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3939 - mae: 0.4712 - mse: 0.3939 - val_loss: 2.5331 - val_mae: 1.0242 - val_mse: 2.5331\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3704 - mae: 0.4600 - mse: 0.3704 - val_loss: 2.8466 - val_mae: 1.1364 - val_mse: 2.8466\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3822 - mae: 0.4632 - mse: 0.3822 - val_loss: 3.1597 - val_mae: 1.3534 - val_mse: 3.1597\n",
      "Epoch 295/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4082 - mae: 0.4794 - mse: 0.4082 - val_loss: 3.4802 - val_mae: 1.0810 - val_mse: 3.4802\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3835 - mae: 0.4733 - mse: 0.3835 - val_loss: 2.7837 - val_mae: 1.0815 - val_mse: 2.7837\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3699 - mae: 0.4597 - mse: 0.3699 - val_loss: 2.5451 - val_mae: 1.0523 - val_mse: 2.5451\n",
      "Epoch 298/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3597 - mae: 0.4542 - mse: 0.3597 - val_loss: 3.0111 - val_mae: 1.1381 - val_mse: 3.0111\n",
      "Epoch 299/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3880 - mae: 0.4733 - mse: 0.3880 - val_loss: 2.7813 - val_mae: 1.1094 - val_mse: 2.7813\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3776 - mae: 0.4631 - mse: 0.3776 - val_loss: 3.7242 - val_mae: 1.1664 - val_mse: 3.7242\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3597 - mae: 0.4496 - mse: 0.3597 - val_loss: 3.0933 - val_mae: 1.0829 - val_mse: 3.0933\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3939 - mae: 0.4755 - mse: 0.3939 - val_loss: 2.8431 - val_mae: 1.0975 - val_mse: 2.8431\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3795 - mae: 0.4682 - mse: 0.3795 - val_loss: 2.6132 - val_mae: 1.0448 - val_mse: 2.6132\n",
      "Epoch 304/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3373 - mae: 0.4315 - mse: 0.3373 - val_loss: 4.8551 - val_mae: 1.4673 - val_mse: 4.8551\n",
      "Epoch 305/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3615 - mae: 0.4481 - mse: 0.3615 - val_loss: 2.9100 - val_mae: 1.0731 - val_mse: 2.9100\n",
      "Epoch 306/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3814 - mae: 0.4698 - mse: 0.3814 - val_loss: 2.8766 - val_mae: 1.1310 - val_mse: 2.8766\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3562 - mae: 0.4463 - mse: 0.3562 - val_loss: 3.0132 - val_mae: 1.0770 - val_mse: 3.0132\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3658 - mae: 0.4528 - mse: 0.3658 - val_loss: 2.7635 - val_mae: 1.0716 - val_mse: 2.7635\n",
      "Epoch 309/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3455 - mae: 0.4421 - mse: 0.3455 - val_loss: 2.9262 - val_mae: 1.0625 - val_mse: 2.9262\n",
      "Epoch 310/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3666 - mae: 0.4686 - mse: 0.3666 - val_loss: 2.6767 - val_mae: 1.0915 - val_mse: 2.6767\n",
      "Epoch 311/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3376 - mae: 0.4376 - mse: 0.3376 - val_loss: 2.7914 - val_mae: 1.0391 - val_mse: 2.7914\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3476 - mae: 0.4398 - mse: 0.3476 - val_loss: 2.7774 - val_mae: 1.1286 - val_mse: 2.7774\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3453 - mae: 0.4399 - mse: 0.3453 - val_loss: 3.1661 - val_mae: 1.0735 - val_mse: 3.1661\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3481 - mae: 0.4420 - mse: 0.3481 - val_loss: 3.4004 - val_mae: 1.1822 - val_mse: 3.4004\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3593 - mae: 0.4577 - mse: 0.3593 - val_loss: 3.5857 - val_mae: 1.1336 - val_mse: 3.5857\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3364 - mae: 0.4449 - mse: 0.3364 - val_loss: 2.8211 - val_mae: 1.0962 - val_mse: 2.8211\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3374 - mae: 0.4411 - mse: 0.3374 - val_loss: 2.7605 - val_mae: 1.1028 - val_mse: 2.7605\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3315 - mae: 0.4225 - mse: 0.3315 - val_loss: 2.9530 - val_mae: 1.0723 - val_mse: 2.9530\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3302 - mae: 0.4392 - mse: 0.3302 - val_loss: 3.4898 - val_mae: 1.1379 - val_mse: 3.4898\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3529 - mae: 0.4492 - mse: 0.3529 - val_loss: 2.8237 - val_mae: 1.0729 - val_mse: 2.8237\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3343 - mae: 0.4342 - mse: 0.3343 - val_loss: 2.6531 - val_mae: 1.0263 - val_mse: 2.6531\n",
      "Epoch 322/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3211 - mae: 0.4299 - mse: 0.3211 - val_loss: 3.8310 - val_mae: 1.2575 - val_mse: 3.8310\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3296 - mae: 0.4376 - mse: 0.3296 - val_loss: 2.4846 - val_mae: 1.0188 - val_mse: 2.4846\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3138 - mae: 0.4194 - mse: 0.3138 - val_loss: 2.6637 - val_mae: 1.1037 - val_mse: 2.6637\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3343 - mae: 0.4402 - mse: 0.3343 - val_loss: 4.9078 - val_mae: 1.2433 - val_mse: 4.9078\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3128 - mae: 0.4128 - mse: 0.3128 - val_loss: 3.4547 - val_mae: 1.2799 - val_mse: 3.4547\n",
      "Epoch 327/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3515 - mae: 0.4383 - mse: 0.3515 - val_loss: 2.7885 - val_mae: 1.1242 - val_mse: 2.7885\n",
      "Epoch 328/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3314 - mae: 0.4324 - mse: 0.3314 - val_loss: 2.6447 - val_mae: 1.0440 - val_mse: 2.6447\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3123 - mae: 0.4162 - mse: 0.3123 - val_loss: 2.5216 - val_mae: 1.0599 - val_mse: 2.5216\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3195 - mae: 0.4232 - mse: 0.3195 - val_loss: 3.0857 - val_mae: 1.0886 - val_mse: 3.0857\n",
      "Epoch 331/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3523 - mae: 0.4479 - mse: 0.3523 - val_loss: 3.3215 - val_mae: 1.1019 - val_mse: 3.3215\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3052 - mae: 0.4150 - mse: 0.3052 - val_loss: 2.7138 - val_mae: 1.1694 - val_mse: 2.7138\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3277 - mae: 0.4299 - mse: 0.3277 - val_loss: 3.6579 - val_mae: 1.2913 - val_mse: 3.6579\n",
      "Epoch 334/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3472 - mae: 0.4535 - mse: 0.3472 - val_loss: 2.4091 - val_mae: 1.0072 - val_mse: 2.4091\n",
      "Epoch 335/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2929 - mae: 0.4054 - mse: 0.2929 - val_loss: 2.6220 - val_mae: 1.0799 - val_mse: 2.6220\n",
      "Epoch 336/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3073 - mae: 0.4184 - mse: 0.3073 - val_loss: 2.7446 - val_mae: 1.0375 - val_mse: 2.7446\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3179 - mae: 0.4360 - mse: 0.3179 - val_loss: 4.0183 - val_mae: 1.1633 - val_mse: 4.0183\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3002 - mae: 0.4115 - mse: 0.3002 - val_loss: 2.6212 - val_mae: 1.0376 - val_mse: 2.6212\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3171 - mae: 0.4308 - mse: 0.3171 - val_loss: 3.3336 - val_mae: 1.3845 - val_mse: 3.3336\n",
      "Epoch 340/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3303 - mae: 0.4279 - mse: 0.3303 - val_loss: 3.0371 - val_mae: 1.0852 - val_mse: 3.0371\n",
      "Epoch 341/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3276 - mae: 0.4357 - mse: 0.3276 - val_loss: 2.8284 - val_mae: 1.1442 - val_mse: 2.8284\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3057 - mae: 0.4092 - mse: 0.3057 - val_loss: 2.5999 - val_mae: 1.0432 - val_mse: 2.5999\n",
      "Epoch 343/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2989 - mae: 0.4153 - mse: 0.2989 - val_loss: 3.5968 - val_mae: 1.1706 - val_mse: 3.5968\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2920 - mae: 0.4062 - mse: 0.2920 - val_loss: 2.7175 - val_mae: 1.0471 - val_mse: 2.7175\n",
      "Epoch 345/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2881 - mae: 0.4101 - mse: 0.2881 - val_loss: 2.9664 - val_mae: 1.2126 - val_mse: 2.9664\n",
      "Epoch 346/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2873 - mae: 0.3924 - mse: 0.2873 - val_loss: 2.5827 - val_mae: 1.0962 - val_mse: 2.5827\n",
      "Epoch 347/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2972 - mae: 0.4112 - mse: 0.2972 - val_loss: 3.1230 - val_mae: 1.0893 - val_mse: 3.1230\n",
      "Epoch 348/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2709 - mae: 0.3927 - mse: 0.2709 - val_loss: 2.8990 - val_mae: 1.1547 - val_mse: 2.8990\n",
      "Epoch 349/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3214 - mae: 0.4182 - mse: 0.3214 - val_loss: 2.7336 - val_mae: 1.0651 - val_mse: 2.7336\n",
      "Epoch 350/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3011 - mae: 0.4174 - mse: 0.3011 - val_loss: 2.8831 - val_mae: 1.0636 - val_mse: 2.8831\n",
      "Epoch 351/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3054 - mae: 0.4183 - mse: 0.3054 - val_loss: 3.8820 - val_mae: 1.1197 - val_mse: 3.8820\n",
      "Epoch 352/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3021 - mae: 0.4122 - mse: 0.3021 - val_loss: 3.5857 - val_mae: 1.1594 - val_mse: 3.5857\n",
      "Epoch 353/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2676 - mae: 0.3879 - mse: 0.2676 - val_loss: 2.7797 - val_mae: 1.1424 - val_mse: 2.7797\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3113 - mae: 0.4153 - mse: 0.3113 - val_loss: 2.9975 - val_mae: 1.1138 - val_mse: 2.9975\n",
      "Epoch 355/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2817 - mae: 0.4006 - mse: 0.2817 - val_loss: 2.8271 - val_mae: 1.0624 - val_mse: 2.8271\n",
      "Epoch 356/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3049 - mae: 0.4168 - mse: 0.3049 - val_loss: 2.7674 - val_mae: 1.0628 - val_mse: 2.7674\n",
      "Epoch 357/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2680 - mae: 0.3932 - mse: 0.2680 - val_loss: 2.6142 - val_mae: 1.0740 - val_mse: 2.6142\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2843 - mae: 0.4104 - mse: 0.2843 - val_loss: 3.2197 - val_mae: 1.1300 - val_mse: 3.2197\n",
      "Epoch 359/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2833 - mae: 0.4056 - mse: 0.2833 - val_loss: 2.7214 - val_mae: 1.1643 - val_mse: 2.7214\n",
      "Epoch 360/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2960 - mae: 0.4043 - mse: 0.2960 - val_loss: 2.9812 - val_mae: 1.1029 - val_mse: 2.9812\n",
      "Epoch 361/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2706 - mae: 0.3973 - mse: 0.2706 - val_loss: 3.1782 - val_mae: 1.1080 - val_mse: 3.1782\n",
      "Epoch 362/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2694 - mae: 0.3872 - mse: 0.2694 - val_loss: 2.5612 - val_mae: 1.0506 - val_mse: 2.5612\n",
      "Epoch 363/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2815 - mae: 0.4012 - mse: 0.2815 - val_loss: 2.9672 - val_mae: 1.0905 - val_mse: 2.9672\n",
      "Epoch 364/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2952 - mae: 0.4060 - mse: 0.2952 - val_loss: 2.6660 - val_mae: 1.1136 - val_mse: 2.6660\n",
      "Epoch 365/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2666 - mae: 0.3877 - mse: 0.2666 - val_loss: 2.8048 - val_mae: 1.0718 - val_mse: 2.8048\n",
      "Epoch 366/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2612 - mae: 0.3871 - mse: 0.2612 - val_loss: 3.4390 - val_mae: 1.1545 - val_mse: 3.4390\n",
      "Epoch 367/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2550 - mae: 0.3820 - mse: 0.2550 - val_loss: 2.9285 - val_mae: 1.2699 - val_mse: 2.9285\n",
      "Epoch 368/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2831 - mae: 0.4050 - mse: 0.2831 - val_loss: 2.6457 - val_mae: 1.0342 - val_mse: 2.6457\n",
      "Epoch 369/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2370 - mae: 0.3682 - mse: 0.2370 - val_loss: 3.1688 - val_mae: 1.1970 - val_mse: 3.1688\n",
      "Epoch 370/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2839 - mae: 0.4003 - mse: 0.2839 - val_loss: 2.5869 - val_mae: 1.1072 - val_mse: 2.5869\n",
      "Epoch 371/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2577 - mae: 0.3842 - mse: 0.2577 - val_loss: 3.1704 - val_mae: 1.1661 - val_mse: 3.1704\n",
      "Epoch 372/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2648 - mae: 0.3948 - mse: 0.2648 - val_loss: 3.6992 - val_mae: 1.2666 - val_mse: 3.6992\n",
      "Epoch 373/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2493 - mae: 0.3769 - mse: 0.2493 - val_loss: 2.8497 - val_mae: 1.2385 - val_mse: 2.8497\n",
      "Epoch 374/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2631 - mae: 0.3820 - mse: 0.2631 - val_loss: 3.8953 - val_mae: 1.3105 - val_mse: 3.8953\n",
      "Epoch 375/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2704 - mae: 0.3894 - mse: 0.2704 - val_loss: 3.0601 - val_mae: 1.1248 - val_mse: 3.0601\n",
      "Epoch 376/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2833 - mae: 0.3933 - mse: 0.2833 - val_loss: 2.5968 - val_mae: 1.1195 - val_mse: 2.5968\n",
      "Epoch 377/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2698 - mae: 0.3940 - mse: 0.2698 - val_loss: 3.2188 - val_mae: 1.2143 - val_mse: 3.2188\n",
      "Epoch 378/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2631 - mae: 0.3865 - mse: 0.2631 - val_loss: 2.8053 - val_mae: 1.0457 - val_mse: 2.8053\n",
      "Epoch 379/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2497 - mae: 0.3788 - mse: 0.2497 - val_loss: 2.7024 - val_mae: 1.0801 - val_mse: 2.7024\n",
      "Epoch 380/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2534 - mae: 0.3786 - mse: 0.2534 - val_loss: 3.1096 - val_mae: 1.1379 - val_mse: 3.1096\n",
      "Epoch 381/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2465 - mae: 0.3759 - mse: 0.2465 - val_loss: 2.6149 - val_mae: 1.1513 - val_mse: 2.6149\n",
      "Epoch 382/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2422 - mae: 0.3700 - mse: 0.2422 - val_loss: 2.9036 - val_mae: 1.0757 - val_mse: 2.9036\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2815 - mae: 0.3996 - mse: 0.2815 - val_loss: 3.2663 - val_mae: 1.0963 - val_mse: 3.2663\n",
      "Epoch 384/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2416 - mae: 0.3630 - mse: 0.2416 - val_loss: 3.8033 - val_mae: 1.2014 - val_mse: 3.8033\n",
      "Epoch 385/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2827 - mae: 0.3973 - mse: 0.2827 - val_loss: 2.7450 - val_mae: 1.0481 - val_mse: 2.7450\n",
      "Epoch 386/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2365 - mae: 0.3678 - mse: 0.2365 - val_loss: 2.8090 - val_mae: 1.0795 - val_mse: 2.8090\n",
      "Epoch 387/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2472 - mae: 0.3817 - mse: 0.2472 - val_loss: 2.6568 - val_mae: 1.0507 - val_mse: 2.6568\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2571 - mae: 0.3684 - mse: 0.2571 - val_loss: 3.1207 - val_mae: 1.1485 - val_mse: 3.1207\n",
      "Epoch 389/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2406 - mae: 0.3693 - mse: 0.2406 - val_loss: 3.4775 - val_mae: 1.2037 - val_mse: 3.4775\n",
      "Epoch 390/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2397 - mae: 0.3717 - mse: 0.2397 - val_loss: 3.0053 - val_mae: 1.1321 - val_mse: 3.0053\n",
      "Epoch 391/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2444 - mae: 0.3797 - mse: 0.2444 - val_loss: 3.3241 - val_mae: 1.1547 - val_mse: 3.3241\n",
      "Epoch 392/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2487 - mae: 0.3749 - mse: 0.2487 - val_loss: 3.0991 - val_mae: 1.0803 - val_mse: 3.0991\n",
      "Epoch 393/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2437 - mae: 0.3645 - mse: 0.2437 - val_loss: 2.6392 - val_mae: 1.0867 - val_mse: 2.6392\n",
      "Epoch 394/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2316 - mae: 0.3660 - mse: 0.2316 - val_loss: 3.0442 - val_mae: 1.1122 - val_mse: 3.0442\n",
      "Epoch 395/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2122 - mae: 0.3495 - mse: 0.2122 - val_loss: 2.9234 - val_mae: 1.1281 - val_mse: 2.9234\n",
      "Epoch 396/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2349 - mae: 0.3648 - mse: 0.2349 - val_loss: 3.2594 - val_mae: 1.1485 - val_mse: 3.2594\n",
      "Epoch 397/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2471 - mae: 0.3762 - mse: 0.2471 - val_loss: 2.6123 - val_mae: 1.0829 - val_mse: 2.6123\n",
      "Epoch 398/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2485 - mae: 0.3755 - mse: 0.2485 - val_loss: 2.8474 - val_mae: 1.0907 - val_mse: 2.8474\n",
      "Epoch 399/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2401 - mae: 0.3640 - mse: 0.2401 - val_loss: 2.8011 - val_mae: 1.0451 - val_mse: 2.8011\n",
      "Epoch 400/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2185 - mae: 0.3493 - mse: 0.2185 - val_loss: 3.0970 - val_mae: 1.1143 - val_mse: 3.0970\n",
      "Epoch 401/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2325 - mae: 0.3671 - mse: 0.2325 - val_loss: 2.7872 - val_mae: 1.1894 - val_mse: 2.7872\n",
      "Epoch 402/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2353 - mae: 0.3631 - mse: 0.2353 - val_loss: 4.1086 - val_mae: 1.4670 - val_mse: 4.1086\n",
      "Epoch 403/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2347 - mae: 0.3593 - mse: 0.2347 - val_loss: 2.7743 - val_mae: 1.0984 - val_mse: 2.7743\n",
      "Epoch 404/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2340 - mae: 0.3642 - mse: 0.2340 - val_loss: 3.9719 - val_mae: 1.2873 - val_mse: 3.9719\n",
      "Epoch 405/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2311 - mae: 0.3634 - mse: 0.2311 - val_loss: 3.4861 - val_mae: 1.1534 - val_mse: 3.4861\n",
      "Epoch 406/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2283 - mae: 0.3631 - mse: 0.2283 - val_loss: 3.0546 - val_mae: 1.2513 - val_mse: 3.0546\n",
      "Epoch 407/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2478 - mae: 0.3686 - mse: 0.2478 - val_loss: 2.7520 - val_mae: 1.0822 - val_mse: 2.7520\n",
      "Epoch 408/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2369 - mae: 0.3539 - mse: 0.2369 - val_loss: 3.6879 - val_mae: 1.1586 - val_mse: 3.6879\n",
      "Epoch 409/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2426 - mae: 0.3682 - mse: 0.2426 - val_loss: 2.6270 - val_mae: 1.0535 - val_mse: 2.6270\n",
      "Epoch 410/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2063 - mae: 0.3318 - mse: 0.2063 - val_loss: 2.8556 - val_mae: 1.0585 - val_mse: 2.8556\n",
      "Epoch 411/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2045 - mae: 0.3435 - mse: 0.2045 - val_loss: 2.7985 - val_mae: 1.0888 - val_mse: 2.7985\n",
      "Epoch 412/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2025 - mae: 0.3413 - mse: 0.2025 - val_loss: 2.7849 - val_mae: 1.0608 - val_mse: 2.7849\n",
      "Epoch 413/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2302 - mae: 0.3576 - mse: 0.2302 - val_loss: 3.3324 - val_mae: 1.2382 - val_mse: 3.3324\n",
      "Epoch 414/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2258 - mae: 0.3504 - mse: 0.2258 - val_loss: 3.3457 - val_mae: 1.0973 - val_mse: 3.3457\n",
      "Epoch 415/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2169 - mae: 0.3500 - mse: 0.2169 - val_loss: 3.6984 - val_mae: 1.2613 - val_mse: 3.6984\n",
      "Epoch 416/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2274 - mae: 0.3481 - mse: 0.2274 - val_loss: 2.7547 - val_mae: 1.1665 - val_mse: 2.7547\n",
      "Epoch 417/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2328 - mae: 0.3640 - mse: 0.2328 - val_loss: 3.0252 - val_mae: 1.0729 - val_mse: 3.0252\n",
      "Epoch 418/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1998 - mae: 0.3404 - mse: 0.1998 - val_loss: 2.8158 - val_mae: 1.1440 - val_mse: 2.8158\n",
      "Epoch 419/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2348 - mae: 0.3613 - mse: 0.2348 - val_loss: 3.0802 - val_mae: 1.1006 - val_mse: 3.0802\n",
      "Epoch 420/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2173 - mae: 0.3503 - mse: 0.2173 - val_loss: 2.5136 - val_mae: 1.0359 - val_mse: 2.5136\n",
      "Epoch 421/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1967 - mae: 0.3315 - mse: 0.1967 - val_loss: 3.3302 - val_mae: 1.1017 - val_mse: 3.3302\n",
      "Epoch 422/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2119 - mae: 0.3538 - mse: 0.2119 - val_loss: 3.6147 - val_mae: 1.1461 - val_mse: 3.6147\n",
      "Epoch 423/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1881 - mae: 0.3224 - mse: 0.1881 - val_loss: 2.5426 - val_mae: 1.0534 - val_mse: 2.5426\n",
      "Epoch 424/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2294 - mae: 0.3550 - mse: 0.2294 - val_loss: 3.7967 - val_mae: 1.2744 - val_mse: 3.7967\n",
      "Epoch 425/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2261 - mae: 0.3506 - mse: 0.2261 - val_loss: 2.6148 - val_mae: 1.0996 - val_mse: 2.6148\n",
      "Epoch 426/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1975 - mae: 0.3447 - mse: 0.1975 - val_loss: 2.6282 - val_mae: 1.0463 - val_mse: 2.6282\n",
      "Epoch 427/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2117 - mae: 0.3371 - mse: 0.2117 - val_loss: 3.1675 - val_mae: 1.1166 - val_mse: 3.1675\n",
      "Epoch 428/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2087 - mae: 0.3422 - mse: 0.2087 - val_loss: 2.7752 - val_mae: 1.0896 - val_mse: 2.7752\n",
      "Epoch 429/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2135 - mae: 0.3494 - mse: 0.2135 - val_loss: 2.8887 - val_mae: 1.0835 - val_mse: 2.8887\n",
      "Epoch 430/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2166 - mae: 0.3555 - mse: 0.2166 - val_loss: 2.8956 - val_mae: 1.0927 - val_mse: 2.8956\n",
      "Epoch 431/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1888 - mae: 0.3211 - mse: 0.1888 - val_loss: 2.9559 - val_mae: 1.1042 - val_mse: 2.9559\n",
      "Epoch 432/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2129 - mae: 0.3489 - mse: 0.2129 - val_loss: 2.9809 - val_mae: 1.0838 - val_mse: 2.9809\n",
      "Epoch 433/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1811 - mae: 0.3209 - mse: 0.1811 - val_loss: 3.0823 - val_mae: 1.1800 - val_mse: 3.0823\n",
      "Epoch 434/1000\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2163 - mae: 0.3558 - mse: 0.2163 - val_loss: 2.6997 - val_mae: 1.1058 - val_mse: 2.6997\n",
      "Kappa Score: 0.5666451795381144\n",
      "\n",
      "###########Set-6###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 128.1019 - mae: 6.6002 - mse: 128.1019 - val_loss: 31.2372 - val_mae: 5.3679 - val_mse: 31.2372\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 31.6661 - mae: 4.5951 - mse: 31.6661 - val_loss: 5.6603 - val_mae: 1.7458 - val_mse: 5.6603\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 18.0369 - mae: 3.3430 - mse: 18.0369 - val_loss: 28.4288 - val_mae: 4.9683 - val_mse: 28.4288\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 12.2291 - mae: 2.9167 - mse: 12.2291 - val_loss: 14.3328 - val_mae: 3.3897 - val_mse: 14.3328\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 5.6822 - mae: 1.8609 - mse: 5.6822 - val_loss: 11.9791 - val_mae: 2.9053 - val_mse: 11.9791\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.4196 - mae: 1.6437 - mse: 4.4196 - val_loss: 6.9831 - val_mae: 1.0706 - val_mse: 6.9831\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.1620 - mae: 1.3696 - mse: 3.1620 - val_loss: 14.6755 - val_mae: 2.2924 - val_mse: 14.6755\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.1287 - mae: 1.3876 - mse: 3.1287 - val_loss: 10.6718 - val_mae: 1.3563 - val_mse: 10.6718\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6830 - mae: 1.3005 - mse: 2.6830 - val_loss: 14.3484 - val_mae: 1.4602 - val_mse: 14.3484\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1641 - mae: 1.1594 - mse: 2.1641 - val_loss: 16.1714 - val_mae: 1.4227 - val_mse: 16.1714\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2840 - mae: 1.2056 - mse: 2.2840 - val_loss: 12.9670 - val_mae: 1.2140 - val_mse: 12.9670\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9561 - mae: 1.0903 - mse: 1.9561 - val_loss: 16.0878 - val_mae: 1.4854 - val_mse: 16.0878\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9642 - mae: 1.1052 - mse: 1.9642 - val_loss: 15.5750 - val_mae: 1.1255 - val_mse: 15.5750\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7285 - mae: 1.0395 - mse: 1.7285 - val_loss: 29.7248 - val_mae: 1.2880 - val_mse: 29.7248\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0076 - mae: 1.1148 - mse: 2.0076 - val_loss: 13.5319 - val_mae: 1.1356 - val_mse: 13.5319\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7735 - mae: 1.0385 - mse: 1.7735 - val_loss: 20.9523 - val_mae: 1.2273 - val_mse: 20.9523\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7914 - mae: 1.0490 - mse: 1.7914 - val_loss: 18.0437 - val_mae: 1.6637 - val_mse: 18.0437\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7418 - mae: 1.0393 - mse: 1.7418 - val_loss: 14.5517 - val_mae: 1.1582 - val_mse: 14.5517\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6896 - mae: 1.0334 - mse: 1.6896 - val_loss: 26.7065 - val_mae: 1.3410 - val_mse: 26.7065\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5055 - mae: 0.9609 - mse: 1.5055 - val_loss: 24.5160 - val_mae: 1.3395 - val_mse: 24.5160\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6069 - mae: 0.9952 - mse: 1.6069 - val_loss: 15.3464 - val_mae: 1.3289 - val_mse: 15.3464\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7573 - mae: 1.0346 - mse: 1.7573 - val_loss: 20.8773 - val_mae: 1.1587 - val_mse: 20.8773\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5245 - mae: 0.9623 - mse: 1.5245 - val_loss: 16.7687 - val_mae: 1.1416 - val_mse: 16.7687\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6038 - mae: 0.9946 - mse: 1.6038 - val_loss: 13.3205 - val_mae: 1.4496 - val_mse: 13.3205\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5860 - mae: 0.9783 - mse: 1.5860 - val_loss: 18.6698 - val_mae: 1.1650 - val_mse: 18.6698\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3930 - mae: 0.9223 - mse: 1.3930 - val_loss: 13.0370 - val_mae: 1.0980 - val_mse: 13.0370\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4356 - mae: 0.9285 - mse: 1.4356 - val_loss: 18.7370 - val_mae: 1.3355 - val_mse: 18.7370\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5614 - mae: 0.9716 - mse: 1.5614 - val_loss: 18.8016 - val_mae: 1.1974 - val_mse: 18.8016\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3567 - mae: 0.9114 - mse: 1.3567 - val_loss: 17.4230 - val_mae: 1.1485 - val_mse: 17.4230\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4825 - mae: 0.9625 - mse: 1.4825 - val_loss: 19.1892 - val_mae: 1.2283 - val_mse: 19.1892\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3906 - mae: 0.9196 - mse: 1.3906 - val_loss: 20.9623 - val_mae: 1.1476 - val_mse: 20.9623\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4016 - mae: 0.9225 - mse: 1.4016 - val_loss: 19.8980 - val_mae: 1.1856 - val_mse: 19.8980\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3624 - mae: 0.9118 - mse: 1.3624 - val_loss: 14.4020 - val_mae: 1.1092 - val_mse: 14.4020\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3819 - mae: 0.9113 - mse: 1.3819 - val_loss: 15.7778 - val_mae: 1.1345 - val_mse: 15.7778\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3260 - mae: 0.8965 - mse: 1.3260 - val_loss: 14.3740 - val_mae: 1.2967 - val_mse: 14.3740\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4102 - mae: 0.9295 - mse: 1.4102 - val_loss: 18.2443 - val_mae: 1.2025 - val_mse: 18.2443\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2717 - mae: 0.8821 - mse: 1.2717 - val_loss: 24.7331 - val_mae: 1.2749 - val_mse: 24.7331\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2837 - mae: 0.8852 - mse: 1.2837 - val_loss: 25.5284 - val_mae: 1.7316 - val_mse: 25.5284\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3142 - mae: 0.8987 - mse: 1.3142 - val_loss: 19.6754 - val_mae: 1.3442 - val_mse: 19.6754\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2701 - mae: 0.8875 - mse: 1.2701 - val_loss: 16.5906 - val_mae: 1.2435 - val_mse: 16.5906\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2059 - mae: 0.8536 - mse: 1.2059 - val_loss: 18.8319 - val_mae: 1.2578 - val_mse: 18.8319\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3332 - mae: 0.8966 - mse: 1.3332 - val_loss: 15.6046 - val_mae: 1.4319 - val_mse: 15.6046\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2865 - mae: 0.8847 - mse: 1.2865 - val_loss: 20.9863 - val_mae: 1.1707 - val_mse: 20.9863\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2629 - mae: 0.8658 - mse: 1.2629 - val_loss: 22.4479 - val_mae: 1.1803 - val_mse: 22.4479\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2589 - mae: 0.8774 - mse: 1.2589 - val_loss: 23.9096 - val_mae: 1.1750 - val_mse: 23.9096\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2395 - mae: 0.8592 - mse: 1.2395 - val_loss: 17.3353 - val_mae: 1.2539 - val_mse: 17.3353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2054 - mae: 0.8518 - mse: 1.2054 - val_loss: 15.5885 - val_mae: 1.1067 - val_mse: 15.5885\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2133 - mae: 0.8533 - mse: 1.2133 - val_loss: 19.6283 - val_mae: 1.1358 - val_mse: 19.6283\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1818 - mae: 0.8452 - mse: 1.1818 - val_loss: 16.2982 - val_mae: 1.1108 - val_mse: 16.2982\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2712 - mae: 0.8752 - mse: 1.2712 - val_loss: 24.2514 - val_mae: 1.3091 - val_mse: 24.2514\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2052 - mae: 0.8557 - mse: 1.2052 - val_loss: 19.9544 - val_mae: 1.1390 - val_mse: 19.9544\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1885 - mae: 0.8519 - mse: 1.1885 - val_loss: 15.5570 - val_mae: 1.7231 - val_mse: 15.5570\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1773 - mae: 0.8530 - mse: 1.1773 - val_loss: 22.9851 - val_mae: 1.5640 - val_mse: 22.9851\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2011 - mae: 0.8657 - mse: 1.2011 - val_loss: 17.8831 - val_mae: 1.1414 - val_mse: 17.8831\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1100 - mae: 0.8193 - mse: 1.1100 - val_loss: 16.7767 - val_mae: 1.1232 - val_mse: 16.7767\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1827 - mae: 0.8482 - mse: 1.1827 - val_loss: 17.0211 - val_mae: 1.1377 - val_mse: 17.0211\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1474 - mae: 0.8349 - mse: 1.1474 - val_loss: 18.9604 - val_mae: 1.2406 - val_mse: 18.9604\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1659 - mae: 0.8372 - mse: 1.1659 - val_loss: 19.6823 - val_mae: 1.1561 - val_mse: 19.6823\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1168 - mae: 0.8195 - mse: 1.1168 - val_loss: 21.4258 - val_mae: 1.4013 - val_mse: 21.4258\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1326 - mae: 0.8293 - mse: 1.1326 - val_loss: 16.0722 - val_mae: 1.1737 - val_mse: 16.0722\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0835 - mae: 0.8113 - mse: 1.0835 - val_loss: 14.1603 - val_mae: 1.6320 - val_mse: 14.1603\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1146 - mae: 0.8223 - mse: 1.1146 - val_loss: 13.6069 - val_mae: 1.0952 - val_mse: 13.6069\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1251 - mae: 0.8229 - mse: 1.1251 - val_loss: 15.6726 - val_mae: 1.1082 - val_mse: 15.6726\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1723 - mae: 0.8534 - mse: 1.1723 - val_loss: 13.5474 - val_mae: 1.1719 - val_mse: 13.5474\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1247 - mae: 0.8188 - mse: 1.1247 - val_loss: 16.8348 - val_mae: 1.1199 - val_mse: 16.8348\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0681 - mae: 0.8077 - mse: 1.0681 - val_loss: 15.3692 - val_mae: 1.1521 - val_mse: 15.3692\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0989 - mae: 0.8049 - mse: 1.0989 - val_loss: 15.4674 - val_mae: 1.1401 - val_mse: 15.4674\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0880 - mae: 0.8160 - mse: 1.0880 - val_loss: 15.8991 - val_mae: 1.2444 - val_mse: 15.8991\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0432 - mae: 0.7867 - mse: 1.0432 - val_loss: 15.9469 - val_mae: 1.1633 - val_mse: 15.9469\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0942 - mae: 0.8136 - mse: 1.0942 - val_loss: 13.3657 - val_mae: 1.1187 - val_mse: 13.3657\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1035 - mae: 0.8041 - mse: 1.1035 - val_loss: 16.7792 - val_mae: 1.1792 - val_mse: 16.7792\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0009 - mae: 0.7795 - mse: 1.0009 - val_loss: 18.1864 - val_mae: 1.2473 - val_mse: 18.1864\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1120 - mae: 0.8111 - mse: 1.1120 - val_loss: 19.9763 - val_mae: 1.1530 - val_mse: 19.9763\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0600 - mae: 0.7961 - mse: 1.0600 - val_loss: 15.3633 - val_mae: 1.1107 - val_mse: 15.3633\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0941 - mae: 0.8087 - mse: 1.0941 - val_loss: 16.0116 - val_mae: 1.1305 - val_mse: 16.0116\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0249 - mae: 0.7956 - mse: 1.0249 - val_loss: 20.1221 - val_mae: 1.1324 - val_mse: 20.1221\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0706 - mae: 0.7959 - mse: 1.0706 - val_loss: 18.1533 - val_mae: 1.1359 - val_mse: 18.1533\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1061 - mae: 0.8018 - mse: 1.1061 - val_loss: 22.6836 - val_mae: 1.1517 - val_mse: 22.6836\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0212 - mae: 0.7832 - mse: 1.0212 - val_loss: 15.2469 - val_mae: 1.1152 - val_mse: 15.2469\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0447 - mae: 0.8004 - mse: 1.0447 - val_loss: 15.4568 - val_mae: 1.1085 - val_mse: 15.4568\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0448 - mae: 0.7847 - mse: 1.0448 - val_loss: 18.8947 - val_mae: 1.1949 - val_mse: 18.8947\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0417 - mae: 0.7841 - mse: 1.0417 - val_loss: 18.5098 - val_mae: 1.1160 - val_mse: 18.5098\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0370 - mae: 0.7849 - mse: 1.0370 - val_loss: 24.0461 - val_mae: 1.3068 - val_mse: 24.0461\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0100 - mae: 0.7743 - mse: 1.0100 - val_loss: 20.0846 - val_mae: 1.1389 - val_mse: 20.0846\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0661 - mae: 0.7904 - mse: 1.0661 - val_loss: 19.0020 - val_mae: 1.1289 - val_mse: 19.0020\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9550 - mae: 0.7474 - mse: 0.9550 - val_loss: 20.8709 - val_mae: 1.1306 - val_mse: 20.8709\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0529 - mae: 0.7946 - mse: 1.0529 - val_loss: 19.3364 - val_mae: 1.1269 - val_mse: 19.3364\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9623 - mae: 0.7592 - mse: 0.9623 - val_loss: 18.0092 - val_mae: 1.1984 - val_mse: 18.0092\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0066 - mae: 0.7726 - mse: 1.0066 - val_loss: 16.9183 - val_mae: 1.3129 - val_mse: 16.9183\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9686 - mae: 0.7575 - mse: 0.9686 - val_loss: 24.3176 - val_mae: 1.1640 - val_mse: 24.3176\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0031 - mae: 0.7693 - mse: 1.0031 - val_loss: 16.2521 - val_mae: 1.3393 - val_mse: 16.2521\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0110 - mae: 0.7757 - mse: 1.0110 - val_loss: 15.1826 - val_mae: 1.1214 - val_mse: 15.1826\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9786 - mae: 0.7600 - mse: 0.9786 - val_loss: 16.4903 - val_mae: 1.1602 - val_mse: 16.4903\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9497 - mae: 0.7626 - mse: 0.9497 - val_loss: 16.6166 - val_mae: 1.2085 - val_mse: 16.6166\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0430 - mae: 0.7828 - mse: 1.0430 - val_loss: 16.3285 - val_mae: 1.1120 - val_mse: 16.3285\n",
      "Epoch 96/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9750 - mae: 0.7719 - mse: 0.9750 - val_loss: 17.9424 - val_mae: 1.3692 - val_mse: 17.9424\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0217 - mae: 0.7808 - mse: 1.0217 - val_loss: 16.7542 - val_mae: 1.1505 - val_mse: 16.7542\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9750 - mae: 0.7586 - mse: 0.9750 - val_loss: 21.0847 - val_mae: 1.1510 - val_mse: 21.0847\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9771 - mae: 0.7644 - mse: 0.9771 - val_loss: 17.0493 - val_mae: 1.1217 - val_mse: 17.0493\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9309 - mae: 0.7472 - mse: 0.9309 - val_loss: 21.4790 - val_mae: 1.1730 - val_mse: 21.4790\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9477 - mae: 0.7568 - mse: 0.9477 - val_loss: 22.7544 - val_mae: 1.3076 - val_mse: 22.7544\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9569 - mae: 0.7441 - mse: 0.9569 - val_loss: 15.7749 - val_mae: 1.1105 - val_mse: 15.7749\n",
      "Kappa Score: 0.5281852974007336\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 87.8846 - mae: 4.9316 - mse: 87.8846 - val_loss: 62.5984 - val_mae: 7.1621 - val_mse: 62.5984\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 25.5571 - mae: 4.4793 - mse: 25.5571 - val_loss: 27.1100 - val_mae: 4.2616 - val_mse: 27.1100\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 14.2526 - mae: 2.9981 - mse: 14.2526 - val_loss: 14.3680 - val_mae: 2.6746 - val_mse: 14.3680\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.6880 - mae: 2.0268 - mse: 6.6880 - val_loss: 9.8471 - val_mae: 2.2499 - val_mse: 9.8471\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.4932 - mae: 1.7122 - mse: 4.4932 - val_loss: 3.5418 - val_mae: 1.4476 - val_mse: 3.5418\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.7558 - mae: 1.5926 - mse: 3.7558 - val_loss: 4.9583 - val_mae: 1.6021 - val_mse: 4.9583\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.9053 - mae: 1.3546 - mse: 2.9053 - val_loss: 3.5331 - val_mae: 1.1531 - val_mse: 3.5331\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7602 - mae: 1.3231 - mse: 2.7602 - val_loss: 5.4129 - val_mae: 1.2309 - val_mse: 5.4129\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3701 - mae: 1.2148 - mse: 2.3701 - val_loss: 4.0647 - val_mae: 1.1380 - val_mse: 4.0647\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8479 - mae: 1.3083 - mse: 2.8479 - val_loss: 5.0248 - val_mae: 1.3521 - val_mse: 5.0248\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1073 - mae: 1.1381 - mse: 2.1073 - val_loss: 3.3288 - val_mae: 1.1781 - val_mse: 3.3288\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2117 - mae: 1.1864 - mse: 2.2117 - val_loss: 6.4955 - val_mae: 1.2588 - val_mse: 6.4955\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1093 - mae: 1.1439 - mse: 2.1093 - val_loss: 4.6832 - val_mae: 1.3320 - val_mse: 4.6832\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9084 - mae: 1.0959 - mse: 1.9084 - val_loss: 4.9950 - val_mae: 1.4233 - val_mse: 4.9950\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9248 - mae: 1.0816 - mse: 1.9248 - val_loss: 5.9791 - val_mae: 1.1760 - val_mse: 5.9791\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7551 - mae: 1.0218 - mse: 1.7551 - val_loss: 3.6006 - val_mae: 1.2122 - val_mse: 3.6006\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8370 - mae: 1.0667 - mse: 1.8370 - val_loss: 5.0281 - val_mae: 1.1143 - val_mse: 5.0281\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7690 - mae: 1.0271 - mse: 1.7690 - val_loss: 5.0147 - val_mae: 1.2720 - val_mse: 5.0147\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5329 - mae: 0.9563 - mse: 1.5329 - val_loss: 3.7908 - val_mae: 1.1790 - val_mse: 3.7908\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6711 - mae: 1.0182 - mse: 1.6711 - val_loss: 3.2453 - val_mae: 1.0756 - val_mse: 3.2453\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6052 - mae: 0.9832 - mse: 1.6052 - val_loss: 7.8520 - val_mae: 1.5025 - val_mse: 7.8520\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5188 - mae: 0.9547 - mse: 1.5188 - val_loss: 2.9707 - val_mae: 1.0431 - val_mse: 2.9707\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.5445 - mae: 0.9509 - mse: 1.544 - 0s 1ms/step - loss: 1.5376 - mae: 0.9672 - mse: 1.5376 - val_loss: 4.6917 - val_mae: 1.5375 - val_mse: 4.6917\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3963 - mae: 0.9274 - mse: 1.3963 - val_loss: 3.3922 - val_mae: 1.0875 - val_mse: 3.3922\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4413 - mae: 0.9217 - mse: 1.4413 - val_loss: 2.9803 - val_mae: 1.0748 - val_mse: 2.9803\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5750 - mae: 0.9735 - mse: 1.5750 - val_loss: 3.2217 - val_mae: 1.0996 - val_mse: 3.2217\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4955 - mae: 0.9444 - mse: 1.4955 - val_loss: 3.5303 - val_mae: 1.0747 - val_mse: 3.5303\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4725 - mae: 0.9478 - mse: 1.4725 - val_loss: 6.0908 - val_mae: 1.2835 - val_mse: 6.0908\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3777 - mae: 0.9099 - mse: 1.3777 - val_loss: 2.8306 - val_mae: 1.1288 - val_mse: 2.8306\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4596 - mae: 0.9418 - mse: 1.4596 - val_loss: 4.3956 - val_mae: 1.1077 - val_mse: 4.3956\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4075 - mae: 0.9074 - mse: 1.4075 - val_loss: 3.2187 - val_mae: 1.1367 - val_mse: 3.2187\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4236 - mae: 0.9194 - mse: 1.4236 - val_loss: 4.8491 - val_mae: 1.1824 - val_mse: 4.8491\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2887 - mae: 0.8795 - mse: 1.2887 - val_loss: 2.8925 - val_mae: 1.0442 - val_mse: 2.8925\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3614 - mae: 0.9027 - mse: 1.3614 - val_loss: 5.1594 - val_mae: 1.2610 - val_mse: 5.1594\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3317 - mae: 0.8982 - mse: 1.3317 - val_loss: 2.8210 - val_mae: 1.0256 - val_mse: 2.8210\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4080 - mae: 0.9285 - mse: 1.4080 - val_loss: 5.8952 - val_mae: 1.2109 - val_mse: 5.8952\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3827 - mae: 0.9118 - mse: 1.3827 - val_loss: 2.7135 - val_mae: 1.0860 - val_mse: 2.7135\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4455 - mae: 0.9310 - mse: 1.4455 - val_loss: 4.3794 - val_mae: 1.1260 - val_mse: 4.3794\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3255 - mae: 0.8780 - mse: 1.3255 - val_loss: 2.8199 - val_mae: 1.0139 - val_mse: 2.8199\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2561 - mae: 0.8701 - mse: 1.2561 - val_loss: 4.5828 - val_mae: 1.1229 - val_mse: 4.5828\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2689 - mae: 0.8740 - mse: 1.2689 - val_loss: 3.0767 - val_mae: 1.0812 - val_mse: 3.0767\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4073 - mae: 0.9046 - mse: 1.4073 - val_loss: 3.8061 - val_mae: 1.0637 - val_mse: 3.8061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2162 - mae: 0.8612 - mse: 1.2162 - val_loss: 2.5485 - val_mae: 0.9697 - val_mse: 2.5485\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2449 - mae: 0.8626 - mse: 1.2449 - val_loss: 4.1469 - val_mae: 1.0985 - val_mse: 4.1469\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3309 - mae: 0.8864 - mse: 1.3309 - val_loss: 3.0363 - val_mae: 1.0753 - val_mse: 3.0363\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2207 - mae: 0.8448 - mse: 1.2207 - val_loss: 5.7046 - val_mae: 1.2059 - val_mse: 5.7046\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2903 - mae: 0.8782 - mse: 1.2903 - val_loss: 2.8289 - val_mae: 1.2122 - val_mse: 2.8289\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2565 - mae: 0.8794 - mse: 1.2565 - val_loss: 5.1845 - val_mae: 1.1170 - val_mse: 5.1845\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2927 - mae: 0.8817 - mse: 1.2927 - val_loss: 2.6751 - val_mae: 0.9945 - val_mse: 2.6751\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1307 - mae: 0.8241 - mse: 1.1307 - val_loss: 3.4424 - val_mae: 1.0522 - val_mse: 3.4424\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2167 - mae: 0.8613 - mse: 1.2167 - val_loss: 2.4915 - val_mae: 0.9924 - val_mse: 2.4915\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1869 - mae: 0.8408 - mse: 1.1869 - val_loss: 5.7587 - val_mae: 1.1453 - val_mse: 5.7587\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2055 - mae: 0.8471 - mse: 1.2055 - val_loss: 2.7907 - val_mae: 1.0168 - val_mse: 2.7907\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1686 - mae: 0.8353 - mse: 1.1686 - val_loss: 4.9829 - val_mae: 1.1655 - val_mse: 4.9829\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2331 - mae: 0.8600 - mse: 1.2331 - val_loss: 2.9002 - val_mae: 1.0152 - val_mse: 2.9002\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1418 - mae: 0.8096 - mse: 1.1418 - val_loss: 4.2307 - val_mae: 1.0937 - val_mse: 4.2307\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1309 - mae: 0.8306 - mse: 1.1309 - val_loss: 2.7625 - val_mae: 1.1760 - val_mse: 2.7625\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1892 - mae: 0.8474 - mse: 1.1892 - val_loss: 4.8640 - val_mae: 1.1033 - val_mse: 4.8640\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1248 - mae: 0.8175 - mse: 1.1248 - val_loss: 2.6473 - val_mae: 0.9890 - val_mse: 2.6473\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1487 - mae: 0.8194 - mse: 1.1487 - val_loss: 3.0609 - val_mae: 1.0169 - val_mse: 3.0609\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1307 - mae: 0.8094 - mse: 1.1307 - val_loss: 2.7539 - val_mae: 1.0064 - val_mse: 2.7539\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0931 - mae: 0.8072 - mse: 1.0931 - val_loss: 4.8808 - val_mae: 1.1690 - val_mse: 4.8808\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1602 - mae: 0.8295 - mse: 1.1602 - val_loss: 2.8737 - val_mae: 1.0262 - val_mse: 2.8737\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1034 - mae: 0.8109 - mse: 1.1034 - val_loss: 2.5438 - val_mae: 1.0336 - val_mse: 2.5438\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0998 - mae: 0.8140 - mse: 1.0998 - val_loss: 3.4483 - val_mae: 1.1128 - val_mse: 3.4483\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0945 - mae: 0.8022 - mse: 1.0945 - val_loss: 2.6355 - val_mae: 1.0278 - val_mse: 2.6355\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1021 - mae: 0.8234 - mse: 1.1021 - val_loss: 3.5571 - val_mae: 1.0902 - val_mse: 3.5571\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1576 - mae: 0.8214 - mse: 1.1576 - val_loss: 4.7026 - val_mae: 1.3182 - val_mse: 4.7026\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1227 - mae: 0.8250 - mse: 1.1227 - val_loss: 2.8183 - val_mae: 1.0726 - val_mse: 2.8183\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0985 - mae: 0.8081 - mse: 1.0985 - val_loss: 4.4653 - val_mae: 1.2813 - val_mse: 4.4653\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1238 - mae: 0.8203 - mse: 1.1238 - val_loss: 2.9294 - val_mae: 1.1750 - val_mse: 2.9294\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2325 - mae: 0.8542 - mse: 1.2325 - val_loss: 2.6793 - val_mae: 1.0053 - val_mse: 2.6793\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0507 - mae: 0.7881 - mse: 1.0507 - val_loss: 3.8287 - val_mae: 1.1650 - val_mse: 3.8287\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0666 - mae: 0.8043 - mse: 1.0666 - val_loss: 2.6815 - val_mae: 1.1159 - val_mse: 2.6815\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0987 - mae: 0.8117 - mse: 1.0987 - val_loss: 4.1948 - val_mae: 1.1150 - val_mse: 4.1948\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0945 - mae: 0.8119 - mse: 1.0945 - val_loss: 3.6753 - val_mae: 1.2334 - val_mse: 3.6753\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0432 - mae: 0.7878 - mse: 1.0432 - val_loss: 3.4083 - val_mae: 1.0526 - val_mse: 3.4083\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0525 - mae: 0.7893 - mse: 1.0525 - val_loss: 2.6255 - val_mae: 0.9817 - val_mse: 2.6255\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0454 - mae: 0.7849 - mse: 1.0454 - val_loss: 3.7850 - val_mae: 1.1293 - val_mse: 3.7850\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1135 - mae: 0.8096 - mse: 1.1135 - val_loss: 2.7920 - val_mae: 0.9932 - val_mse: 2.7920\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0698 - mae: 0.7918 - mse: 1.0698 - val_loss: 3.3381 - val_mae: 1.0731 - val_mse: 3.3381\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9761 - mae: 0.7637 - mse: 0.9761 - val_loss: 2.6895 - val_mae: 0.9834 - val_mse: 2.6895\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0936 - mae: 0.8103 - mse: 1.0936 - val_loss: 3.0811 - val_mae: 1.0150 - val_mse: 3.0811\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9742 - mae: 0.7589 - mse: 0.9742 - val_loss: 2.7266 - val_mae: 0.9943 - val_mse: 2.7266\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0948 - mae: 0.7951 - mse: 1.0948 - val_loss: 3.3382 - val_mae: 1.0938 - val_mse: 3.3382\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9552 - mae: 0.7481 - mse: 0.9552 - val_loss: 2.6159 - val_mae: 0.9821 - val_mse: 2.6159\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0193 - mae: 0.7856 - mse: 1.0193 - val_loss: 3.1731 - val_mae: 1.0192 - val_mse: 3.1731\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9630 - mae: 0.7613 - mse: 0.9630 - val_loss: 2.8917 - val_mae: 1.0046 - val_mse: 2.8917\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9857 - mae: 0.7589 - mse: 0.9857 - val_loss: 3.0265 - val_mae: 1.0126 - val_mse: 3.0265\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9634 - mae: 0.7535 - mse: 0.9634 - val_loss: 2.6061 - val_mae: 1.0146 - val_mse: 2.6061\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0606 - mae: 0.7875 - mse: 1.0606 - val_loss: 3.3848 - val_mae: 1.0556 - val_mse: 3.3848\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9405 - mae: 0.7432 - mse: 0.9405 - val_loss: 2.6311 - val_mae: 0.9903 - val_mse: 2.6311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9962 - mae: 0.7709 - mse: 0.9962 - val_loss: 3.2644 - val_mae: 1.0355 - val_mse: 3.2644\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9633 - mae: 0.7520 - mse: 0.9633 - val_loss: 2.6522 - val_mae: 1.0022 - val_mse: 2.6522\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9488 - mae: 0.7466 - mse: 0.9488 - val_loss: 3.4588 - val_mae: 1.2350 - val_mse: 3.4588\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9055 - mae: 0.7297 - mse: 0.9055 - val_loss: 2.6160 - val_mae: 1.0358 - val_mse: 2.6160\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9501 - mae: 0.7507 - mse: 0.9501 - val_loss: 3.1863 - val_mae: 1.0262 - val_mse: 3.1863\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9728 - mae: 0.7517 - mse: 0.9728 - val_loss: 2.7729 - val_mae: 0.9887 - val_mse: 2.7729\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9360 - mae: 0.7457 - mse: 0.9360 - val_loss: 2.9263 - val_mae: 1.0450 - val_mse: 2.9263\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9429 - mae: 0.7326 - mse: 0.9429 - val_loss: 2.7446 - val_mae: 0.9851 - val_mse: 2.7446\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9433 - mae: 0.7311 - mse: 0.9433 - val_loss: 3.4892 - val_mae: 1.0549 - val_mse: 3.4892\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9041 - mae: 0.7225 - mse: 0.9041 - val_loss: 2.6538 - val_mae: 1.0061 - val_mse: 2.6538\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9516 - mae: 0.7520 - mse: 0.9516 - val_loss: 3.7004 - val_mae: 1.1418 - val_mse: 3.7004\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9410 - mae: 0.7504 - mse: 0.9410 - val_loss: 2.7585 - val_mae: 0.9951 - val_mse: 2.7585\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9689 - mae: 0.7581 - mse: 0.9689 - val_loss: 2.7295 - val_mae: 1.0344 - val_mse: 2.7295\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9628 - mae: 0.7515 - mse: 0.9628 - val_loss: 2.7039 - val_mae: 0.9724 - val_mse: 2.7039\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9343 - mae: 0.7498 - mse: 0.9343 - val_loss: 3.2298 - val_mae: 1.0154 - val_mse: 3.2298\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9617 - mae: 0.7563 - mse: 0.9617 - val_loss: 2.7373 - val_mae: 1.0419 - val_mse: 2.7373\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9371 - mae: 0.7323 - mse: 0.9371 - val_loss: 3.3291 - val_mae: 1.2574 - val_mse: 3.3291\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8922 - mae: 0.7177 - mse: 0.8922 - val_loss: 2.7524 - val_mae: 1.1241 - val_mse: 2.7524\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9168 - mae: 0.7317 - mse: 0.9168 - val_loss: 3.0974 - val_mae: 1.0986 - val_mse: 3.0974\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9591 - mae: 0.7457 - mse: 0.9591 - val_loss: 2.6760 - val_mae: 0.9741 - val_mse: 2.6760\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9184 - mae: 0.7348 - mse: 0.9184 - val_loss: 3.2165 - val_mae: 1.0294 - val_mse: 3.2165\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9070 - mae: 0.7266 - mse: 0.9070 - val_loss: 2.6343 - val_mae: 0.9733 - val_mse: 2.6343\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9523 - mae: 0.7632 - mse: 0.9523 - val_loss: 3.1750 - val_mae: 1.0269 - val_mse: 3.1750\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9172 - mae: 0.7382 - mse: 0.9172 - val_loss: 2.8176 - val_mae: 1.0188 - val_mse: 2.8176\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8707 - mae: 0.7173 - mse: 0.8707 - val_loss: 3.5895 - val_mae: 1.1111 - val_mse: 3.5895\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8715 - mae: 0.7123 - mse: 0.8715 - val_loss: 3.3017 - val_mae: 1.0939 - val_mse: 3.3017\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9034 - mae: 0.7280 - mse: 0.9034 - val_loss: 2.7327 - val_mae: 1.0195 - val_mse: 2.7327\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8366 - mae: 0.6922 - mse: 0.8366 - val_loss: 3.0697 - val_mae: 1.0224 - val_mse: 3.0697\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9055 - mae: 0.7229 - mse: 0.9055 - val_loss: 2.9866 - val_mae: 1.0328 - val_mse: 2.9866\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8213 - mae: 0.6886 - mse: 0.8213 - val_loss: 3.0617 - val_mae: 1.2854 - val_mse: 3.0617\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8968 - mae: 0.7343 - mse: 0.8968 - val_loss: 4.3256 - val_mae: 1.2655 - val_mse: 4.3256\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8592 - mae: 0.7048 - mse: 0.8592 - val_loss: 2.8297 - val_mae: 1.0406 - val_mse: 2.8297\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8875 - mae: 0.7156 - mse: 0.8875 - val_loss: 3.0997 - val_mae: 1.1078 - val_mse: 3.0997\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9324 - mae: 0.7365 - mse: 0.9324 - val_loss: 2.8092 - val_mae: 0.9922 - val_mse: 2.8092\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8396 - mae: 0.7049 - mse: 0.8396 - val_loss: 3.1691 - val_mae: 1.0347 - val_mse: 3.1691\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8329 - mae: 0.7010 - mse: 0.8329 - val_loss: 3.9166 - val_mae: 1.2281 - val_mse: 3.9166\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8740 - mae: 0.7107 - mse: 0.8740 - val_loss: 3.2206 - val_mae: 1.1596 - val_mse: 3.2206\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8498 - mae: 0.6996 - mse: 0.8498 - val_loss: 2.7988 - val_mae: 0.9901 - val_mse: 2.7988\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8179 - mae: 0.7033 - mse: 0.8179 - val_loss: 3.1695 - val_mae: 1.1366 - val_mse: 3.1695\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8540 - mae: 0.7062 - mse: 0.8540 - val_loss: 2.6886 - val_mae: 1.0120 - val_mse: 2.6886\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8648 - mae: 0.6972 - mse: 0.8648 - val_loss: 3.0967 - val_mae: 1.0294 - val_mse: 3.0967\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8318 - mae: 0.6970 - mse: 0.8318 - val_loss: 2.6980 - val_mae: 1.0062 - val_mse: 2.6980\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8429 - mae: 0.6961 - mse: 0.8429 - val_loss: 3.1947 - val_mae: 1.0620 - val_mse: 3.1947\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8531 - mae: 0.7012 - mse: 0.8531 - val_loss: 2.8369 - val_mae: 0.9877 - val_mse: 2.8369\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8471 - mae: 0.7130 - mse: 0.8471 - val_loss: 3.2372 - val_mae: 1.0679 - val_mse: 3.2372\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7678 - mae: 0.6634 - mse: 0.7678 - val_loss: 3.6036 - val_mae: 1.0586 - val_mse: 3.6036\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8280 - mae: 0.6932 - mse: 0.8280 - val_loss: 3.4407 - val_mae: 1.1208 - val_mse: 3.4407\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8958 - mae: 0.7181 - mse: 0.8958 - val_loss: 2.7031 - val_mae: 1.0347 - val_mse: 2.7031\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8336 - mae: 0.6950 - mse: 0.8336 - val_loss: 3.3588 - val_mae: 1.3474 - val_mse: 3.3588\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8137 - mae: 0.6907 - mse: 0.8137 - val_loss: 3.4020 - val_mae: 1.1234 - val_mse: 3.4020\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7531 - mae: 0.6484 - mse: 0.7531 - val_loss: 3.8750 - val_mae: 1.1531 - val_mse: 3.8750\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8269 - mae: 0.6957 - mse: 0.8269 - val_loss: 3.8731 - val_mae: 1.2086 - val_mse: 3.8731\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7773 - mae: 0.6707 - mse: 0.7773 - val_loss: 3.3804 - val_mae: 1.0415 - val_mse: 3.3804\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7661 - mae: 0.6686 - mse: 0.7661 - val_loss: 3.0243 - val_mae: 1.1284 - val_mse: 3.0243\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7939 - mae: 0.6647 - mse: 0.7939 - val_loss: 3.1105 - val_mae: 1.0120 - val_mse: 3.1105\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8438 - mae: 0.7000 - mse: 0.8438 - val_loss: 2.9350 - val_mae: 1.1022 - val_mse: 2.9350\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7776 - mae: 0.6624 - mse: 0.7776 - val_loss: 4.4305 - val_mae: 1.3208 - val_mse: 4.4305\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8272 - mae: 0.7036 - mse: 0.8272 - val_loss: 3.3583 - val_mae: 1.0640 - val_mse: 3.3583\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7779 - mae: 0.6693 - mse: 0.7779 - val_loss: 3.2595 - val_mae: 1.0401 - val_mse: 3.2595\n",
      "Kappa Score: 0.7272572994027945\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 97.6683 - mae: 5.7585 - mse: 97.6683 - val_loss: 25.5243 - val_mae: 4.7830 - val_mse: 25.5243\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 24.6222 - mae: 4.4864 - mse: 24.6222 - val_loss: 17.0976 - val_mae: 3.9313 - val_mse: 17.0976\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 12.1923 - mae: 3.0631 - mse: 12.1923 - val_loss: 14.5720 - val_mae: 3.5929 - val_mse: 14.5720\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 9.0746 - mae: 2.2424 - mse: 9.0746 - val_loss: 4.3134 - val_mae: 1.6185 - val_mse: 4.3134\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.3703 - mae: 1.6633 - mse: 4.3703 - val_loss: 5.4278 - val_mae: 2.0138 - val_mse: 5.4278\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.6842 - mae: 1.7032 - mse: 4.6842 - val_loss: 4.7928 - val_mae: 1.4607 - val_mse: 4.7928\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.2817 - mae: 1.4336 - mse: 3.2817 - val_loss: 8.7942 - val_mae: 2.7747 - val_mse: 8.7942\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.3062 - mae: 1.4458 - mse: 3.3062 - val_loss: 3.1292 - val_mae: 1.1343 - val_mse: 3.1292\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6517 - mae: 1.2812 - mse: 2.6517 - val_loss: 5.2920 - val_mae: 1.5039 - val_mse: 5.2920\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2669 - mae: 1.1875 - mse: 2.2669 - val_loss: 4.4038 - val_mae: 1.2714 - val_mse: 4.4038\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4291 - mae: 1.2593 - mse: 2.4291 - val_loss: 3.5078 - val_mae: 1.4213 - val_mse: 3.5078\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9141 - mae: 1.0763 - mse: 1.9141 - val_loss: 3.1869 - val_mae: 1.0834 - val_mse: 3.1869\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2494 - mae: 1.1625 - mse: 2.2494 - val_loss: 3.6694 - val_mae: 1.1728 - val_mse: 3.6694\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9515 - mae: 1.0940 - mse: 1.9515 - val_loss: 3.1941 - val_mae: 1.0637 - val_mse: 3.1941\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9751 - mae: 1.0969 - mse: 1.9751 - val_loss: 3.0622 - val_mae: 1.0463 - val_mse: 3.0622\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8776 - mae: 1.0710 - mse: 1.8776 - val_loss: 3.2214 - val_mae: 1.1488 - val_mse: 3.2214\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8095 - mae: 1.0246 - mse: 1.8095 - val_loss: 4.1484 - val_mae: 1.3091 - val_mse: 4.1484\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7568 - mae: 1.0448 - mse: 1.7568 - val_loss: 2.9983 - val_mae: 1.0559 - val_mse: 2.9983\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8097 - mae: 1.0583 - mse: 1.8097 - val_loss: 3.5518 - val_mae: 1.2392 - val_mse: 3.5518\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8222 - mae: 1.0667 - mse: 1.8222 - val_loss: 4.3681 - val_mae: 1.3068 - val_mse: 4.3681\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7170 - mae: 1.0240 - mse: 1.7170 - val_loss: 2.8393 - val_mae: 1.0205 - val_mse: 2.8393\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5940 - mae: 1.0015 - mse: 1.5940 - val_loss: 4.5145 - val_mae: 1.2321 - val_mse: 4.5145\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6755 - mae: 1.0105 - mse: 1.6755 - val_loss: 4.2850 - val_mae: 1.3244 - val_mse: 4.2850\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7133 - mae: 1.0130 - mse: 1.7133 - val_loss: 8.5653 - val_mae: 2.1922 - val_mse: 8.5653\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4423 - mae: 0.9318 - mse: 1.4423 - val_loss: 3.0820 - val_mae: 1.0777 - val_mse: 3.0820\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6936 - mae: 1.0130 - mse: 1.6936 - val_loss: 4.3460 - val_mae: 1.2730 - val_mse: 4.3460\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5452 - mae: 0.9640 - mse: 1.5452 - val_loss: 3.7580 - val_mae: 1.1126 - val_mse: 3.7580\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5770 - mae: 0.9908 - mse: 1.5770 - val_loss: 2.8723 - val_mae: 1.0168 - val_mse: 2.8723\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5010 - mae: 0.9443 - mse: 1.5010 - val_loss: 4.0228 - val_mae: 1.1417 - val_mse: 4.0228\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4930 - mae: 0.9489 - mse: 1.4930 - val_loss: 3.0149 - val_mae: 1.2272 - val_mse: 3.0149\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4361 - mae: 0.9306 - mse: 1.4361 - val_loss: 2.5338 - val_mae: 1.0059 - val_mse: 2.5338\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4378 - mae: 0.9189 - mse: 1.4378 - val_loss: 3.2798 - val_mae: 1.0413 - val_mse: 3.2798\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3894 - mae: 0.9061 - mse: 1.3894 - val_loss: 2.7850 - val_mae: 1.0981 - val_mse: 2.7850\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3960 - mae: 0.9247 - mse: 1.3960 - val_loss: 2.9414 - val_mae: 1.0237 - val_mse: 2.9414\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3766 - mae: 0.9065 - mse: 1.3766 - val_loss: 3.1684 - val_mae: 1.0986 - val_mse: 3.1684\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2993 - mae: 0.8760 - mse: 1.2993 - val_loss: 3.2878 - val_mae: 1.0287 - val_mse: 3.2878\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4743 - mae: 0.9363 - mse: 1.4743 - val_loss: 3.2792 - val_mae: 1.1053 - val_mse: 3.2792\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4781 - mae: 0.9354 - mse: 1.4781 - val_loss: 2.7029 - val_mae: 0.9932 - val_mse: 2.7029\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3030 - mae: 0.8876 - mse: 1.3030 - val_loss: 3.3361 - val_mae: 1.0842 - val_mse: 3.3361\n",
      "Epoch 40/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3346 - mae: 0.9122 - mse: 1.3346 - val_loss: 2.7081 - val_mae: 1.0729 - val_mse: 2.7081\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2674 - mae: 0.8706 - mse: 1.2674 - val_loss: 3.7351 - val_mae: 1.1983 - val_mse: 3.7351\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4198 - mae: 0.9294 - mse: 1.4198 - val_loss: 3.1075 - val_mae: 1.3206 - val_mse: 3.1075\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3579 - mae: 0.9023 - mse: 1.3579 - val_loss: 3.3449 - val_mae: 1.2573 - val_mse: 3.3449\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2422 - mae: 0.8595 - mse: 1.2422 - val_loss: 2.8379 - val_mae: 1.0096 - val_mse: 2.8379\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3631 - mae: 0.9081 - mse: 1.3631 - val_loss: 3.1676 - val_mae: 1.0607 - val_mse: 3.1676\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2459 - mae: 0.8728 - mse: 1.2459 - val_loss: 2.5656 - val_mae: 0.9787 - val_mse: 2.5656\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2347 - mae: 0.8515 - mse: 1.2347 - val_loss: 3.5472 - val_mae: 1.3679 - val_mse: 3.5472\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3022 - mae: 0.8931 - mse: 1.3022 - val_loss: 2.8173 - val_mae: 1.1815 - val_mse: 2.8173\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2603 - mae: 0.8700 - mse: 1.2603 - val_loss: 2.8243 - val_mae: 1.0111 - val_mse: 2.8243\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2083 - mae: 0.8651 - mse: 1.2083 - val_loss: 3.0871 - val_mae: 1.2768 - val_mse: 3.0871\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2269 - mae: 0.8576 - mse: 1.2269 - val_loss: 3.6234 - val_mae: 1.1176 - val_mse: 3.6234\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2005 - mae: 0.8514 - mse: 1.2005 - val_loss: 2.7146 - val_mae: 1.0403 - val_mse: 2.7146\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0700 - mae: 0.7996 - mse: 1.0700 - val_loss: 3.6879 - val_mae: 1.1866 - val_mse: 3.6879\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3093 - mae: 0.8896 - mse: 1.3093 - val_loss: 2.6934 - val_mae: 0.9911 - val_mse: 2.6934\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1351 - mae: 0.8287 - mse: 1.1351 - val_loss: 3.4100 - val_mae: 1.1101 - val_mse: 3.4100\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1647 - mae: 0.8411 - mse: 1.1647 - val_loss: 3.0582 - val_mae: 1.0919 - val_mse: 3.0582\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1323 - mae: 0.8318 - mse: 1.1323 - val_loss: 3.5100 - val_mae: 1.1642 - val_mse: 3.5100\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2363 - mae: 0.8565 - mse: 1.2363 - val_loss: 2.6544 - val_mae: 1.0647 - val_mse: 2.6544\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1648 - mae: 0.8318 - mse: 1.1648 - val_loss: 3.0747 - val_mae: 1.0025 - val_mse: 3.0747\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1006 - mae: 0.8129 - mse: 1.1006 - val_loss: 2.5365 - val_mae: 0.9898 - val_mse: 2.5365\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1582 - mae: 0.8386 - mse: 1.1582 - val_loss: 3.1623 - val_mae: 1.0330 - val_mse: 3.1623\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1155 - mae: 0.8224 - mse: 1.1155 - val_loss: 3.2353 - val_mae: 1.0393 - val_mse: 3.2353\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1907 - mae: 0.8544 - mse: 1.1907 - val_loss: 2.6270 - val_mae: 1.0023 - val_mse: 2.6270\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0875 - mae: 0.8106 - mse: 1.0875 - val_loss: 3.2493 - val_mae: 1.1082 - val_mse: 3.2493\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0745 - mae: 0.7976 - mse: 1.0745 - val_loss: 3.1720 - val_mae: 1.0188 - val_mse: 3.1720\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1155 - mae: 0.8112 - mse: 1.1155 - val_loss: 2.7718 - val_mae: 0.9973 - val_mse: 2.7718\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1011 - mae: 0.7973 - mse: 1.1011 - val_loss: 2.6887 - val_mae: 0.9905 - val_mse: 2.6887\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0985 - mae: 0.8085 - mse: 1.0985 - val_loss: 2.6969 - val_mae: 0.9963 - val_mse: 2.6969\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0518 - mae: 0.7976 - mse: 1.0518 - val_loss: 2.9850 - val_mae: 1.0203 - val_mse: 2.9850\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1767 - mae: 0.8397 - mse: 1.1767 - val_loss: 2.5796 - val_mae: 1.0418 - val_mse: 2.5796\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0374 - mae: 0.7889 - mse: 1.0374 - val_loss: 2.8527 - val_mae: 1.0104 - val_mse: 2.8527\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0633 - mae: 0.8039 - mse: 1.0633 - val_loss: 2.7139 - val_mae: 1.0504 - val_mse: 2.7139\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0719 - mae: 0.8122 - mse: 1.0719 - val_loss: 3.2498 - val_mae: 1.0677 - val_mse: 3.2498\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0287 - mae: 0.7799 - mse: 1.0287 - val_loss: 2.8383 - val_mae: 1.0126 - val_mse: 2.8383\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0133 - mae: 0.7792 - mse: 1.0133 - val_loss: 3.2930 - val_mae: 1.1458 - val_mse: 3.2930\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0780 - mae: 0.8026 - mse: 1.0780 - val_loss: 3.2550 - val_mae: 1.0718 - val_mse: 3.2550\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0154 - mae: 0.7760 - mse: 1.0154 - val_loss: 3.4179 - val_mae: 1.1583 - val_mse: 3.4179\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0587 - mae: 0.8022 - mse: 1.0587 - val_loss: 3.0836 - val_mae: 1.0543 - val_mse: 3.0836\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0206 - mae: 0.7866 - mse: 1.0206 - val_loss: 2.9843 - val_mae: 1.0196 - val_mse: 2.9843\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0464 - mae: 0.7852 - mse: 1.0464 - val_loss: 3.0312 - val_mae: 1.0408 - val_mse: 3.0312\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9733 - mae: 0.7608 - mse: 0.9733 - val_loss: 2.6263 - val_mae: 0.9895 - val_mse: 2.6263\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9337 - mae: 0.7344 - mse: 0.9337 - val_loss: 3.1805 - val_mae: 1.0821 - val_mse: 3.1805\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0327 - mae: 0.7902 - mse: 1.0327 - val_loss: 3.5084 - val_mae: 1.1608 - val_mse: 3.5084\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9734 - mae: 0.7628 - mse: 0.9734 - val_loss: 2.8192 - val_mae: 0.9871 - val_mse: 2.8192\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9639 - mae: 0.7443 - mse: 0.9639 - val_loss: 3.0146 - val_mae: 1.0438 - val_mse: 3.0146\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0100 - mae: 0.7774 - mse: 1.0100 - val_loss: 3.0832 - val_mae: 1.0542 - val_mse: 3.0832\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9183 - mae: 0.7381 - mse: 0.9183 - val_loss: 2.5828 - val_mae: 1.0468 - val_mse: 2.5828\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9627 - mae: 0.7470 - mse: 0.9627 - val_loss: 2.7332 - val_mae: 0.9923 - val_mse: 2.7332\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0068 - mae: 0.7640 - mse: 1.0068 - val_loss: 2.8126 - val_mae: 1.0001 - val_mse: 2.8126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9684 - mae: 0.7599 - mse: 0.9684 - val_loss: 2.7018 - val_mae: 0.9751 - val_mse: 2.7018\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9533 - mae: 0.7454 - mse: 0.9533 - val_loss: 2.9291 - val_mae: 1.2088 - val_mse: 2.9291\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9560 - mae: 0.7464 - mse: 0.9560 - val_loss: 3.5549 - val_mae: 1.1847 - val_mse: 3.5549\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9326 - mae: 0.7482 - mse: 0.9326 - val_loss: 2.7498 - val_mae: 1.1019 - val_mse: 2.7498\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9365 - mae: 0.7497 - mse: 0.9365 - val_loss: 2.6020 - val_mae: 0.9709 - val_mse: 2.6020\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9494 - mae: 0.7417 - mse: 0.9494 - val_loss: 3.1768 - val_mae: 1.3210 - val_mse: 3.1768\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9813 - mae: 0.7548 - mse: 0.9813 - val_loss: 3.3830 - val_mae: 1.1134 - val_mse: 3.3830\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9099 - mae: 0.7263 - mse: 0.9099 - val_loss: 2.7548 - val_mae: 0.9864 - val_mse: 2.7548\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8874 - mae: 0.7191 - mse: 0.8874 - val_loss: 2.6153 - val_mae: 1.0248 - val_mse: 2.6153\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9380 - mae: 0.7450 - mse: 0.9380 - val_loss: 2.8965 - val_mae: 1.1827 - val_mse: 2.8965\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9539 - mae: 0.7585 - mse: 0.9539 - val_loss: 2.7147 - val_mae: 1.0133 - val_mse: 2.7147\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8543 - mae: 0.6984 - mse: 0.8543 - val_loss: 2.7337 - val_mae: 0.9877 - val_mse: 2.7337\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8481 - mae: 0.7053 - mse: 0.8481 - val_loss: 2.6909 - val_mae: 1.0687 - val_mse: 2.6909\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9160 - mae: 0.7338 - mse: 0.9160 - val_loss: 2.8295 - val_mae: 1.0002 - val_mse: 2.8295\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9120 - mae: 0.7334 - mse: 0.9120 - val_loss: 3.3990 - val_mae: 1.1590 - val_mse: 3.3990\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8704 - mae: 0.7106 - mse: 0.8704 - val_loss: 2.6306 - val_mae: 0.9770 - val_mse: 2.6306\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8772 - mae: 0.7107 - mse: 0.8772 - val_loss: 2.8091 - val_mae: 0.9918 - val_mse: 2.8091\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9090 - mae: 0.7242 - mse: 0.9090 - val_loss: 2.6326 - val_mae: 1.0279 - val_mse: 2.6326\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8991 - mae: 0.7308 - mse: 0.8991 - val_loss: 2.7556 - val_mae: 0.9874 - val_mse: 2.7556\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9008 - mae: 0.7199 - mse: 0.9008 - val_loss: 2.5680 - val_mae: 0.9927 - val_mse: 2.5680\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8526 - mae: 0.7038 - mse: 0.8526 - val_loss: 2.7220 - val_mae: 0.9989 - val_mse: 2.7220\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9096 - mae: 0.7314 - mse: 0.9096 - val_loss: 2.5434 - val_mae: 0.9976 - val_mse: 2.5434\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8799 - mae: 0.7157 - mse: 0.8799 - val_loss: 2.7517 - val_mae: 0.9828 - val_mse: 2.7517\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8380 - mae: 0.7044 - mse: 0.8380 - val_loss: 2.7265 - val_mae: 1.0743 - val_mse: 2.7265\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8813 - mae: 0.7157 - mse: 0.8813 - val_loss: 3.3008 - val_mae: 1.1165 - val_mse: 3.3008\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8740 - mae: 0.7181 - mse: 0.8740 - val_loss: 3.3691 - val_mae: 1.1295 - val_mse: 3.3691\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8647 - mae: 0.7211 - mse: 0.8647 - val_loss: 2.6662 - val_mae: 1.0617 - val_mse: 2.6662\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8089 - mae: 0.6808 - mse: 0.8089 - val_loss: 2.7959 - val_mae: 0.9928 - val_mse: 2.7959\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8508 - mae: 0.7003 - mse: 0.8508 - val_loss: 3.0746 - val_mae: 1.0871 - val_mse: 3.0746\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8404 - mae: 0.7010 - mse: 0.8404 - val_loss: 2.8678 - val_mae: 1.1702 - val_mse: 2.8678\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8241 - mae: 0.7045 - mse: 0.8241 - val_loss: 2.6993 - val_mae: 0.9885 - val_mse: 2.6993\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8324 - mae: 0.6850 - mse: 0.8324 - val_loss: 2.6874 - val_mae: 1.0243 - val_mse: 2.6874\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8357 - mae: 0.7022 - mse: 0.8357 - val_loss: 2.6508 - val_mae: 0.9891 - val_mse: 2.6508\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8535 - mae: 0.7016 - mse: 0.8535 - val_loss: 2.8849 - val_mae: 1.1888 - val_mse: 2.8849\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8346 - mae: 0.6907 - mse: 0.8346 - val_loss: 2.7474 - val_mae: 1.0449 - val_mse: 2.7474\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8572 - mae: 0.7117 - mse: 0.8572 - val_loss: 2.6865 - val_mae: 0.9870 - val_mse: 2.6865\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7633 - mae: 0.6645 - mse: 0.7633 - val_loss: 2.7187 - val_mae: 1.0811 - val_mse: 2.7187\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8378 - mae: 0.7083 - mse: 0.8378 - val_loss: 2.9230 - val_mae: 1.0468 - val_mse: 2.9230\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8061 - mae: 0.6916 - mse: 0.8061 - val_loss: 2.7630 - val_mae: 1.0099 - val_mse: 2.7630\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7888 - mae: 0.6736 - mse: 0.7888 - val_loss: 2.7073 - val_mae: 1.0712 - val_mse: 2.7073\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8522 - mae: 0.7006 - mse: 0.8522 - val_loss: 3.0275 - val_mae: 1.0207 - val_mse: 3.0275\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8133 - mae: 0.6898 - mse: 0.8133 - val_loss: 2.9747 - val_mae: 1.0363 - val_mse: 2.9747\n",
      "Kappa Score: 0.7635077113317075\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 76.5471 - mae: 4.0827 - mse: 76.5471 - val_loss: 11.5698 - val_mae: 2.4364 - val_mse: 11.5698\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 20.9814 - mae: 3.8584 - mse: 20.9814 - val_loss: 9.7321 - val_mae: 1.7721 - val_mse: 9.7321\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 12.5421 - mae: 2.6380 - mse: 12.5421 - val_loss: 4.0001 - val_mae: 1.2928 - val_mse: 4.0001\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 8.7122 - mae: 2.0709 - mse: 8.7122 - val_loss: 5.5695 - val_mae: 2.0700 - val_mse: 5.5695\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 6.9148 - mae: 2.0813 - mse: 6.9148 - val_loss: 7.6662 - val_mae: 1.7107 - val_mse: 7.6662\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.8143 - mae: 1.7416 - mse: 4.8143 - val_loss: 2.7471 - val_mae: 1.2934 - val_mse: 2.7471\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.5430 - mae: 1.4943 - mse: 3.5430 - val_loss: 5.8113 - val_mae: 1.4405 - val_mse: 5.8113\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.3825 - mae: 1.4604 - mse: 3.3825 - val_loss: 2.2309 - val_mae: 0.9954 - val_mse: 2.2309\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5121 - mae: 1.2752 - mse: 2.5121 - val_loss: 6.9414 - val_mae: 1.2191 - val_mse: 6.9414\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4584 - mae: 1.2416 - mse: 2.4584 - val_loss: 3.5673 - val_mae: 1.2159 - val_mse: 3.5673\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4571 - mae: 1.2433 - mse: 2.4571 - val_loss: 4.2849 - val_mae: 1.8265 - val_mse: 4.2849\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3805 - mae: 1.2027 - mse: 2.3805 - val_loss: 4.8120 - val_mae: 1.1850 - val_mse: 4.8120\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0362 - mae: 1.1335 - mse: 2.0362 - val_loss: 5.9701 - val_mae: 1.7869 - val_mse: 5.9701\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2195 - mae: 1.1627 - mse: 2.2195 - val_loss: 4.2766 - val_mae: 1.1743 - val_mse: 4.2766\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0064 - mae: 1.1028 - mse: 2.0064 - val_loss: 2.2514 - val_mae: 0.9811 - val_mse: 2.2514\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7191 - mae: 1.0134 - mse: 1.7191 - val_loss: 3.7268 - val_mae: 1.0813 - val_mse: 3.7268\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8453 - mae: 1.0713 - mse: 1.8453 - val_loss: 3.2028 - val_mae: 1.4878 - val_mse: 3.2028\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8921 - mae: 1.0696 - mse: 1.8921 - val_loss: 3.4849 - val_mae: 1.1401 - val_mse: 3.4849\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5871 - mae: 0.9825 - mse: 1.5871 - val_loss: 2.3160 - val_mae: 0.9914 - val_mse: 2.3160\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7485 - mae: 1.0357 - mse: 1.7485 - val_loss: 4.1483 - val_mae: 1.2656 - val_mse: 4.1483\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5324 - mae: 0.9716 - mse: 1.5324 - val_loss: 2.1174 - val_mae: 0.9541 - val_mse: 2.1174\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6010 - mae: 0.9938 - mse: 1.6010 - val_loss: 3.7019 - val_mae: 1.1254 - val_mse: 3.7019\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5350 - mae: 0.9807 - mse: 1.5350 - val_loss: 3.2383 - val_mae: 1.4867 - val_mse: 3.2383\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6532 - mae: 1.0229 - mse: 1.6532 - val_loss: 3.2544 - val_mae: 1.2144 - val_mse: 3.2544\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4065 - mae: 0.9282 - mse: 1.4065 - val_loss: 2.0653 - val_mae: 0.9571 - val_mse: 2.0653\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5086 - mae: 0.9658 - mse: 1.5086 - val_loss: 3.0529 - val_mae: 1.0554 - val_mse: 3.0529\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5224 - mae: 0.9471 - mse: 1.5224 - val_loss: 3.2215 - val_mae: 1.2275 - val_mse: 3.2215\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3977 - mae: 0.9322 - mse: 1.3977 - val_loss: 3.7308 - val_mae: 1.1572 - val_mse: 3.7308\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4503 - mae: 0.9456 - mse: 1.4503 - val_loss: 2.3028 - val_mae: 1.0613 - val_mse: 2.3028\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4073 - mae: 0.9390 - mse: 1.4073 - val_loss: 3.5792 - val_mae: 1.1237 - val_mse: 3.5792\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4014 - mae: 0.9253 - mse: 1.4014 - val_loss: 2.2726 - val_mae: 0.9627 - val_mse: 2.2726\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3602 - mae: 0.9155 - mse: 1.3602 - val_loss: 3.6813 - val_mae: 1.0342 - val_mse: 3.6813\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2784 - mae: 0.8786 - mse: 1.2784 - val_loss: 3.5872 - val_mae: 1.3146 - val_mse: 3.5872\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4701 - mae: 0.9473 - mse: 1.4701 - val_loss: 3.5901 - val_mae: 1.2842 - val_mse: 3.5901\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3455 - mae: 0.9014 - mse: 1.3455 - val_loss: 2.3469 - val_mae: 1.0270 - val_mse: 2.3469\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3367 - mae: 0.9034 - mse: 1.3367 - val_loss: 3.0837 - val_mae: 1.0648 - val_mse: 3.0837\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3110 - mae: 0.8924 - mse: 1.3110 - val_loss: 2.3318 - val_mae: 0.9788 - val_mse: 2.3318\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3097 - mae: 0.8976 - mse: 1.3097 - val_loss: 2.7228 - val_mae: 0.9846 - val_mse: 2.7228\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3792 - mae: 0.9379 - mse: 1.3792 - val_loss: 2.7166 - val_mae: 1.0324 - val_mse: 2.7166\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2866 - mae: 0.8853 - mse: 1.2866 - val_loss: 2.8049 - val_mae: 0.9955 - val_mse: 2.8049\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3210 - mae: 0.8907 - mse: 1.3210 - val_loss: 2.3745 - val_mae: 1.1144 - val_mse: 2.3745\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2763 - mae: 0.8869 - mse: 1.2763 - val_loss: 3.0010 - val_mae: 1.0580 - val_mse: 3.0010\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2584 - mae: 0.8749 - mse: 1.2584 - val_loss: 2.6860 - val_mae: 1.0593 - val_mse: 2.6860\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2427 - mae: 0.8687 - mse: 1.2427 - val_loss: 3.2417 - val_mae: 1.0458 - val_mse: 3.2417\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2652 - mae: 0.8796 - mse: 1.2652 - val_loss: 2.2969 - val_mae: 1.0804 - val_mse: 2.2969\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2269 - mae: 0.8691 - mse: 1.2269 - val_loss: 2.9417 - val_mae: 1.0541 - val_mse: 2.9417\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2352 - mae: 0.8662 - mse: 1.2352 - val_loss: 2.1326 - val_mae: 0.9849 - val_mse: 2.1326\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2594 - mae: 0.8703 - mse: 1.2594 - val_loss: 3.2068 - val_mae: 1.1128 - val_mse: 3.2068\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2141 - mae: 0.8572 - mse: 1.2141 - val_loss: 2.5114 - val_mae: 1.0225 - val_mse: 2.5114\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2018 - mae: 0.8561 - mse: 1.2018 - val_loss: 3.6981 - val_mae: 1.2592 - val_mse: 3.6981\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1716 - mae: 0.8443 - mse: 1.1716 - val_loss: 2.1682 - val_mae: 0.9403 - val_mse: 2.1682\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1996 - mae: 0.8522 - mse: 1.1996 - val_loss: 3.6667 - val_mae: 1.0577 - val_mse: 3.6667\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1700 - mae: 0.8414 - mse: 1.1700 - val_loss: 2.1966 - val_mae: 0.9681 - val_mse: 2.1966\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2311 - mae: 0.8613 - mse: 1.2311 - val_loss: 2.7706 - val_mae: 1.1885 - val_mse: 2.7706\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1826 - mae: 0.8493 - mse: 1.1826 - val_loss: 2.7479 - val_mae: 0.9916 - val_mse: 2.7479\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1939 - mae: 0.8533 - mse: 1.1939 - val_loss: 2.7439 - val_mae: 1.2949 - val_mse: 2.7439\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2128 - mae: 0.8546 - mse: 1.2128 - val_loss: 2.7354 - val_mae: 1.2104 - val_mse: 2.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1391 - mae: 0.8232 - mse: 1.1391 - val_loss: 2.1395 - val_mae: 0.9307 - val_mse: 2.1395\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0911 - mae: 0.8077 - mse: 1.0911 - val_loss: 2.5389 - val_mae: 0.9623 - val_mse: 2.5389\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0995 - mae: 0.8137 - mse: 1.0995 - val_loss: 2.2803 - val_mae: 0.9556 - val_mse: 2.2803\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1136 - mae: 0.8223 - mse: 1.1136 - val_loss: 2.4122 - val_mae: 1.0537 - val_mse: 2.4122\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1956 - mae: 0.8500 - mse: 1.1956 - val_loss: 2.7157 - val_mae: 1.0119 - val_mse: 2.7157\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0954 - mae: 0.8247 - mse: 1.0954 - val_loss: 2.3367 - val_mae: 1.1148 - val_mse: 2.3367\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1059 - mae: 0.8135 - mse: 1.1059 - val_loss: 2.8289 - val_mae: 1.0774 - val_mse: 2.8289\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1730 - mae: 0.8505 - mse: 1.1730 - val_loss: 2.0860 - val_mae: 0.9119 - val_mse: 2.0860\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1335 - mae: 0.8128 - mse: 1.1335 - val_loss: 3.1728 - val_mae: 1.1867 - val_mse: 3.1728\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0837 - mae: 0.8102 - mse: 1.0837 - val_loss: 2.1119 - val_mae: 0.9489 - val_mse: 2.1119\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0846 - mae: 0.8109 - mse: 1.0846 - val_loss: 2.9437 - val_mae: 1.1084 - val_mse: 2.9437\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1617 - mae: 0.8353 - mse: 1.1617 - val_loss: 2.1032 - val_mae: 0.9190 - val_mse: 2.1032\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0941 - mae: 0.8070 - mse: 1.0941 - val_loss: 2.3419 - val_mae: 0.9515 - val_mse: 2.3419\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0147 - mae: 0.7827 - mse: 1.0147 - val_loss: 2.8424 - val_mae: 1.2874 - val_mse: 2.8424\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1718 - mae: 0.8433 - mse: 1.1718 - val_loss: 2.2486 - val_mae: 1.0258 - val_mse: 2.2486\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9936 - mae: 0.7735 - mse: 0.9936 - val_loss: 2.5373 - val_mae: 1.1577 - val_mse: 2.5373\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1199 - mae: 0.8166 - mse: 1.1199 - val_loss: 2.8443 - val_mae: 1.1070 - val_mse: 2.8443\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0137 - mae: 0.7840 - mse: 1.0137 - val_loss: 2.2033 - val_mae: 0.9708 - val_mse: 2.2033\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0421 - mae: 0.7881 - mse: 1.0421 - val_loss: 2.7351 - val_mae: 1.0858 - val_mse: 2.7351\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0558 - mae: 0.8059 - mse: 1.0558 - val_loss: 2.3165 - val_mae: 1.0422 - val_mse: 2.3165\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0215 - mae: 0.7828 - mse: 1.0215 - val_loss: 2.1211 - val_mae: 0.9179 - val_mse: 2.1211\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0274 - mae: 0.7826 - mse: 1.0274 - val_loss: 2.2394 - val_mae: 0.9622 - val_mse: 2.2394\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0825 - mae: 0.8029 - mse: 1.0825 - val_loss: 2.8939 - val_mae: 1.1136 - val_mse: 2.8939\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0107 - mae: 0.7785 - mse: 1.0107 - val_loss: 2.5514 - val_mae: 0.9865 - val_mse: 2.5514\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9698 - mae: 0.7665 - mse: 0.9698 - val_loss: 2.8872 - val_mae: 1.1093 - val_mse: 2.8872\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0558 - mae: 0.8012 - mse: 1.0558 - val_loss: 3.1662 - val_mae: 1.1733 - val_mse: 3.1662\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0159 - mae: 0.7707 - mse: 1.0159 - val_loss: 2.6296 - val_mae: 1.0112 - val_mse: 2.6296\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9990 - mae: 0.7672 - mse: 0.9990 - val_loss: 2.1944 - val_mae: 0.9860 - val_mse: 2.1944\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9744 - mae: 0.7722 - mse: 0.9744 - val_loss: 2.4644 - val_mae: 0.9711 - val_mse: 2.4644\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9952 - mae: 0.7719 - mse: 0.9952 - val_loss: 2.1978 - val_mae: 0.9175 - val_mse: 2.1978\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0299 - mae: 0.7776 - mse: 1.0299 - val_loss: 2.7607 - val_mae: 1.0722 - val_mse: 2.7607\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0275 - mae: 0.7723 - mse: 1.0275 - val_loss: 2.8572 - val_mae: 1.0824 - val_mse: 2.8572\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9535 - mae: 0.7497 - mse: 0.9535 - val_loss: 2.1850 - val_mae: 0.9090 - val_mse: 2.1850\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0249 - mae: 0.7802 - mse: 1.0249 - val_loss: 2.7564 - val_mae: 1.0537 - val_mse: 2.7564\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9836 - mae: 0.7522 - mse: 0.9836 - val_loss: 2.2989 - val_mae: 0.9368 - val_mse: 2.2989\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9507 - mae: 0.7553 - mse: 0.9507 - val_loss: 2.1985 - val_mae: 0.9146 - val_mse: 2.1985\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0053 - mae: 0.7687 - mse: 1.0053 - val_loss: 2.1230 - val_mae: 0.9143 - val_mse: 2.1230\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9658 - mae: 0.7557 - mse: 0.9658 - val_loss: 2.3741 - val_mae: 1.0937 - val_mse: 2.3741\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9677 - mae: 0.7693 - mse: 0.9677 - val_loss: 2.1825 - val_mae: 0.9543 - val_mse: 2.1825\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9727 - mae: 0.7673 - mse: 0.9727 - val_loss: 2.2327 - val_mae: 1.0434 - val_mse: 2.2327\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9868 - mae: 0.7595 - mse: 0.9868 - val_loss: 2.2160 - val_mae: 0.9246 - val_mse: 2.2160\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9627 - mae: 0.7519 - mse: 0.9627 - val_loss: 2.2592 - val_mae: 0.9234 - val_mse: 2.2592\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0015 - mae: 0.7792 - mse: 1.0015 - val_loss: 2.1409 - val_mae: 0.8995 - val_mse: 2.1409\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9674 - mae: 0.7615 - mse: 0.9674 - val_loss: 2.2928 - val_mae: 1.0329 - val_mse: 2.2928\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9296 - mae: 0.7381 - mse: 0.9296 - val_loss: 2.1881 - val_mae: 0.9706 - val_mse: 2.1881\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9329 - mae: 0.7381 - mse: 0.9329 - val_loss: 2.3970 - val_mae: 0.9332 - val_mse: 2.3970\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9618 - mae: 0.7454 - mse: 0.9618 - val_loss: 2.4233 - val_mae: 0.9528 - val_mse: 2.4233\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9548 - mae: 0.7646 - mse: 0.9548 - val_loss: 2.2636 - val_mae: 1.0584 - val_mse: 2.2636\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9183 - mae: 0.7329 - mse: 0.9183 - val_loss: 2.2143 - val_mae: 0.9907 - val_mse: 2.2143\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9611 - mae: 0.7556 - mse: 0.9611 - val_loss: 2.4942 - val_mae: 0.9603 - val_mse: 2.4942\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9693 - mae: 0.7586 - mse: 0.9693 - val_loss: 2.1612 - val_mae: 0.9664 - val_mse: 2.1612\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9162 - mae: 0.7365 - mse: 0.9162 - val_loss: 2.1365 - val_mae: 0.9062 - val_mse: 2.1365\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8609 - mae: 0.7112 - mse: 0.8609 - val_loss: 2.3652 - val_mae: 0.9257 - val_mse: 2.3652\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9383 - mae: 0.7384 - mse: 0.9383 - val_loss: 2.1467 - val_mae: 0.9431 - val_mse: 2.1467\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9072 - mae: 0.7423 - mse: 0.9072 - val_loss: 2.2725 - val_mae: 0.9625 - val_mse: 2.2725\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9094 - mae: 0.7263 - mse: 0.9094 - val_loss: 2.2446 - val_mae: 0.9169 - val_mse: 2.2446\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9221 - mae: 0.7432 - mse: 0.9221 - val_loss: 2.3430 - val_mae: 0.9259 - val_mse: 2.3430\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8809 - mae: 0.7286 - mse: 0.8809 - val_loss: 2.1899 - val_mae: 0.9084 - val_mse: 2.1899\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8976 - mae: 0.7280 - mse: 0.8976 - val_loss: 2.4246 - val_mae: 1.1165 - val_mse: 2.4246\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9506 - mae: 0.7575 - mse: 0.9506 - val_loss: 2.5380 - val_mae: 1.0131 - val_mse: 2.5380\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8479 - mae: 0.7102 - mse: 0.8479 - val_loss: 2.2835 - val_mae: 0.9085 - val_mse: 2.2835\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9350 - mae: 0.7373 - mse: 0.9350 - val_loss: 2.1536 - val_mae: 0.9350 - val_mse: 2.1536\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9142 - mae: 0.7398 - mse: 0.9142 - val_loss: 2.4288 - val_mae: 0.9368 - val_mse: 2.4288\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8617 - mae: 0.7086 - mse: 0.8617 - val_loss: 2.1292 - val_mae: 0.9188 - val_mse: 2.1292\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9096 - mae: 0.7251 - mse: 0.9096 - val_loss: 2.5015 - val_mae: 0.9497 - val_mse: 2.5015\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8398 - mae: 0.7027 - mse: 0.8398 - val_loss: 2.2549 - val_mae: 0.9081 - val_mse: 2.2549\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8903 - mae: 0.7336 - mse: 0.8903 - val_loss: 2.2425 - val_mae: 0.9382 - val_mse: 2.2425\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8156 - mae: 0.6937 - mse: 0.8156 - val_loss: 2.3494 - val_mae: 0.9520 - val_mse: 2.3494\n",
      "Kappa Score: 0.7165876439342627\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 108.5016 - mae: 5.5205 - mse: 108.5016 - val_loss: 95.7881 - val_mae: 8.6087 - val_mse: 95.7881\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 35.3043 - mae: 4.5680 - mse: 35.3043 - val_loss: 36.1224 - val_mae: 5.1507 - val_mse: 36.1224\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 20.0488 - mae: 3.4842 - mse: 20.0488 - val_loss: 22.4600 - val_mae: 3.6023 - val_mse: 22.4600\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 12.3120 - mae: 2.7112 - mse: 12.3120 - val_loss: 18.7794 - val_mae: 3.5762 - val_mse: 18.7794\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 7.3104 - mae: 2.0934 - mse: 7.3104 - val_loss: 5.1762 - val_mae: 1.5622 - val_mse: 5.1762\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 4.1794 - mae: 1.5927 - mse: 4.1794 - val_loss: 5.1030 - val_mae: 1.3146 - val_mse: 5.1030\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.2662 - mae: 1.4228 - mse: 3.2662 - val_loss: 3.4600 - val_mae: 1.1445 - val_mse: 3.4600\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5626 - mae: 1.2734 - mse: 2.5626 - val_loss: 7.1410 - val_mae: 1.5412 - val_mse: 7.1410\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2276 - mae: 1.1699 - mse: 2.2276 - val_loss: 2.9532 - val_mae: 1.0745 - val_mse: 2.9532\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2842 - mae: 1.2055 - mse: 2.2842 - val_loss: 3.1846 - val_mae: 1.0507 - val_mse: 3.1846\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9011 - mae: 1.0819 - mse: 1.9011 - val_loss: 3.8450 - val_mae: 1.0594 - val_mse: 3.8450\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0327 - mae: 1.1446 - mse: 2.0327 - val_loss: 2.6981 - val_mae: 1.0290 - val_mse: 2.6981\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9218 - mae: 1.0902 - mse: 1.9218 - val_loss: 7.2993 - val_mae: 1.1744 - val_mse: 7.2993\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.7603 - mae: 1.0407 - mse: 1.7603 - val_loss: 3.3095 - val_mae: 1.3168 - val_mse: 3.3095\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.8548 - mae: 1.0687 - mse: 1.8548 - val_loss: 6.0836 - val_mae: 1.5717 - val_mse: 6.0836\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6353 - mae: 1.0047 - mse: 1.6353 - val_loss: 4.3053 - val_mae: 1.3842 - val_mse: 4.3053\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.6875 - mae: 1.0173 - mse: 1.6875 - val_loss: 8.8773 - val_mae: 1.2736 - val_mse: 8.8773\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5332 - mae: 0.9743 - mse: 1.5332 - val_loss: 3.4547 - val_mae: 1.2006 - val_mse: 3.4547\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5442 - mae: 0.9802 - mse: 1.5442 - val_loss: 6.0924 - val_mae: 1.2909 - val_mse: 6.0924\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5763 - mae: 0.9819 - mse: 1.5763 - val_loss: 2.7700 - val_mae: 1.0476 - val_mse: 2.7700\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5446 - mae: 0.9810 - mse: 1.5446 - val_loss: 4.7753 - val_mae: 1.1657 - val_mse: 4.7753\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5021 - mae: 0.9610 - mse: 1.5021 - val_loss: 2.5499 - val_mae: 1.0829 - val_mse: 2.5499\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5198 - mae: 0.9677 - mse: 1.5198 - val_loss: 3.1850 - val_mae: 1.1995 - val_mse: 3.1850\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.5061 - mae: 0.9658 - mse: 1.5061 - val_loss: 3.7794 - val_mae: 1.1219 - val_mse: 3.7794\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4141 - mae: 0.9367 - mse: 1.4141 - val_loss: 2.5713 - val_mae: 0.9920 - val_mse: 2.5713\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4409 - mae: 0.9455 - mse: 1.4409 - val_loss: 5.2204 - val_mae: 1.2940 - val_mse: 5.2204\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3856 - mae: 0.9167 - mse: 1.3856 - val_loss: 2.4028 - val_mae: 0.9722 - val_mse: 2.4028\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4296 - mae: 0.9299 - mse: 1.4296 - val_loss: 5.5761 - val_mae: 1.5794 - val_mse: 5.5761\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4625 - mae: 0.9632 - mse: 1.4625 - val_loss: 3.6434 - val_mae: 1.2563 - val_mse: 3.6434\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3753 - mae: 0.9366 - mse: 1.3753 - val_loss: 5.0403 - val_mae: 1.0747 - val_mse: 5.0403\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4152 - mae: 0.9460 - mse: 1.4152 - val_loss: 2.9464 - val_mae: 1.0480 - val_mse: 2.9464\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4111 - mae: 0.9463 - mse: 1.4111 - val_loss: 4.4155 - val_mae: 1.0449 - val_mse: 4.4155\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.4353 - mae: 0.9421 - mse: 1.4353 - val_loss: 2.8903 - val_mae: 1.2803 - val_mse: 2.8903\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3071 - mae: 0.9013 - mse: 1.3071 - val_loss: 5.5395 - val_mae: 1.0984 - val_mse: 5.5395\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3918 - mae: 0.9274 - mse: 1.3918 - val_loss: 2.3824 - val_mae: 0.9469 - val_mse: 2.3824\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3052 - mae: 0.8958 - mse: 1.3052 - val_loss: 4.9669 - val_mae: 1.1126 - val_mse: 4.9669\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3318 - mae: 0.8984 - mse: 1.3318 - val_loss: 2.8559 - val_mae: 1.2587 - val_mse: 2.8559\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3482 - mae: 0.9087 - mse: 1.3482 - val_loss: 4.6824 - val_mae: 1.0567 - val_mse: 4.6824\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.3176 - mae: 0.8976 - mse: 1.3176 - val_loss: 2.3588 - val_mae: 0.9467 - val_mse: 2.3588\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2591 - mae: 0.8818 - mse: 1.2591 - val_loss: 4.5553 - val_mae: 1.0479 - val_mse: 4.5553\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2618 - mae: 0.8723 - mse: 1.2618 - val_loss: 2.2307 - val_mae: 0.9384 - val_mse: 2.2307\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2560 - mae: 0.8903 - mse: 1.2560 - val_loss: 4.0405 - val_mae: 1.0456 - val_mse: 4.0405\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1868 - mae: 0.8609 - mse: 1.1868 - val_loss: 3.0339 - val_mae: 1.3320 - val_mse: 3.0339\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2461 - mae: 0.8729 - mse: 1.2461 - val_loss: 5.2457 - val_mae: 1.1290 - val_mse: 5.2457\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2156 - mae: 0.8594 - mse: 1.2156 - val_loss: 2.2234 - val_mae: 0.9317 - val_mse: 2.2234\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2318 - mae: 0.8703 - mse: 1.2318 - val_loss: 4.3983 - val_mae: 1.1722 - val_mse: 4.3983\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2411 - mae: 0.8740 - mse: 1.2411 - val_loss: 2.7848 - val_mae: 1.0861 - val_mse: 2.7848\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2051 - mae: 0.8591 - mse: 1.2051 - val_loss: 3.3860 - val_mae: 1.2238 - val_mse: 3.3860\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2768 - mae: 0.8851 - mse: 1.2768 - val_loss: 4.0396 - val_mae: 1.3421 - val_mse: 4.0396\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2076 - mae: 0.8560 - mse: 1.2076 - val_loss: 2.4707 - val_mae: 0.9644 - val_mse: 2.4707\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1547 - mae: 0.8403 - mse: 1.1547 - val_loss: 3.6162 - val_mae: 1.0140 - val_mse: 3.6162\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0814 - mae: 0.8100 - mse: 1.0814 - val_loss: 2.6750 - val_mae: 1.0290 - val_mse: 2.6750\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2486 - mae: 0.8656 - mse: 1.2486 - val_loss: 3.4570 - val_mae: 1.0167 - val_mse: 3.4570\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.2029 - mae: 0.8555 - mse: 1.2029 - val_loss: 2.5106 - val_mae: 0.9590 - val_mse: 2.5106\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1092 - mae: 0.8217 - mse: 1.1092 - val_loss: 5.1403 - val_mae: 1.2420 - val_mse: 5.1403\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1505 - mae: 0.8384 - mse: 1.1505 - val_loss: 2.5575 - val_mae: 0.9836 - val_mse: 2.5575\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1092 - mae: 0.8201 - mse: 1.1092 - val_loss: 3.8232 - val_mae: 1.2439 - val_mse: 3.8232\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1970 - mae: 0.8579 - mse: 1.1970 - val_loss: 2.4143 - val_mae: 0.9648 - val_mse: 2.4143\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0825 - mae: 0.8066 - mse: 1.0825 - val_loss: 4.5233 - val_mae: 1.1707 - val_mse: 4.5233\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1417 - mae: 0.8318 - mse: 1.1417 - val_loss: 2.5664 - val_mae: 0.9978 - val_mse: 2.5664\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1763 - mae: 0.8433 - mse: 1.1763 - val_loss: 3.5962 - val_mae: 1.0084 - val_mse: 3.5962\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1204 - mae: 0.8234 - mse: 1.1204 - val_loss: 2.1490 - val_mae: 0.9083 - val_mse: 2.1490\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1601 - mae: 0.8352 - mse: 1.1601 - val_loss: 4.4768 - val_mae: 1.1562 - val_mse: 4.4768\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0852 - mae: 0.8096 - mse: 1.0852 - val_loss: 2.5427 - val_mae: 1.1454 - val_mse: 2.5427\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0275 - mae: 0.7893 - mse: 1.0275 - val_loss: 2.3012 - val_mae: 0.9742 - val_mse: 2.3012\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1798 - mae: 0.8355 - mse: 1.1798 - val_loss: 2.4613 - val_mae: 0.9635 - val_mse: 2.4613\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0536 - mae: 0.7786 - mse: 1.0536 - val_loss: 3.4740 - val_mae: 1.2163 - val_mse: 3.4740\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0739 - mae: 0.8137 - mse: 1.0739 - val_loss: 3.3702 - val_mae: 1.0102 - val_mse: 3.3702\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1006 - mae: 0.8117 - mse: 1.1006 - val_loss: 3.6595 - val_mae: 1.2619 - val_mse: 3.6595\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1050 - mae: 0.8132 - mse: 1.1050 - val_loss: 2.3213 - val_mae: 1.0333 - val_mse: 2.3213\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0941 - mae: 0.8211 - mse: 1.0941 - val_loss: 3.3727 - val_mae: 1.0768 - val_mse: 3.3727\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9866 - mae: 0.7741 - mse: 0.9866 - val_loss: 2.4528 - val_mae: 0.9607 - val_mse: 2.4528\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0691 - mae: 0.8005 - mse: 1.0691 - val_loss: 2.6812 - val_mae: 0.9584 - val_mse: 2.6812\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.1509 - mae: 0.8333 - mse: 1.1509 - val_loss: 2.1596 - val_mae: 0.9335 - val_mse: 2.1596\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0057 - mae: 0.7804 - mse: 1.0057 - val_loss: 3.4816 - val_mae: 1.0865 - val_mse: 3.4816\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0198 - mae: 0.7966 - mse: 1.0198 - val_loss: 2.6763 - val_mae: 1.0191 - val_mse: 2.6763\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0413 - mae: 0.7970 - mse: 1.0413 - val_loss: 2.9739 - val_mae: 1.0633 - val_mse: 2.9739\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0390 - mae: 0.7853 - mse: 1.0390 - val_loss: 2.2109 - val_mae: 0.8974 - val_mse: 2.2109\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0636 - mae: 0.7999 - mse: 1.0636 - val_loss: 2.3926 - val_mae: 0.9302 - val_mse: 2.3926\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0035 - mae: 0.7870 - mse: 1.0035 - val_loss: 3.0791 - val_mae: 1.1124 - val_mse: 3.0791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0090 - mae: 0.7784 - mse: 1.0090 - val_loss: 2.3440 - val_mae: 1.0539 - val_mse: 2.3440\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0609 - mae: 0.8047 - mse: 1.0609 - val_loss: 2.1721 - val_mae: 0.8934 - val_mse: 2.1721\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9164 - mae: 0.7412 - mse: 0.9164 - val_loss: 2.8501 - val_mae: 1.1154 - val_mse: 2.8501\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9186 - mae: 0.7339 - mse: 0.9186 - val_loss: 2.2372 - val_mae: 0.9053 - val_mse: 2.2372\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0169 - mae: 0.7871 - mse: 1.0169 - val_loss: 3.0312 - val_mae: 1.0240 - val_mse: 3.0312\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.0213 - mae: 0.7831 - mse: 1.0213 - val_loss: 2.1518 - val_mae: 0.9002 - val_mse: 2.1518\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9549 - mae: 0.7668 - mse: 0.9549 - val_loss: 3.6026 - val_mae: 1.1942 - val_mse: 3.6026\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9811 - mae: 0.7713 - mse: 0.9811 - val_loss: 2.3066 - val_mae: 1.0400 - val_mse: 2.3066\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9662 - mae: 0.7705 - mse: 0.9662 - val_loss: 2.7871 - val_mae: 0.9653 - val_mse: 2.7871\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9379 - mae: 0.7537 - mse: 0.9379 - val_loss: 2.7953 - val_mae: 1.0341 - val_mse: 2.7953\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9780 - mae: 0.7587 - mse: 0.9780 - val_loss: 2.4596 - val_mae: 0.9507 - val_mse: 2.4596\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9200 - mae: 0.7364 - mse: 0.9200 - val_loss: 2.3492 - val_mae: 0.9216 - val_mse: 2.3492\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9643 - mae: 0.7514 - mse: 0.9643 - val_loss: 3.2137 - val_mae: 1.0570 - val_mse: 3.2137\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9682 - mae: 0.7505 - mse: 0.9682 - val_loss: 2.0858 - val_mae: 0.8942 - val_mse: 2.0858\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8870 - mae: 0.7302 - mse: 0.8870 - val_loss: 2.5735 - val_mae: 0.9362 - val_mse: 2.5735\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9144 - mae: 0.7450 - mse: 0.9144 - val_loss: 2.2154 - val_mae: 0.9695 - val_mse: 2.2154\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8964 - mae: 0.7312 - mse: 0.8964 - val_loss: 3.4621 - val_mae: 1.2303 - val_mse: 3.4621\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9033 - mae: 0.7354 - mse: 0.9033 - val_loss: 2.4174 - val_mae: 1.0520 - val_mse: 2.4174\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9618 - mae: 0.7561 - mse: 0.9618 - val_loss: 2.2157 - val_mae: 0.9325 - val_mse: 2.2157\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9092 - mae: 0.7373 - mse: 0.9092 - val_loss: 2.4079 - val_mae: 0.9574 - val_mse: 2.4079\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9365 - mae: 0.7408 - mse: 0.9365 - val_loss: 2.3412 - val_mae: 1.0010 - val_mse: 2.3412\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8732 - mae: 0.7257 - mse: 0.8732 - val_loss: 2.2244 - val_mae: 0.9073 - val_mse: 2.2244\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9222 - mae: 0.7327 - mse: 0.9222 - val_loss: 2.3622 - val_mae: 0.9238 - val_mse: 2.3622\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8669 - mae: 0.7187 - mse: 0.8669 - val_loss: 3.1065 - val_mae: 1.0601 - val_mse: 3.1065\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9241 - mae: 0.7337 - mse: 0.9241 - val_loss: 2.1386 - val_mae: 0.8917 - val_mse: 2.1386\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9215 - mae: 0.7368 - mse: 0.9215 - val_loss: 2.2838 - val_mae: 0.9147 - val_mse: 2.2838\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9020 - mae: 0.7373 - mse: 0.9020 - val_loss: 2.3982 - val_mae: 0.9246 - val_mse: 2.3982\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9114 - mae: 0.7244 - mse: 0.9114 - val_loss: 2.2785 - val_mae: 0.9166 - val_mse: 2.2785\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8240 - mae: 0.7017 - mse: 0.8240 - val_loss: 2.2547 - val_mae: 0.9273 - val_mse: 2.2547\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8534 - mae: 0.7046 - mse: 0.8534 - val_loss: 2.2116 - val_mae: 0.8900 - val_mse: 2.2116\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8518 - mae: 0.7040 - mse: 0.8518 - val_loss: 3.8070 - val_mae: 1.2364 - val_mse: 3.8070\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8635 - mae: 0.7197 - mse: 0.8635 - val_loss: 2.7141 - val_mae: 1.0167 - val_mse: 2.7141\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8614 - mae: 0.7192 - mse: 0.8614 - val_loss: 2.6771 - val_mae: 0.9725 - val_mse: 2.6771\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8693 - mae: 0.7154 - mse: 0.8693 - val_loss: 2.1958 - val_mae: 0.8919 - val_mse: 2.1958\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8324 - mae: 0.7086 - mse: 0.8324 - val_loss: 2.7681 - val_mae: 0.9898 - val_mse: 2.7681\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.9290 - mae: 0.7494 - mse: 0.9290 - val_loss: 2.6321 - val_mae: 0.9994 - val_mse: 2.6321\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8029 - mae: 0.6844 - mse: 0.8029 - val_loss: 2.2615 - val_mae: 0.9035 - val_mse: 2.2615\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8573 - mae: 0.7135 - mse: 0.8573 - val_loss: 2.6467 - val_mae: 0.9893 - val_mse: 2.6467\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8055 - mae: 0.7018 - mse: 0.8055 - val_loss: 2.4118 - val_mae: 0.9274 - val_mse: 2.4118\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8484 - mae: 0.7028 - mse: 0.8484 - val_loss: 2.4692 - val_mae: 1.0240 - val_mse: 2.4692\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8829 - mae: 0.7187 - mse: 0.8829 - val_loss: 2.2066 - val_mae: 0.8991 - val_mse: 2.2066\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8175 - mae: 0.6921 - mse: 0.8175 - val_loss: 2.3178 - val_mae: 0.9236 - val_mse: 2.3178\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7917 - mae: 0.6870 - mse: 0.7917 - val_loss: 2.2171 - val_mae: 0.9533 - val_mse: 2.2171\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7706 - mae: 0.6775 - mse: 0.7706 - val_loss: 2.3154 - val_mae: 0.9050 - val_mse: 2.3154\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7661 - mae: 0.6751 - mse: 0.7661 - val_loss: 2.1760 - val_mae: 0.9002 - val_mse: 2.1760\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8209 - mae: 0.7030 - mse: 0.8209 - val_loss: 2.4605 - val_mae: 0.9559 - val_mse: 2.4605\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7684 - mae: 0.6729 - mse: 0.7684 - val_loss: 2.1622 - val_mae: 0.9160 - val_mse: 2.1622\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8020 - mae: 0.6887 - mse: 0.8020 - val_loss: 2.3803 - val_mae: 0.9218 - val_mse: 2.3803\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7886 - mae: 0.6760 - mse: 0.7886 - val_loss: 2.2369 - val_mae: 0.9981 - val_mse: 2.2369\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8118 - mae: 0.6954 - mse: 0.8118 - val_loss: 2.4211 - val_mae: 1.0709 - val_mse: 2.4211\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7739 - mae: 0.6802 - mse: 0.7739 - val_loss: 2.1598 - val_mae: 0.9069 - val_mse: 2.1598\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7956 - mae: 0.6885 - mse: 0.7956 - val_loss: 2.6234 - val_mae: 0.9524 - val_mse: 2.6234\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7838 - mae: 0.6887 - mse: 0.7838 - val_loss: 2.2773 - val_mae: 1.0123 - val_mse: 2.2773\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7822 - mae: 0.6783 - mse: 0.7822 - val_loss: 2.6336 - val_mae: 1.1347 - val_mse: 2.6336\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7333 - mae: 0.6588 - mse: 0.7333 - val_loss: 2.1945 - val_mae: 0.9760 - val_mse: 2.1945\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.8155 - mae: 0.7034 - mse: 0.8155 - val_loss: 2.8732 - val_mae: 1.0154 - val_mse: 2.8732\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7743 - mae: 0.6778 - mse: 0.7743 - val_loss: 2.1827 - val_mae: 0.9056 - val_mse: 2.1827\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7353 - mae: 0.6658 - mse: 0.7353 - val_loss: 2.7452 - val_mae: 0.9709 - val_mse: 2.7452\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7621 - mae: 0.6735 - mse: 0.7621 - val_loss: 2.5914 - val_mae: 0.9652 - val_mse: 2.5914\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7464 - mae: 0.6685 - mse: 0.7464 - val_loss: 2.5991 - val_mae: 1.1785 - val_mse: 2.5991\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7880 - mae: 0.6836 - mse: 0.7880 - val_loss: 2.2878 - val_mae: 0.9919 - val_mse: 2.2878\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7704 - mae: 0.6716 - mse: 0.7704 - val_loss: 2.3665 - val_mae: 0.9441 - val_mse: 2.3665\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7151 - mae: 0.6526 - mse: 0.7151 - val_loss: 2.1946 - val_mae: 0.9856 - val_mse: 2.1946\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7346 - mae: 0.6526 - mse: 0.7346 - val_loss: 3.2295 - val_mae: 1.0984 - val_mse: 3.2295\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7401 - mae: 0.6645 - mse: 0.7401 - val_loss: 2.3150 - val_mae: 0.9250 - val_mse: 2.3150\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7416 - mae: 0.6625 - mse: 0.7416 - val_loss: 2.1729 - val_mae: 0.8904 - val_mse: 2.1729\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7135 - mae: 0.6474 - mse: 0.7135 - val_loss: 2.3288 - val_mae: 0.9339 - val_mse: 2.3288\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7519 - mae: 0.6615 - mse: 0.7519 - val_loss: 2.4653 - val_mae: 0.9462 - val_mse: 2.4653\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7513 - mae: 0.6635 - mse: 0.7513 - val_loss: 2.5177 - val_mae: 0.9439 - val_mse: 2.5177\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6784 - mae: 0.6356 - mse: 0.6784 - val_loss: 2.3744 - val_mae: 0.9958 - val_mse: 2.3744\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7236 - mae: 0.6489 - mse: 0.7236 - val_loss: 2.2149 - val_mae: 0.9262 - val_mse: 2.2149\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7146 - mae: 0.6540 - mse: 0.7146 - val_loss: 2.7162 - val_mae: 1.2132 - val_mse: 2.7162\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7026 - mae: 0.6438 - mse: 0.7026 - val_loss: 3.7749 - val_mae: 1.3129 - val_mse: 3.7749\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7323 - mae: 0.6583 - mse: 0.7323 - val_loss: 2.9348 - val_mae: 1.0724 - val_mse: 2.9348\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7168 - mae: 0.6592 - mse: 0.7168 - val_loss: 2.9236 - val_mae: 1.0527 - val_mse: 2.9236\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6835 - mae: 0.6255 - mse: 0.6835 - val_loss: 2.8617 - val_mae: 1.0484 - val_mse: 2.8617\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7065 - mae: 0.6429 - mse: 0.7065 - val_loss: 2.2486 - val_mae: 0.9968 - val_mse: 2.2486\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7642 - mae: 0.6706 - mse: 0.7642 - val_loss: 2.7486 - val_mae: 1.0088 - val_mse: 2.7486\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7104 - mae: 0.6416 - mse: 0.7104 - val_loss: 2.2169 - val_mae: 0.9462 - val_mse: 2.2169\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6460 - mae: 0.6076 - mse: 0.6460 - val_loss: 3.4543 - val_mae: 1.1846 - val_mse: 3.4543\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7443 - mae: 0.6694 - mse: 0.7443 - val_loss: 2.2673 - val_mae: 0.9373 - val_mse: 2.2673\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6545 - mae: 0.6270 - mse: 0.6545 - val_loss: 2.5295 - val_mae: 1.1619 - val_mse: 2.5295\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7479 - mae: 0.6614 - mse: 0.7479 - val_loss: 2.4331 - val_mae: 0.9355 - val_mse: 2.4331\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6882 - mae: 0.6375 - mse: 0.6882 - val_loss: 2.2546 - val_mae: 0.9825 - val_mse: 2.2546\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6782 - mae: 0.6213 - mse: 0.6782 - val_loss: 2.5827 - val_mae: 0.9592 - val_mse: 2.5827\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6456 - mae: 0.6234 - mse: 0.6456 - val_loss: 2.3089 - val_mae: 0.9209 - val_mse: 2.3089\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6862 - mae: 0.6360 - mse: 0.6862 - val_loss: 3.0619 - val_mae: 1.1063 - val_mse: 3.0619\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6956 - mae: 0.6402 - mse: 0.6956 - val_loss: 2.2498 - val_mae: 0.9409 - val_mse: 2.2498\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6865 - mae: 0.6346 - mse: 0.6865 - val_loss: 2.4664 - val_mae: 0.9511 - val_mse: 2.4664\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6601 - mae: 0.6208 - mse: 0.6601 - val_loss: 2.2555 - val_mae: 0.9240 - val_mse: 2.2555\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6575 - mae: 0.6290 - mse: 0.6575 - val_loss: 2.5019 - val_mae: 1.0156 - val_mse: 2.5019\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6477 - mae: 0.6122 - mse: 0.6477 - val_loss: 2.2251 - val_mae: 0.9406 - val_mse: 2.2251\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6288 - mae: 0.6068 - mse: 0.6288 - val_loss: 2.9534 - val_mae: 1.0430 - val_mse: 2.9534\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6517 - mae: 0.6229 - mse: 0.6517 - val_loss: 2.2490 - val_mae: 0.9297 - val_mse: 2.2490\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6560 - mae: 0.6114 - mse: 0.6560 - val_loss: 2.4070 - val_mae: 0.9556 - val_mse: 2.4070\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6210 - mae: 0.6047 - mse: 0.6210 - val_loss: 2.3921 - val_mae: 1.0681 - val_mse: 2.3921\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6326 - mae: 0.6068 - mse: 0.6326 - val_loss: 3.0810 - val_mae: 1.0851 - val_mse: 3.0810\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6852 - mae: 0.6319 - mse: 0.6852 - val_loss: 2.5040 - val_mae: 0.9736 - val_mse: 2.5040\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6079 - mae: 0.5990 - mse: 0.6079 - val_loss: 2.4788 - val_mae: 0.9385 - val_mse: 2.4788\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.7084 - mae: 0.6332 - mse: 0.7084 - val_loss: 2.6696 - val_mae: 0.9953 - val_mse: 2.6696\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6065 - mae: 0.6016 - mse: 0.6065 - val_loss: 2.2437 - val_mae: 0.9220 - val_mse: 2.2437\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6622 - mae: 0.6212 - mse: 0.6622 - val_loss: 2.5094 - val_mae: 1.0549 - val_mse: 2.5094\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6350 - mae: 0.6108 - mse: 0.6350 - val_loss: 2.3869 - val_mae: 0.9352 - val_mse: 2.3869\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6411 - mae: 0.6127 - mse: 0.6411 - val_loss: 2.3930 - val_mae: 1.0761 - val_mse: 2.3930\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6192 - mae: 0.5969 - mse: 0.6192 - val_loss: 2.9759 - val_mae: 1.0625 - val_mse: 2.9759\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6503 - mae: 0.6203 - mse: 0.6503 - val_loss: 2.3745 - val_mae: 1.0761 - val_mse: 2.3745\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5997 - mae: 0.5877 - mse: 0.5997 - val_loss: 2.5062 - val_mae: 1.1108 - val_mse: 2.5062\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6635 - mae: 0.6193 - mse: 0.6635 - val_loss: 2.1776 - val_mae: 0.9192 - val_mse: 2.1776\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6126 - mae: 0.6011 - mse: 0.6126 - val_loss: 2.4628 - val_mae: 0.9411 - val_mse: 2.4628\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6322 - mae: 0.6034 - mse: 0.6322 - val_loss: 2.2876 - val_mae: 0.9174 - val_mse: 2.2876\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6532 - mae: 0.6108 - mse: 0.6532 - val_loss: 2.2129 - val_mae: 0.9280 - val_mse: 2.2129\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5814 - mae: 0.5803 - mse: 0.5814 - val_loss: 2.4609 - val_mae: 0.9486 - val_mse: 2.4609\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6324 - mae: 0.6054 - mse: 0.6324 - val_loss: 2.2977 - val_mae: 0.9339 - val_mse: 2.2977\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5619 - mae: 0.5673 - mse: 0.5619 - val_loss: 2.2302 - val_mae: 0.9403 - val_mse: 2.2302\n",
      "Kappa Score: 0.6436031331592689\n",
      "\n",
      "###########Set-7###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n",
      " 1/32 [..............................] - ETA: 0s - loss: 6.0433 - mae: 2.0934 - mse: 6.0433WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 142.4765 - mae: 5.0519 - mse: 142.4765 - val_loss: 2.9446 - val_mae: 1.2931 - val_mse: 2.9446\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 37.7658 - mae: 4.6183 - mse: 37.7658 - val_loss: 56.2159 - val_mae: 7.2399 - val_mse: 56.2159\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 24.8093 - mae: 4.1763 - mse: 24.8093 - val_loss: 9.0205 - val_mae: 2.5257 - val_mse: 9.0205\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.3560 - mae: 2.9174 - mse: 12.3560 - val_loss: 4.0668 - val_mae: 1.6071 - val_mse: 4.0668\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.3587 - mae: 2.2725 - mse: 8.3587 - val_loss: 1.5180 - val_mae: 0.9813 - val_mse: 1.5180\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 5.6661 - mae: 1.8906 - mse: 5.6661 - val_loss: 11.4528 - val_mae: 3.2425 - val_mse: 11.4528\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.6519 - mae: 1.5193 - mse: 3.6519 - val_loss: 2.9564 - val_mae: 1.3291 - val_mse: 2.9564\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.2879 - mae: 1.4601 - mse: 3.2879 - val_loss: 11.1150 - val_mae: 3.1781 - val_mse: 11.1150\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0573 - mae: 1.3756 - mse: 3.0573 - val_loss: 4.7068 - val_mae: 1.9628 - val_mse: 4.7068\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1411 - mae: 1.3899 - mse: 3.1411 - val_loss: 2.5744 - val_mae: 1.2597 - val_mse: 2.5744\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.8428 - mae: 1.3527 - mse: 2.8428 - val_loss: 3.1001 - val_mae: 1.5382 - val_mse: 3.1001\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.4454 - mae: 1.2069 - mse: 2.4454 - val_loss: 1.1183 - val_mae: 0.8148 - val_mse: 1.1183\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9425 - mae: 1.0894 - mse: 1.9425 - val_loss: 1.6526 - val_mae: 1.0105 - val_mse: 1.6526\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1406 - mae: 1.1716 - mse: 2.1406 - val_loss: 1.3075 - val_mae: 0.8816 - val_mse: 1.3075\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9509 - mae: 1.1099 - mse: 1.9509 - val_loss: 2.2444 - val_mae: 1.1744 - val_mse: 2.2444\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.2013 - mae: 1.1880 - mse: 2.2013 - val_loss: 1.0436 - val_mae: 0.7968 - val_mse: 1.0436\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0607 - mae: 1.1209 - mse: 2.0607 - val_loss: 2.1962 - val_mae: 1.2445 - val_mse: 2.1962\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0553 - mae: 1.1238 - mse: 2.0553 - val_loss: 1.7070 - val_mae: 1.0141 - val_mse: 1.7070\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6107 - mae: 0.9767 - mse: 1.6107 - val_loss: 3.4541 - val_mae: 1.6092 - val_mse: 3.4541\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7934 - mae: 1.0505 - mse: 1.7934 - val_loss: 1.5833 - val_mae: 1.0075 - val_mse: 1.5833\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7843 - mae: 1.0393 - mse: 1.7843 - val_loss: 1.8705 - val_mae: 1.0585 - val_mse: 1.8705\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6979 - mae: 1.0155 - mse: 1.6979 - val_loss: 1.8180 - val_mae: 1.0996 - val_mse: 1.8180\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8288 - mae: 1.0711 - mse: 1.8288 - val_loss: 1.0747 - val_mae: 0.8163 - val_mse: 1.0747\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5543 - mae: 0.9725 - mse: 1.5543 - val_loss: 1.1736 - val_mae: 0.8558 - val_mse: 1.1736\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6457 - mae: 0.9927 - mse: 1.6457 - val_loss: 2.7559 - val_mae: 1.4211 - val_mse: 2.7559\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7098 - mae: 1.0179 - mse: 1.7098 - val_loss: 2.6353 - val_mae: 1.3821 - val_mse: 2.6353\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7223 - mae: 1.0328 - mse: 1.7223 - val_loss: 1.5836 - val_mae: 1.0225 - val_mse: 1.5836\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4923 - mae: 0.9493 - mse: 1.4923 - val_loss: 1.9143 - val_mae: 1.0755 - val_mse: 1.9143\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8198 - mae: 1.0667 - mse: 1.8198 - val_loss: 1.0378 - val_mae: 0.8029 - val_mse: 1.0378\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4886 - mae: 0.9538 - mse: 1.4886 - val_loss: 1.1833 - val_mae: 0.8635 - val_mse: 1.1833\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7843 - mae: 1.0452 - mse: 1.7843 - val_loss: 1.3563 - val_mae: 0.9120 - val_mse: 1.3563\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4472 - mae: 0.9380 - mse: 1.4472 - val_loss: 1.1044 - val_mae: 0.8242 - val_mse: 1.1044\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7258 - mae: 1.0280 - mse: 1.7258 - val_loss: 1.0452 - val_mae: 0.8009 - val_mse: 1.0452\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6784 - mae: 1.0115 - mse: 1.6784 - val_loss: 1.8440 - val_mae: 1.1110 - val_mse: 1.8440\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5731 - mae: 0.9726 - mse: 1.5731 - val_loss: 0.9868 - val_mae: 0.7772 - val_mse: 0.9868\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5502 - mae: 0.9794 - mse: 1.5502 - val_loss: 1.0639 - val_mae: 0.8097 - val_mse: 1.0639\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5851 - mae: 0.9871 - mse: 1.5851 - val_loss: 1.1323 - val_mae: 0.8394 - val_mse: 1.1323\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4201 - mae: 0.9352 - mse: 1.4201 - val_loss: 2.5354 - val_mae: 1.3546 - val_mse: 2.5354\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5801 - mae: 0.9927 - mse: 1.5801 - val_loss: 1.2671 - val_mae: 0.8755 - val_mse: 1.2671\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5408 - mae: 0.9600 - mse: 1.5408 - val_loss: 0.9595 - val_mae: 0.7668 - val_mse: 0.9595\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3833 - mae: 0.9277 - mse: 1.3833 - val_loss: 1.1993 - val_mae: 0.8604 - val_mse: 1.1993\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4345 - mae: 0.9327 - mse: 1.4345 - val_loss: 1.8826 - val_mae: 1.1241 - val_mse: 1.8826\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3996 - mae: 0.8990 - mse: 1.3996 - val_loss: 1.3031 - val_mae: 0.9036 - val_mse: 1.3031\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4768 - mae: 0.9526 - mse: 1.4768 - val_loss: 0.9586 - val_mae: 0.7680 - val_mse: 0.9586\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2774 - mae: 0.8823 - mse: 1.2774 - val_loss: 1.6354 - val_mae: 1.0293 - val_mse: 1.6354\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3767 - mae: 0.9240 - mse: 1.3767 - val_loss: 0.9893 - val_mae: 0.7827 - val_mse: 0.9893\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4030 - mae: 0.9316 - mse: 1.4030 - val_loss: 1.2379 - val_mae: 0.8656 - val_mse: 1.2379\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3173 - mae: 0.8762 - mse: 1.3173 - val_loss: 1.5976 - val_mae: 1.0116 - val_mse: 1.5976\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3400 - mae: 0.8979 - mse: 1.3400 - val_loss: 3.2764 - val_mae: 1.5549 - val_mse: 3.2764\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2924 - mae: 0.8858 - mse: 1.2924 - val_loss: 1.8929 - val_mae: 1.0755 - val_mse: 1.8929\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3971 - mae: 0.9192 - mse: 1.3971 - val_loss: 0.9433 - val_mae: 0.7632 - val_mse: 0.9433\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3150 - mae: 0.8980 - mse: 1.3150 - val_loss: 2.9364 - val_mae: 1.4838 - val_mse: 2.9364\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2152 - mae: 0.8644 - mse: 1.2152 - val_loss: 1.3460 - val_mae: 0.9100 - val_mse: 1.3460\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3176 - mae: 0.9020 - mse: 1.3176 - val_loss: 0.9693 - val_mae: 0.7805 - val_mse: 0.9693\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2856 - mae: 0.8794 - mse: 1.2856 - val_loss: 1.1333 - val_mae: 0.8362 - val_mse: 1.1333\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2366 - mae: 0.8572 - mse: 1.2366 - val_loss: 1.1043 - val_mae: 0.8280 - val_mse: 1.1043\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2422 - mae: 0.8712 - mse: 1.2422 - val_loss: 1.2272 - val_mae: 0.8713 - val_mse: 1.2272\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2320 - mae: 0.8828 - mse: 1.2320 - val_loss: 1.0367 - val_mae: 0.8047 - val_mse: 1.0367\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2249 - mae: 0.8690 - mse: 1.2249 - val_loss: 1.0979 - val_mae: 0.8268 - val_mse: 1.0979\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3173 - mae: 0.9067 - mse: 1.3173 - val_loss: 1.2645 - val_mae: 0.8914 - val_mse: 1.2645\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1473 - mae: 0.8382 - mse: 1.1473 - val_loss: 2.0904 - val_mae: 1.1463 - val_mse: 2.0904\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2012 - mae: 0.8540 - mse: 1.2012 - val_loss: 1.3629 - val_mae: 0.9235 - val_mse: 1.3629\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2366 - mae: 0.8619 - mse: 1.2366 - val_loss: 1.3686 - val_mae: 0.9220 - val_mse: 1.3686\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1715 - mae: 0.8380 - mse: 1.1715 - val_loss: 1.3791 - val_mae: 0.9182 - val_mse: 1.3791\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2824 - mae: 0.8887 - mse: 1.2824 - val_loss: 1.2488 - val_mae: 0.8892 - val_mse: 1.2488\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1880 - mae: 0.8501 - mse: 1.1880 - val_loss: 1.7133 - val_mae: 1.0487 - val_mse: 1.7133\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2569 - mae: 0.8785 - mse: 1.2569 - val_loss: 1.0619 - val_mae: 0.8090 - val_mse: 1.0619\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2255 - mae: 0.8543 - mse: 1.2255 - val_loss: 1.1206 - val_mae: 0.8314 - val_mse: 1.1206\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1654 - mae: 0.8371 - mse: 1.1654 - val_loss: 0.9633 - val_mae: 0.7701 - val_mse: 0.9633\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2655 - mae: 0.8710 - mse: 1.2655 - val_loss: 1.2508 - val_mae: 0.8821 - val_mse: 1.2508\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1831 - mae: 0.8543 - mse: 1.1831 - val_loss: 0.9996 - val_mae: 0.7850 - val_mse: 0.9996\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1487 - mae: 0.8409 - mse: 1.1487 - val_loss: 1.4948 - val_mae: 0.9741 - val_mse: 1.4948\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1015 - mae: 0.8118 - mse: 1.1015 - val_loss: 1.2277 - val_mae: 0.8739 - val_mse: 1.2277\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1366 - mae: 0.8220 - mse: 1.1366 - val_loss: 1.4753 - val_mae: 0.9483 - val_mse: 1.4753\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0770 - mae: 0.8094 - mse: 1.0770 - val_loss: 1.0120 - val_mae: 0.7947 - val_mse: 1.0120\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1620 - mae: 0.8396 - mse: 1.1620 - val_loss: 1.1578 - val_mae: 0.8525 - val_mse: 1.1578\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1102 - mae: 0.8192 - mse: 1.1102 - val_loss: 1.0762 - val_mae: 0.8196 - val_mse: 1.0762\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0433 - mae: 0.7876 - mse: 1.0433 - val_loss: 2.3746 - val_mae: 1.2303 - val_mse: 2.3746\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2039 - mae: 0.8571 - mse: 1.2039 - val_loss: 1.1002 - val_mae: 0.8254 - val_mse: 1.1002\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0316 - mae: 0.7861 - mse: 1.0316 - val_loss: 1.2175 - val_mae: 0.8662 - val_mse: 1.2175\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2384 - mae: 0.8584 - mse: 1.2384 - val_loss: 1.0724 - val_mae: 0.8158 - val_mse: 1.0724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0909 - mae: 0.7988 - mse: 1.0909 - val_loss: 0.9941 - val_mae: 0.7871 - val_mse: 0.9941\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0512 - mae: 0.7943 - mse: 1.0512 - val_loss: 2.4905 - val_mae: 1.3209 - val_mse: 2.4905\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1067 - mae: 0.8136 - mse: 1.1067 - val_loss: 0.9383 - val_mae: 0.7596 - val_mse: 0.9383\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0712 - mae: 0.8133 - mse: 1.0712 - val_loss: 0.9802 - val_mae: 0.7797 - val_mse: 0.9802\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1167 - mae: 0.8271 - mse: 1.1167 - val_loss: 1.2146 - val_mae: 0.8725 - val_mse: 1.2146\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9947 - mae: 0.7646 - mse: 0.9947 - val_loss: 1.3428 - val_mae: 0.9067 - val_mse: 1.3428\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1467 - mae: 0.8319 - mse: 1.1467 - val_loss: 1.3595 - val_mae: 0.9075 - val_mse: 1.3595\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0584 - mae: 0.7904 - mse: 1.0584 - val_loss: 0.9769 - val_mae: 0.7871 - val_mse: 0.9769\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0581 - mae: 0.8081 - mse: 1.0581 - val_loss: 1.1296 - val_mae: 0.8352 - val_mse: 1.1296\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9617 - mae: 0.7642 - mse: 0.9617 - val_loss: 0.9499 - val_mae: 0.7647 - val_mse: 0.9499\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0347 - mae: 0.7922 - mse: 1.0347 - val_loss: 1.1584 - val_mae: 0.8468 - val_mse: 1.1584\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0237 - mae: 0.7756 - mse: 1.0237 - val_loss: 1.2083 - val_mae: 0.8690 - val_mse: 1.2083\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0289 - mae: 0.7841 - mse: 1.0289 - val_loss: 1.1562 - val_mae: 0.8492 - val_mse: 1.1562\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9906 - mae: 0.7656 - mse: 0.9906 - val_loss: 1.1083 - val_mae: 0.8247 - val_mse: 1.1083\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0572 - mae: 0.7983 - mse: 1.0572 - val_loss: 0.9708 - val_mae: 0.7772 - val_mse: 0.9708\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9905 - mae: 0.7693 - mse: 0.9905 - val_loss: 1.5475 - val_mae: 0.9773 - val_mse: 1.5475\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9367 - mae: 0.7417 - mse: 0.9367 - val_loss: 1.3734 - val_mae: 0.9163 - val_mse: 1.3734\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0345 - mae: 0.7781 - mse: 1.0345 - val_loss: 0.9589 - val_mae: 0.7684 - val_mse: 0.9589\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0186 - mae: 0.7766 - mse: 1.0186 - val_loss: 1.3544 - val_mae: 0.9308 - val_mse: 1.3544\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9242 - mae: 0.7372 - mse: 0.9242 - val_loss: 2.0469 - val_mae: 1.1341 - val_mse: 2.0469\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0030 - mae: 0.7659 - mse: 1.0030 - val_loss: 1.0124 - val_mae: 0.7956 - val_mse: 1.0124\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9384 - mae: 0.7534 - mse: 0.9384 - val_loss: 0.9605 - val_mae: 0.7663 - val_mse: 0.9605\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0343 - mae: 0.7847 - mse: 1.0343 - val_loss: 1.2870 - val_mae: 0.9051 - val_mse: 1.2870\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9020 - mae: 0.7274 - mse: 0.9020 - val_loss: 0.9749 - val_mae: 0.7787 - val_mse: 0.9749\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9166 - mae: 0.7400 - mse: 0.9166 - val_loss: 1.5724 - val_mae: 1.0048 - val_mse: 1.5724\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0235 - mae: 0.7856 - mse: 1.0235 - val_loss: 1.5319 - val_mae: 0.9673 - val_mse: 1.5319\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9532 - mae: 0.7572 - mse: 0.9532 - val_loss: 0.9967 - val_mae: 0.7770 - val_mse: 0.9967\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9123 - mae: 0.7371 - mse: 0.9123 - val_loss: 1.4953 - val_mae: 0.9708 - val_mse: 1.4953\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9748 - mae: 0.7583 - mse: 0.9748 - val_loss: 2.0404 - val_mae: 1.1768 - val_mse: 2.0404\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9744 - mae: 0.7580 - mse: 0.9744 - val_loss: 1.0813 - val_mae: 0.8112 - val_mse: 1.0813\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9237 - mae: 0.7389 - mse: 0.9237 - val_loss: 0.9834 - val_mae: 0.7902 - val_mse: 0.9834\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9481 - mae: 0.7460 - mse: 0.9481 - val_loss: 0.9632 - val_mae: 0.7646 - val_mse: 0.9632\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8688 - mae: 0.7210 - mse: 0.8688 - val_loss: 2.3148 - val_mae: 1.2373 - val_mse: 2.3148\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9471 - mae: 0.7482 - mse: 0.9471 - val_loss: 0.9531 - val_mae: 0.7602 - val_mse: 0.9531\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9122 - mae: 0.7291 - mse: 0.9122 - val_loss: 1.4916 - val_mae: 0.9838 - val_mse: 1.4916\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8324 - mae: 0.7016 - mse: 0.8324 - val_loss: 0.9816 - val_mae: 0.7785 - val_mse: 0.9816\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8931 - mae: 0.7295 - mse: 0.8931 - val_loss: 0.9962 - val_mae: 0.7819 - val_mse: 0.9962\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9493 - mae: 0.7467 - mse: 0.9493 - val_loss: 1.0225 - val_mae: 0.7994 - val_mse: 1.0225\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8366 - mae: 0.7084 - mse: 0.8366 - val_loss: 1.6933 - val_mae: 1.0384 - val_mse: 1.6933\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8596 - mae: 0.7156 - mse: 0.8596 - val_loss: 1.0203 - val_mae: 0.8077 - val_mse: 1.0203\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9259 - mae: 0.7320 - mse: 0.9259 - val_loss: 1.1205 - val_mae: 0.8227 - val_mse: 1.1205\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8606 - mae: 0.7116 - mse: 0.8606 - val_loss: 1.1507 - val_mae: 0.8425 - val_mse: 1.1507\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8284 - mae: 0.7034 - mse: 0.8284 - val_loss: 0.9952 - val_mae: 0.7814 - val_mse: 0.9952\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8730 - mae: 0.7037 - mse: 0.8730 - val_loss: 1.4978 - val_mae: 0.9640 - val_mse: 1.4978\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8555 - mae: 0.7085 - mse: 0.8555 - val_loss: 1.2209 - val_mae: 0.8902 - val_mse: 1.2209\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8965 - mae: 0.7237 - mse: 0.8965 - val_loss: 0.9997 - val_mae: 0.7999 - val_mse: 0.9997\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8013 - mae: 0.6800 - mse: 0.8013 - val_loss: 2.5764 - val_mae: 1.3356 - val_mse: 2.5764\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8840 - mae: 0.7248 - mse: 0.8840 - val_loss: 2.0149 - val_mae: 1.1477 - val_mse: 2.0149\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8007 - mae: 0.6807 - mse: 0.8007 - val_loss: 1.0082 - val_mae: 0.7789 - val_mse: 1.0082\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8589 - mae: 0.7126 - mse: 0.8589 - val_loss: 1.3394 - val_mae: 0.9207 - val_mse: 1.3394\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8039 - mae: 0.6824 - mse: 0.8039 - val_loss: 1.0143 - val_mae: 0.7851 - val_mse: 1.0143\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9003 - mae: 0.7359 - mse: 0.9003 - val_loss: 1.2470 - val_mae: 0.8839 - val_mse: 1.2470\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8225 - mae: 0.7083 - mse: 0.8225 - val_loss: 0.9927 - val_mae: 0.7936 - val_mse: 0.9927\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8215 - mae: 0.6898 - mse: 0.8215 - val_loss: 0.9759 - val_mae: 0.7774 - val_mse: 0.9759\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8347 - mae: 0.7052 - mse: 0.8347 - val_loss: 1.6889 - val_mae: 1.0438 - val_mse: 1.6889\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8243 - mae: 0.7111 - mse: 0.8243 - val_loss: 1.0176 - val_mae: 0.7989 - val_mse: 1.0176\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7863 - mae: 0.6846 - mse: 0.7863 - val_loss: 1.3724 - val_mae: 0.9210 - val_mse: 1.3724\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7687 - mae: 0.6695 - mse: 0.7687 - val_loss: 1.3595 - val_mae: 0.9190 - val_mse: 1.3595\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8340 - mae: 0.7003 - mse: 0.8340 - val_loss: 0.9890 - val_mae: 0.7869 - val_mse: 0.9890\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8089 - mae: 0.6742 - mse: 0.8089 - val_loss: 1.3038 - val_mae: 0.9029 - val_mse: 1.3038\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8268 - mae: 0.6923 - mse: 0.8268 - val_loss: 1.2382 - val_mae: 0.8798 - val_mse: 1.2382\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8433 - mae: 0.6987 - mse: 0.8433 - val_loss: 1.2840 - val_mae: 0.8940 - val_mse: 1.2840\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8314 - mae: 0.6891 - mse: 0.8314 - val_loss: 1.0716 - val_mae: 0.8033 - val_mse: 1.0716\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7862 - mae: 0.6875 - mse: 0.7862 - val_loss: 1.3193 - val_mae: 0.9296 - val_mse: 1.3193\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7552 - mae: 0.6712 - mse: 0.7552 - val_loss: 0.9808 - val_mae: 0.7775 - val_mse: 0.9808\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8400 - mae: 0.6885 - mse: 0.8400 - val_loss: 1.0810 - val_mae: 0.8195 - val_mse: 1.0810\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7697 - mae: 0.6744 - mse: 0.7697 - val_loss: 1.0397 - val_mae: 0.8118 - val_mse: 1.0397\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7703 - mae: 0.6667 - mse: 0.7703 - val_loss: 1.9223 - val_mae: 1.0922 - val_mse: 1.9223\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7777 - mae: 0.6756 - mse: 0.7777 - val_loss: 1.4374 - val_mae: 0.9505 - val_mse: 1.4374\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8767 - mae: 0.7146 - mse: 0.8767 - val_loss: 1.2235 - val_mae: 0.8653 - val_mse: 1.2235\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7266 - mae: 0.6606 - mse: 0.7266 - val_loss: 0.9880 - val_mae: 0.7751 - val_mse: 0.9880\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7448 - mae: 0.6509 - mse: 0.7448 - val_loss: 1.0428 - val_mae: 0.7925 - val_mse: 1.0428\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7442 - mae: 0.6667 - mse: 0.7442 - val_loss: 1.3802 - val_mae: 0.9253 - val_mse: 1.3802\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7558 - mae: 0.6722 - mse: 0.7558 - val_loss: 1.3467 - val_mae: 0.9431 - val_mse: 1.3467\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7978 - mae: 0.6756 - mse: 0.7978 - val_loss: 1.0639 - val_mae: 0.8057 - val_mse: 1.0639\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7596 - mae: 0.6642 - mse: 0.7596 - val_loss: 1.0080 - val_mae: 0.7797 - val_mse: 1.0080\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7732 - mae: 0.6691 - mse: 0.7732 - val_loss: 1.0478 - val_mae: 0.7985 - val_mse: 1.0478\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7669 - mae: 0.6644 - mse: 0.7669 - val_loss: 1.2197 - val_mae: 0.8955 - val_mse: 1.2197\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7051 - mae: 0.6442 - mse: 0.7051 - val_loss: 1.2640 - val_mae: 0.9138 - val_mse: 1.2640\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7168 - mae: 0.6457 - mse: 0.7168 - val_loss: 1.0593 - val_mae: 0.8199 - val_mse: 1.0593\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7723 - mae: 0.6785 - mse: 0.7723 - val_loss: 1.0870 - val_mae: 0.8189 - val_mse: 1.0870\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7147 - mae: 0.6480 - mse: 0.7147 - val_loss: 1.3414 - val_mae: 0.9122 - val_mse: 1.3414\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6698 - mae: 0.6317 - mse: 0.6698 - val_loss: 1.0855 - val_mae: 0.8168 - val_mse: 1.0855\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7335 - mae: 0.6557 - mse: 0.7335 - val_loss: 1.1927 - val_mae: 0.8475 - val_mse: 1.1927\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7149 - mae: 0.6405 - mse: 0.7149 - val_loss: 0.9845 - val_mae: 0.7773 - val_mse: 0.9845\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7540 - mae: 0.6636 - mse: 0.7540 - val_loss: 1.2864 - val_mae: 0.8778 - val_mse: 1.2864\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7462 - mae: 0.6581 - mse: 0.7462 - val_loss: 1.0383 - val_mae: 0.7938 - val_mse: 1.0383\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7282 - mae: 0.6524 - mse: 0.7282 - val_loss: 1.6212 - val_mae: 1.0394 - val_mse: 1.6212\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7103 - mae: 0.6424 - mse: 0.7103 - val_loss: 1.9898 - val_mae: 1.1501 - val_mse: 1.9898\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7300 - mae: 0.6506 - mse: 0.7300 - val_loss: 1.2970 - val_mae: 0.8875 - val_mse: 1.2970\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7123 - mae: 0.6379 - mse: 0.7123 - val_loss: 1.0618 - val_mae: 0.8057 - val_mse: 1.0618\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6580 - mae: 0.6167 - mse: 0.6580 - val_loss: 1.1592 - val_mae: 0.8405 - val_mse: 1.1592\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6854 - mae: 0.6264 - mse: 0.6854 - val_loss: 1.4021 - val_mae: 0.9387 - val_mse: 1.4021\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6961 - mae: 0.6373 - mse: 0.6961 - val_loss: 1.9086 - val_mae: 1.0868 - val_mse: 1.9086\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7029 - mae: 0.6520 - mse: 0.7029 - val_loss: 1.0837 - val_mae: 0.8146 - val_mse: 1.0837\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7035 - mae: 0.6345 - mse: 0.7035 - val_loss: 1.0788 - val_mae: 0.8066 - val_mse: 1.0788\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6568 - mae: 0.6030 - mse: 0.6568 - val_loss: 2.1041 - val_mae: 1.1907 - val_mse: 2.1041\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6968 - mae: 0.6355 - mse: 0.6968 - val_loss: 1.1072 - val_mae: 0.8137 - val_mse: 1.1072\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6698 - mae: 0.6340 - mse: 0.6698 - val_loss: 1.0489 - val_mae: 0.8034 - val_mse: 1.0489\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7145 - mae: 0.6368 - mse: 0.7145 - val_loss: 1.1977 - val_mae: 0.8510 - val_mse: 1.1977\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6264 - mae: 0.6089 - mse: 0.6264 - val_loss: 1.9826 - val_mae: 1.1274 - val_mse: 1.9826\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7298 - mae: 0.6445 - mse: 0.7298 - val_loss: 1.0662 - val_mae: 0.8121 - val_mse: 1.0662\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6342 - mae: 0.6083 - mse: 0.6342 - val_loss: 1.2750 - val_mae: 0.8742 - val_mse: 1.2750\n",
      "Kappa Score: 0.7279157402618339\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 114.1119 - mae: 5.5526 - mse: 114.1119 - val_loss: 15.8639 - val_mae: 3.7527 - val_mse: 15.8639\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 34.0712 - mae: 5.1377 - mse: 34.0712 - val_loss: 5.4470 - val_mae: 2.1254 - val_mse: 5.4470\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.1032 - mae: 3.5546 - mse: 20.1032 - val_loss: 4.6897 - val_mae: 1.9469 - val_mse: 4.6897\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.5331 - mae: 2.0270 - mse: 8.5331 - val_loss: 20.3991 - val_mae: 4.3625 - val_mse: 20.3991\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.0433 - mae: 2.2654 - mse: 8.0433 - val_loss: 2.5290 - val_mae: 1.1969 - val_mse: 2.5290\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.2384 - mae: 1.6452 - mse: 4.2384 - val_loss: 3.9197 - val_mae: 1.5838 - val_mse: 3.9197\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.9982 - mae: 1.6025 - mse: 3.9982 - val_loss: 10.5936 - val_mae: 2.7114 - val_mse: 10.5936\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.5369 - mae: 1.4835 - mse: 3.5369 - val_loss: 1.3802 - val_mae: 0.9086 - val_mse: 1.3802\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.2341 - mae: 1.4299 - mse: 3.2341 - val_loss: 1.2942 - val_mae: 0.9020 - val_mse: 1.2942\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.4821 - mae: 1.2835 - mse: 2.4821 - val_loss: 2.4905 - val_mae: 1.3280 - val_mse: 2.4905\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.5228 - mae: 1.2583 - mse: 2.5228 - val_loss: 1.4871 - val_mae: 0.9469 - val_mse: 1.4871\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.5049 - mae: 1.2388 - mse: 2.5049 - val_loss: 3.0658 - val_mae: 1.5094 - val_mse: 3.0658\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.5673 - mae: 1.2680 - mse: 2.5673 - val_loss: 1.7821 - val_mae: 1.0138 - val_mse: 1.7821\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1011 - mae: 1.1374 - mse: 2.1011 - val_loss: 3.5680 - val_mae: 1.6350 - val_mse: 3.5680\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1774 - mae: 1.1513 - mse: 2.1774 - val_loss: 1.7483 - val_mae: 1.0768 - val_mse: 1.7483\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0761 - mae: 1.1270 - mse: 2.0761 - val_loss: 1.1855 - val_mae: 0.8569 - val_mse: 1.1855\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1422 - mae: 1.1635 - mse: 2.1422 - val_loss: 2.7356 - val_mae: 1.4016 - val_mse: 2.7356\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7223 - mae: 1.0234 - mse: 1.7223 - val_loss: 4.2381 - val_mae: 1.8285 - val_mse: 4.2381\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1052 - mae: 1.1521 - mse: 2.1052 - val_loss: 2.1524 - val_mae: 1.2238 - val_mse: 2.1524\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0426 - mae: 1.1402 - mse: 2.0426 - val_loss: 1.1193 - val_mae: 0.8410 - val_mse: 1.1193\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8541 - mae: 1.0792 - mse: 1.8541 - val_loss: 1.4877 - val_mae: 0.9808 - val_mse: 1.4877\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7743 - mae: 1.0419 - mse: 1.7743 - val_loss: 4.8096 - val_mae: 1.9708 - val_mse: 4.8096\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9239 - mae: 1.0778 - mse: 1.9239 - val_loss: 1.1690 - val_mae: 0.8498 - val_mse: 1.1690\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4821 - mae: 0.9532 - mse: 1.4821 - val_loss: 3.0703 - val_mae: 1.5105 - val_mse: 3.0703\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8318 - mae: 1.0726 - mse: 1.8318 - val_loss: 1.4044 - val_mae: 0.9478 - val_mse: 1.4044\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9871 - mae: 1.1022 - mse: 1.9871 - val_loss: 1.2832 - val_mae: 0.8994 - val_mse: 1.2832\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5496 - mae: 0.9784 - mse: 1.5496 - val_loss: 1.4731 - val_mae: 0.9791 - val_mse: 1.4731\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7714 - mae: 1.0484 - mse: 1.7714 - val_loss: 1.8832 - val_mae: 1.1154 - val_mse: 1.8832\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4193 - mae: 0.9397 - mse: 1.4193 - val_loss: 1.2229 - val_mae: 0.8771 - val_mse: 1.2229\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5215 - mae: 0.9580 - mse: 1.5215 - val_loss: 3.1582 - val_mae: 1.5246 - val_mse: 3.1582\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6780 - mae: 1.0101 - mse: 1.6780 - val_loss: 1.1809 - val_mae: 0.8516 - val_mse: 1.1809\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3750 - mae: 0.9177 - mse: 1.3750 - val_loss: 1.8800 - val_mae: 1.0617 - val_mse: 1.8800\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5798 - mae: 0.9998 - mse: 1.5798 - val_loss: 1.3663 - val_mae: 0.9115 - val_mse: 1.3663\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3626 - mae: 0.9015 - mse: 1.3626 - val_loss: 3.5852 - val_mae: 1.6528 - val_mse: 3.5852\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5639 - mae: 0.9873 - mse: 1.5639 - val_loss: 1.9215 - val_mae: 1.0692 - val_mse: 1.9215\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4419 - mae: 0.9526 - mse: 1.4419 - val_loss: 1.1040 - val_mae: 0.8236 - val_mse: 1.1040\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6359 - mae: 1.0036 - mse: 1.6359 - val_loss: 1.4246 - val_mae: 0.9642 - val_mse: 1.4246\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3225 - mae: 0.8899 - mse: 1.3225 - val_loss: 1.3779 - val_mae: 0.9401 - val_mse: 1.3779\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4617 - mae: 0.9373 - mse: 1.4617 - val_loss: 4.4534 - val_mae: 1.8662 - val_mse: 4.4534\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3582 - mae: 0.9252 - mse: 1.3582 - val_loss: 2.8428 - val_mae: 1.3507 - val_mse: 2.8428\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4207 - mae: 0.9333 - mse: 1.4207 - val_loss: 1.4135 - val_mae: 0.9597 - val_mse: 1.4135\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3382 - mae: 0.9025 - mse: 1.3382 - val_loss: 2.0650 - val_mae: 1.1937 - val_mse: 2.0650\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4601 - mae: 0.9411 - mse: 1.4601 - val_loss: 1.1476 - val_mae: 0.8438 - val_mse: 1.1476\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3193 - mae: 0.8891 - mse: 1.3193 - val_loss: 2.5656 - val_mae: 1.3527 - val_mse: 2.5656\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3861 - mae: 0.9220 - mse: 1.3861 - val_loss: 3.2419 - val_mae: 1.4606 - val_mse: 3.2419\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3898 - mae: 0.9246 - mse: 1.3898 - val_loss: 2.4642 - val_mae: 1.3269 - val_mse: 2.4642\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2660 - mae: 0.8949 - mse: 1.2660 - val_loss: 3.2443 - val_mae: 1.5531 - val_mse: 3.2443\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2244 - mae: 0.8757 - mse: 1.2244 - val_loss: 1.6331 - val_mae: 1.0402 - val_mse: 1.6331\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2828 - mae: 0.8808 - mse: 1.2828 - val_loss: 1.2706 - val_mae: 0.8965 - val_mse: 1.2706\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3288 - mae: 0.8981 - mse: 1.3288 - val_loss: 1.3803 - val_mae: 0.9420 - val_mse: 1.3803\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2368 - mae: 0.8736 - mse: 1.2368 - val_loss: 1.4223 - val_mae: 0.9264 - val_mse: 1.4223\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2397 - mae: 0.8708 - mse: 1.2397 - val_loss: 1.3921 - val_mae: 0.9444 - val_mse: 1.3921\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2093 - mae: 0.8605 - mse: 1.2093 - val_loss: 1.0785 - val_mae: 0.8135 - val_mse: 1.0785\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3300 - mae: 0.9052 - mse: 1.3300 - val_loss: 1.8093 - val_mae: 1.1166 - val_mse: 1.8093\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2778 - mae: 0.8766 - mse: 1.2778 - val_loss: 1.1990 - val_mae: 0.8580 - val_mse: 1.1990\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2332 - mae: 0.8632 - mse: 1.2332 - val_loss: 1.1014 - val_mae: 0.8254 - val_mse: 1.1014\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1482 - mae: 0.8290 - mse: 1.1482 - val_loss: 1.1065 - val_mae: 0.8266 - val_mse: 1.1065\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2043 - mae: 0.8484 - mse: 1.2043 - val_loss: 1.0672 - val_mae: 0.8119 - val_mse: 1.0672\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2158 - mae: 0.8630 - mse: 1.2158 - val_loss: 1.6868 - val_mae: 1.0174 - val_mse: 1.6868\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1950 - mae: 0.8492 - mse: 1.1950 - val_loss: 1.0714 - val_mae: 0.8144 - val_mse: 1.0714\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1424 - mae: 0.8352 - mse: 1.1424 - val_loss: 1.7163 - val_mae: 1.0233 - val_mse: 1.7163\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1729 - mae: 0.8540 - mse: 1.1729 - val_loss: 2.2568 - val_mae: 1.2648 - val_mse: 2.2568\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1160 - mae: 0.8154 - mse: 1.1160 - val_loss: 1.0463 - val_mae: 0.8007 - val_mse: 1.0463\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1359 - mae: 0.8327 - mse: 1.1359 - val_loss: 1.7885 - val_mae: 1.0465 - val_mse: 1.7885\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1046 - mae: 0.8289 - mse: 1.1046 - val_loss: 1.0363 - val_mae: 0.8055 - val_mse: 1.0363\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1544 - mae: 0.8368 - mse: 1.1544 - val_loss: 1.1763 - val_mae: 0.8378 - val_mse: 1.1763\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1164 - mae: 0.8187 - mse: 1.1164 - val_loss: 1.7033 - val_mae: 1.0408 - val_mse: 1.7033\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1496 - mae: 0.8336 - mse: 1.1496 - val_loss: 1.2363 - val_mae: 0.8791 - val_mse: 1.2363\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1192 - mae: 0.8236 - mse: 1.1192 - val_loss: 1.1855 - val_mae: 0.8573 - val_mse: 1.1855\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1075 - mae: 0.8174 - mse: 1.1075 - val_loss: 2.6580 - val_mae: 1.3816 - val_mse: 2.6580\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1070 - mae: 0.8120 - mse: 1.1070 - val_loss: 1.1655 - val_mae: 0.8530 - val_mse: 1.1655\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0723 - mae: 0.8142 - mse: 1.0723 - val_loss: 1.3266 - val_mae: 0.9030 - val_mse: 1.3266\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0521 - mae: 0.7948 - mse: 1.0521 - val_loss: 1.0565 - val_mae: 0.7981 - val_mse: 1.0565\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0321 - mae: 0.7998 - mse: 1.0321 - val_loss: 2.7456 - val_mae: 1.3074 - val_mse: 2.7456\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0778 - mae: 0.8058 - mse: 1.0778 - val_loss: 3.5460 - val_mae: 1.5531 - val_mse: 3.5460\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1146 - mae: 0.8183 - mse: 1.1146 - val_loss: 1.0988 - val_mae: 0.8200 - val_mse: 1.0988\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0182 - mae: 0.7797 - mse: 1.0182 - val_loss: 1.1043 - val_mae: 0.8220 - val_mse: 1.1043\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0324 - mae: 0.7899 - mse: 1.0324 - val_loss: 1.4793 - val_mae: 0.9923 - val_mse: 1.4793\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0407 - mae: 0.7869 - mse: 1.0407 - val_loss: 1.0962 - val_mae: 0.8237 - val_mse: 1.0962\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0040 - mae: 0.7733 - mse: 1.0040 - val_loss: 1.3895 - val_mae: 0.9486 - val_mse: 1.3895\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9722 - mae: 0.7751 - mse: 0.9722 - val_loss: 1.3787 - val_mae: 0.9144 - val_mse: 1.3787\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0070 - mae: 0.7868 - mse: 1.0070 - val_loss: 1.0536 - val_mae: 0.7996 - val_mse: 1.0536\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0109 - mae: 0.7835 - mse: 1.0109 - val_loss: 1.3720 - val_mae: 0.9382 - val_mse: 1.3720\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9712 - mae: 0.7666 - mse: 0.9712 - val_loss: 1.4608 - val_mae: 0.9623 - val_mse: 1.4608\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9596 - mae: 0.7658 - mse: 0.9596 - val_loss: 1.5927 - val_mae: 0.9805 - val_mse: 1.5927\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0452 - mae: 0.7859 - mse: 1.0452 - val_loss: 2.1810 - val_mae: 1.1481 - val_mse: 2.1810\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9759 - mae: 0.7621 - mse: 0.9759 - val_loss: 1.1672 - val_mae: 0.8448 - val_mse: 1.1672\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9617 - mae: 0.7541 - mse: 0.9617 - val_loss: 1.1216 - val_mae: 0.8239 - val_mse: 1.1216\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8768 - mae: 0.7321 - mse: 0.8768 - val_loss: 1.2501 - val_mae: 0.8771 - val_mse: 1.2501\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9487 - mae: 0.7425 - mse: 0.9487 - val_loss: 1.2395 - val_mae: 0.8663 - val_mse: 1.2395\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9275 - mae: 0.7475 - mse: 0.9275 - val_loss: 1.4633 - val_mae: 0.9641 - val_mse: 1.4633\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9912 - mae: 0.7716 - mse: 0.9912 - val_loss: 1.1808 - val_mae: 0.8538 - val_mse: 1.1808\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9317 - mae: 0.7506 - mse: 0.9317 - val_loss: 1.2772 - val_mae: 0.8920 - val_mse: 1.2772\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9596 - mae: 0.7604 - mse: 0.9596 - val_loss: 1.7077 - val_mae: 1.0158 - val_mse: 1.7077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9254 - mae: 0.7531 - mse: 0.9254 - val_loss: 1.4166 - val_mae: 0.9540 - val_mse: 1.4166\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9127 - mae: 0.7384 - mse: 0.9127 - val_loss: 1.0515 - val_mae: 0.7986 - val_mse: 1.0515\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9441 - mae: 0.7556 - mse: 0.9441 - val_loss: 1.1619 - val_mae: 0.8430 - val_mse: 1.1619\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9135 - mae: 0.7400 - mse: 0.9135 - val_loss: 1.1784 - val_mae: 0.8406 - val_mse: 1.1784\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9315 - mae: 0.7324 - mse: 0.9315 - val_loss: 1.1427 - val_mae: 0.8411 - val_mse: 1.1427\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9114 - mae: 0.7470 - mse: 0.9114 - val_loss: 1.2313 - val_mae: 0.8796 - val_mse: 1.2313\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9071 - mae: 0.7345 - mse: 0.9071 - val_loss: 1.3903 - val_mae: 0.9475 - val_mse: 1.3903\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9274 - mae: 0.7378 - mse: 0.9274 - val_loss: 1.5232 - val_mae: 1.0036 - val_mse: 1.5232\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8601 - mae: 0.7087 - mse: 0.8601 - val_loss: 1.0200 - val_mae: 0.7823 - val_mse: 1.0200\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9446 - mae: 0.7424 - mse: 0.9446 - val_loss: 1.1204 - val_mae: 0.8272 - val_mse: 1.1204\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8999 - mae: 0.7232 - mse: 0.8999 - val_loss: 1.0634 - val_mae: 0.8018 - val_mse: 1.0634\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8696 - mae: 0.7188 - mse: 0.8696 - val_loss: 1.1133 - val_mae: 0.8371 - val_mse: 1.1133\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8908 - mae: 0.7349 - mse: 0.8908 - val_loss: 1.4415 - val_mae: 0.9133 - val_mse: 1.4415\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8902 - mae: 0.7329 - mse: 0.8902 - val_loss: 1.1436 - val_mae: 0.8390 - val_mse: 1.1436\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8843 - mae: 0.7178 - mse: 0.8843 - val_loss: 1.6507 - val_mae: 0.9855 - val_mse: 1.6507\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7904 - mae: 0.6917 - mse: 0.7904 - val_loss: 1.1184 - val_mae: 0.8113 - val_mse: 1.1184\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8888 - mae: 0.7186 - mse: 0.8888 - val_loss: 1.0834 - val_mae: 0.8171 - val_mse: 1.0834\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8937 - mae: 0.7252 - mse: 0.8937 - val_loss: 1.0497 - val_mae: 0.7924 - val_mse: 1.0497\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7957 - mae: 0.6824 - mse: 0.7957 - val_loss: 1.0371 - val_mae: 0.7966 - val_mse: 1.0371\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8519 - mae: 0.7245 - mse: 0.8519 - val_loss: 1.1763 - val_mae: 0.8483 - val_mse: 1.1763\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8304 - mae: 0.7029 - mse: 0.8304 - val_loss: 1.5791 - val_mae: 1.0171 - val_mse: 1.5791\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8853 - mae: 0.7202 - mse: 0.8853 - val_loss: 1.3943 - val_mae: 0.8926 - val_mse: 1.3943\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8529 - mae: 0.6986 - mse: 0.8529 - val_loss: 1.1181 - val_mae: 0.8296 - val_mse: 1.1181\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7776 - mae: 0.6802 - mse: 0.7776 - val_loss: 1.3814 - val_mae: 0.9211 - val_mse: 1.3814\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8601 - mae: 0.7152 - mse: 0.8601 - val_loss: 1.0595 - val_mae: 0.8066 - val_mse: 1.0595\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8714 - mae: 0.7286 - mse: 0.8714 - val_loss: 1.0872 - val_mae: 0.8105 - val_mse: 1.0872\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7728 - mae: 0.6721 - mse: 0.7728 - val_loss: 1.6456 - val_mae: 1.0216 - val_mse: 1.6456\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8439 - mae: 0.7019 - mse: 0.8439 - val_loss: 2.0759 - val_mae: 1.1146 - val_mse: 2.0759\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8106 - mae: 0.6832 - mse: 0.8106 - val_loss: 1.3468 - val_mae: 0.8945 - val_mse: 1.3468\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7854 - mae: 0.6851 - mse: 0.7854 - val_loss: 1.1837 - val_mae: 0.8516 - val_mse: 1.1837\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7797 - mae: 0.6822 - mse: 0.7797 - val_loss: 1.0978 - val_mae: 0.8222 - val_mse: 1.0978\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7431 - mae: 0.6591 - mse: 0.7431 - val_loss: 1.6774 - val_mae: 0.9877 - val_mse: 1.6774\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8094 - mae: 0.6914 - mse: 0.8094 - val_loss: 1.0663 - val_mae: 0.8052 - val_mse: 1.0663\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7916 - mae: 0.6926 - mse: 0.7916 - val_loss: 1.0548 - val_mae: 0.8105 - val_mse: 1.0548\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7700 - mae: 0.6740 - mse: 0.7700 - val_loss: 1.6914 - val_mae: 1.0638 - val_mse: 1.6914\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7558 - mae: 0.6792 - mse: 0.7558 - val_loss: 1.6747 - val_mae: 0.9985 - val_mse: 1.6747\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7362 - mae: 0.6677 - mse: 0.7362 - val_loss: 1.7069 - val_mae: 1.0412 - val_mse: 1.7069\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7588 - mae: 0.6747 - mse: 0.7588 - val_loss: 1.8664 - val_mae: 1.1017 - val_mse: 1.8664\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7112 - mae: 0.6452 - mse: 0.7112 - val_loss: 2.6119 - val_mae: 1.3261 - val_mse: 2.6119\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7874 - mae: 0.6773 - mse: 0.7874 - val_loss: 1.3673 - val_mae: 0.8860 - val_mse: 1.3673\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7391 - mae: 0.6667 - mse: 0.7391 - val_loss: 1.5600 - val_mae: 0.9884 - val_mse: 1.5600\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7653 - mae: 0.6648 - mse: 0.7653 - val_loss: 1.1736 - val_mae: 0.8560 - val_mse: 1.1736\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7423 - mae: 0.6614 - mse: 0.7423 - val_loss: 1.0969 - val_mae: 0.8162 - val_mse: 1.0969\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7544 - mae: 0.6628 - mse: 0.7544 - val_loss: 1.2263 - val_mae: 0.8760 - val_mse: 1.2263\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7596 - mae: 0.6666 - mse: 0.7596 - val_loss: 1.4635 - val_mae: 0.9478 - val_mse: 1.4635\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7096 - mae: 0.6423 - mse: 0.7096 - val_loss: 1.8548 - val_mae: 1.0787 - val_mse: 1.8548\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7102 - mae: 0.6543 - mse: 0.7102 - val_loss: 1.1457 - val_mae: 0.8447 - val_mse: 1.1457\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7216 - mae: 0.6527 - mse: 0.7216 - val_loss: 1.2639 - val_mae: 0.9010 - val_mse: 1.2639\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6925 - mae: 0.6389 - mse: 0.6925 - val_loss: 1.8218 - val_mae: 1.0469 - val_mse: 1.8218\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7228 - mae: 0.6512 - mse: 0.7228 - val_loss: 1.3369 - val_mae: 0.9099 - val_mse: 1.3369\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7158 - mae: 0.6527 - mse: 0.7158 - val_loss: 1.1105 - val_mae: 0.8221 - val_mse: 1.1105\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6763 - mae: 0.6257 - mse: 0.6763 - val_loss: 1.1164 - val_mae: 0.8275 - val_mse: 1.1164\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6974 - mae: 0.6453 - mse: 0.6974 - val_loss: 1.1125 - val_mae: 0.8278 - val_mse: 1.1125\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6783 - mae: 0.6401 - mse: 0.6783 - val_loss: 1.1491 - val_mae: 0.8505 - val_mse: 1.1491\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6352 - mae: 0.6076 - mse: 0.6352 - val_loss: 1.1493 - val_mae: 0.8359 - val_mse: 1.1493\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6938 - mae: 0.6318 - mse: 0.6938 - val_loss: 1.2623 - val_mae: 0.8929 - val_mse: 1.2623\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6796 - mae: 0.6352 - mse: 0.6796 - val_loss: 1.1479 - val_mae: 0.8570 - val_mse: 1.1479\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6544 - mae: 0.6227 - mse: 0.6544 - val_loss: 1.4643 - val_mae: 0.9629 - val_mse: 1.4643\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6840 - mae: 0.6366 - mse: 0.6840 - val_loss: 1.0741 - val_mae: 0.8119 - val_mse: 1.0741\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6861 - mae: 0.6390 - mse: 0.6861 - val_loss: 1.3217 - val_mae: 0.8775 - val_mse: 1.3217\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6378 - mae: 0.6118 - mse: 0.6378 - val_loss: 1.4897 - val_mae: 0.9490 - val_mse: 1.4897\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6764 - mae: 0.6358 - mse: 0.6764 - val_loss: 1.3006 - val_mae: 0.8978 - val_mse: 1.3006\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6422 - mae: 0.6256 - mse: 0.6422 - val_loss: 1.2400 - val_mae: 0.8809 - val_mse: 1.2400\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6727 - mae: 0.6294 - mse: 0.6727 - val_loss: 1.3703 - val_mae: 0.9186 - val_mse: 1.3703\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6410 - mae: 0.6180 - mse: 0.6410 - val_loss: 1.2503 - val_mae: 0.8687 - val_mse: 1.2503\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5884 - mae: 0.5815 - mse: 0.5884 - val_loss: 1.4827 - val_mae: 0.9805 - val_mse: 1.4827\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6180 - mae: 0.6047 - mse: 0.6180 - val_loss: 1.2016 - val_mae: 0.8747 - val_mse: 1.2016\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6424 - mae: 0.6102 - mse: 0.6424 - val_loss: 1.1243 - val_mae: 0.8418 - val_mse: 1.1243\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5746 - mae: 0.5854 - mse: 0.5746 - val_loss: 1.1557 - val_mae: 0.8395 - val_mse: 1.1557\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6127 - mae: 0.6001 - mse: 0.6127 - val_loss: 1.1539 - val_mae: 0.8439 - val_mse: 1.1539\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6175 - mae: 0.6036 - mse: 0.6175 - val_loss: 1.2841 - val_mae: 0.8862 - val_mse: 1.2841\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6078 - mae: 0.6025 - mse: 0.6078 - val_loss: 1.3332 - val_mae: 0.9016 - val_mse: 1.3332\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5846 - mae: 0.5917 - mse: 0.5846 - val_loss: 1.4673 - val_mae: 0.9682 - val_mse: 1.4673\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5751 - mae: 0.5780 - mse: 0.5751 - val_loss: 1.0951 - val_mae: 0.8208 - val_mse: 1.0951\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6476 - mae: 0.6100 - mse: 0.6476 - val_loss: 1.1961 - val_mae: 0.8607 - val_mse: 1.1961\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5008 - mae: 0.5388 - mse: 0.5008 - val_loss: 1.2243 - val_mae: 0.8871 - val_mse: 1.2243\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6024 - mae: 0.5905 - mse: 0.6024 - val_loss: 1.1869 - val_mae: 0.8411 - val_mse: 1.1869\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5241 - mae: 0.5400 - mse: 0.5241 - val_loss: 1.1942 - val_mae: 0.8620 - val_mse: 1.1942\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5538 - mae: 0.5614 - mse: 0.5538 - val_loss: 1.1572 - val_mae: 0.8429 - val_mse: 1.1572\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5907 - mae: 0.5943 - mse: 0.5907 - val_loss: 1.3733 - val_mae: 0.9368 - val_mse: 1.3733\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5869 - mae: 0.5779 - mse: 0.5869 - val_loss: 1.1757 - val_mae: 0.8561 - val_mse: 1.1757\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5691 - mae: 0.5710 - mse: 0.5691 - val_loss: 1.2102 - val_mae: 0.8562 - val_mse: 1.2102\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5159 - mae: 0.5432 - mse: 0.5159 - val_loss: 1.2566 - val_mae: 0.8908 - val_mse: 1.2566\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5863 - mae: 0.5596 - mse: 0.5863 - val_loss: 1.2008 - val_mae: 0.8763 - val_mse: 1.2008\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6137 - mae: 0.6092 - mse: 0.6137 - val_loss: 1.3597 - val_mae: 0.9315 - val_mse: 1.3597\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5173 - mae: 0.5402 - mse: 0.5173 - val_loss: 1.2383 - val_mae: 0.8974 - val_mse: 1.2383\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5422 - mae: 0.5623 - mse: 0.5422 - val_loss: 1.2858 - val_mae: 0.9129 - val_mse: 1.2858\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5536 - mae: 0.5663 - mse: 0.5536 - val_loss: 1.2197 - val_mae: 0.8591 - val_mse: 1.2197\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5467 - mae: 0.5604 - mse: 0.5467 - val_loss: 1.2555 - val_mae: 0.8871 - val_mse: 1.2555\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5048 - mae: 0.5287 - mse: 0.5048 - val_loss: 1.1888 - val_mae: 0.8554 - val_mse: 1.1888\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5485 - mae: 0.5705 - mse: 0.5485 - val_loss: 1.1605 - val_mae: 0.8594 - val_mse: 1.1605\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5563 - mae: 0.5683 - mse: 0.5563 - val_loss: 1.1717 - val_mae: 0.8535 - val_mse: 1.1717\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5389 - mae: 0.5639 - mse: 0.5389 - val_loss: 1.3665 - val_mae: 0.9048 - val_mse: 1.3665\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4748 - mae: 0.5259 - mse: 0.4748 - val_loss: 1.1526 - val_mae: 0.8441 - val_mse: 1.1526\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5830 - mae: 0.5705 - mse: 0.5830 - val_loss: 1.1991 - val_mae: 0.8725 - val_mse: 1.1991\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5260 - mae: 0.5447 - mse: 0.5260 - val_loss: 1.3235 - val_mae: 0.9024 - val_mse: 1.3235\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4981 - mae: 0.5365 - mse: 0.4981 - val_loss: 1.1811 - val_mae: 0.8640 - val_mse: 1.1811\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4938 - mae: 0.5295 - mse: 0.4938 - val_loss: 1.2597 - val_mae: 0.8772 - val_mse: 1.2597\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5334 - mae: 0.5463 - mse: 0.5334 - val_loss: 1.5341 - val_mae: 0.9610 - val_mse: 1.5341\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5206 - mae: 0.5485 - mse: 0.5206 - val_loss: 1.2037 - val_mae: 0.8742 - val_mse: 1.2037\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4865 - mae: 0.5214 - mse: 0.4865 - val_loss: 1.3938 - val_mae: 0.9312 - val_mse: 1.3938\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4953 - mae: 0.5277 - mse: 0.4953 - val_loss: 1.4024 - val_mae: 0.9406 - val_mse: 1.4024\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4766 - mae: 0.5311 - mse: 0.4766 - val_loss: 1.2809 - val_mae: 0.8807 - val_mse: 1.2809\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4576 - mae: 0.5173 - mse: 0.4576 - val_loss: 1.5319 - val_mae: 1.0017 - val_mse: 1.5319\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5297 - mae: 0.5598 - mse: 0.5297 - val_loss: 1.2107 - val_mae: 0.8683 - val_mse: 1.2107\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4621 - mae: 0.5228 - mse: 0.4621 - val_loss: 1.4582 - val_mae: 0.9754 - val_mse: 1.4582\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4958 - mae: 0.5416 - mse: 0.4958 - val_loss: 1.5107 - val_mae: 0.9622 - val_mse: 1.5107\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4395 - mae: 0.5142 - mse: 0.4395 - val_loss: 1.5509 - val_mae: 0.9691 - val_mse: 1.5509\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5097 - mae: 0.5465 - mse: 0.5097 - val_loss: 1.1424 - val_mae: 0.8451 - val_mse: 1.1424\n",
      "Kappa Score: 0.7280091380705345\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 123.1386 - mae: 5.8713 - mse: 123.1386 - val_loss: 4.4747 - val_mae: 1.8514 - val_mse: 4.4747\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 44.4302 - mae: 5.1345 - mse: 44.4302 - val_loss: 1.6731 - val_mae: 1.0121 - val_mse: 1.6731\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 23.1113 - mae: 2.8685 - mse: 23.1113 - val_loss: 102.3262 - val_mae: 9.8233 - val_mse: 102.3262\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 15.9296 - mae: 3.1426 - mse: 15.9296 - val_loss: 26.3464 - val_mae: 4.9378 - val_mse: 26.3464\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.4093 - mae: 2.2563 - mse: 8.4093 - val_loss: 10.7270 - val_mae: 3.0509 - val_mse: 10.7270\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 6.4542 - mae: 1.9517 - mse: 6.4542 - val_loss: 5.8906 - val_mae: 2.0095 - val_mse: 5.8906\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.9712 - mae: 1.7478 - mse: 4.9712 - val_loss: 4.7487 - val_mae: 1.9162 - val_mse: 4.7487\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.6893 - mae: 1.2772 - mse: 2.6893 - val_loss: 4.3192 - val_mae: 1.8369 - val_mse: 4.3192\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.8156 - mae: 1.3335 - mse: 2.8156 - val_loss: 5.3705 - val_mae: 2.0895 - val_mse: 5.3705\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.7833 - mae: 1.3212 - mse: 2.7833 - val_loss: 3.8141 - val_mae: 1.7088 - val_mse: 3.8141\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.7464 - mae: 1.2904 - mse: 2.7464 - val_loss: 2.9393 - val_mae: 1.4644 - val_mse: 2.9393\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.3248 - mae: 1.1930 - mse: 2.3248 - val_loss: 1.2778 - val_mae: 0.8909 - val_mse: 1.2778\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0163 - mae: 1.1144 - mse: 2.0163 - val_loss: 1.4972 - val_mae: 0.9632 - val_mse: 1.4972\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.2500 - mae: 1.1791 - mse: 2.2500 - val_loss: 1.9995 - val_mae: 1.1122 - val_mse: 1.9995\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0556 - mae: 1.1520 - mse: 2.0556 - val_loss: 2.0654 - val_mae: 1.1246 - val_mse: 2.0654\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9824 - mae: 1.1062 - mse: 1.9824 - val_loss: 1.8224 - val_mae: 1.0531 - val_mse: 1.8224\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0227 - mae: 1.1196 - mse: 2.0227 - val_loss: 1.1831 - val_mae: 0.8582 - val_mse: 1.1831\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.0232 - mae: 1.1142 - mse: 2.0232 - val_loss: 1.3660 - val_mae: 0.9222 - val_mse: 1.3660\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1409 - mae: 1.1499 - mse: 2.1409 - val_loss: 1.6803 - val_mae: 1.0321 - val_mse: 1.6803\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7418 - mae: 1.0312 - mse: 1.7418 - val_loss: 1.1719 - val_mae: 0.8625 - val_mse: 1.1719\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8616 - mae: 1.0798 - mse: 1.8616 - val_loss: 1.8805 - val_mae: 1.0841 - val_mse: 1.8805\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6939 - mae: 1.0229 - mse: 1.6939 - val_loss: 1.2544 - val_mae: 0.8893 - val_mse: 1.2544\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7053 - mae: 1.0352 - mse: 1.7053 - val_loss: 2.4033 - val_mae: 1.2413 - val_mse: 2.4033\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4916 - mae: 0.9495 - mse: 1.4916 - val_loss: 4.8404 - val_mae: 1.9600 - val_mse: 4.8404\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8390 - mae: 1.0531 - mse: 1.8390 - val_loss: 1.4642 - val_mae: 0.9454 - val_mse: 1.4642\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5995 - mae: 1.0000 - mse: 1.5995 - val_loss: 2.2408 - val_mae: 1.1729 - val_mse: 2.2408\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7142 - mae: 1.0187 - mse: 1.7142 - val_loss: 1.1876 - val_mae: 0.8640 - val_mse: 1.1876\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4089 - mae: 0.9252 - mse: 1.4089 - val_loss: 1.1561 - val_mae: 0.8546 - val_mse: 1.1561\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4513 - mae: 0.9595 - mse: 1.4513 - val_loss: 1.5955 - val_mae: 0.9994 - val_mse: 1.5955\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5897 - mae: 0.9832 - mse: 1.5897 - val_loss: 1.4183 - val_mae: 0.9358 - val_mse: 1.4183\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5286 - mae: 0.9785 - mse: 1.5286 - val_loss: 1.1751 - val_mae: 0.8614 - val_mse: 1.1751\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4061 - mae: 0.9367 - mse: 1.4061 - val_loss: 2.3072 - val_mae: 1.2548 - val_mse: 2.3072\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4983 - mae: 0.9683 - mse: 1.4983 - val_loss: 3.0155 - val_mae: 1.4911 - val_mse: 3.0155\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2617 - mae: 0.8890 - mse: 1.2617 - val_loss: 1.6001 - val_mae: 0.9892 - val_mse: 1.6001\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3617 - mae: 0.9096 - mse: 1.3617 - val_loss: 1.0636 - val_mae: 0.8179 - val_mse: 1.0636\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4277 - mae: 0.9397 - mse: 1.4277 - val_loss: 1.6041 - val_mae: 1.0017 - val_mse: 1.6041\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3170 - mae: 0.8917 - mse: 1.3170 - val_loss: 1.5019 - val_mae: 0.9846 - val_mse: 1.5019\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2733 - mae: 0.8880 - mse: 1.2733 - val_loss: 1.0810 - val_mae: 0.8207 - val_mse: 1.0810\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3215 - mae: 0.9008 - mse: 1.3215 - val_loss: 1.1214 - val_mae: 0.8313 - val_mse: 1.1214\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2989 - mae: 0.8901 - mse: 1.2989 - val_loss: 2.5218 - val_mae: 1.3274 - val_mse: 2.5218\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2513 - mae: 0.8830 - mse: 1.2513 - val_loss: 1.1403 - val_mae: 0.8475 - val_mse: 1.1403\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3196 - mae: 0.8978 - mse: 1.3196 - val_loss: 1.1163 - val_mae: 0.8320 - val_mse: 1.1163\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2303 - mae: 0.8524 - mse: 1.2303 - val_loss: 1.1727 - val_mae: 0.8599 - val_mse: 1.1727\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2732 - mae: 0.8744 - mse: 1.2732 - val_loss: 1.1110 - val_mae: 0.8236 - val_mse: 1.1110\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1867 - mae: 0.8440 - mse: 1.1867 - val_loss: 1.5863 - val_mae: 1.0146 - val_mse: 1.5863\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1786 - mae: 0.8465 - mse: 1.1786 - val_loss: 1.1455 - val_mae: 0.8462 - val_mse: 1.1455\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1924 - mae: 0.8531 - mse: 1.1924 - val_loss: 1.0664 - val_mae: 0.8147 - val_mse: 1.0664\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2254 - mae: 0.8647 - mse: 1.2254 - val_loss: 1.0832 - val_mae: 0.8337 - val_mse: 1.0832\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1094 - mae: 0.8196 - mse: 1.1094 - val_loss: 1.1468 - val_mae: 0.8492 - val_mse: 1.1468\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2897 - mae: 0.8885 - mse: 1.2897 - val_loss: 1.1548 - val_mae: 0.8566 - val_mse: 1.1548\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1364 - mae: 0.8201 - mse: 1.1364 - val_loss: 2.0535 - val_mae: 1.1712 - val_mse: 2.0535\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1551 - mae: 0.8371 - mse: 1.1551 - val_loss: 2.3630 - val_mae: 1.2380 - val_mse: 2.3630\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2353 - mae: 0.8725 - mse: 1.2353 - val_loss: 1.0891 - val_mae: 0.8367 - val_mse: 1.0891\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1686 - mae: 0.8488 - mse: 1.1686 - val_loss: 1.1831 - val_mae: 0.8672 - val_mse: 1.1831\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1203 - mae: 0.8087 - mse: 1.1203 - val_loss: 1.3924 - val_mae: 0.9440 - val_mse: 1.3924\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1076 - mae: 0.8136 - mse: 1.1076 - val_loss: 1.1179 - val_mae: 0.8331 - val_mse: 1.1179\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1111 - mae: 0.8147 - mse: 1.1111 - val_loss: 1.1018 - val_mae: 0.8290 - val_mse: 1.1018\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1702 - mae: 0.8402 - mse: 1.1702 - val_loss: 1.1036 - val_mae: 0.8263 - val_mse: 1.1036\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1502 - mae: 0.8254 - mse: 1.1502 - val_loss: 1.2769 - val_mae: 0.8837 - val_mse: 1.2769\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0940 - mae: 0.8189 - mse: 1.0940 - val_loss: 1.9072 - val_mae: 1.1378 - val_mse: 1.9072\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1128 - mae: 0.8237 - mse: 1.1128 - val_loss: 1.2567 - val_mae: 0.8962 - val_mse: 1.2567\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1096 - mae: 0.8110 - mse: 1.1096 - val_loss: 1.0904 - val_mae: 0.8240 - val_mse: 1.0904\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0426 - mae: 0.7906 - mse: 1.0426 - val_loss: 1.4651 - val_mae: 0.9728 - val_mse: 1.4651\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0556 - mae: 0.8024 - mse: 1.0556 - val_loss: 1.0688 - val_mae: 0.8141 - val_mse: 1.0688\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0932 - mae: 0.8203 - mse: 1.0932 - val_loss: 1.9434 - val_mae: 1.1475 - val_mse: 1.9434\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0702 - mae: 0.7959 - mse: 1.0702 - val_loss: 1.7077 - val_mae: 1.0271 - val_mse: 1.7077\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0939 - mae: 0.8135 - mse: 1.0939 - val_loss: 2.3438 - val_mae: 1.2849 - val_mse: 2.3438\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0455 - mae: 0.8068 - mse: 1.0455 - val_loss: 1.1685 - val_mae: 0.8608 - val_mse: 1.1685\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0168 - mae: 0.7765 - mse: 1.0168 - val_loss: 1.0827 - val_mae: 0.8302 - val_mse: 1.0827\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9954 - mae: 0.7672 - mse: 0.9954 - val_loss: 2.3571 - val_mae: 1.2849 - val_mse: 2.3571\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0355 - mae: 0.7955 - mse: 1.0355 - val_loss: 1.4112 - val_mae: 0.9581 - val_mse: 1.4112\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9774 - mae: 0.7559 - mse: 0.9774 - val_loss: 1.0918 - val_mae: 0.8264 - val_mse: 1.0918\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0755 - mae: 0.8004 - mse: 1.0755 - val_loss: 1.4723 - val_mae: 0.9752 - val_mse: 1.4723\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0131 - mae: 0.7642 - mse: 1.0131 - val_loss: 1.1164 - val_mae: 0.8360 - val_mse: 1.1164\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0186 - mae: 0.7763 - mse: 1.0186 - val_loss: 1.1812 - val_mae: 0.8575 - val_mse: 1.1812\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0066 - mae: 0.7809 - mse: 1.0066 - val_loss: 1.2672 - val_mae: 0.9172 - val_mse: 1.2672\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0068 - mae: 0.7855 - mse: 1.0068 - val_loss: 1.0269 - val_mae: 0.8051 - val_mse: 1.0269\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9758 - mae: 0.7572 - mse: 0.9758 - val_loss: 1.1248 - val_mae: 0.8449 - val_mse: 1.1248\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0147 - mae: 0.7679 - mse: 1.0147 - val_loss: 1.9420 - val_mae: 1.1500 - val_mse: 1.9420\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9347 - mae: 0.7449 - mse: 0.9347 - val_loss: 1.0876 - val_mae: 0.8344 - val_mse: 1.0876\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9282 - mae: 0.7595 - mse: 0.9282 - val_loss: 1.2945 - val_mae: 0.9038 - val_mse: 1.2945\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9455 - mae: 0.7449 - mse: 0.9455 - val_loss: 1.1937 - val_mae: 0.8709 - val_mse: 1.1937\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9889 - mae: 0.7669 - mse: 0.9889 - val_loss: 1.5955 - val_mae: 0.9991 - val_mse: 1.5955\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9285 - mae: 0.7492 - mse: 0.9285 - val_loss: 1.0689 - val_mae: 0.8300 - val_mse: 1.0689\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9265 - mae: 0.7384 - mse: 0.9265 - val_loss: 2.0403 - val_mae: 1.1733 - val_mse: 2.0403\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9488 - mae: 0.7454 - mse: 0.9488 - val_loss: 2.2470 - val_mae: 1.2547 - val_mse: 2.2470\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9145 - mae: 0.7387 - mse: 0.9145 - val_loss: 1.5525 - val_mae: 1.0198 - val_mse: 1.5525\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9782 - mae: 0.7559 - mse: 0.9782 - val_loss: 1.6448 - val_mae: 1.0392 - val_mse: 1.6448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9014 - mae: 0.7375 - mse: 0.9014 - val_loss: 1.6145 - val_mae: 1.0406 - val_mse: 1.6145\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9188 - mae: 0.7243 - mse: 0.9188 - val_loss: 1.4179 - val_mae: 0.9481 - val_mse: 1.4179\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9759 - mae: 0.7674 - mse: 0.9759 - val_loss: 1.3089 - val_mae: 0.9086 - val_mse: 1.3089\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9022 - mae: 0.7352 - mse: 0.9022 - val_loss: 1.0986 - val_mae: 0.8396 - val_mse: 1.0986\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9014 - mae: 0.7186 - mse: 0.9014 - val_loss: 1.0500 - val_mae: 0.8184 - val_mse: 1.0500\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9007 - mae: 0.7228 - mse: 0.9007 - val_loss: 1.1900 - val_mae: 0.8521 - val_mse: 1.1900\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8953 - mae: 0.7222 - mse: 0.8953 - val_loss: 1.5662 - val_mae: 0.9906 - val_mse: 1.5662\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8996 - mae: 0.7226 - mse: 0.8996 - val_loss: 2.0008 - val_mae: 1.1721 - val_mse: 2.0008\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8517 - mae: 0.7046 - mse: 0.8517 - val_loss: 1.0704 - val_mae: 0.8255 - val_mse: 1.0704\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8765 - mae: 0.7130 - mse: 0.8765 - val_loss: 1.7267 - val_mae: 1.0863 - val_mse: 1.7267\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9088 - mae: 0.7330 - mse: 0.9088 - val_loss: 1.3953 - val_mae: 0.9379 - val_mse: 1.3953\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9052 - mae: 0.7254 - mse: 0.9052 - val_loss: 1.1324 - val_mae: 0.8548 - val_mse: 1.1324\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8644 - mae: 0.7179 - mse: 0.8644 - val_loss: 1.5791 - val_mae: 1.0361 - val_mse: 1.5791\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8844 - mae: 0.7202 - mse: 0.8844 - val_loss: 1.6751 - val_mae: 1.0627 - val_mse: 1.6751\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8775 - mae: 0.7172 - mse: 0.8775 - val_loss: 1.0693 - val_mae: 0.8189 - val_mse: 1.0693\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8506 - mae: 0.7126 - mse: 0.8506 - val_loss: 1.2111 - val_mae: 0.8847 - val_mse: 1.2111\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8373 - mae: 0.7002 - mse: 0.8373 - val_loss: 1.4873 - val_mae: 0.9915 - val_mse: 1.4873\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8846 - mae: 0.7214 - mse: 0.8846 - val_loss: 1.1625 - val_mae: 0.8616 - val_mse: 1.1625\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8012 - mae: 0.6888 - mse: 0.8012 - val_loss: 1.2667 - val_mae: 0.8853 - val_mse: 1.2667\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8455 - mae: 0.7035 - mse: 0.8455 - val_loss: 1.0843 - val_mae: 0.8328 - val_mse: 1.0843\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9265 - mae: 0.7367 - mse: 0.9265 - val_loss: 1.0380 - val_mae: 0.8146 - val_mse: 1.0380\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7978 - mae: 0.6854 - mse: 0.7978 - val_loss: 1.0586 - val_mae: 0.8270 - val_mse: 1.0586\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8589 - mae: 0.7056 - mse: 0.8589 - val_loss: 1.1299 - val_mae: 0.8487 - val_mse: 1.1299\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7775 - mae: 0.6698 - mse: 0.7775 - val_loss: 1.0911 - val_mae: 0.8291 - val_mse: 1.0911\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8129 - mae: 0.6955 - mse: 0.8129 - val_loss: 1.0853 - val_mae: 0.8340 - val_mse: 1.0853\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8044 - mae: 0.6854 - mse: 0.8044 - val_loss: 1.3209 - val_mae: 0.9284 - val_mse: 1.3209\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7999 - mae: 0.6813 - mse: 0.7999 - val_loss: 1.3655 - val_mae: 0.9231 - val_mse: 1.3655\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8371 - mae: 0.7014 - mse: 0.8371 - val_loss: 1.1079 - val_mae: 0.8359 - val_mse: 1.1079\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7928 - mae: 0.6782 - mse: 0.7928 - val_loss: 1.2028 - val_mae: 0.8783 - val_mse: 1.2028\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8420 - mae: 0.7053 - mse: 0.8420 - val_loss: 1.0579 - val_mae: 0.8251 - val_mse: 1.0579\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7920 - mae: 0.6762 - mse: 0.7920 - val_loss: 1.0583 - val_mae: 0.8265 - val_mse: 1.0583\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7935 - mae: 0.6801 - mse: 0.7935 - val_loss: 1.3394 - val_mae: 0.9159 - val_mse: 1.3394\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8246 - mae: 0.6896 - mse: 0.8246 - val_loss: 1.1033 - val_mae: 0.8504 - val_mse: 1.1033\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7576 - mae: 0.6539 - mse: 0.7576 - val_loss: 1.2008 - val_mae: 0.8661 - val_mse: 1.2008\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7955 - mae: 0.6707 - mse: 0.7955 - val_loss: 2.6747 - val_mae: 1.3772 - val_mse: 2.6747\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7942 - mae: 0.6704 - mse: 0.7942 - val_loss: 1.5519 - val_mae: 0.9973 - val_mse: 1.5519\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7679 - mae: 0.6767 - mse: 0.7679 - val_loss: 1.1896 - val_mae: 0.8775 - val_mse: 1.1896\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8173 - mae: 0.6790 - mse: 0.8173 - val_loss: 1.1034 - val_mae: 0.8516 - val_mse: 1.1034\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7059 - mae: 0.6341 - mse: 0.7059 - val_loss: 1.0973 - val_mae: 0.8437 - val_mse: 1.0973\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7899 - mae: 0.6784 - mse: 0.7899 - val_loss: 1.1765 - val_mae: 0.8604 - val_mse: 1.1765\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7467 - mae: 0.6650 - mse: 0.7467 - val_loss: 1.1921 - val_mae: 0.8692 - val_mse: 1.1921\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7557 - mae: 0.6455 - mse: 0.7557 - val_loss: 1.0759 - val_mae: 0.8252 - val_mse: 1.0759\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7391 - mae: 0.6589 - mse: 0.7391 - val_loss: 1.0685 - val_mae: 0.8230 - val_mse: 1.0685\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7472 - mae: 0.6567 - mse: 0.7472 - val_loss: 1.4329 - val_mae: 0.9800 - val_mse: 1.4329\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7461 - mae: 0.6543 - mse: 0.7461 - val_loss: 1.4850 - val_mae: 0.9908 - val_mse: 1.4850\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7898 - mae: 0.6731 - mse: 0.7898 - val_loss: 1.5295 - val_mae: 0.9755 - val_mse: 1.5295\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6768 - mae: 0.6233 - mse: 0.6768 - val_loss: 1.2161 - val_mae: 0.8867 - val_mse: 1.2161\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7594 - mae: 0.6749 - mse: 0.7594 - val_loss: 1.0979 - val_mae: 0.8481 - val_mse: 1.0979\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7226 - mae: 0.6354 - mse: 0.7226 - val_loss: 1.4728 - val_mae: 0.9560 - val_mse: 1.4728\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6641 - mae: 0.6184 - mse: 0.6641 - val_loss: 1.4463 - val_mae: 0.9910 - val_mse: 1.4463\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7197 - mae: 0.6542 - mse: 0.7197 - val_loss: 1.3476 - val_mae: 0.9497 - val_mse: 1.3476\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7211 - mae: 0.6485 - mse: 0.7211 - val_loss: 1.2133 - val_mae: 0.8916 - val_mse: 1.2133\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6724 - mae: 0.6234 - mse: 0.6724 - val_loss: 1.8859 - val_mae: 1.0921 - val_mse: 1.8859\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7234 - mae: 0.6498 - mse: 0.7234 - val_loss: 1.2593 - val_mae: 0.8877 - val_mse: 1.2593\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6811 - mae: 0.6277 - mse: 0.6811 - val_loss: 1.1416 - val_mae: 0.8701 - val_mse: 1.1416\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7048 - mae: 0.6320 - mse: 0.7048 - val_loss: 1.2464 - val_mae: 0.8890 - val_mse: 1.2464\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6933 - mae: 0.6368 - mse: 0.6933 - val_loss: 1.1564 - val_mae: 0.8695 - val_mse: 1.1564\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6303 - mae: 0.6039 - mse: 0.6303 - val_loss: 1.1735 - val_mae: 0.8650 - val_mse: 1.1735\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6887 - mae: 0.6223 - mse: 0.6887 - val_loss: 1.3050 - val_mae: 0.9053 - val_mse: 1.3050\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7008 - mae: 0.6284 - mse: 0.7008 - val_loss: 1.6760 - val_mae: 1.0618 - val_mse: 1.6760\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6692 - mae: 0.6184 - mse: 0.6692 - val_loss: 1.2081 - val_mae: 0.8963 - val_mse: 1.2081\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6325 - mae: 0.6004 - mse: 0.6325 - val_loss: 1.3855 - val_mae: 0.9570 - val_mse: 1.3855\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6847 - mae: 0.6312 - mse: 0.6847 - val_loss: 1.2889 - val_mae: 0.9170 - val_mse: 1.2889\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6776 - mae: 0.6261 - mse: 0.6776 - val_loss: 1.3130 - val_mae: 0.9107 - val_mse: 1.3130\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6160 - mae: 0.5935 - mse: 0.6160 - val_loss: 1.1007 - val_mae: 0.8502 - val_mse: 1.1007\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6533 - mae: 0.6057 - mse: 0.6533 - val_loss: 1.4133 - val_mae: 0.9427 - val_mse: 1.4133\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6664 - mae: 0.6161 - mse: 0.6664 - val_loss: 1.4928 - val_mae: 0.9998 - val_mse: 1.4928\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6789 - mae: 0.6273 - mse: 0.6789 - val_loss: 1.3625 - val_mae: 0.9601 - val_mse: 1.3625\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6206 - mae: 0.6017 - mse: 0.6206 - val_loss: 1.2904 - val_mae: 0.9063 - val_mse: 1.2904\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6324 - mae: 0.6031 - mse: 0.6324 - val_loss: 1.2141 - val_mae: 0.8771 - val_mse: 1.2141\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6075 - mae: 0.5901 - mse: 0.6075 - val_loss: 1.2653 - val_mae: 0.9168 - val_mse: 1.2653\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6355 - mae: 0.6161 - mse: 0.6355 - val_loss: 1.2038 - val_mae: 0.8885 - val_mse: 1.2038\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6013 - mae: 0.5897 - mse: 0.6013 - val_loss: 1.0478 - val_mae: 0.8300 - val_mse: 1.0478\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6331 - mae: 0.6087 - mse: 0.6331 - val_loss: 1.2885 - val_mae: 0.9171 - val_mse: 1.2885\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6083 - mae: 0.5903 - mse: 0.6083 - val_loss: 1.5403 - val_mae: 1.0093 - val_mse: 1.5403\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6645 - mae: 0.6344 - mse: 0.6645 - val_loss: 1.0985 - val_mae: 0.8370 - val_mse: 1.0985\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6105 - mae: 0.5854 - mse: 0.6105 - val_loss: 1.1806 - val_mae: 0.8624 - val_mse: 1.1806\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6415 - mae: 0.5999 - mse: 0.6415 - val_loss: 1.1123 - val_mae: 0.8509 - val_mse: 1.1123\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5999 - mae: 0.5784 - mse: 0.5999 - val_loss: 1.1235 - val_mae: 0.8653 - val_mse: 1.1235\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6436 - mae: 0.6104 - mse: 0.6436 - val_loss: 1.1502 - val_mae: 0.8688 - val_mse: 1.1502\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5861 - mae: 0.5834 - mse: 0.5861 - val_loss: 1.4519 - val_mae: 0.9739 - val_mse: 1.4519\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5699 - mae: 0.5668 - mse: 0.5699 - val_loss: 1.3625 - val_mae: 0.9267 - val_mse: 1.3625\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5883 - mae: 0.5810 - mse: 0.5883 - val_loss: 1.4074 - val_mae: 0.9577 - val_mse: 1.4074\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6202 - mae: 0.6043 - mse: 0.6202 - val_loss: 1.3452 - val_mae: 0.9451 - val_mse: 1.3452\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5957 - mae: 0.5747 - mse: 0.5957 - val_loss: 1.2850 - val_mae: 0.9265 - val_mse: 1.2850\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5825 - mae: 0.5588 - mse: 0.5825 - val_loss: 1.3219 - val_mae: 0.9368 - val_mse: 1.3219\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5611 - mae: 0.5699 - mse: 0.5611 - val_loss: 1.2111 - val_mae: 0.8795 - val_mse: 1.2111\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5864 - mae: 0.5849 - mse: 0.5864 - val_loss: 1.7563 - val_mae: 1.0729 - val_mse: 1.7563\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6168 - mae: 0.5883 - mse: 0.6168 - val_loss: 1.3179 - val_mae: 0.9025 - val_mse: 1.3179\n",
      "Kappa Score: 0.7813623550934309\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 127.8522 - mae: 6.0600 - mse: 127.8522 - val_loss: 5.7067 - val_mae: 1.8472 - val_mse: 5.7067\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.9745 - mae: 3.8646 - mse: 20.9745 - val_loss: 80.1557 - val_mae: 8.1838 - val_mse: 80.1557\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.4782 - mae: 3.3433 - mse: 17.4782 - val_loss: 3.7008 - val_mae: 1.4634 - val_mse: 3.7008\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.7053 - mae: 2.2720 - mse: 8.7053 - val_loss: 6.8643 - val_mae: 2.4159 - val_mse: 6.8643\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 5.2512 - mae: 1.8846 - mse: 5.2512 - val_loss: 3.2354 - val_mae: 1.5557 - val_mse: 3.2354\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.1875 - mae: 1.5974 - mse: 4.1875 - val_loss: 1.4334 - val_mae: 0.9363 - val_mse: 1.4334\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.9328 - mae: 1.3899 - mse: 2.9328 - val_loss: 1.3722 - val_mae: 0.9036 - val_mse: 1.3722\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.5302 - mae: 1.2522 - mse: 2.5302 - val_loss: 2.6606 - val_mae: 1.3880 - val_mse: 2.6606\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.5283 - mae: 1.2832 - mse: 2.5283 - val_loss: 1.4349 - val_mae: 0.9345 - val_mse: 1.4349\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1320 - mae: 1.1631 - mse: 2.1320 - val_loss: 1.7738 - val_mae: 1.0521 - val_mse: 1.7738\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8907 - mae: 1.0818 - mse: 1.8907 - val_loss: 2.6532 - val_mae: 1.3532 - val_mse: 2.6532\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9548 - mae: 1.1239 - mse: 1.9548 - val_loss: 1.3735 - val_mae: 0.9152 - val_mse: 1.3735\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9180 - mae: 1.1014 - mse: 1.9180 - val_loss: 2.3418 - val_mae: 1.2677 - val_mse: 2.3418\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8345 - mae: 1.0825 - mse: 1.8345 - val_loss: 1.4089 - val_mae: 0.9304 - val_mse: 1.4089\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8769 - mae: 1.0760 - mse: 1.8769 - val_loss: 1.7699 - val_mae: 1.0149 - val_mse: 1.7699\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6726 - mae: 1.0147 - mse: 1.6726 - val_loss: 1.4192 - val_mae: 0.9319 - val_mse: 1.4192\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6533 - mae: 1.0112 - mse: 1.6533 - val_loss: 1.5141 - val_mae: 0.9514 - val_mse: 1.5141\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5464 - mae: 0.9802 - mse: 1.5464 - val_loss: 2.6005 - val_mae: 1.3350 - val_mse: 2.6005\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6378 - mae: 1.0097 - mse: 1.6378 - val_loss: 1.2497 - val_mae: 0.8760 - val_mse: 1.2497\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5173 - mae: 0.9883 - mse: 1.5173 - val_loss: 1.9336 - val_mae: 1.1233 - val_mse: 1.9336\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5512 - mae: 0.9538 - mse: 1.5512 - val_loss: 1.2831 - val_mae: 0.8898 - val_mse: 1.2831\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6137 - mae: 1.0138 - mse: 1.6137 - val_loss: 2.1708 - val_mae: 1.2185 - val_mse: 2.1708\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3551 - mae: 0.9085 - mse: 1.3551 - val_loss: 2.7911 - val_mae: 1.3226 - val_mse: 2.7911\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4585 - mae: 0.9554 - mse: 1.4585 - val_loss: 1.3265 - val_mae: 0.8999 - val_mse: 1.3265\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5261 - mae: 0.9473 - mse: 1.5261 - val_loss: 1.3855 - val_mae: 0.9124 - val_mse: 1.3855\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3973 - mae: 0.9261 - mse: 1.3973 - val_loss: 1.2601 - val_mae: 0.8779 - val_mse: 1.2601\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3751 - mae: 0.9292 - mse: 1.3751 - val_loss: 1.2205 - val_mae: 0.8568 - val_mse: 1.2205\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4665 - mae: 0.9495 - mse: 1.4665 - val_loss: 1.2296 - val_mae: 0.8657 - val_mse: 1.2296\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2566 - mae: 0.8719 - mse: 1.2566 - val_loss: 1.1555 - val_mae: 0.8391 - val_mse: 1.1555\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3897 - mae: 0.9228 - mse: 1.3897 - val_loss: 1.2375 - val_mae: 0.8667 - val_mse: 1.2375\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2383 - mae: 0.8772 - mse: 1.2383 - val_loss: 2.5928 - val_mae: 1.3410 - val_mse: 2.5928\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3079 - mae: 0.8958 - mse: 1.3079 - val_loss: 1.2207 - val_mae: 0.8586 - val_mse: 1.2207\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1852 - mae: 0.8458 - mse: 1.1852 - val_loss: 2.2374 - val_mae: 1.2325 - val_mse: 2.2374\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4352 - mae: 0.9374 - mse: 1.4352 - val_loss: 1.7157 - val_mae: 1.0043 - val_mse: 1.7157\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2117 - mae: 0.8601 - mse: 1.2117 - val_loss: 2.4000 - val_mae: 1.2051 - val_mse: 2.4000\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2202 - mae: 0.8729 - mse: 1.2202 - val_loss: 1.4754 - val_mae: 0.9632 - val_mse: 1.4754\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2607 - mae: 0.8739 - mse: 1.2607 - val_loss: 2.8179 - val_mae: 1.4167 - val_mse: 2.8179\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.8552 - mae: 1.1295 - mse: 1.855 - 0s 1ms/step - loss: 1.2248 - mae: 0.8627 - mse: 1.2248 - val_loss: 1.1723 - val_mae: 0.8448 - val_mse: 1.1723\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1550 - mae: 0.8322 - mse: 1.1550 - val_loss: 1.7686 - val_mae: 1.0241 - val_mse: 1.7686\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3023 - mae: 0.8963 - mse: 1.3023 - val_loss: 1.1664 - val_mae: 0.8364 - val_mse: 1.1664\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1592 - mae: 0.8467 - mse: 1.1592 - val_loss: 1.3190 - val_mae: 0.9016 - val_mse: 1.3190\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2431 - mae: 0.8690 - mse: 1.2431 - val_loss: 1.1512 - val_mae: 0.8363 - val_mse: 1.1512\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1848 - mae: 0.8518 - mse: 1.1848 - val_loss: 1.4712 - val_mae: 0.9435 - val_mse: 1.4712\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2421 - mae: 0.8793 - mse: 1.2421 - val_loss: 1.1459 - val_mae: 0.8327 - val_mse: 1.1459\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1571 - mae: 0.8309 - mse: 1.1571 - val_loss: 1.1343 - val_mae: 0.8359 - val_mse: 1.1343\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2385 - mae: 0.8611 - mse: 1.2385 - val_loss: 1.2490 - val_mae: 0.8727 - val_mse: 1.2490\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1567 - mae: 0.8304 - mse: 1.1567 - val_loss: 1.3339 - val_mae: 0.9081 - val_mse: 1.3339\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1176 - mae: 0.8213 - mse: 1.1176 - val_loss: 2.7311 - val_mae: 1.3935 - val_mse: 2.7311\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2241 - mae: 0.8614 - mse: 1.2241 - val_loss: 1.3573 - val_mae: 0.9019 - val_mse: 1.3573\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0442 - mae: 0.7950 - mse: 1.0442 - val_loss: 1.1697 - val_mae: 0.8435 - val_mse: 1.1697\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1461 - mae: 0.8327 - mse: 1.1461 - val_loss: 1.5017 - val_mae: 0.9592 - val_mse: 1.5017\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0966 - mae: 0.8253 - mse: 1.0966 - val_loss: 1.2695 - val_mae: 0.8855 - val_mse: 1.2695\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0654 - mae: 0.8029 - mse: 1.0654 - val_loss: 1.1877 - val_mae: 0.8511 - val_mse: 1.1877\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1086 - mae: 0.8086 - mse: 1.1086 - val_loss: 1.1590 - val_mae: 0.8341 - val_mse: 1.1590\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0242 - mae: 0.7972 - mse: 1.0242 - val_loss: 1.1337 - val_mae: 0.8312 - val_mse: 1.1337\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0540 - mae: 0.7904 - mse: 1.0540 - val_loss: 1.1722 - val_mae: 0.8438 - val_mse: 1.1722\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1674 - mae: 0.8299 - mse: 1.1674 - val_loss: 2.0648 - val_mae: 1.1772 - val_mse: 2.0648\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0623 - mae: 0.8060 - mse: 1.0623 - val_loss: 1.7921 - val_mae: 1.0870 - val_mse: 1.7921\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0260 - mae: 0.7854 - mse: 1.0260 - val_loss: 1.2168 - val_mae: 0.8620 - val_mse: 1.2168\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1106 - mae: 0.8154 - mse: 1.1106 - val_loss: 1.6888 - val_mae: 1.0566 - val_mse: 1.6888\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1047 - mae: 0.8185 - mse: 1.1047 - val_loss: 1.3301 - val_mae: 0.9096 - val_mse: 1.3301\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0340 - mae: 0.7875 - mse: 1.0340 - val_loss: 1.3471 - val_mae: 0.9008 - val_mse: 1.3471\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1030 - mae: 0.8116 - mse: 1.1030 - val_loss: 1.3725 - val_mae: 0.9214 - val_mse: 1.3725\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0211 - mae: 0.7925 - mse: 1.0211 - val_loss: 1.3609 - val_mae: 0.9137 - val_mse: 1.3609\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0199 - mae: 0.7840 - mse: 1.0199 - val_loss: 1.1143 - val_mae: 0.8208 - val_mse: 1.1143\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9615 - mae: 0.7554 - mse: 0.9615 - val_loss: 1.5407 - val_mae: 0.9921 - val_mse: 1.5407\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0058 - mae: 0.7710 - mse: 1.0058 - val_loss: 1.1519 - val_mae: 0.8387 - val_mse: 1.1519\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0036 - mae: 0.7674 - mse: 1.0036 - val_loss: 1.1904 - val_mae: 0.8512 - val_mse: 1.1904\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0496 - mae: 0.7926 - mse: 1.0496 - val_loss: 1.1166 - val_mae: 0.8312 - val_mse: 1.1166\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9646 - mae: 0.7612 - mse: 0.9646 - val_loss: 1.1912 - val_mae: 0.8416 - val_mse: 1.1912\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0341 - mae: 0.7918 - mse: 1.0341 - val_loss: 1.1421 - val_mae: 0.8309 - val_mse: 1.1421\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9799 - mae: 0.7695 - mse: 0.9799 - val_loss: 1.1208 - val_mae: 0.8274 - val_mse: 1.1208\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0561 - mae: 0.7820 - mse: 1.0561 - val_loss: 1.5823 - val_mae: 1.0108 - val_mse: 1.5823\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0190 - mae: 0.7771 - mse: 1.0190 - val_loss: 1.1049 - val_mae: 0.8213 - val_mse: 1.1049\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9362 - mae: 0.7498 - mse: 0.9362 - val_loss: 1.1648 - val_mae: 0.8475 - val_mse: 1.1648\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9670 - mae: 0.7493 - mse: 0.9670 - val_loss: 1.1778 - val_mae: 0.8452 - val_mse: 1.1778\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9296 - mae: 0.7501 - mse: 0.9296 - val_loss: 1.1367 - val_mae: 0.8372 - val_mse: 1.1367\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9730 - mae: 0.7623 - mse: 0.9730 - val_loss: 2.2997 - val_mae: 1.2663 - val_mse: 2.2997\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9732 - mae: 0.7537 - mse: 0.9732 - val_loss: 1.4630 - val_mae: 0.9406 - val_mse: 1.4630\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8987 - mae: 0.7421 - mse: 0.8987 - val_loss: 1.1125 - val_mae: 0.8244 - val_mse: 1.1125\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9412 - mae: 0.7539 - mse: 0.9412 - val_loss: 1.2791 - val_mae: 0.8939 - val_mse: 1.2791\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0130 - mae: 0.7732 - mse: 1.0130 - val_loss: 1.1280 - val_mae: 0.8192 - val_mse: 1.1280\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9272 - mae: 0.7316 - mse: 0.9272 - val_loss: 1.0848 - val_mae: 0.8127 - val_mse: 1.0848\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9548 - mae: 0.7529 - mse: 0.9548 - val_loss: 1.0643 - val_mae: 0.8045 - val_mse: 1.0643\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9650 - mae: 0.7635 - mse: 0.9650 - val_loss: 1.5221 - val_mae: 0.9958 - val_mse: 1.5221\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8964 - mae: 0.7266 - mse: 0.8964 - val_loss: 2.0031 - val_mae: 1.1718 - val_mse: 2.0031\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9209 - mae: 0.7394 - mse: 0.9209 - val_loss: 1.5644 - val_mae: 1.0169 - val_mse: 1.5644\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9552 - mae: 0.7531 - mse: 0.9552 - val_loss: 1.4372 - val_mae: 0.9316 - val_mse: 1.4372\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8525 - mae: 0.7127 - mse: 0.8525 - val_loss: 1.0981 - val_mae: 0.8222 - val_mse: 1.0981\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9105 - mae: 0.7347 - mse: 0.9105 - val_loss: 1.1064 - val_mae: 0.8213 - val_mse: 1.1064\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9082 - mae: 0.7259 - mse: 0.9082 - val_loss: 2.3115 - val_mae: 1.2657 - val_mse: 2.3115\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8463 - mae: 0.7068 - mse: 0.8463 - val_loss: 1.3500 - val_mae: 0.8971 - val_mse: 1.3500\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9794 - mae: 0.7624 - mse: 0.9794 - val_loss: 1.0948 - val_mae: 0.8180 - val_mse: 1.0948\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8195 - mae: 0.6957 - mse: 0.8195 - val_loss: 2.0046 - val_mae: 1.1648 - val_mse: 2.0046\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8976 - mae: 0.7150 - mse: 0.8976 - val_loss: 1.0933 - val_mae: 0.8085 - val_mse: 1.0933\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8862 - mae: 0.7353 - mse: 0.8862 - val_loss: 1.1461 - val_mae: 0.8289 - val_mse: 1.1461\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8744 - mae: 0.7236 - mse: 0.8744 - val_loss: 1.0730 - val_mae: 0.8042 - val_mse: 1.0730\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8297 - mae: 0.7050 - mse: 0.8297 - val_loss: 1.2036 - val_mae: 0.8461 - val_mse: 1.2036\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9109 - mae: 0.7378 - mse: 0.9109 - val_loss: 1.1177 - val_mae: 0.8177 - val_mse: 1.1177\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7985 - mae: 0.6868 - mse: 0.7985 - val_loss: 2.1589 - val_mae: 1.2160 - val_mse: 2.1589\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8835 - mae: 0.7210 - mse: 0.8835 - val_loss: 1.0569 - val_mae: 0.8006 - val_mse: 1.0569\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8239 - mae: 0.6970 - mse: 0.8239 - val_loss: 1.3088 - val_mae: 0.8945 - val_mse: 1.3088\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8460 - mae: 0.7054 - mse: 0.8460 - val_loss: 1.0558 - val_mae: 0.8001 - val_mse: 1.0558\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7938 - mae: 0.6920 - mse: 0.7938 - val_loss: 1.1603 - val_mae: 0.8439 - val_mse: 1.1603\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7932 - mae: 0.6889 - mse: 0.7932 - val_loss: 1.2183 - val_mae: 0.8699 - val_mse: 1.2183\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8497 - mae: 0.7056 - mse: 0.8497 - val_loss: 1.0816 - val_mae: 0.8101 - val_mse: 1.0816\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8108 - mae: 0.6855 - mse: 0.8108 - val_loss: 1.2828 - val_mae: 0.8791 - val_mse: 1.2828\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8230 - mae: 0.6957 - mse: 0.8230 - val_loss: 1.1591 - val_mae: 0.8348 - val_mse: 1.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8392 - mae: 0.6977 - mse: 0.8392 - val_loss: 1.1303 - val_mae: 0.8324 - val_mse: 1.1303\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7974 - mae: 0.6824 - mse: 0.7974 - val_loss: 1.5934 - val_mae: 1.0239 - val_mse: 1.5934\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8284 - mae: 0.7066 - mse: 0.8284 - val_loss: 1.5594 - val_mae: 0.9708 - val_mse: 1.5594\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7803 - mae: 0.6875 - mse: 0.7803 - val_loss: 1.1453 - val_mae: 0.8332 - val_mse: 1.1453\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7715 - mae: 0.6667 - mse: 0.7715 - val_loss: 1.2797 - val_mae: 0.8717 - val_mse: 1.2797\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7814 - mae: 0.6808 - mse: 0.7814 - val_loss: 1.1448 - val_mae: 0.8439 - val_mse: 1.1448\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7954 - mae: 0.6873 - mse: 0.7954 - val_loss: 1.1418 - val_mae: 0.8440 - val_mse: 1.1418\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8387 - mae: 0.7010 - mse: 0.8387 - val_loss: 1.0884 - val_mae: 0.8181 - val_mse: 1.0884\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7775 - mae: 0.6792 - mse: 0.7775 - val_loss: 1.0601 - val_mae: 0.8072 - val_mse: 1.0601\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7150 - mae: 0.6459 - mse: 0.7150 - val_loss: 1.4728 - val_mae: 0.9679 - val_mse: 1.4728\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8346 - mae: 0.7063 - mse: 0.8346 - val_loss: 1.1591 - val_mae: 0.8357 - val_mse: 1.1591\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7639 - mae: 0.6706 - mse: 0.7639 - val_loss: 1.1713 - val_mae: 0.8418 - val_mse: 1.1713\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7644 - mae: 0.6749 - mse: 0.7644 - val_loss: 1.2355 - val_mae: 0.8798 - val_mse: 1.2355\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7957 - mae: 0.6833 - mse: 0.7957 - val_loss: 1.0796 - val_mae: 0.8175 - val_mse: 1.0796\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7904 - mae: 0.6755 - mse: 0.7904 - val_loss: 1.5780 - val_mae: 1.0118 - val_mse: 1.5780\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7387 - mae: 0.6623 - mse: 0.7387 - val_loss: 1.2890 - val_mae: 0.8916 - val_mse: 1.2890\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8095 - mae: 0.6830 - mse: 0.8095 - val_loss: 1.8086 - val_mae: 1.0969 - val_mse: 1.8086\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7109 - mae: 0.6409 - mse: 0.7109 - val_loss: 1.8430 - val_mae: 1.1151 - val_mse: 1.8430\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7735 - mae: 0.6617 - mse: 0.7735 - val_loss: 1.3726 - val_mae: 0.9129 - val_mse: 1.3726\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7579 - mae: 0.6658 - mse: 0.7579 - val_loss: 1.1591 - val_mae: 0.8607 - val_mse: 1.1591\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7427 - mae: 0.6551 - mse: 0.7427 - val_loss: 1.4474 - val_mae: 0.9375 - val_mse: 1.4474\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7528 - mae: 0.6720 - mse: 0.7528 - val_loss: 1.2882 - val_mae: 0.8978 - val_mse: 1.2882\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7839 - mae: 0.6837 - mse: 0.7839 - val_loss: 1.1034 - val_mae: 0.8282 - val_mse: 1.1034\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6503 - mae: 0.6160 - mse: 0.6503 - val_loss: 1.3121 - val_mae: 0.9078 - val_mse: 1.3121\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7531 - mae: 0.6657 - mse: 0.7531 - val_loss: 1.2705 - val_mae: 0.8976 - val_mse: 1.2705\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7347 - mae: 0.6413 - mse: 0.7347 - val_loss: 1.2609 - val_mae: 0.8685 - val_mse: 1.2609\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7032 - mae: 0.6371 - mse: 0.7032 - val_loss: 1.4296 - val_mae: 0.9538 - val_mse: 1.4296\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6933 - mae: 0.6386 - mse: 0.6933 - val_loss: 1.2322 - val_mae: 0.8709 - val_mse: 1.2322\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7154 - mae: 0.6502 - mse: 0.7154 - val_loss: 1.0824 - val_mae: 0.8154 - val_mse: 1.0824\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7335 - mae: 0.6527 - mse: 0.7335 - val_loss: 1.2975 - val_mae: 0.9068 - val_mse: 1.2975\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6959 - mae: 0.6361 - mse: 0.6959 - val_loss: 1.8785 - val_mae: 1.1333 - val_mse: 1.8785\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7216 - mae: 0.6517 - mse: 0.7216 - val_loss: 1.1098 - val_mae: 0.8291 - val_mse: 1.1098\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7151 - mae: 0.6432 - mse: 0.7151 - val_loss: 1.0973 - val_mae: 0.8251 - val_mse: 1.0973\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6845 - mae: 0.6193 - mse: 0.6845 - val_loss: 1.2661 - val_mae: 0.8907 - val_mse: 1.2661\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7057 - mae: 0.6351 - mse: 0.7057 - val_loss: 1.1218 - val_mae: 0.8329 - val_mse: 1.1218\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6743 - mae: 0.6218 - mse: 0.6743 - val_loss: 2.0292 - val_mae: 1.1843 - val_mse: 2.0292\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7032 - mae: 0.6394 - mse: 0.7032 - val_loss: 1.3995 - val_mae: 0.9521 - val_mse: 1.3995\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7007 - mae: 0.6424 - mse: 0.7007 - val_loss: 1.3123 - val_mae: 0.9146 - val_mse: 1.3123\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7636 - mae: 0.6583 - mse: 0.7636 - val_loss: 1.0882 - val_mae: 0.8245 - val_mse: 1.0882\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6061 - mae: 0.5858 - mse: 0.6061 - val_loss: 1.1413 - val_mae: 0.8496 - val_mse: 1.1413\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6926 - mae: 0.6344 - mse: 0.6926 - val_loss: 1.1651 - val_mae: 0.8554 - val_mse: 1.1651\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7361 - mae: 0.6478 - mse: 0.7361 - val_loss: 1.6103 - val_mae: 1.0255 - val_mse: 1.6103\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6694 - mae: 0.6181 - mse: 0.6694 - val_loss: 1.0948 - val_mae: 0.8220 - val_mse: 1.0948\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6638 - mae: 0.6182 - mse: 0.6638 - val_loss: 1.1212 - val_mae: 0.8325 - val_mse: 1.1212\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6792 - mae: 0.6146 - mse: 0.6792 - val_loss: 1.1343 - val_mae: 0.8340 - val_mse: 1.1343\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6353 - mae: 0.6049 - mse: 0.6353 - val_loss: 1.2309 - val_mae: 0.8484 - val_mse: 1.2309\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6555 - mae: 0.6151 - mse: 0.6555 - val_loss: 1.1162 - val_mae: 0.8343 - val_mse: 1.1162\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6516 - mae: 0.6050 - mse: 0.6516 - val_loss: 1.5102 - val_mae: 1.0024 - val_mse: 1.5102\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6204 - mae: 0.6004 - mse: 0.6204 - val_loss: 1.6056 - val_mae: 0.9750 - val_mse: 1.6056\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6885 - mae: 0.6363 - mse: 0.6885 - val_loss: 1.4099 - val_mae: 0.9454 - val_mse: 1.4099\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6632 - mae: 0.6194 - mse: 0.6632 - val_loss: 1.1922 - val_mae: 0.8456 - val_mse: 1.1922\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6540 - mae: 0.6211 - mse: 0.6540 - val_loss: 1.1231 - val_mae: 0.8309 - val_mse: 1.1231\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6343 - mae: 0.6008 - mse: 0.6343 - val_loss: 1.7610 - val_mae: 1.0312 - val_mse: 1.7610\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7081 - mae: 0.6364 - mse: 0.7081 - val_loss: 1.2267 - val_mae: 0.8561 - val_mse: 1.2267\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6230 - mae: 0.6027 - mse: 0.6230 - val_loss: 1.5114 - val_mae: 0.9966 - val_mse: 1.5114\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6316 - mae: 0.5955 - mse: 0.6316 - val_loss: 1.0886 - val_mae: 0.8202 - val_mse: 1.0886\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6461 - mae: 0.6015 - mse: 0.6461 - val_loss: 1.0844 - val_mae: 0.8232 - val_mse: 1.0844\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6536 - mae: 0.6097 - mse: 0.6536 - val_loss: 1.1230 - val_mae: 0.8353 - val_mse: 1.1230\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5979 - mae: 0.5787 - mse: 0.5979 - val_loss: 2.2213 - val_mae: 1.2416 - val_mse: 2.2213\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6580 - mae: 0.6179 - mse: 0.6580 - val_loss: 1.6401 - val_mae: 1.0354 - val_mse: 1.6401\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6168 - mae: 0.5949 - mse: 0.6168 - val_loss: 1.6996 - val_mae: 1.0606 - val_mse: 1.6996\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.1991 - mae: 0.8712 - mse: 1.199 - 0s 1ms/step - loss: 0.6221 - mae: 0.5914 - mse: 0.6221 - val_loss: 1.1225 - val_mae: 0.8337 - val_mse: 1.1225\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5752 - mae: 0.5794 - mse: 0.5752 - val_loss: 1.6181 - val_mae: 0.9735 - val_mse: 1.6181\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6228 - mae: 0.5974 - mse: 0.6228 - val_loss: 1.5011 - val_mae: 0.9916 - val_mse: 1.5011\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5823 - mae: 0.5803 - mse: 0.5823 - val_loss: 2.1171 - val_mae: 1.1421 - val_mse: 2.1171\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6581 - mae: 0.6201 - mse: 0.6581 - val_loss: 1.0999 - val_mae: 0.8335 - val_mse: 1.0999\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6275 - mae: 0.6048 - mse: 0.6275 - val_loss: 1.7066 - val_mae: 1.0545 - val_mse: 1.7066\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5583 - mae: 0.5638 - mse: 0.5583 - val_loss: 1.2661 - val_mae: 0.8796 - val_mse: 1.2661\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6521 - mae: 0.6756 - mse: 0.652 - 0s 1ms/step - loss: 0.5547 - mae: 0.5665 - mse: 0.5547 - val_loss: 1.6278 - val_mae: 1.0350 - val_mse: 1.6278\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5874 - mae: 0.5780 - mse: 0.5874 - val_loss: 1.6639 - val_mae: 0.9941 - val_mse: 1.6639\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5984 - mae: 0.5728 - mse: 0.5984 - val_loss: 1.1406 - val_mae: 0.8383 - val_mse: 1.1406\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5641 - mae: 0.5599 - mse: 0.5641 - val_loss: 1.1465 - val_mae: 0.8441 - val_mse: 1.1465\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5666 - mae: 0.5653 - mse: 0.5666 - val_loss: 2.3894 - val_mae: 1.3142 - val_mse: 2.3894\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5885 - mae: 0.5687 - mse: 0.5885 - val_loss: 1.5135 - val_mae: 1.0048 - val_mse: 1.5135\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6066 - mae: 0.5924 - mse: 0.6066 - val_loss: 1.3094 - val_mae: 0.9056 - val_mse: 1.3094\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6260 - mae: 0.6082 - mse: 0.6260 - val_loss: 1.0940 - val_mae: 0.8311 - val_mse: 1.0940\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5593 - mae: 0.5632 - mse: 0.5593 - val_loss: 1.3100 - val_mae: 0.8860 - val_mse: 1.3100\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5554 - mae: 0.5576 - mse: 0.5554 - val_loss: 1.2887 - val_mae: 0.9024 - val_mse: 1.2887\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6441 - mae: 0.6104 - mse: 0.6441 - val_loss: 1.3594 - val_mae: 0.9377 - val_mse: 1.3594\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5831 - mae: 0.5772 - mse: 0.5831 - val_loss: 1.1942 - val_mae: 0.8511 - val_mse: 1.1942\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5887 - mae: 0.5789 - mse: 0.5887 - val_loss: 1.3107 - val_mae: 0.8883 - val_mse: 1.3107\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5409 - mae: 0.5567 - mse: 0.5409 - val_loss: 1.8477 - val_mae: 1.1050 - val_mse: 1.8477\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6148 - mae: 0.5806 - mse: 0.6148 - val_loss: 1.2534 - val_mae: 0.8833 - val_mse: 1.2534\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5382 - mae: 0.5490 - mse: 0.5382 - val_loss: 2.1773 - val_mae: 1.2388 - val_mse: 2.1773\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5455 - mae: 0.5642 - mse: 0.5455 - val_loss: 1.5540 - val_mae: 1.0164 - val_mse: 1.5540\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5508 - mae: 0.5667 - mse: 0.5508 - val_loss: 1.2100 - val_mae: 0.8782 - val_mse: 1.2100\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5444 - mae: 0.5579 - mse: 0.5444 - val_loss: 2.0669 - val_mae: 1.1937 - val_mse: 2.0669\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5911 - mae: 0.5760 - mse: 0.5911 - val_loss: 1.1797 - val_mae: 0.8644 - val_mse: 1.1797\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5657 - mae: 0.5771 - mse: 0.5657 - val_loss: 1.1669 - val_mae: 0.8627 - val_mse: 1.1669\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4929 - mae: 0.5325 - mse: 0.4929 - val_loss: 1.1838 - val_mae: 0.8555 - val_mse: 1.1838\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5619 - mae: 0.5735 - mse: 0.5619 - val_loss: 1.1900 - val_mae: 0.8540 - val_mse: 1.1900\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5469 - mae: 0.5558 - mse: 0.5469 - val_loss: 1.1319 - val_mae: 0.8429 - val_mse: 1.1319\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4871 - mae: 0.5277 - mse: 0.4871 - val_loss: 1.2027 - val_mae: 0.8719 - val_mse: 1.2027\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5665 - mae: 0.5637 - mse: 0.5665 - val_loss: 1.4163 - val_mae: 0.9536 - val_mse: 1.4163\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5550 - mae: 0.5606 - mse: 0.5550 - val_loss: 1.6671 - val_mae: 1.0521 - val_mse: 1.6671\n",
      "Kappa Score: 0.6372650289175985\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 131.4459 - mae: 6.2697 - mse: 131.4459 - val_loss: 4.1791 - val_mae: 1.7910 - val_mse: 4.1791\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 33.3518 - mae: 4.2786 - mse: 33.3518 - val_loss: 12.4614 - val_mae: 3.3213 - val_mse: 12.4614\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 22.4070 - mae: 3.6067 - mse: 22.4070 - val_loss: 14.2283 - val_mae: 3.5378 - val_mse: 14.2283\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 18.2182 - mae: 3.1635 - mse: 18.2182 - val_loss: 1.3811 - val_mae: 0.9349 - val_mse: 1.3811\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.5869 - mae: 2.4955 - mse: 8.5869 - val_loss: 8.9539 - val_mae: 2.4861 - val_mse: 8.9539\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.9135 - mae: 1.7524 - mse: 4.9135 - val_loss: 1.8740 - val_mae: 1.1082 - val_mse: 1.8740\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1137 - mae: 1.4147 - mse: 3.1137 - val_loss: 10.7086 - val_mae: 3.0295 - val_mse: 10.7086\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0812 - mae: 1.3939 - mse: 3.0812 - val_loss: 1.4002 - val_mae: 0.9466 - val_mse: 1.4002\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.4828 - mae: 1.2661 - mse: 2.4828 - val_loss: 2.1744 - val_mae: 1.1952 - val_mse: 2.1744\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1854 - mae: 1.1702 - mse: 2.1854 - val_loss: 3.1326 - val_mae: 1.4134 - val_mse: 3.1326\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 2.1306 - mae: 1.1707 - mse: 2.1306 - val_loss: 2.4518 - val_mae: 1.2421 - val_mse: 2.4518\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9836 - mae: 1.0894 - mse: 1.9836 - val_loss: 1.2945 - val_mae: 0.8978 - val_mse: 1.2945\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8377 - mae: 1.0672 - mse: 1.8377 - val_loss: 1.9786 - val_mae: 1.1227 - val_mse: 1.9786\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7894 - mae: 1.0526 - mse: 1.7894 - val_loss: 1.3183 - val_mae: 0.9186 - val_mse: 1.3183\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.8706 - mae: 1.0748 - mse: 1.8706 - val_loss: 1.2128 - val_mae: 0.8724 - val_mse: 1.2128\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7817 - mae: 1.0376 - mse: 1.7817 - val_loss: 1.6525 - val_mae: 1.0106 - val_mse: 1.6525\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6164 - mae: 0.9951 - mse: 1.6164 - val_loss: 1.8162 - val_mae: 1.0477 - val_mse: 1.8162\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5695 - mae: 0.9729 - mse: 1.5695 - val_loss: 3.0478 - val_mae: 1.4159 - val_mse: 3.0478\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6975 - mae: 1.0138 - mse: 1.6975 - val_loss: 2.0025 - val_mae: 1.1368 - val_mse: 2.0025\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5373 - mae: 0.9804 - mse: 1.5373 - val_loss: 1.4836 - val_mae: 0.9482 - val_mse: 1.4836\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5519 - mae: 0.9825 - mse: 1.5519 - val_loss: 1.3480 - val_mae: 0.9123 - val_mse: 1.3480\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5478 - mae: 0.9839 - mse: 1.5478 - val_loss: 2.5965 - val_mae: 1.3332 - val_mse: 2.5965\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5609 - mae: 0.9893 - mse: 1.5609 - val_loss: 1.3539 - val_mae: 0.9173 - val_mse: 1.3539\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6242 - mae: 0.9949 - mse: 1.6242 - val_loss: 1.1987 - val_mae: 0.8775 - val_mse: 1.1987\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4047 - mae: 0.9274 - mse: 1.4047 - val_loss: 1.4301 - val_mae: 0.9599 - val_mse: 1.4301\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5163 - mae: 0.9561 - mse: 1.5163 - val_loss: 1.1512 - val_mae: 0.8517 - val_mse: 1.1512\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3842 - mae: 0.9218 - mse: 1.3842 - val_loss: 1.2053 - val_mae: 0.8600 - val_mse: 1.2053\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.5111 - mae: 0.9478 - mse: 1.5111 - val_loss: 1.1876 - val_mae: 0.8754 - val_mse: 1.1876\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.4457 - mae: 0.9442 - mse: 1.4457 - val_loss: 1.2738 - val_mae: 0.9042 - val_mse: 1.2738\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3354 - mae: 0.8874 - mse: 1.3354 - val_loss: 1.4149 - val_mae: 0.9339 - val_mse: 1.4149\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3988 - mae: 0.9285 - mse: 1.3988 - val_loss: 1.1679 - val_mae: 0.8601 - val_mse: 1.1679\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3299 - mae: 0.8980 - mse: 1.3299 - val_loss: 1.2004 - val_mae: 0.8789 - val_mse: 1.2004\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3250 - mae: 0.9031 - mse: 1.3250 - val_loss: 1.4463 - val_mae: 0.9502 - val_mse: 1.4463\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3843 - mae: 0.9274 - mse: 1.3843 - val_loss: 1.3810 - val_mae: 0.9295 - val_mse: 1.3810\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3801 - mae: 0.9235 - mse: 1.3801 - val_loss: 1.8515 - val_mae: 1.0948 - val_mse: 1.8515\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2617 - mae: 0.8837 - mse: 1.2617 - val_loss: 1.2179 - val_mae: 0.8676 - val_mse: 1.2179\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3021 - mae: 0.8933 - mse: 1.3021 - val_loss: 1.1683 - val_mae: 0.8658 - val_mse: 1.1683\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2701 - mae: 0.8740 - mse: 1.2701 - val_loss: 1.8293 - val_mae: 1.0879 - val_mse: 1.8293\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3004 - mae: 0.9090 - mse: 1.3004 - val_loss: 2.0568 - val_mae: 1.1428 - val_mse: 2.0568\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2433 - mae: 0.8756 - mse: 1.2433 - val_loss: 1.3387 - val_mae: 0.9173 - val_mse: 1.3387\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2504 - mae: 0.8874 - mse: 1.2504 - val_loss: 1.3456 - val_mae: 0.9288 - val_mse: 1.3456\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3472 - mae: 0.9199 - mse: 1.3472 - val_loss: 1.3872 - val_mae: 0.9256 - val_mse: 1.3872\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2145 - mae: 0.8570 - mse: 1.2145 - val_loss: 1.1222 - val_mae: 0.8401 - val_mse: 1.1222\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3291 - mae: 0.8904 - mse: 1.3291 - val_loss: 1.2054 - val_mae: 0.8727 - val_mse: 1.2054\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1682 - mae: 0.8606 - mse: 1.1682 - val_loss: 1.3106 - val_mae: 0.9059 - val_mse: 1.3106\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2228 - mae: 0.8683 - mse: 1.2228 - val_loss: 1.4260 - val_mae: 0.9553 - val_mse: 1.4260\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1543 - mae: 0.8408 - mse: 1.1543 - val_loss: 1.5343 - val_mae: 0.9894 - val_mse: 1.5343\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2297 - mae: 0.8713 - mse: 1.2297 - val_loss: 1.4940 - val_mae: 0.9766 - val_mse: 1.4940\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1447 - mae: 0.8250 - mse: 1.1447 - val_loss: 2.1959 - val_mae: 1.2044 - val_mse: 2.1959\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1869 - mae: 0.8532 - mse: 1.1869 - val_loss: 2.5870 - val_mae: 1.3439 - val_mse: 2.5870\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1119 - mae: 0.8253 - mse: 1.1119 - val_loss: 1.4265 - val_mae: 0.9436 - val_mse: 1.4265\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1402 - mae: 0.8394 - mse: 1.1402 - val_loss: 1.3785 - val_mae: 0.9254 - val_mse: 1.3785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1495 - mae: 0.8344 - mse: 1.1495 - val_loss: 1.4220 - val_mae: 0.9520 - val_mse: 1.4220\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1620 - mae: 0.8411 - mse: 1.1620 - val_loss: 1.8976 - val_mae: 1.1164 - val_mse: 1.8976\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1480 - mae: 0.8273 - mse: 1.1480 - val_loss: 1.5524 - val_mae: 0.9924 - val_mse: 1.5524\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1518 - mae: 0.8304 - mse: 1.1518 - val_loss: 3.3627 - val_mae: 1.5654 - val_mse: 3.3627\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0778 - mae: 0.8165 - mse: 1.0778 - val_loss: 1.1413 - val_mae: 0.8512 - val_mse: 1.1413\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2059 - mae: 0.8539 - mse: 1.2059 - val_loss: 1.2944 - val_mae: 0.9016 - val_mse: 1.2944\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0434 - mae: 0.8014 - mse: 1.0434 - val_loss: 1.3466 - val_mae: 0.9200 - val_mse: 1.3466\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1256 - mae: 0.8273 - mse: 1.1256 - val_loss: 1.2213 - val_mae: 0.8718 - val_mse: 1.2213\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1060 - mae: 0.8161 - mse: 1.1060 - val_loss: 1.1510 - val_mae: 0.8487 - val_mse: 1.1510\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0784 - mae: 0.7978 - mse: 1.0784 - val_loss: 1.1900 - val_mae: 0.8714 - val_mse: 1.1900\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9963 - mae: 0.7808 - mse: 0.9963 - val_loss: 1.3809 - val_mae: 0.9290 - val_mse: 1.3809\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1283 - mae: 0.8291 - mse: 1.1283 - val_loss: 1.1650 - val_mae: 0.8700 - val_mse: 1.1650\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0464 - mae: 0.7935 - mse: 1.0464 - val_loss: 1.1564 - val_mae: 0.8627 - val_mse: 1.1564\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0858 - mae: 0.8123 - mse: 1.0858 - val_loss: 1.5599 - val_mae: 0.9915 - val_mse: 1.5599\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0441 - mae: 0.7955 - mse: 1.0441 - val_loss: 2.6243 - val_mae: 1.3292 - val_mse: 2.6243\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1433 - mae: 0.8415 - mse: 1.1433 - val_loss: 1.2418 - val_mae: 0.8782 - val_mse: 1.2418\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0406 - mae: 0.7880 - mse: 1.0406 - val_loss: 1.2120 - val_mae: 0.8826 - val_mse: 1.2120\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0015 - mae: 0.7766 - mse: 1.0015 - val_loss: 1.2722 - val_mae: 0.8900 - val_mse: 1.2722\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0248 - mae: 0.7876 - mse: 1.0248 - val_loss: 1.3850 - val_mae: 0.9327 - val_mse: 1.3850\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0420 - mae: 0.7893 - mse: 1.0420 - val_loss: 2.2599 - val_mae: 1.2058 - val_mse: 2.2599\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9840 - mae: 0.7773 - mse: 0.9840 - val_loss: 1.3096 - val_mae: 0.9058 - val_mse: 1.3096\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0204 - mae: 0.7771 - mse: 1.0204 - val_loss: 2.0690 - val_mae: 1.1512 - val_mse: 2.0690\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0536 - mae: 0.8096 - mse: 1.0536 - val_loss: 1.1272 - val_mae: 0.8426 - val_mse: 1.1272\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9352 - mae: 0.7456 - mse: 0.9352 - val_loss: 1.3641 - val_mae: 0.9311 - val_mse: 1.3641\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0678 - mae: 0.8013 - mse: 1.0678 - val_loss: 1.1887 - val_mae: 0.8642 - val_mse: 1.1887\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9464 - mae: 0.7607 - mse: 0.9464 - val_loss: 1.3217 - val_mae: 0.9185 - val_mse: 1.3217\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9808 - mae: 0.7550 - mse: 0.9808 - val_loss: 1.1305 - val_mae: 0.8473 - val_mse: 1.1305\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9691 - mae: 0.7652 - mse: 0.9691 - val_loss: 1.3248 - val_mae: 0.9118 - val_mse: 1.3248\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9518 - mae: 0.7583 - mse: 0.9518 - val_loss: 2.0999 - val_mae: 1.1582 - val_mse: 2.0999\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9686 - mae: 0.7584 - mse: 0.9686 - val_loss: 1.1531 - val_mae: 0.8557 - val_mse: 1.1531\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0000 - mae: 0.7759 - mse: 1.0000 - val_loss: 2.1565 - val_mae: 1.1897 - val_mse: 2.1565\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9472 - mae: 0.7583 - mse: 0.9472 - val_loss: 1.1704 - val_mae: 0.8543 - val_mse: 1.1704\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9286 - mae: 0.7453 - mse: 0.9286 - val_loss: 1.6240 - val_mae: 1.0185 - val_mse: 1.6240\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9224 - mae: 0.7416 - mse: 0.9224 - val_loss: 1.2295 - val_mae: 0.8730 - val_mse: 1.2295\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9572 - mae: 0.7479 - mse: 0.9572 - val_loss: 1.1696 - val_mae: 0.8585 - val_mse: 1.1696\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9638 - mae: 0.7526 - mse: 0.9638 - val_loss: 1.2410 - val_mae: 0.8737 - val_mse: 1.2410\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8828 - mae: 0.7242 - mse: 0.8828 - val_loss: 1.1973 - val_mae: 0.8714 - val_mse: 1.1973\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9371 - mae: 0.7507 - mse: 0.9371 - val_loss: 1.1813 - val_mae: 0.8625 - val_mse: 1.1813\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9858 - mae: 0.7703 - mse: 0.9858 - val_loss: 1.1410 - val_mae: 0.8456 - val_mse: 1.1410\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9367 - mae: 0.7483 - mse: 0.9367 - val_loss: 1.5673 - val_mae: 1.0083 - val_mse: 1.5673\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8479 - mae: 0.7157 - mse: 0.8479 - val_loss: 1.7157 - val_mae: 1.0472 - val_mse: 1.7157\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9367 - mae: 0.7410 - mse: 0.9367 - val_loss: 1.1944 - val_mae: 0.8639 - val_mse: 1.1944\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9485 - mae: 0.7456 - mse: 0.9485 - val_loss: 1.1544 - val_mae: 0.8538 - val_mse: 1.1544\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8916 - mae: 0.7253 - mse: 0.8916 - val_loss: 1.2826 - val_mae: 0.8956 - val_mse: 1.2826\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9212 - mae: 0.7506 - mse: 0.9212 - val_loss: 1.2971 - val_mae: 0.9027 - val_mse: 1.2971\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8594 - mae: 0.7024 - mse: 0.8594 - val_loss: 1.2842 - val_mae: 0.8904 - val_mse: 1.2842\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9346 - mae: 0.7431 - mse: 0.9346 - val_loss: 1.2304 - val_mae: 0.8708 - val_mse: 1.2304\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9043 - mae: 0.7242 - mse: 0.9043 - val_loss: 1.1446 - val_mae: 0.8474 - val_mse: 1.1446\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8652 - mae: 0.7184 - mse: 0.8652 - val_loss: 1.3947 - val_mae: 0.9261 - val_mse: 1.3947\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8966 - mae: 0.7256 - mse: 0.8966 - val_loss: 1.1791 - val_mae: 0.8634 - val_mse: 1.1791\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9104 - mae: 0.7311 - mse: 0.9104 - val_loss: 1.2115 - val_mae: 0.8659 - val_mse: 1.2115\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8642 - mae: 0.7151 - mse: 0.8642 - val_loss: 1.3018 - val_mae: 0.8937 - val_mse: 1.3018\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8583 - mae: 0.7209 - mse: 0.8583 - val_loss: 2.6768 - val_mae: 1.3588 - val_mse: 2.6768\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8553 - mae: 0.7061 - mse: 0.8553 - val_loss: 1.4273 - val_mae: 0.9385 - val_mse: 1.4273\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8196 - mae: 0.6989 - mse: 0.8196 - val_loss: 1.9163 - val_mae: 1.1112 - val_mse: 1.9163\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8875 - mae: 0.7385 - mse: 0.8875 - val_loss: 1.4417 - val_mae: 0.9619 - val_mse: 1.4417\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8345 - mae: 0.7089 - mse: 0.8345 - val_loss: 1.2582 - val_mae: 0.8771 - val_mse: 1.2582\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8596 - mae: 0.7132 - mse: 0.8596 - val_loss: 1.8001 - val_mae: 1.0785 - val_mse: 1.8001\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8621 - mae: 0.7197 - mse: 0.8621 - val_loss: 2.0337 - val_mae: 1.1281 - val_mse: 2.0337\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8300 - mae: 0.6925 - mse: 0.8300 - val_loss: 1.5865 - val_mae: 1.0010 - val_mse: 1.5865\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8127 - mae: 0.6966 - mse: 0.8127 - val_loss: 1.1702 - val_mae: 0.8447 - val_mse: 1.1702\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8042 - mae: 0.6908 - mse: 0.8042 - val_loss: 1.4407 - val_mae: 0.9440 - val_mse: 1.4407\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7757 - mae: 0.6731 - mse: 0.7757 - val_loss: 1.6930 - val_mae: 1.0382 - val_mse: 1.6930\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8807 - mae: 0.7286 - mse: 0.8807 - val_loss: 1.4905 - val_mae: 0.9655 - val_mse: 1.4905\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8293 - mae: 0.7016 - mse: 0.8293 - val_loss: 1.3496 - val_mae: 0.9213 - val_mse: 1.3496\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8634 - mae: 0.7073 - mse: 0.8634 - val_loss: 1.1722 - val_mae: 0.8506 - val_mse: 1.1722\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7917 - mae: 0.6848 - mse: 0.7917 - val_loss: 1.2392 - val_mae: 0.8656 - val_mse: 1.2392\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8202 - mae: 0.6862 - mse: 0.8202 - val_loss: 1.6258 - val_mae: 1.0158 - val_mse: 1.6258\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8308 - mae: 0.7007 - mse: 0.8308 - val_loss: 1.3215 - val_mae: 0.8889 - val_mse: 1.3215\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7392 - mae: 0.6515 - mse: 0.7392 - val_loss: 1.1790 - val_mae: 0.8632 - val_mse: 1.1790\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8164 - mae: 0.6994 - mse: 0.8164 - val_loss: 1.1488 - val_mae: 0.8457 - val_mse: 1.1488\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8124 - mae: 0.6921 - mse: 0.8124 - val_loss: 1.1733 - val_mae: 0.8481 - val_mse: 1.1733\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7887 - mae: 0.6767 - mse: 0.7887 - val_loss: 2.4650 - val_mae: 1.2859 - val_mse: 2.4650\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7836 - mae: 0.6755 - mse: 0.7836 - val_loss: 1.2101 - val_mae: 0.8697 - val_mse: 1.2101\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7755 - mae: 0.6684 - mse: 0.7755 - val_loss: 1.2442 - val_mae: 0.8691 - val_mse: 1.2442\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8175 - mae: 0.6985 - mse: 0.8175 - val_loss: 1.2076 - val_mae: 0.8528 - val_mse: 1.2076\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8086 - mae: 0.6801 - mse: 0.8086 - val_loss: 1.2112 - val_mae: 0.8601 - val_mse: 1.2112\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7538 - mae: 0.6620 - mse: 0.7538 - val_loss: 1.1808 - val_mae: 0.8460 - val_mse: 1.1808\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7271 - mae: 0.6493 - mse: 0.7271 - val_loss: 1.2075 - val_mae: 0.8542 - val_mse: 1.2075\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7755 - mae: 0.6734 - mse: 0.7755 - val_loss: 1.2829 - val_mae: 0.8833 - val_mse: 1.2829\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7677 - mae: 0.6736 - mse: 0.7677 - val_loss: 1.2265 - val_mae: 0.8740 - val_mse: 1.2265\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7653 - mae: 0.6697 - mse: 0.7653 - val_loss: 1.1849 - val_mae: 0.8614 - val_mse: 1.1849\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7354 - mae: 0.6501 - mse: 0.7354 - val_loss: 1.2716 - val_mae: 0.8735 - val_mse: 1.2716\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7293 - mae: 0.6506 - mse: 0.7293 - val_loss: 1.2338 - val_mae: 0.8653 - val_mse: 1.2338\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7184 - mae: 0.6398 - mse: 0.7184 - val_loss: 1.5336 - val_mae: 0.9753 - val_mse: 1.5336\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7360 - mae: 0.6514 - mse: 0.7360 - val_loss: 1.1769 - val_mae: 0.8521 - val_mse: 1.1769\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7718 - mae: 0.6876 - mse: 0.7718 - val_loss: 1.2056 - val_mae: 0.8606 - val_mse: 1.2056\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6757 - mae: 0.6237 - mse: 0.6757 - val_loss: 1.4530 - val_mae: 0.9451 - val_mse: 1.4530\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6658 - mae: 0.6162 - mse: 0.6658 - val_loss: 2.4638 - val_mae: 1.2930 - val_mse: 2.4638\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7397 - mae: 0.6655 - mse: 0.7397 - val_loss: 1.2357 - val_mae: 0.8796 - val_mse: 1.2357\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7169 - mae: 0.6524 - mse: 0.7169 - val_loss: 1.4182 - val_mae: 0.9263 - val_mse: 1.4182\n",
      "Kappa Score: 0.7049640432540061\n",
      "\n",
      "###########Set-8###########\n",
      "\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Epoch 1/1000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 184.0735 - mae: 6.2488 - mse: 184.0735 - val_loss: 12.1616 - val_mae: 3.0610 - val_mse: 12.1616\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 40.4455 - mae: 5.7493 - mse: 40.4455 - val_loss: 35.7464 - val_mae: 5.7583 - val_mse: 35.7464\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 33.0157 - mae: 4.8447 - mse: 33.0157 - val_loss: 2.3813 - val_mae: 1.1631 - val_mse: 2.3813\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 29.1275 - mae: 4.1165 - mse: 29.1275 - val_loss: 6.4580 - val_mae: 2.3056 - val_mse: 6.4580\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 19.0823 - mae: 3.2839 - mse: 19.0823 - val_loss: 11.4102 - val_mae: 2.5698 - val_mse: 11.4102\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 10.6619 - mae: 2.4225 - mse: 10.6619 - val_loss: 3.5153 - val_mae: 1.5701 - val_mse: 3.5153\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 13.8626 - mae: 3.0999 - mse: 13.8626 - val_loss: 2.5448 - val_mae: 1.2105 - val_mse: 2.5448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.4678 - mae: 1.4417 - mse: 3.4678 - val_loss: 38.7515 - val_mae: 6.0666 - val_mse: 38.7515\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 10.8991 - mae: 2.7093 - mse: 10.8991 - val_loss: 6.6036 - val_mae: 2.1984 - val_mse: 6.6036\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 4.8012 - mae: 1.8637 - mse: 4.8012 - val_loss: 5.7002 - val_mae: 2.1546 - val_mse: 5.7002\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.0334 - mae: 2.0206 - mse: 6.0334 - val_loss: 2.4221 - val_mae: 1.2114 - val_mse: 2.4221\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.9143 - mae: 1.5386 - mse: 3.9143 - val_loss: 1.4137 - val_mae: 0.9031 - val_mse: 1.4137\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 5.0954 - mae: 1.6146 - mse: 5.0954 - val_loss: 1.7398 - val_mae: 0.9953 - val_mse: 1.7398\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2412 - mae: 1.3795 - mse: 3.2412 - val_loss: 1.7479 - val_mae: 1.0371 - val_mse: 1.7479\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.7351 - mae: 1.5175 - mse: 3.7351 - val_loss: 1.7191 - val_mae: 1.0181 - val_mse: 1.7191\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.6746 - mae: 1.3405 - mse: 2.6746 - val_loss: 4.1065 - val_mae: 1.7142 - val_mse: 4.1065\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.0172 - mae: 1.3949 - mse: 3.0172 - val_loss: 1.5303 - val_mae: 0.9472 - val_mse: 1.5303\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.6473 - mae: 1.5659 - mse: 3.6473 - val_loss: 1.7848 - val_mae: 1.0382 - val_mse: 1.7848\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.7469 - mae: 1.3135 - mse: 2.7469 - val_loss: 2.5362 - val_mae: 1.2432 - val_mse: 2.5362\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.7320 - mae: 1.4459 - mse: 3.7320 - val_loss: 2.3342 - val_mae: 1.2013 - val_mse: 2.3342\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.3651 - mae: 1.2176 - mse: 2.3651 - val_loss: 2.3633 - val_mae: 1.2239 - val_mse: 2.3633\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.0822 - mae: 1.1333 - mse: 2.0822 - val_loss: 2.1080 - val_mae: 1.1470 - val_mse: 2.1080\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.5951 - mae: 1.2932 - mse: 2.5951 - val_loss: 1.7174 - val_mae: 1.0130 - val_mse: 1.7174\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.1804 - mae: 1.1485 - mse: 2.1804 - val_loss: 2.0767 - val_mae: 1.1503 - val_mse: 2.0767\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8816 - mae: 1.0997 - mse: 1.8816 - val_loss: 1.9075 - val_mae: 1.0753 - val_mse: 1.9075\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7506 - mae: 1.0252 - mse: 1.7506 - val_loss: 4.7370 - val_mae: 1.8161 - val_mse: 4.7370\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.2312 - mae: 1.1595 - mse: 2.2312 - val_loss: 1.2939 - val_mae: 0.8830 - val_mse: 1.2939\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.1551 - mae: 1.1347 - mse: 2.1551 - val_loss: 1.4288 - val_mae: 0.9134 - val_mse: 1.4288\n",
      "Epoch 29/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7301 - mae: 1.0284 - mse: 1.7301 - val_loss: 1.5002 - val_mae: 0.9440 - val_mse: 1.5002\n",
      "Epoch 30/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7583 - mae: 1.0465 - mse: 1.7583 - val_loss: 2.6996 - val_mae: 1.3615 - val_mse: 2.6996\n",
      "Epoch 31/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0582 - mae: 1.1752 - mse: 2.0582 - val_loss: 1.6393 - val_mae: 1.0222 - val_mse: 1.6393\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0469 - mae: 1.1435 - mse: 2.0469 - val_loss: 2.5148 - val_mae: 1.2891 - val_mse: 2.5148\n",
      "Epoch 33/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.8708 - mae: 1.0732 - mse: 1.8708 - val_loss: 1.4853 - val_mae: 0.9506 - val_mse: 1.4853\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.0915 - mae: 1.1088 - mse: 2.0915 - val_loss: 1.3320 - val_mae: 0.9023 - val_mse: 1.3320\n",
      "Epoch 35/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4192 - mae: 0.9346 - mse: 1.4192 - val_loss: 1.7600 - val_mae: 1.0445 - val_mse: 1.7600\n",
      "Epoch 36/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9761 - mae: 1.1238 - mse: 1.9761 - val_loss: 1.9505 - val_mae: 1.0707 - val_mse: 1.9505\n",
      "Epoch 37/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6910 - mae: 1.0118 - mse: 1.6910 - val_loss: 1.3014 - val_mae: 0.8718 - val_mse: 1.3014\n",
      "Epoch 38/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5636 - mae: 0.9649 - mse: 1.5636 - val_loss: 2.7561 - val_mae: 1.3884 - val_mse: 2.7561\n",
      "Epoch 39/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4340 - mae: 0.9374 - mse: 1.4340 - val_loss: 1.2861 - val_mae: 0.8784 - val_mse: 1.2861\n",
      "Epoch 40/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7502 - mae: 1.0316 - mse: 1.7502 - val_loss: 1.9334 - val_mae: 1.0883 - val_mse: 1.9334\n",
      "Epoch 41/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2403 - mae: 0.8756 - mse: 1.2403 - val_loss: 1.3347 - val_mae: 0.8960 - val_mse: 1.3347\n",
      "Epoch 42/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8396 - mae: 1.0375 - mse: 1.8396 - val_loss: 1.6772 - val_mae: 1.0065 - val_mse: 1.6772\n",
      "Epoch 43/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5932 - mae: 0.9991 - mse: 1.5932 - val_loss: 1.4564 - val_mae: 0.9427 - val_mse: 1.4564\n",
      "Epoch 44/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5796 - mae: 0.9737 - mse: 1.5796 - val_loss: 1.4108 - val_mae: 0.8890 - val_mse: 1.4108\n",
      "Epoch 45/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6290 - mae: 0.9875 - mse: 1.6290 - val_loss: 1.6076 - val_mae: 1.0222 - val_mse: 1.6076\n",
      "Epoch 46/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3274 - mae: 0.9075 - mse: 1.3274 - val_loss: 1.2586 - val_mae: 0.8697 - val_mse: 1.2586\n",
      "Epoch 47/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7570 - mae: 1.0189 - mse: 1.7570 - val_loss: 2.5680 - val_mae: 1.3106 - val_mse: 2.5680\n",
      "Epoch 48/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2838 - mae: 0.8745 - mse: 1.2838 - val_loss: 2.1853 - val_mae: 1.1865 - val_mse: 2.1853\n",
      "Epoch 49/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6084 - mae: 0.9841 - mse: 1.6084 - val_loss: 2.8935 - val_mae: 1.4291 - val_mse: 2.8935\n",
      "Epoch 50/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2458 - mae: 0.8651 - mse: 1.2458 - val_loss: 1.2584 - val_mae: 0.8623 - val_mse: 1.2584\n",
      "Epoch 51/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5205 - mae: 0.9650 - mse: 1.5205 - val_loss: 1.1907 - val_mae: 0.8491 - val_mse: 1.1907\n",
      "Epoch 52/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2931 - mae: 0.8941 - mse: 1.2931 - val_loss: 1.2535 - val_mae: 0.8518 - val_mse: 1.2535\n",
      "Epoch 53/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3746 - mae: 0.8987 - mse: 1.3746 - val_loss: 1.2246 - val_mae: 0.8599 - val_mse: 1.2246\n",
      "Epoch 54/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3461 - mae: 0.9014 - mse: 1.3461 - val_loss: 1.5677 - val_mae: 0.9912 - val_mse: 1.5677\n",
      "Epoch 55/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4860 - mae: 0.9323 - mse: 1.4860 - val_loss: 1.2768 - val_mae: 0.8840 - val_mse: 1.2768\n",
      "Epoch 56/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8029 - mae: 1.0545 - mse: 1.8029 - val_loss: 1.2624 - val_mae: 0.8813 - val_mse: 1.2624\n",
      "Epoch 57/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6237 - mae: 0.9704 - mse: 1.6237 - val_loss: 1.4551 - val_mae: 0.9286 - val_mse: 1.4551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2145 - mae: 0.8381 - mse: 1.2145 - val_loss: 1.3797 - val_mae: 0.9047 - val_mse: 1.3797\n",
      "Epoch 59/1000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4634 - mae: 0.9522 - mse: 1.4634 - val_loss: 1.2785 - val_mae: 0.8676 - val_mse: 1.2785\n",
      "Epoch 60/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1991 - mae: 0.8347 - mse: 1.1991 - val_loss: 1.0741 - val_mae: 0.7906 - val_mse: 1.0741\n",
      "Epoch 61/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3402 - mae: 0.9004 - mse: 1.3402 - val_loss: 1.1392 - val_mae: 0.8277 - val_mse: 1.1392\n",
      "Epoch 62/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9881 - mae: 0.7784 - mse: 0.9881 - val_loss: 1.1959 - val_mae: 0.8470 - val_mse: 1.1959\n",
      "Epoch 63/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5394 - mae: 0.9179 - mse: 1.5394 - val_loss: 2.2061 - val_mae: 1.2161 - val_mse: 2.2061\n",
      "Epoch 64/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1188 - mae: 0.8422 - mse: 1.1188 - val_loss: 1.5764 - val_mae: 0.9828 - val_mse: 1.5764\n",
      "Epoch 65/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2153 - mae: 0.8589 - mse: 1.2153 - val_loss: 1.8330 - val_mae: 1.0642 - val_mse: 1.8330\n",
      "Epoch 66/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3708 - mae: 0.9104 - mse: 1.3708 - val_loss: 1.2373 - val_mae: 0.8692 - val_mse: 1.2373\n",
      "Epoch 67/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2411 - mae: 0.8770 - mse: 1.2411 - val_loss: 1.4682 - val_mae: 0.9497 - val_mse: 1.4682\n",
      "Epoch 68/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0836 - mae: 0.8029 - mse: 1.0836 - val_loss: 2.3971 - val_mae: 1.2510 - val_mse: 2.3971\n",
      "Epoch 69/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2551 - mae: 0.8629 - mse: 1.2551 - val_loss: 1.7232 - val_mae: 1.0708 - val_mse: 1.7232\n",
      "Epoch 70/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2482 - mae: 0.8858 - mse: 1.2482 - val_loss: 1.1287 - val_mae: 0.8136 - val_mse: 1.1287\n",
      "Epoch 71/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1764 - mae: 0.8405 - mse: 1.1764 - val_loss: 1.2235 - val_mae: 0.8317 - val_mse: 1.2235\n",
      "Epoch 72/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3211 - mae: 0.8643 - mse: 1.3211 - val_loss: 1.1472 - val_mae: 0.8449 - val_mse: 1.1472\n",
      "Epoch 73/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1684 - mae: 0.8241 - mse: 1.1684 - val_loss: 1.7983 - val_mae: 1.0774 - val_mse: 1.7983\n",
      "Epoch 74/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0821 - mae: 0.8164 - mse: 1.0821 - val_loss: 2.6765 - val_mae: 1.3937 - val_mse: 2.6765\n",
      "Epoch 75/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2881 - mae: 0.8908 - mse: 1.2881 - val_loss: 1.3589 - val_mae: 0.9030 - val_mse: 1.3589\n",
      "Epoch 76/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2220 - mae: 0.8449 - mse: 1.2220 - val_loss: 1.0725 - val_mae: 0.7996 - val_mse: 1.0725\n",
      "Epoch 77/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1825 - mae: 0.8304 - mse: 1.1825 - val_loss: 1.4634 - val_mae: 0.9387 - val_mse: 1.4634\n",
      "Epoch 78/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2159 - mae: 0.8484 - mse: 1.2159 - val_loss: 1.0783 - val_mae: 0.7912 - val_mse: 1.0783\n",
      "Epoch 79/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9662 - mae: 0.7668 - mse: 0.9662 - val_loss: 1.8758 - val_mae: 1.0730 - val_mse: 1.8758\n",
      "Epoch 80/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0845 - mae: 0.7993 - mse: 1.0845 - val_loss: 1.7165 - val_mae: 1.0479 - val_mse: 1.7165\n",
      "Epoch 81/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0900 - mae: 0.8304 - mse: 1.0900 - val_loss: 1.2460 - val_mae: 0.8436 - val_mse: 1.2460\n",
      "Epoch 82/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2346 - mae: 0.8430 - mse: 1.2346 - val_loss: 1.3865 - val_mae: 0.9203 - val_mse: 1.3865\n",
      "Epoch 83/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3233 - mae: 0.8869 - mse: 1.3233 - val_loss: 1.1030 - val_mae: 0.8000 - val_mse: 1.1030\n",
      "Epoch 84/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0136 - mae: 0.7766 - mse: 1.0136 - val_loss: 1.2270 - val_mae: 0.8469 - val_mse: 1.2270\n",
      "Epoch 85/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0950 - mae: 0.7942 - mse: 1.0950 - val_loss: 1.1053 - val_mae: 0.7932 - val_mse: 1.1053\n",
      "Epoch 86/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0224 - mae: 0.7664 - mse: 1.0224 - val_loss: 1.3779 - val_mae: 0.8960 - val_mse: 1.3779\n",
      "Epoch 87/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0284 - mae: 0.7938 - mse: 1.0284 - val_loss: 2.9594 - val_mae: 1.4014 - val_mse: 2.9594\n",
      "Epoch 88/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2081 - mae: 0.8485 - mse: 1.2081 - val_loss: 1.8410 - val_mae: 1.0897 - val_mse: 1.8410\n",
      "Epoch 89/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1138 - mae: 0.8176 - mse: 1.1138 - val_loss: 1.1609 - val_mae: 0.8196 - val_mse: 1.1609\n",
      "Epoch 90/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0628 - mae: 0.7913 - mse: 1.0628 - val_loss: 1.1898 - val_mae: 0.8222 - val_mse: 1.1898\n",
      "Epoch 91/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0033 - mae: 0.7821 - mse: 1.0033 - val_loss: 1.0778 - val_mae: 0.8111 - val_mse: 1.0778\n",
      "Epoch 92/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1040 - mae: 0.8233 - mse: 1.1040 - val_loss: 1.1222 - val_mae: 0.7890 - val_mse: 1.1222\n",
      "Epoch 93/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8669 - mae: 0.7098 - mse: 0.8669 - val_loss: 1.7945 - val_mae: 1.0833 - val_mse: 1.7945\n",
      "Epoch 94/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0404 - mae: 0.7911 - mse: 1.0404 - val_loss: 2.9831 - val_mae: 1.4917 - val_mse: 2.9831\n",
      "Epoch 95/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1008 - mae: 0.8137 - mse: 1.1008 - val_loss: 1.4759 - val_mae: 0.9590 - val_mse: 1.4759\n",
      "Epoch 96/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8567 - mae: 0.7174 - mse: 0.8567 - val_loss: 1.5139 - val_mae: 0.9722 - val_mse: 1.5139\n",
      "Epoch 97/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2456 - mae: 0.8494 - mse: 1.2456 - val_loss: 1.1860 - val_mae: 0.8257 - val_mse: 1.1860\n",
      "Epoch 98/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9782 - mae: 0.7690 - mse: 0.9782 - val_loss: 2.8125 - val_mae: 1.4409 - val_mse: 2.8125\n",
      "Epoch 99/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0313 - mae: 0.7860 - mse: 1.0313 - val_loss: 1.1308 - val_mae: 0.7915 - val_mse: 1.1308\n",
      "Epoch 100/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0743 - mae: 0.8057 - mse: 1.0743 - val_loss: 1.2448 - val_mae: 0.8866 - val_mse: 1.2448\n",
      "Epoch 101/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0256 - mae: 0.7813 - mse: 1.0256 - val_loss: 1.4976 - val_mae: 0.9582 - val_mse: 1.4976\n",
      "Epoch 102/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1480 - mae: 0.8114 - mse: 1.1480 - val_loss: 1.2590 - val_mae: 0.8510 - val_mse: 1.2590\n",
      "Epoch 103/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9076 - mae: 0.7293 - mse: 0.9076 - val_loss: 1.1548 - val_mae: 0.8324 - val_mse: 1.1548\n",
      "Epoch 104/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0496 - mae: 0.7922 - mse: 1.0496 - val_loss: 1.3886 - val_mae: 0.8993 - val_mse: 1.3886\n",
      "Epoch 105/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9248 - mae: 0.7408 - mse: 0.9248 - val_loss: 1.2601 - val_mae: 0.8642 - val_mse: 1.2601\n",
      "Epoch 106/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9646 - mae: 0.7564 - mse: 0.9646 - val_loss: 1.0562 - val_mae: 0.7669 - val_mse: 1.0562\n",
      "Epoch 107/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0617 - mae: 0.7938 - mse: 1.0617 - val_loss: 1.8642 - val_mae: 1.0990 - val_mse: 1.8642\n",
      "Epoch 108/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9190 - mae: 0.7411 - mse: 0.9190 - val_loss: 1.4629 - val_mae: 0.9440 - val_mse: 1.4629\n",
      "Epoch 109/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0300 - mae: 0.7750 - mse: 1.0300 - val_loss: 1.3805 - val_mae: 0.9039 - val_mse: 1.3805\n",
      "Epoch 110/1000\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6025 - mae: 0.5744 - mse: 0.602 - 0s 1ms/step - loss: 0.9604 - mae: 0.7597 - mse: 0.9604 - val_loss: 1.3992 - val_mae: 0.9221 - val_mse: 1.3992\n",
      "Epoch 111/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9933 - mae: 0.7730 - mse: 0.9933 - val_loss: 1.3505 - val_mae: 0.8878 - val_mse: 1.3505\n",
      "Epoch 112/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0535 - mae: 0.7955 - mse: 1.0535 - val_loss: 1.4511 - val_mae: 0.9434 - val_mse: 1.4511\n",
      "Epoch 113/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9310 - mae: 0.7295 - mse: 0.9310 - val_loss: 1.1772 - val_mae: 0.8395 - val_mse: 1.1772\n",
      "Epoch 114/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8066 - mae: 0.6899 - mse: 0.8066 - val_loss: 2.0525 - val_mae: 1.1366 - val_mse: 2.0525\n",
      "Epoch 115/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9155 - mae: 0.7462 - mse: 0.9155 - val_loss: 1.5162 - val_mae: 0.9660 - val_mse: 1.5162\n",
      "Epoch 116/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0420 - mae: 0.7989 - mse: 1.0420 - val_loss: 1.1026 - val_mae: 0.7962 - val_mse: 1.1026\n",
      "Epoch 117/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8456 - mae: 0.6919 - mse: 0.8456 - val_loss: 2.3576 - val_mae: 1.2741 - val_mse: 2.3576\n",
      "Epoch 118/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9683 - mae: 0.7768 - mse: 0.9683 - val_loss: 1.2591 - val_mae: 0.8551 - val_mse: 1.2591\n",
      "Epoch 119/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7460 - mae: 0.6680 - mse: 0.7460 - val_loss: 1.3964 - val_mae: 0.9340 - val_mse: 1.3964\n",
      "Epoch 120/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0916 - mae: 0.8025 - mse: 1.0916 - val_loss: 2.3079 - val_mae: 1.2782 - val_mse: 2.3079\n",
      "Epoch 121/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8836 - mae: 0.7136 - mse: 0.8836 - val_loss: 2.7446 - val_mae: 1.4054 - val_mse: 2.7446\n",
      "Epoch 122/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8714 - mae: 0.7234 - mse: 0.8714 - val_loss: 1.2760 - val_mae: 0.8885 - val_mse: 1.2760\n",
      "Epoch 123/1000\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6660 - mae: 0.5918 - mse: 0.666 - 0s 1ms/step - loss: 0.8374 - mae: 0.7000 - mse: 0.8374 - val_loss: 1.1141 - val_mae: 0.8169 - val_mse: 1.1141\n",
      "Epoch 124/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8934 - mae: 0.7102 - mse: 0.8934 - val_loss: 1.1784 - val_mae: 0.8307 - val_mse: 1.1784\n",
      "Epoch 125/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9995 - mae: 0.7485 - mse: 0.9995 - val_loss: 1.1990 - val_mae: 0.8717 - val_mse: 1.1990\n",
      "Epoch 126/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8213 - mae: 0.7018 - mse: 0.8213 - val_loss: 1.2359 - val_mae: 0.8862 - val_mse: 1.2359\n",
      "Epoch 127/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0070 - mae: 0.7815 - mse: 1.0070 - val_loss: 1.0950 - val_mae: 0.8191 - val_mse: 1.0950\n",
      "Epoch 128/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7073 - mae: 0.6526 - mse: 0.7073 - val_loss: 1.1315 - val_mae: 0.7976 - val_mse: 1.1315\n",
      "Epoch 129/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9909 - mae: 0.7748 - mse: 0.9909 - val_loss: 1.0660 - val_mae: 0.8329 - val_mse: 1.0660\n",
      "Epoch 130/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8204 - mae: 0.6849 - mse: 0.8204 - val_loss: 1.2888 - val_mae: 0.9132 - val_mse: 1.2888\n",
      "Epoch 131/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9658 - mae: 0.7563 - mse: 0.9658 - val_loss: 1.0716 - val_mae: 0.7930 - val_mse: 1.0716\n",
      "Epoch 132/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7830 - mae: 0.6880 - mse: 0.7830 - val_loss: 1.1434 - val_mae: 0.8147 - val_mse: 1.1434\n",
      "Epoch 133/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7212 - mae: 0.6602 - mse: 0.7212 - val_loss: 2.2435 - val_mae: 1.2504 - val_mse: 2.2435\n",
      "Epoch 134/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9818 - mae: 0.7656 - mse: 0.9818 - val_loss: 1.3314 - val_mae: 0.8994 - val_mse: 1.3314\n",
      "Epoch 135/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8983 - mae: 0.7304 - mse: 0.8983 - val_loss: 1.5186 - val_mae: 0.9663 - val_mse: 1.5186\n",
      "Epoch 136/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8395 - mae: 0.7032 - mse: 0.8395 - val_loss: 1.3878 - val_mae: 0.9332 - val_mse: 1.3878\n",
      "Epoch 137/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8864 - mae: 0.7258 - mse: 0.8864 - val_loss: 1.0340 - val_mae: 0.8052 - val_mse: 1.0340\n",
      "Epoch 138/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6468 - mae: 0.6037 - mse: 0.6468 - val_loss: 2.8997 - val_mae: 1.4432 - val_mse: 2.8997\n",
      "Epoch 139/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8544 - mae: 0.7016 - mse: 0.8544 - val_loss: 1.2431 - val_mae: 0.8896 - val_mse: 1.2431\n",
      "Epoch 140/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7958 - mae: 0.6801 - mse: 0.7958 - val_loss: 1.0808 - val_mae: 0.8059 - val_mse: 1.0808\n",
      "Epoch 141/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8348 - mae: 0.7105 - mse: 0.8348 - val_loss: 1.1365 - val_mae: 0.8268 - val_mse: 1.1365\n",
      "Epoch 142/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7073 - mae: 0.6460 - mse: 0.7073 - val_loss: 1.0320 - val_mae: 0.8019 - val_mse: 1.0320\n",
      "Epoch 143/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9617 - mae: 0.7478 - mse: 0.9617 - val_loss: 1.2424 - val_mae: 0.8499 - val_mse: 1.2424\n",
      "Epoch 144/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8238 - mae: 0.7035 - mse: 0.8238 - val_loss: 1.6730 - val_mae: 1.0279 - val_mse: 1.6730\n",
      "Epoch 145/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9243 - mae: 0.7337 - mse: 0.9243 - val_loss: 1.1092 - val_mae: 0.8169 - val_mse: 1.1092\n",
      "Epoch 146/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8245 - mae: 0.6997 - mse: 0.8245 - val_loss: 1.9841 - val_mae: 1.1351 - val_mse: 1.9841\n",
      "Epoch 147/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7443 - mae: 0.6635 - mse: 0.7443 - val_loss: 1.0752 - val_mae: 0.7901 - val_mse: 1.0752\n",
      "Epoch 148/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7638 - mae: 0.6672 - mse: 0.7638 - val_loss: 1.6404 - val_mae: 1.0071 - val_mse: 1.6404\n",
      "Epoch 149/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7655 - mae: 0.6895 - mse: 0.7655 - val_loss: 1.2704 - val_mae: 0.8636 - val_mse: 1.2704\n",
      "Epoch 150/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8090 - mae: 0.7001 - mse: 0.8090 - val_loss: 1.3906 - val_mae: 0.9723 - val_mse: 1.3906\n",
      "Epoch 151/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7944 - mae: 0.6755 - mse: 0.7944 - val_loss: 1.3149 - val_mae: 0.9364 - val_mse: 1.3149\n",
      "Epoch 152/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7138 - mae: 0.6305 - mse: 0.7138 - val_loss: 1.4635 - val_mae: 0.9370 - val_mse: 1.4635\n",
      "Epoch 153/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8328 - mae: 0.6822 - mse: 0.8328 - val_loss: 1.2070 - val_mae: 0.8449 - val_mse: 1.2070\n",
      "Epoch 154/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9028 - mae: 0.7376 - mse: 0.9028 - val_loss: 1.3137 - val_mae: 0.8848 - val_mse: 1.3137\n",
      "Epoch 155/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7813 - mae: 0.6785 - mse: 0.7813 - val_loss: 1.0359 - val_mae: 0.7851 - val_mse: 1.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7339 - mae: 0.6551 - mse: 0.7339 - val_loss: 2.0763 - val_mae: 1.1618 - val_mse: 2.0763\n",
      "Epoch 157/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7903 - mae: 0.6888 - mse: 0.7903 - val_loss: 1.0909 - val_mae: 0.8077 - val_mse: 1.0909\n",
      "Epoch 158/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6506 - mae: 0.6213 - mse: 0.6506 - val_loss: 1.2445 - val_mae: 0.9227 - val_mse: 1.2445\n",
      "Epoch 159/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8212 - mae: 0.7110 - mse: 0.8212 - val_loss: 1.8861 - val_mae: 1.1000 - val_mse: 1.8861\n",
      "Epoch 160/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7156 - mae: 0.6543 - mse: 0.7156 - val_loss: 1.3481 - val_mae: 0.9042 - val_mse: 1.3481\n",
      "Epoch 161/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6880 - mae: 0.6381 - mse: 0.6880 - val_loss: 1.5504 - val_mae: 0.9612 - val_mse: 1.5504\n",
      "Epoch 162/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7577 - mae: 0.6666 - mse: 0.7577 - val_loss: 1.3299 - val_mae: 0.9043 - val_mse: 1.3299\n",
      "Epoch 163/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6065 - mae: 0.5911 - mse: 0.6065 - val_loss: 1.3469 - val_mae: 0.8878 - val_mse: 1.3469\n",
      "Epoch 164/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8234 - mae: 0.6927 - mse: 0.8234 - val_loss: 1.1061 - val_mae: 0.8320 - val_mse: 1.1061\n",
      "Epoch 165/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6443 - mae: 0.6097 - mse: 0.6443 - val_loss: 1.2417 - val_mae: 0.8636 - val_mse: 1.2417\n",
      "Epoch 166/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7756 - mae: 0.6760 - mse: 0.7756 - val_loss: 1.5047 - val_mae: 0.9457 - val_mse: 1.5047\n",
      "Epoch 167/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7128 - mae: 0.6465 - mse: 0.7128 - val_loss: 1.2090 - val_mae: 0.8523 - val_mse: 1.2090\n",
      "Epoch 168/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7509 - mae: 0.6568 - mse: 0.7509 - val_loss: 1.3553 - val_mae: 0.8903 - val_mse: 1.3553\n",
      "Epoch 169/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9270 - mae: 0.7382 - mse: 0.9270 - val_loss: 1.1832 - val_mae: 0.8358 - val_mse: 1.1832\n",
      "Epoch 170/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5780 - mae: 0.5751 - mse: 0.5780 - val_loss: 1.1386 - val_mae: 0.8022 - val_mse: 1.1386\n",
      "Epoch 171/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7852 - mae: 0.6788 - mse: 0.7852 - val_loss: 1.3313 - val_mae: 0.9068 - val_mse: 1.3313\n",
      "Epoch 172/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6795 - mae: 0.6449 - mse: 0.6795 - val_loss: 1.5719 - val_mae: 0.9682 - val_mse: 1.5719\n",
      "Epoch 173/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7415 - mae: 0.6784 - mse: 0.7415 - val_loss: 1.3887 - val_mae: 0.8966 - val_mse: 1.3887\n",
      "Epoch 174/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7122 - mae: 0.6497 - mse: 0.7122 - val_loss: 1.4999 - val_mae: 0.9584 - val_mse: 1.4999\n",
      "Epoch 175/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6247 - mae: 0.6127 - mse: 0.6247 - val_loss: 1.6013 - val_mae: 0.9790 - val_mse: 1.6013\n",
      "Epoch 176/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8288 - mae: 0.7069 - mse: 0.8288 - val_loss: 1.0991 - val_mae: 0.8356 - val_mse: 1.0991\n",
      "Epoch 177/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6784 - mae: 0.6305 - mse: 0.6784 - val_loss: 1.1744 - val_mae: 0.8318 - val_mse: 1.1744\n",
      "Epoch 178/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7263 - mae: 0.6582 - mse: 0.7263 - val_loss: 1.4466 - val_mae: 0.9311 - val_mse: 1.4466\n",
      "Epoch 179/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7603 - mae: 0.6676 - mse: 0.7603 - val_loss: 1.5917 - val_mae: 0.9816 - val_mse: 1.5917\n",
      "Epoch 180/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6484 - mae: 0.5966 - mse: 0.6484 - val_loss: 2.2211 - val_mae: 1.2062 - val_mse: 2.2211\n",
      "Epoch 181/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6935 - mae: 0.6375 - mse: 0.6935 - val_loss: 1.1132 - val_mae: 0.8326 - val_mse: 1.1132\n",
      "Epoch 182/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5965 - mae: 0.5983 - mse: 0.5965 - val_loss: 1.0833 - val_mae: 0.8332 - val_mse: 1.0833\n",
      "Epoch 183/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6227 - mae: 0.5889 - mse: 0.6227 - val_loss: 1.7633 - val_mae: 1.0969 - val_mse: 1.7633\n",
      "Epoch 184/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6157 - mae: 0.6004 - mse: 0.6157 - val_loss: 1.2152 - val_mae: 0.8517 - val_mse: 1.2152\n",
      "Epoch 185/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8166 - mae: 0.6980 - mse: 0.8166 - val_loss: 1.3527 - val_mae: 0.9221 - val_mse: 1.3527\n",
      "Epoch 186/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5283 - mae: 0.5422 - mse: 0.5283 - val_loss: 3.2827 - val_mae: 1.5139 - val_mse: 3.2827\n",
      "Epoch 187/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9141 - mae: 0.7021 - mse: 0.9141 - val_loss: 1.2148 - val_mae: 0.8584 - val_mse: 1.2148\n",
      "Epoch 188/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7000 - mae: 0.6261 - mse: 0.7000 - val_loss: 1.1568 - val_mae: 0.8438 - val_mse: 1.1568\n",
      "Epoch 189/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5671 - mae: 0.5743 - mse: 0.5671 - val_loss: 1.4011 - val_mae: 0.9220 - val_mse: 1.4011\n",
      "Epoch 190/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6465 - mae: 0.5887 - mse: 0.6465 - val_loss: 2.3460 - val_mae: 1.2231 - val_mse: 2.3460\n",
      "Epoch 191/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7233 - mae: 0.6248 - mse: 0.7233 - val_loss: 1.1832 - val_mae: 0.8702 - val_mse: 1.1832\n",
      "Epoch 192/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6619 - mae: 0.6075 - mse: 0.6619 - val_loss: 1.3859 - val_mae: 0.9385 - val_mse: 1.3859\n",
      "Epoch 193/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5206 - mae: 0.5412 - mse: 0.5206 - val_loss: 1.2955 - val_mae: 0.8816 - val_mse: 1.2955\n",
      "Epoch 194/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7121 - mae: 0.6264 - mse: 0.7121 - val_loss: 1.4969 - val_mae: 0.9993 - val_mse: 1.4969\n",
      "Epoch 195/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6144 - mae: 0.5963 - mse: 0.6144 - val_loss: 1.6427 - val_mae: 0.9992 - val_mse: 1.6427\n",
      "Epoch 196/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6425 - mae: 0.5938 - mse: 0.6425 - val_loss: 1.3364 - val_mae: 0.8833 - val_mse: 1.3364\n",
      "Epoch 197/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6827 - mae: 0.5924 - mse: 0.6827 - val_loss: 1.1969 - val_mae: 0.8485 - val_mse: 1.1969\n",
      "Epoch 198/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5335 - mae: 0.5518 - mse: 0.5335 - val_loss: 1.8253 - val_mae: 1.0687 - val_mse: 1.8253\n",
      "Epoch 199/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5244 - mae: 0.5490 - mse: 0.5244 - val_loss: 1.1167 - val_mae: 0.8071 - val_mse: 1.1167\n",
      "Epoch 200/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6999 - mae: 0.6495 - mse: 0.6999 - val_loss: 1.2095 - val_mae: 0.8591 - val_mse: 1.2095\n",
      "Epoch 201/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6926 - mae: 0.6378 - mse: 0.6926 - val_loss: 1.1170 - val_mae: 0.8320 - val_mse: 1.1170\n",
      "Epoch 202/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5525 - mae: 0.5426 - mse: 0.5525 - val_loss: 1.3406 - val_mae: 0.8968 - val_mse: 1.3406\n",
      "Epoch 203/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5491 - mae: 0.5482 - mse: 0.5491 - val_loss: 1.3450 - val_mae: 0.9059 - val_mse: 1.3450\n",
      "Epoch 204/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7748 - mae: 0.6740 - mse: 0.7748 - val_loss: 1.3550 - val_mae: 0.9709 - val_mse: 1.3550\n",
      "Epoch 205/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5419 - mae: 0.5649 - mse: 0.5419 - val_loss: 1.2640 - val_mae: 0.8932 - val_mse: 1.2640\n",
      "Epoch 206/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6174 - mae: 0.5992 - mse: 0.6174 - val_loss: 1.1233 - val_mae: 0.8581 - val_mse: 1.1233\n",
      "Epoch 207/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6671 - mae: 0.6257 - mse: 0.6671 - val_loss: 1.5442 - val_mae: 0.9640 - val_mse: 1.5442\n",
      "Epoch 208/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5639 - mae: 0.5698 - mse: 0.5639 - val_loss: 1.9127 - val_mae: 1.0788 - val_mse: 1.9127\n",
      "Epoch 209/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5647 - mae: 0.5644 - mse: 0.5647 - val_loss: 1.3947 - val_mae: 0.9268 - val_mse: 1.3947\n",
      "Epoch 210/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5967 - mae: 0.5987 - mse: 0.5967 - val_loss: 1.1137 - val_mae: 0.8367 - val_mse: 1.1137\n",
      "Epoch 211/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5852 - mae: 0.5852 - mse: 0.5852 - val_loss: 1.4148 - val_mae: 0.9130 - val_mse: 1.4148\n",
      "Epoch 212/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6808 - mae: 0.6156 - mse: 0.6808 - val_loss: 1.1904 - val_mae: 0.8508 - val_mse: 1.1904\n",
      "Epoch 213/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5921 - mae: 0.5765 - mse: 0.5921 - val_loss: 1.2605 - val_mae: 0.8772 - val_mse: 1.2605\n",
      "Epoch 214/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6099 - mae: 0.6029 - mse: 0.6099 - val_loss: 1.1627 - val_mae: 0.8446 - val_mse: 1.1627\n",
      "Epoch 215/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6103 - mae: 0.6125 - mse: 0.6103 - val_loss: 1.4226 - val_mae: 0.9309 - val_mse: 1.4226\n",
      "Epoch 216/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6355 - mae: 0.6132 - mse: 0.6355 - val_loss: 1.1809 - val_mae: 0.8414 - val_mse: 1.1809\n",
      "Epoch 217/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5010 - mae: 0.5340 - mse: 0.5010 - val_loss: 1.1542 - val_mae: 0.8326 - val_mse: 1.1542\n",
      "Epoch 218/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5641 - mae: 0.5610 - mse: 0.5641 - val_loss: 1.3309 - val_mae: 0.8997 - val_mse: 1.3309\n",
      "Epoch 219/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5501 - mae: 0.5698 - mse: 0.5501 - val_loss: 1.6959 - val_mae: 1.0045 - val_mse: 1.6959\n",
      "Epoch 220/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6301 - mae: 0.5891 - mse: 0.6301 - val_loss: 1.1490 - val_mae: 0.8109 - val_mse: 1.1490\n",
      "Epoch 221/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4442 - mae: 0.4993 - mse: 0.4442 - val_loss: 1.1899 - val_mae: 0.8805 - val_mse: 1.1899\n",
      "Epoch 222/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6521 - mae: 0.5828 - mse: 0.6521 - val_loss: 1.3333 - val_mae: 0.8922 - val_mse: 1.3333\n",
      "Epoch 223/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5769 - mae: 0.5711 - mse: 0.5769 - val_loss: 1.1674 - val_mae: 0.8612 - val_mse: 1.1674\n",
      "Epoch 224/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5136 - mae: 0.5303 - mse: 0.5136 - val_loss: 1.2840 - val_mae: 0.9358 - val_mse: 1.2840\n",
      "Epoch 225/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4403 - mae: 0.5036 - mse: 0.4403 - val_loss: 1.5299 - val_mae: 0.9638 - val_mse: 1.5299\n",
      "Epoch 226/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6232 - mae: 0.6107 - mse: 0.6232 - val_loss: 1.1427 - val_mae: 0.8612 - val_mse: 1.1427\n",
      "Epoch 227/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6395 - mae: 0.6093 - mse: 0.6395 - val_loss: 1.3175 - val_mae: 0.9086 - val_mse: 1.3175\n",
      "Epoch 228/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5870 - mae: 0.5668 - mse: 0.5870 - val_loss: 1.2722 - val_mae: 0.8819 - val_mse: 1.2722\n",
      "Epoch 229/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4842 - mae: 0.5028 - mse: 0.4842 - val_loss: 1.3374 - val_mae: 0.8958 - val_mse: 1.3374\n",
      "Epoch 230/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5050 - mae: 0.5562 - mse: 0.5050 - val_loss: 1.0801 - val_mae: 0.8161 - val_mse: 1.0801\n",
      "Epoch 231/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5430 - mae: 0.5691 - mse: 0.5430 - val_loss: 1.1322 - val_mae: 0.8527 - val_mse: 1.1322\n",
      "Epoch 232/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4891 - mae: 0.5316 - mse: 0.4891 - val_loss: 1.8456 - val_mae: 1.0744 - val_mse: 1.8456\n",
      "Epoch 233/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5175 - mae: 0.5545 - mse: 0.5175 - val_loss: 1.3244 - val_mae: 0.8987 - val_mse: 1.3244\n",
      "Epoch 234/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5533 - mae: 0.5542 - mse: 0.5533 - val_loss: 1.2590 - val_mae: 0.8735 - val_mse: 1.2590\n",
      "Epoch 235/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5235 - mae: 0.5578 - mse: 0.5235 - val_loss: 1.2350 - val_mae: 0.8862 - val_mse: 1.2350\n",
      "Epoch 236/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5789 - mae: 0.5892 - mse: 0.5789 - val_loss: 1.5287 - val_mae: 0.9728 - val_mse: 1.5287\n",
      "Epoch 237/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3879 - mae: 0.4765 - mse: 0.3879 - val_loss: 1.5441 - val_mae: 0.9639 - val_mse: 1.5441\n",
      "Epoch 238/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6055 - mae: 0.5857 - mse: 0.6055 - val_loss: 1.1670 - val_mae: 0.8321 - val_mse: 1.1670\n",
      "Epoch 239/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4863 - mae: 0.5306 - mse: 0.4863 - val_loss: 2.0680 - val_mae: 1.1712 - val_mse: 2.0680\n",
      "Epoch 240/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3962 - mae: 0.4645 - mse: 0.3962 - val_loss: 1.1291 - val_mae: 0.8394 - val_mse: 1.1291\n",
      "Epoch 241/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5707 - mae: 0.5871 - mse: 0.5707 - val_loss: 1.1333 - val_mae: 0.8622 - val_mse: 1.1333\n",
      "Epoch 242/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4880 - mae: 0.5208 - mse: 0.4880 - val_loss: 2.0852 - val_mae: 1.1374 - val_mse: 2.0852\n",
      "Kappa Score: 0.6784677611230074\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Epoch 1/1000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 75.2172 - mae: 4.3695 - mse: 75.2172 - val_loss: 9.2312 - val_mae: 2.5981 - val_mse: 9.2312\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 14.6164 - mae: 3.2989 - mse: 14.6164 - val_loss: 23.8405 - val_mae: 4.7250 - val_mse: 23.8405\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 15.6593 - mae: 3.1393 - mse: 15.6593 - val_loss: 12.6412 - val_mae: 3.0995 - val_mse: 12.6412\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 11.8613 - mae: 2.9460 - mse: 11.8613 - val_loss: 5.3971 - val_mae: 2.0625 - val_mse: 5.3971\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 11.1499 - mae: 2.6342 - mse: 11.1499 - val_loss: 15.0060 - val_mae: 3.2745 - val_mse: 15.0060\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 4.4216 - mae: 1.6164 - mse: 4.4216 - val_loss: 43.5791 - val_mae: 6.4145 - val_mse: 43.5791\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.8991 - mae: 1.8006 - mse: 6.8991 - val_loss: 2.2532 - val_mae: 1.1752 - val_mse: 2.2532\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.3029 - mae: 2.0426 - mse: 6.3029 - val_loss: 3.9598 - val_mae: 1.6497 - val_mse: 3.9598\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 5.3156 - mae: 1.8500 - mse: 5.3156 - val_loss: 6.3996 - val_mae: 2.2953 - val_mse: 6.3996\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 4.2038 - mae: 1.6967 - mse: 4.2038 - val_loss: 7.2793 - val_mae: 2.2232 - val_mse: 7.2793\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.1124 - mae: 1.3392 - mse: 3.1124 - val_loss: 3.4785 - val_mae: 1.4988 - val_mse: 3.4785\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 3.3696 - mae: 1.4727 - mse: 3.3696 - val_loss: 1.5811 - val_mae: 0.9936 - val_mse: 1.5811\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.5555 - mae: 1.5058 - mse: 3.5555 - val_loss: 3.5989 - val_mae: 1.6015 - val_mse: 3.5989\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.2151 - mae: 1.1812 - mse: 2.2151 - val_loss: 2.0318 - val_mae: 1.1285 - val_mse: 2.0318\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.2043 - mae: 1.3950 - mse: 3.2043 - val_loss: 2.2153 - val_mae: 1.1343 - val_mse: 2.2153\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.2915 - mae: 1.1527 - mse: 2.2915 - val_loss: 1.4481 - val_mae: 0.9455 - val_mse: 1.4481\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.9314 - mae: 1.0747 - mse: 1.9314 - val_loss: 3.4888 - val_mae: 1.4315 - val_mse: 3.4888\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.9171 - mae: 1.2880 - mse: 2.9171 - val_loss: 2.6159 - val_mae: 1.2660 - val_mse: 2.6159\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8075 - mae: 1.0563 - mse: 1.8075 - val_loss: 2.8237 - val_mae: 1.3325 - val_mse: 2.8237\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.3930 - mae: 1.2472 - mse: 2.3930 - val_loss: 1.5445 - val_mae: 0.9574 - val_mse: 1.5445\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0821 - mae: 1.0903 - mse: 2.0821 - val_loss: 1.3162 - val_mae: 0.9087 - val_mse: 1.3162\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7485 - mae: 1.0850 - mse: 1.7485 - val_loss: 4.3048 - val_mae: 1.7914 - val_mse: 4.3048\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9923 - mae: 1.0911 - mse: 1.9923 - val_loss: 1.3806 - val_mae: 0.9094 - val_mse: 1.3806\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7547 - mae: 1.0263 - mse: 1.7547 - val_loss: 1.3256 - val_mae: 0.8940 - val_mse: 1.3256\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9398 - mae: 1.1035 - mse: 1.9398 - val_loss: 1.6243 - val_mae: 0.9952 - val_mse: 1.6243\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9075 - mae: 1.0906 - mse: 1.9075 - val_loss: 1.2834 - val_mae: 0.8777 - val_mse: 1.2834\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6840 - mae: 1.0339 - mse: 1.6840 - val_loss: 3.0625 - val_mae: 1.4267 - val_mse: 3.0625\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4581 - mae: 0.9458 - mse: 1.4581 - val_loss: 1.5551 - val_mae: 0.9828 - val_mse: 1.5551\n",
      "Epoch 29/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.9209 - mae: 1.0912 - mse: 1.9209 - val_loss: 2.1731 - val_mae: 1.1462 - val_mse: 2.1731\n",
      "Epoch 30/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5261 - mae: 0.9742 - mse: 1.5261 - val_loss: 2.1925 - val_mae: 1.1589 - val_mse: 2.1925\n",
      "Epoch 31/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6165 - mae: 1.0073 - mse: 1.6165 - val_loss: 1.8534 - val_mae: 1.0722 - val_mse: 1.8534\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6769 - mae: 1.0432 - mse: 1.6769 - val_loss: 1.3133 - val_mae: 0.8796 - val_mse: 1.3133\n",
      "Epoch 33/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4100 - mae: 0.9218 - mse: 1.4100 - val_loss: 1.4744 - val_mae: 0.9691 - val_mse: 1.4744\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5678 - mae: 0.9748 - mse: 1.5678 - val_loss: 1.2636 - val_mae: 0.8780 - val_mse: 1.2636\n",
      "Epoch 35/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4399 - mae: 0.9386 - mse: 1.4399 - val_loss: 1.6832 - val_mae: 0.9906 - val_mse: 1.6832\n",
      "Epoch 36/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4595 - mae: 0.9414 - mse: 1.4595 - val_loss: 1.5850 - val_mae: 0.9867 - val_mse: 1.5850\n",
      "Epoch 37/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6075 - mae: 1.0124 - mse: 1.6075 - val_loss: 1.7395 - val_mae: 1.0231 - val_mse: 1.7395\n",
      "Epoch 38/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4230 - mae: 0.9441 - mse: 1.4230 - val_loss: 2.3613 - val_mae: 1.2286 - val_mse: 2.3613\n",
      "Epoch 39/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5354 - mae: 0.9421 - mse: 1.5354 - val_loss: 1.2536 - val_mae: 0.8631 - val_mse: 1.2536\n",
      "Epoch 40/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4460 - mae: 0.9597 - mse: 1.4460 - val_loss: 2.1597 - val_mae: 1.1618 - val_mse: 2.1597\n",
      "Epoch 41/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4912 - mae: 0.9710 - mse: 1.4912 - val_loss: 2.0276 - val_mae: 1.1237 - val_mse: 2.0276\n",
      "Epoch 42/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2826 - mae: 0.9021 - mse: 1.2826 - val_loss: 1.2381 - val_mae: 0.8781 - val_mse: 1.2381\n",
      "Epoch 43/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7507 - mae: 1.0593 - mse: 1.7507 - val_loss: 1.2455 - val_mae: 0.8471 - val_mse: 1.2455\n",
      "Epoch 44/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2150 - mae: 0.8705 - mse: 1.2150 - val_loss: 1.1953 - val_mae: 0.8381 - val_mse: 1.1953\n",
      "Epoch 45/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5865 - mae: 0.9617 - mse: 1.5865 - val_loss: 2.1603 - val_mae: 1.1910 - val_mse: 2.1603\n",
      "Epoch 46/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1660 - mae: 0.8330 - mse: 1.1660 - val_loss: 1.4661 - val_mae: 0.9649 - val_mse: 1.4661\n",
      "Epoch 47/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4857 - mae: 0.9731 - mse: 1.4857 - val_loss: 1.2580 - val_mae: 0.8426 - val_mse: 1.2580\n",
      "Epoch 48/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3970 - mae: 0.9277 - mse: 1.3970 - val_loss: 2.0336 - val_mae: 1.1314 - val_mse: 2.0336\n",
      "Epoch 49/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3839 - mae: 0.9270 - mse: 1.3839 - val_loss: 1.6509 - val_mae: 0.9831 - val_mse: 1.6509\n",
      "Epoch 50/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4924 - mae: 0.9426 - mse: 1.4924 - val_loss: 1.5631 - val_mae: 1.0021 - val_mse: 1.5631\n",
      "Epoch 51/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1123 - mae: 0.8083 - mse: 1.1123 - val_loss: 2.8078 - val_mae: 1.3732 - val_mse: 2.8078\n",
      "Epoch 52/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3787 - mae: 0.9213 - mse: 1.3787 - val_loss: 1.4819 - val_mae: 0.9789 - val_mse: 1.4819\n",
      "Epoch 53/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4150 - mae: 0.9297 - mse: 1.4150 - val_loss: 1.3455 - val_mae: 0.8739 - val_mse: 1.3455\n",
      "Epoch 54/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3094 - mae: 0.8897 - mse: 1.3094 - val_loss: 1.2634 - val_mae: 0.8603 - val_mse: 1.2634\n",
      "Epoch 55/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0681 - mae: 0.7988 - mse: 1.0681 - val_loss: 2.5434 - val_mae: 1.3032 - val_mse: 2.5434\n",
      "Epoch 56/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7949 - mae: 1.0293 - mse: 1.7949 - val_loss: 1.2228 - val_mae: 0.8283 - val_mse: 1.2228\n",
      "Epoch 57/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3110 - mae: 0.8748 - mse: 1.3110 - val_loss: 1.2251 - val_mae: 0.8893 - val_mse: 1.2251\n",
      "Epoch 58/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1114 - mae: 0.8408 - mse: 1.1114 - val_loss: 1.1464 - val_mae: 0.8040 - val_mse: 1.1464\n",
      "Epoch 59/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1031 - mae: 0.7977 - mse: 1.1031 - val_loss: 1.4272 - val_mae: 0.9886 - val_mse: 1.4272\n",
      "Epoch 60/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1488 - mae: 0.8333 - mse: 1.1488 - val_loss: 1.1172 - val_mae: 0.8176 - val_mse: 1.1172\n",
      "Epoch 61/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3160 - mae: 0.9032 - mse: 1.3160 - val_loss: 1.2792 - val_mae: 0.9020 - val_mse: 1.2792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1198 - mae: 0.8180 - mse: 1.1198 - val_loss: 1.2809 - val_mae: 0.8530 - val_mse: 1.2809\n",
      "Epoch 63/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9530 - mae: 0.7609 - mse: 0.9530 - val_loss: 1.7379 - val_mae: 1.0491 - val_mse: 1.7379\n",
      "Epoch 64/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1804 - mae: 0.8588 - mse: 1.1804 - val_loss: 1.0977 - val_mae: 0.8099 - val_mse: 1.0977\n",
      "Epoch 65/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2200 - mae: 0.8656 - mse: 1.2200 - val_loss: 1.0846 - val_mae: 0.8246 - val_mse: 1.0846\n",
      "Epoch 66/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2025 - mae: 0.8468 - mse: 1.2025 - val_loss: 1.3109 - val_mae: 0.8760 - val_mse: 1.3109\n",
      "Epoch 67/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3440 - mae: 0.9350 - mse: 1.3440 - val_loss: 1.1765 - val_mae: 0.8487 - val_mse: 1.1765\n",
      "Epoch 68/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0921 - mae: 0.8161 - mse: 1.0921 - val_loss: 1.6670 - val_mae: 1.0284 - val_mse: 1.6670\n",
      "Epoch 69/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0707 - mae: 0.8153 - mse: 1.0707 - val_loss: 1.2657 - val_mae: 0.8844 - val_mse: 1.2657\n",
      "Epoch 70/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0595 - mae: 0.8091 - mse: 1.0595 - val_loss: 2.0727 - val_mae: 1.2112 - val_mse: 2.0727\n",
      "Epoch 71/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1566 - mae: 0.8441 - mse: 1.1566 - val_loss: 1.4904 - val_mae: 0.9359 - val_mse: 1.4904\n",
      "Epoch 72/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1813 - mae: 0.8382 - mse: 1.1813 - val_loss: 1.2822 - val_mae: 0.8382 - val_mse: 1.2822\n",
      "Epoch 73/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9562 - mae: 0.7670 - mse: 0.9562 - val_loss: 1.1155 - val_mae: 0.8234 - val_mse: 1.1155\n",
      "Epoch 74/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2472 - mae: 0.8465 - mse: 1.2472 - val_loss: 1.0944 - val_mae: 0.8014 - val_mse: 1.0944\n",
      "Epoch 75/1000\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3952 - mae: 0.4771 - mse: 0.395 - 0s 2ms/step - loss: 0.9894 - mae: 0.7700 - mse: 0.9894 - val_loss: 1.5965 - val_mae: 0.9738 - val_mse: 1.5965\n",
      "Epoch 76/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1758 - mae: 0.8577 - mse: 1.1758 - val_loss: 1.8718 - val_mae: 1.1013 - val_mse: 1.8718\n",
      "Epoch 77/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1412 - mae: 0.8297 - mse: 1.1412 - val_loss: 2.2526 - val_mae: 1.1882 - val_mse: 2.2526\n",
      "Epoch 78/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9231 - mae: 0.7738 - mse: 0.9231 - val_loss: 1.0431 - val_mae: 0.7837 - val_mse: 1.0431\n",
      "Epoch 79/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0845 - mae: 0.8328 - mse: 1.0845 - val_loss: 1.0778 - val_mae: 0.7896 - val_mse: 1.0778\n",
      "Epoch 80/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8298 - mae: 0.7069 - mse: 0.8298 - val_loss: 1.0937 - val_mae: 0.8021 - val_mse: 1.0937\n",
      "Epoch 81/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0234 - mae: 0.7578 - mse: 1.0234 - val_loss: 1.1216 - val_mae: 0.8076 - val_mse: 1.1216\n",
      "Epoch 82/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9163 - mae: 0.7294 - mse: 0.9163 - val_loss: 1.4329 - val_mae: 0.9593 - val_mse: 1.4329\n",
      "Epoch 83/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1289 - mae: 0.8457 - mse: 1.1289 - val_loss: 1.2688 - val_mae: 0.8388 - val_mse: 1.2688\n",
      "Epoch 84/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0575 - mae: 0.7994 - mse: 1.0575 - val_loss: 1.2635 - val_mae: 0.9126 - val_mse: 1.2635\n",
      "Epoch 85/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0019 - mae: 0.7845 - mse: 1.0019 - val_loss: 1.7681 - val_mae: 1.0586 - val_mse: 1.7681\n",
      "Epoch 86/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9065 - mae: 0.7462 - mse: 0.9065 - val_loss: 1.2283 - val_mae: 0.8338 - val_mse: 1.2283\n",
      "Epoch 87/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1763 - mae: 0.8527 - mse: 1.1763 - val_loss: 1.3583 - val_mae: 0.9486 - val_mse: 1.3583\n",
      "Epoch 88/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9321 - mae: 0.7644 - mse: 0.9321 - val_loss: 1.3011 - val_mae: 0.8914 - val_mse: 1.3011\n",
      "Epoch 89/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8521 - mae: 0.7041 - mse: 0.8521 - val_loss: 2.4657 - val_mae: 1.2722 - val_mse: 2.4657\n",
      "Epoch 90/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8384 - mae: 0.6849 - mse: 0.8384 - val_loss: 1.1819 - val_mae: 0.8487 - val_mse: 1.1819\n",
      "Epoch 91/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9453 - mae: 0.7563 - mse: 0.9453 - val_loss: 2.7295 - val_mae: 1.3789 - val_mse: 2.7295\n",
      "Epoch 92/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0484 - mae: 0.8049 - mse: 1.0484 - val_loss: 1.7078 - val_mae: 1.0041 - val_mse: 1.7078\n",
      "Epoch 93/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8919 - mae: 0.7349 - mse: 0.8919 - val_loss: 1.3937 - val_mae: 0.9579 - val_mse: 1.3937\n",
      "Epoch 94/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1397 - mae: 0.8163 - mse: 1.1397 - val_loss: 1.8612 - val_mae: 1.1069 - val_mse: 1.8612\n",
      "Epoch 95/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8979 - mae: 0.7246 - mse: 0.8979 - val_loss: 1.0981 - val_mae: 0.8498 - val_mse: 1.0981\n",
      "Epoch 96/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9408 - mae: 0.7500 - mse: 0.9408 - val_loss: 1.0602 - val_mae: 0.7835 - val_mse: 1.0602\n",
      "Epoch 97/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8792 - mae: 0.7238 - mse: 0.8792 - val_loss: 1.0634 - val_mae: 0.7783 - val_mse: 1.0634\n",
      "Epoch 98/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0024 - mae: 0.7695 - mse: 1.0024 - val_loss: 1.0536 - val_mae: 0.7664 - val_mse: 1.0536\n",
      "Epoch 99/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7943 - mae: 0.6961 - mse: 0.7943 - val_loss: 1.5556 - val_mae: 0.9473 - val_mse: 1.5556\n",
      "Epoch 100/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0409 - mae: 0.8058 - mse: 1.0409 - val_loss: 1.9669 - val_mae: 1.1179 - val_mse: 1.9669\n",
      "Epoch 101/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9349 - mae: 0.7616 - mse: 0.9349 - val_loss: 1.7599 - val_mae: 1.0554 - val_mse: 1.7599\n",
      "Epoch 102/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7720 - mae: 0.6733 - mse: 0.7720 - val_loss: 1.5562 - val_mae: 0.9448 - val_mse: 1.5562\n",
      "Epoch 103/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9262 - mae: 0.7546 - mse: 0.9262 - val_loss: 1.2040 - val_mae: 0.9046 - val_mse: 1.2040\n",
      "Epoch 104/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9073 - mae: 0.7526 - mse: 0.9073 - val_loss: 1.3846 - val_mae: 0.9438 - val_mse: 1.3846\n",
      "Epoch 105/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8018 - mae: 0.6831 - mse: 0.8018 - val_loss: 2.5570 - val_mae: 1.2717 - val_mse: 2.5570\n",
      "Epoch 106/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9500 - mae: 0.7759 - mse: 0.9500 - val_loss: 1.2481 - val_mae: 0.8421 - val_mse: 1.2481\n",
      "Epoch 107/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6790 - mae: 0.6485 - mse: 0.6790 - val_loss: 1.1836 - val_mae: 0.8118 - val_mse: 1.1836\n",
      "Epoch 108/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0344 - mae: 0.8049 - mse: 1.0344 - val_loss: 1.2351 - val_mae: 0.8322 - val_mse: 1.2351\n",
      "Epoch 109/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8527 - mae: 0.7067 - mse: 0.8527 - val_loss: 1.0865 - val_mae: 0.8159 - val_mse: 1.0865\n",
      "Epoch 110/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8718 - mae: 0.7064 - mse: 0.8718 - val_loss: 2.1907 - val_mae: 1.2416 - val_mse: 2.1907\n",
      "Epoch 111/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7438 - mae: 0.6734 - mse: 0.7438 - val_loss: 1.5181 - val_mae: 0.9514 - val_mse: 1.5181\n",
      "Epoch 112/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9786 - mae: 0.7627 - mse: 0.9786 - val_loss: 1.4453 - val_mae: 0.9060 - val_mse: 1.4453\n",
      "Epoch 113/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8744 - mae: 0.7274 - mse: 0.8744 - val_loss: 1.6220 - val_mae: 1.0521 - val_mse: 1.6220\n",
      "Epoch 114/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8505 - mae: 0.7143 - mse: 0.8505 - val_loss: 2.0115 - val_mae: 1.1307 - val_mse: 2.0115\n",
      "Epoch 115/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8744 - mae: 0.7232 - mse: 0.8744 - val_loss: 2.5639 - val_mae: 1.3284 - val_mse: 2.5639\n",
      "Epoch 116/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9108 - mae: 0.7244 - mse: 0.9108 - val_loss: 1.5617 - val_mae: 0.9762 - val_mse: 1.5617\n",
      "Epoch 117/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8051 - mae: 0.6932 - mse: 0.8051 - val_loss: 1.7837 - val_mae: 1.0582 - val_mse: 1.7837\n",
      "Epoch 118/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7180 - mae: 0.6520 - mse: 0.7180 - val_loss: 1.4009 - val_mae: 0.9359 - val_mse: 1.4009\n",
      "Epoch 119/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8069 - mae: 0.7156 - mse: 0.8069 - val_loss: 1.3463 - val_mae: 0.9062 - val_mse: 1.3463\n",
      "Epoch 120/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7931 - mae: 0.6756 - mse: 0.7931 - val_loss: 2.7999 - val_mae: 1.4128 - val_mse: 2.7999\n",
      "Epoch 121/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9131 - mae: 0.7298 - mse: 0.9131 - val_loss: 1.3191 - val_mae: 0.9469 - val_mse: 1.3191\n",
      "Epoch 122/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8425 - mae: 0.7178 - mse: 0.8425 - val_loss: 1.1652 - val_mae: 0.8280 - val_mse: 1.1652\n",
      "Epoch 123/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7760 - mae: 0.6759 - mse: 0.7760 - val_loss: 1.1927 - val_mae: 0.8756 - val_mse: 1.1927\n",
      "Epoch 124/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8498 - mae: 0.7201 - mse: 0.8498 - val_loss: 1.5330 - val_mae: 1.0208 - val_mse: 1.5330\n",
      "Epoch 125/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7115 - mae: 0.6375 - mse: 0.7115 - val_loss: 1.2956 - val_mae: 0.9286 - val_mse: 1.2956\n",
      "Epoch 126/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9447 - mae: 0.7655 - mse: 0.9447 - val_loss: 1.1505 - val_mae: 0.8272 - val_mse: 1.1505\n",
      "Epoch 127/1000\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4845 - mae: 0.5811 - mse: 0.484 - 0s 2ms/step - loss: 0.6615 - mae: 0.6285 - mse: 0.6615 - val_loss: 1.4149 - val_mae: 0.9186 - val_mse: 1.4149\n",
      "Epoch 128/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7848 - mae: 0.6932 - mse: 0.7848 - val_loss: 1.2833 - val_mae: 0.8870 - val_mse: 1.2833\n",
      "Epoch 129/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8459 - mae: 0.7048 - mse: 0.8459 - val_loss: 1.8794 - val_mae: 1.1414 - val_mse: 1.8794\n",
      "Epoch 130/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7976 - mae: 0.6791 - mse: 0.7976 - val_loss: 1.2444 - val_mae: 0.8851 - val_mse: 1.2444\n",
      "Epoch 131/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5721 - mae: 0.5698 - mse: 0.5721 - val_loss: 1.1399 - val_mae: 0.8436 - val_mse: 1.1399\n",
      "Epoch 132/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9412 - mae: 0.7565 - mse: 0.9412 - val_loss: 1.4391 - val_mae: 0.9091 - val_mse: 1.4391\n",
      "Epoch 133/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7003 - mae: 0.6334 - mse: 0.7003 - val_loss: 1.8614 - val_mae: 1.1028 - val_mse: 1.8614\n",
      "Epoch 134/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6860 - mae: 0.6497 - mse: 0.6860 - val_loss: 1.1706 - val_mae: 0.8462 - val_mse: 1.1706\n",
      "Epoch 135/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6555 - mae: 0.6138 - mse: 0.6555 - val_loss: 1.6578 - val_mae: 1.0252 - val_mse: 1.6578\n",
      "Epoch 136/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8150 - mae: 0.6873 - mse: 0.8150 - val_loss: 1.0857 - val_mae: 0.8032 - val_mse: 1.0857\n",
      "Epoch 137/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8038 - mae: 0.6884 - mse: 0.8038 - val_loss: 1.2492 - val_mae: 0.8498 - val_mse: 1.2492\n",
      "Epoch 138/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5272 - mae: 0.5608 - mse: 0.5272 - val_loss: 1.5916 - val_mae: 0.9723 - val_mse: 1.5916\n",
      "Epoch 139/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8668 - mae: 0.7194 - mse: 0.8668 - val_loss: 1.1420 - val_mae: 0.8259 - val_mse: 1.1420\n",
      "Epoch 140/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7326 - mae: 0.6499 - mse: 0.7326 - val_loss: 1.4702 - val_mae: 0.9285 - val_mse: 1.4702\n",
      "Epoch 141/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6588 - mae: 0.6195 - mse: 0.6588 - val_loss: 1.3276 - val_mae: 0.9003 - val_mse: 1.3276\n",
      "Epoch 142/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6890 - mae: 0.6492 - mse: 0.6890 - val_loss: 1.4571 - val_mae: 0.9480 - val_mse: 1.4571\n",
      "Epoch 143/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6858 - mae: 0.6618 - mse: 0.6858 - val_loss: 1.7103 - val_mae: 1.0239 - val_mse: 1.7103\n",
      "Epoch 144/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8876 - mae: 0.7346 - mse: 0.8876 - val_loss: 1.2931 - val_mae: 0.8631 - val_mse: 1.2931\n",
      "Epoch 145/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5834 - mae: 0.5937 - mse: 0.5834 - val_loss: 1.1308 - val_mae: 0.8014 - val_mse: 1.1308\n",
      "Epoch 146/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7605 - mae: 0.6749 - mse: 0.7605 - val_loss: 1.1482 - val_mae: 0.8217 - val_mse: 1.1482\n",
      "Epoch 147/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8197 - mae: 0.6774 - mse: 0.8197 - val_loss: 1.2153 - val_mae: 0.8485 - val_mse: 1.2153\n",
      "Epoch 148/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5874 - mae: 0.5959 - mse: 0.5874 - val_loss: 1.1487 - val_mae: 0.8013 - val_mse: 1.1487\n",
      "Epoch 149/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7215 - mae: 0.6547 - mse: 0.7215 - val_loss: 1.2153 - val_mae: 0.8256 - val_mse: 1.2153\n",
      "Epoch 150/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7095 - mae: 0.6651 - mse: 0.7095 - val_loss: 1.5227 - val_mae: 0.9913 - val_mse: 1.5227\n",
      "Epoch 151/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7966 - mae: 0.6853 - mse: 0.7966 - val_loss: 1.2868 - val_mae: 0.8455 - val_mse: 1.2868\n",
      "Epoch 152/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7636 - mae: 0.6776 - mse: 0.7636 - val_loss: 1.1602 - val_mae: 0.8127 - val_mse: 1.1602\n",
      "Epoch 153/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5827 - mae: 0.5834 - mse: 0.5827 - val_loss: 2.0013 - val_mae: 1.1242 - val_mse: 2.0013\n",
      "Epoch 154/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5671 - mae: 0.5812 - mse: 0.5671 - val_loss: 1.1717 - val_mae: 0.8441 - val_mse: 1.1717\n",
      "Epoch 155/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7161 - mae: 0.6453 - mse: 0.7161 - val_loss: 1.2137 - val_mae: 0.8460 - val_mse: 1.2137\n",
      "Epoch 156/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6852 - mae: 0.6508 - mse: 0.6852 - val_loss: 1.6522 - val_mae: 0.9886 - val_mse: 1.6522\n",
      "Epoch 157/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7153 - mae: 0.6558 - mse: 0.7153 - val_loss: 1.1537 - val_mae: 0.8226 - val_mse: 1.1537\n",
      "Epoch 158/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6318 - mae: 0.6204 - mse: 0.6318 - val_loss: 1.1885 - val_mae: 0.8212 - val_mse: 1.1885\n",
      "Epoch 159/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6548 - mae: 0.6037 - mse: 0.6548 - val_loss: 1.1504 - val_mae: 0.8047 - val_mse: 1.1504\n",
      "Epoch 160/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6652 - mae: 0.6262 - mse: 0.6652 - val_loss: 1.2226 - val_mae: 0.8657 - val_mse: 1.2226\n",
      "Epoch 161/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5325 - mae: 0.5588 - mse: 0.5325 - val_loss: 1.5489 - val_mae: 0.9773 - val_mse: 1.5489\n",
      "Epoch 162/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7099 - mae: 0.6539 - mse: 0.7099 - val_loss: 1.2206 - val_mae: 0.8369 - val_mse: 1.2206\n",
      "Epoch 163/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6025 - mae: 0.5981 - mse: 0.6025 - val_loss: 1.1410 - val_mae: 0.8199 - val_mse: 1.1410\n",
      "Epoch 164/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6598 - mae: 0.6278 - mse: 0.6598 - val_loss: 1.9699 - val_mae: 1.1564 - val_mse: 1.9699\n",
      "Epoch 165/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5481 - mae: 0.5607 - mse: 0.5481 - val_loss: 1.9293 - val_mae: 1.1269 - val_mse: 1.9293\n",
      "Epoch 166/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7351 - mae: 0.6733 - mse: 0.7351 - val_loss: 1.1319 - val_mae: 0.8063 - val_mse: 1.1319\n",
      "Epoch 167/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6072 - mae: 0.5987 - mse: 0.6072 - val_loss: 1.3684 - val_mae: 0.8945 - val_mse: 1.3684\n",
      "Epoch 168/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5508 - mae: 0.5670 - mse: 0.5508 - val_loss: 1.1836 - val_mae: 0.8198 - val_mse: 1.1836\n",
      "Epoch 169/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6939 - mae: 0.6445 - mse: 0.6939 - val_loss: 1.1785 - val_mae: 0.8410 - val_mse: 1.1785\n",
      "Epoch 170/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3713 - mae: 0.4572 - mse: 0.3713 - val_loss: 1.7486 - val_mae: 1.1051 - val_mse: 1.7486\n",
      "Epoch 171/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6776 - mae: 0.6291 - mse: 0.6776 - val_loss: 1.1621 - val_mae: 0.8337 - val_mse: 1.1621\n",
      "Epoch 172/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6856 - mae: 0.6385 - mse: 0.6856 - val_loss: 1.3666 - val_mae: 0.8824 - val_mse: 1.3666\n",
      "Epoch 173/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6169 - mae: 0.6109 - mse: 0.6169 - val_loss: 1.1752 - val_mae: 0.8197 - val_mse: 1.1752\n",
      "Epoch 174/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5856 - mae: 0.5907 - mse: 0.5856 - val_loss: 1.2313 - val_mae: 0.8614 - val_mse: 1.2313\n",
      "Epoch 175/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7550 - mae: 0.6639 - mse: 0.7550 - val_loss: 1.1432 - val_mae: 0.8590 - val_mse: 1.1432\n",
      "Epoch 176/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5917 - mae: 0.5990 - mse: 0.5917 - val_loss: 1.4739 - val_mae: 0.9484 - val_mse: 1.4739\n",
      "Epoch 177/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5364 - mae: 0.5595 - mse: 0.5364 - val_loss: 2.1110 - val_mae: 1.1805 - val_mse: 2.1110\n",
      "Epoch 178/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6620 - mae: 0.6326 - mse: 0.6620 - val_loss: 1.6711 - val_mae: 1.0201 - val_mse: 1.6711\n",
      "Kappa Score: 0.6579537647847571\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Epoch 1/1000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 166.2715 - mae: 5.3473 - mse: 166.2715 - val_loss: 5.4234 - val_mae: 1.8475 - val_mse: 5.4234\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 26.5000 - mae: 4.5552 - mse: 26.5000 - val_loss: 12.1910 - val_mae: 3.3050 - val_mse: 12.1910\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 31.6529 - mae: 4.9054 - mse: 31.6529 - val_loss: 9.8882 - val_mae: 2.5608 - val_mse: 9.8882\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 24.5492 - mae: 3.1677 - mse: 24.5492 - val_loss: 66.1450 - val_mae: 7.2640 - val_mse: 66.1450\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 14.3153 - mae: 2.6127 - mse: 14.3153 - val_loss: 50.9304 - val_mae: 6.9224 - val_mse: 50.9304\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 12.4015 - mae: 2.3487 - mse: 12.4015 - val_loss: 1.4351 - val_mae: 0.9208 - val_mse: 1.4351\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 16.1729 - mae: 2.9553 - mse: 16.1729 - val_loss: 12.3614 - val_mae: 3.3652 - val_mse: 12.3614\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 13.1940 - mae: 2.6260 - mse: 13.1940 - val_loss: 2.6022 - val_mae: 1.2596 - val_mse: 2.6022\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 11.3844 - mae: 2.8174 - mse: 11.3844 - val_loss: 8.2310 - val_mae: 2.6707 - val_mse: 8.2310\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.7901 - mae: 2.0877 - mse: 6.7901 - val_loss: 1.7890 - val_mae: 0.9908 - val_mse: 1.7890\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.7913 - mae: 2.0903 - mse: 7.7913 - val_loss: 7.8401 - val_mae: 2.3344 - val_mse: 7.8401\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.1647 - mae: 1.9133 - mse: 6.1647 - val_loss: 3.0907 - val_mae: 1.4725 - val_mse: 3.0907\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 4.5482 - mae: 1.7098 - mse: 4.5482 - val_loss: 5.8354 - val_mae: 2.0088 - val_mse: 5.8354\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 4.7707 - mae: 1.8212 - mse: 4.7707 - val_loss: 1.4146 - val_mae: 0.9488 - val_mse: 1.4146\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.5189 - mae: 1.4870 - mse: 3.5189 - val_loss: 2.0540 - val_mae: 1.1134 - val_mse: 2.0540\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.9176 - mae: 1.0817 - mse: 1.9176 - val_loss: 1.8669 - val_mae: 1.0558 - val_mse: 1.8669\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.4802 - mae: 1.4565 - mse: 3.4802 - val_loss: 1.1795 - val_mae: 0.8424 - val_mse: 1.1795\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2211 - mae: 1.4156 - mse: 3.2211 - val_loss: 2.3606 - val_mae: 1.2379 - val_mse: 2.3606\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4099 - mae: 1.2100 - mse: 2.4099 - val_loss: 2.1164 - val_mae: 1.1477 - val_mse: 2.1164\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7767 - mae: 1.0585 - mse: 1.7767 - val_loss: 2.2568 - val_mae: 1.2022 - val_mse: 2.2568\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0822 - mae: 1.1210 - mse: 2.0822 - val_loss: 1.2870 - val_mae: 0.8918 - val_mse: 1.2870\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8653 - mae: 1.0971 - mse: 1.8653 - val_loss: 1.2585 - val_mae: 0.8739 - val_mse: 1.2585\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.3340 - mae: 1.1637 - mse: 2.3340 - val_loss: 1.1060 - val_mae: 0.8049 - val_mse: 1.1060\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0199 - mae: 1.0809 - mse: 2.0199 - val_loss: 1.0862 - val_mae: 0.7994 - val_mse: 1.0862\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4829 - mae: 0.9617 - mse: 1.4829 - val_loss: 1.9093 - val_mae: 1.0903 - val_mse: 1.9093\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.1435 - mae: 1.1825 - mse: 2.1435 - val_loss: 0.9974 - val_mae: 0.7746 - val_mse: 0.9974\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5842 - mae: 0.9864 - mse: 1.5842 - val_loss: 1.2912 - val_mae: 0.9047 - val_mse: 1.2912\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3158 - mae: 0.8964 - mse: 1.3158 - val_loss: 4.8083 - val_mae: 1.8273 - val_mse: 4.8083\n",
      "Epoch 29/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.8224 - mae: 1.0493 - mse: 1.8224 - val_loss: 1.4966 - val_mae: 0.8954 - val_mse: 1.4966\n",
      "Epoch 30/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5721 - mae: 0.9836 - mse: 1.5721 - val_loss: 1.3910 - val_mae: 0.9362 - val_mse: 1.3910\n",
      "Epoch 31/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5554 - mae: 0.9922 - mse: 1.5554 - val_loss: 1.0474 - val_mae: 0.7990 - val_mse: 1.0474\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7041 - mae: 1.0061 - mse: 1.7041 - val_loss: 1.2409 - val_mae: 0.8720 - val_mse: 1.2409\n",
      "Epoch 33/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3920 - mae: 0.9206 - mse: 1.3920 - val_loss: 1.0348 - val_mae: 0.7883 - val_mse: 1.0348\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5206 - mae: 0.9907 - mse: 1.5206 - val_loss: 1.6576 - val_mae: 1.0319 - val_mse: 1.6576\n",
      "Epoch 35/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5421 - mae: 0.9800 - mse: 1.5421 - val_loss: 1.6480 - val_mae: 0.9902 - val_mse: 1.6480\n",
      "Epoch 36/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4651 - mae: 0.9639 - mse: 1.4651 - val_loss: 1.2483 - val_mae: 0.8940 - val_mse: 1.2483\n",
      "Epoch 37/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4486 - mae: 0.9430 - mse: 1.4486 - val_loss: 1.0621 - val_mae: 0.8004 - val_mse: 1.0621\n",
      "Epoch 38/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3482 - mae: 0.8993 - mse: 1.3482 - val_loss: 0.9887 - val_mae: 0.7848 - val_mse: 0.9887\n",
      "Epoch 39/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3611 - mae: 0.9018 - mse: 1.3611 - val_loss: 1.9824 - val_mae: 1.1171 - val_mse: 1.9824\n",
      "Epoch 40/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2878 - mae: 0.9042 - mse: 1.2878 - val_loss: 1.1603 - val_mae: 0.8272 - val_mse: 1.1603\n",
      "Epoch 41/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4674 - mae: 0.9278 - mse: 1.4674 - val_loss: 1.1325 - val_mae: 0.8582 - val_mse: 1.1325\n",
      "Epoch 42/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2052 - mae: 0.8553 - mse: 1.2052 - val_loss: 2.9233 - val_mae: 1.4927 - val_mse: 2.9233\n",
      "Epoch 43/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2839 - mae: 0.8994 - mse: 1.2839 - val_loss: 1.5515 - val_mae: 1.0010 - val_mse: 1.5515\n",
      "Epoch 44/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3255 - mae: 0.9188 - mse: 1.3255 - val_loss: 1.6566 - val_mae: 1.0073 - val_mse: 1.6566\n",
      "Epoch 45/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2885 - mae: 0.8713 - mse: 1.2885 - val_loss: 1.4571 - val_mae: 0.9815 - val_mse: 1.4571\n",
      "Epoch 46/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2145 - mae: 0.8604 - mse: 1.2145 - val_loss: 1.0763 - val_mae: 0.8071 - val_mse: 1.0763\n",
      "Epoch 47/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1621 - mae: 0.8369 - mse: 1.1621 - val_loss: 1.2145 - val_mae: 0.8548 - val_mse: 1.2145\n",
      "Epoch 48/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4830 - mae: 0.9380 - mse: 1.4830 - val_loss: 1.5373 - val_mae: 1.0128 - val_mse: 1.5373\n",
      "Epoch 49/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4661 - mae: 0.9354 - mse: 1.4661 - val_loss: 1.1137 - val_mae: 0.8258 - val_mse: 1.1137\n",
      "Epoch 50/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0556 - mae: 0.7990 - mse: 1.0556 - val_loss: 1.6169 - val_mae: 1.0061 - val_mse: 1.6169\n",
      "Epoch 51/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2364 - mae: 0.8869 - mse: 1.2364 - val_loss: 0.9919 - val_mae: 0.7581 - val_mse: 0.9919\n",
      "Epoch 52/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0672 - mae: 0.7789 - mse: 1.0672 - val_loss: 1.5751 - val_mae: 0.9901 - val_mse: 1.5751\n",
      "Epoch 53/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0944 - mae: 0.8296 - mse: 1.0944 - val_loss: 1.2217 - val_mae: 0.9166 - val_mse: 1.2217\n",
      "Epoch 54/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3287 - mae: 0.9080 - mse: 1.3287 - val_loss: 0.9556 - val_mae: 0.7743 - val_mse: 0.9556\n",
      "Epoch 55/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1789 - mae: 0.8322 - mse: 1.1789 - val_loss: 1.5325 - val_mae: 1.0086 - val_mse: 1.5325\n",
      "Epoch 56/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9765 - mae: 0.7714 - mse: 0.9765 - val_loss: 1.0723 - val_mae: 0.7933 - val_mse: 1.0723\n",
      "Epoch 57/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1970 - mae: 0.8624 - mse: 1.1970 - val_loss: 1.4977 - val_mae: 0.9818 - val_mse: 1.4977\n",
      "Epoch 58/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1588 - mae: 0.8369 - mse: 1.1588 - val_loss: 3.8123 - val_mae: 1.5806 - val_mse: 3.8123\n",
      "Epoch 59/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1187 - mae: 0.8000 - mse: 1.1187 - val_loss: 1.4754 - val_mae: 0.9693 - val_mse: 1.4754\n",
      "Epoch 60/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1476 - mae: 0.8185 - mse: 1.1476 - val_loss: 2.0295 - val_mae: 1.1503 - val_mse: 2.0295\n",
      "Epoch 61/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2349 - mae: 0.8633 - mse: 1.2349 - val_loss: 1.0573 - val_mae: 0.7913 - val_mse: 1.0573\n",
      "Epoch 62/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1350 - mae: 0.8204 - mse: 1.1350 - val_loss: 0.9779 - val_mae: 0.7554 - val_mse: 0.9779\n",
      "Epoch 63/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3012 - mae: 0.8773 - mse: 1.3012 - val_loss: 1.0520 - val_mae: 0.8208 - val_mse: 1.0520\n",
      "Epoch 64/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7622 - mae: 0.6705 - mse: 0.7622 - val_loss: 1.0769 - val_mae: 0.8200 - val_mse: 1.0769\n",
      "Epoch 65/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2871 - mae: 0.8795 - mse: 1.2871 - val_loss: 0.9778 - val_mae: 0.7787 - val_mse: 0.9778\n",
      "Epoch 66/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0950 - mae: 0.8179 - mse: 1.0950 - val_loss: 3.0671 - val_mae: 1.5244 - val_mse: 3.0671\n",
      "Epoch 67/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0667 - mae: 0.8061 - mse: 1.0667 - val_loss: 1.8141 - val_mae: 1.1083 - val_mse: 1.8141\n",
      "Epoch 68/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0748 - mae: 0.7983 - mse: 1.0748 - val_loss: 2.5665 - val_mae: 1.3544 - val_mse: 2.5665\n",
      "Epoch 69/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0129 - mae: 0.7883 - mse: 1.0129 - val_loss: 1.0617 - val_mae: 0.8117 - val_mse: 1.0617\n",
      "Epoch 70/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1116 - mae: 0.8309 - mse: 1.1116 - val_loss: 1.0125 - val_mae: 0.7808 - val_mse: 1.0125\n",
      "Epoch 71/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0054 - mae: 0.7873 - mse: 1.0054 - val_loss: 1.0864 - val_mae: 0.8463 - val_mse: 1.0864\n",
      "Epoch 72/1000\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6355 - mae: 0.6534 - mse: 0.635 - 0s 2ms/step - loss: 1.0637 - mae: 0.7844 - mse: 1.0637 - val_loss: 1.1928 - val_mae: 0.8696 - val_mse: 1.1928\n",
      "Epoch 73/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9648 - mae: 0.7680 - mse: 0.9648 - val_loss: 1.1287 - val_mae: 0.8362 - val_mse: 1.1287\n",
      "Epoch 74/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0711 - mae: 0.8044 - mse: 1.0711 - val_loss: 1.0260 - val_mae: 0.8058 - val_mse: 1.0260\n",
      "Epoch 75/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9378 - mae: 0.7546 - mse: 0.9378 - val_loss: 1.0620 - val_mae: 0.8193 - val_mse: 1.0620\n",
      "Epoch 76/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0593 - mae: 0.8055 - mse: 1.0593 - val_loss: 1.2947 - val_mae: 0.9101 - val_mse: 1.2947\n",
      "Epoch 77/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9214 - mae: 0.7459 - mse: 0.9214 - val_loss: 1.0653 - val_mae: 0.7901 - val_mse: 1.0653\n",
      "Epoch 78/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9371 - mae: 0.7595 - mse: 0.9371 - val_loss: 1.0735 - val_mae: 0.8320 - val_mse: 1.0735\n",
      "Epoch 79/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9505 - mae: 0.7632 - mse: 0.9505 - val_loss: 1.4688 - val_mae: 0.9651 - val_mse: 1.4688\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9334 - mae: 0.7584 - mse: 0.9334 - val_loss: 1.6112 - val_mae: 1.0108 - val_mse: 1.6112\n",
      "Epoch 81/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0611 - mae: 0.7915 - mse: 1.0611 - val_loss: 1.0348 - val_mae: 0.7828 - val_mse: 1.0348\n",
      "Epoch 82/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9559 - mae: 0.7553 - mse: 0.9559 - val_loss: 0.9667 - val_mae: 0.7588 - val_mse: 0.9667\n",
      "Epoch 83/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0310 - mae: 0.7817 - mse: 1.0310 - val_loss: 0.9798 - val_mae: 0.7693 - val_mse: 0.9798\n",
      "Epoch 84/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9087 - mae: 0.7406 - mse: 0.9087 - val_loss: 0.9800 - val_mae: 0.7587 - val_mse: 0.9800\n",
      "Epoch 85/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9756 - mae: 0.7657 - mse: 0.9756 - val_loss: 1.9288 - val_mae: 1.1466 - val_mse: 1.9288\n",
      "Epoch 86/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8637 - mae: 0.7179 - mse: 0.8637 - val_loss: 1.6386 - val_mae: 1.0514 - val_mse: 1.6386\n",
      "Epoch 87/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9170 - mae: 0.7657 - mse: 0.9170 - val_loss: 2.2560 - val_mae: 1.2061 - val_mse: 2.2560\n",
      "Epoch 88/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9085 - mae: 0.7450 - mse: 0.9085 - val_loss: 1.4533 - val_mae: 0.9570 - val_mse: 1.4533\n",
      "Epoch 89/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0745 - mae: 0.7954 - mse: 1.0745 - val_loss: 1.1302 - val_mae: 0.8215 - val_mse: 1.1302\n",
      "Epoch 90/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8614 - mae: 0.7081 - mse: 0.8614 - val_loss: 1.0983 - val_mae: 0.8407 - val_mse: 1.0983\n",
      "Epoch 91/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7027 - mae: 0.6515 - mse: 0.7027 - val_loss: 1.7181 - val_mae: 1.0849 - val_mse: 1.7181\n",
      "Epoch 92/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0361 - mae: 0.7980 - mse: 1.0361 - val_loss: 1.0029 - val_mae: 0.7717 - val_mse: 1.0029\n",
      "Epoch 93/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8140 - mae: 0.7135 - mse: 0.8140 - val_loss: 1.3663 - val_mae: 0.9246 - val_mse: 1.3663\n",
      "Epoch 94/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8793 - mae: 0.7255 - mse: 0.8793 - val_loss: 1.4235 - val_mae: 0.9387 - val_mse: 1.4235\n",
      "Epoch 95/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8994 - mae: 0.7382 - mse: 0.8994 - val_loss: 1.9469 - val_mae: 1.1421 - val_mse: 1.9469\n",
      "Epoch 96/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8832 - mae: 0.7247 - mse: 0.8832 - val_loss: 0.9166 - val_mae: 0.7449 - val_mse: 0.9166\n",
      "Epoch 97/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0271 - mae: 0.7817 - mse: 1.0271 - val_loss: 0.9856 - val_mae: 0.7829 - val_mse: 0.9856\n",
      "Epoch 98/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7694 - mae: 0.6848 - mse: 0.7694 - val_loss: 1.0054 - val_mae: 0.7548 - val_mse: 1.0054\n",
      "Epoch 99/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9332 - mae: 0.7564 - mse: 0.9332 - val_loss: 2.5762 - val_mae: 1.3432 - val_mse: 2.5762\n",
      "Epoch 100/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8039 - mae: 0.6755 - mse: 0.8039 - val_loss: 2.4459 - val_mae: 1.3174 - val_mse: 2.4459\n",
      "Epoch 101/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8766 - mae: 0.7174 - mse: 0.8766 - val_loss: 1.0702 - val_mae: 0.8095 - val_mse: 1.0702\n",
      "Epoch 102/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8084 - mae: 0.7129 - mse: 0.8084 - val_loss: 0.9831 - val_mae: 0.7859 - val_mse: 0.9831\n",
      "Epoch 103/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8671 - mae: 0.7327 - mse: 0.8671 - val_loss: 1.5792 - val_mae: 1.0088 - val_mse: 1.5792\n",
      "Epoch 104/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7561 - mae: 0.6854 - mse: 0.7561 - val_loss: 1.2681 - val_mae: 0.8848 - val_mse: 1.2681\n",
      "Epoch 105/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7787 - mae: 0.6847 - mse: 0.7787 - val_loss: 1.1380 - val_mae: 0.8505 - val_mse: 1.1380\n",
      "Epoch 106/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8975 - mae: 0.7318 - mse: 0.8975 - val_loss: 1.7180 - val_mae: 1.0496 - val_mse: 1.7180\n",
      "Epoch 107/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7628 - mae: 0.6744 - mse: 0.7628 - val_loss: 0.9869 - val_mae: 0.7809 - val_mse: 0.9869\n",
      "Epoch 108/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7424 - mae: 0.6682 - mse: 0.7424 - val_loss: 1.8120 - val_mae: 1.0950 - val_mse: 1.8120\n",
      "Epoch 109/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8327 - mae: 0.7032 - mse: 0.8327 - val_loss: 0.9942 - val_mae: 0.7757 - val_mse: 0.9942\n",
      "Epoch 110/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8081 - mae: 0.6982 - mse: 0.8081 - val_loss: 1.1961 - val_mae: 0.8365 - val_mse: 1.1961\n",
      "Epoch 111/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7664 - mae: 0.6637 - mse: 0.7664 - val_loss: 1.3305 - val_mae: 0.9206 - val_mse: 1.3305\n",
      "Epoch 112/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7988 - mae: 0.7113 - mse: 0.7988 - val_loss: 1.6934 - val_mae: 1.0603 - val_mse: 1.6934\n",
      "Epoch 113/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6815 - mae: 0.6346 - mse: 0.6815 - val_loss: 1.1815 - val_mae: 0.8604 - val_mse: 1.1815\n",
      "Epoch 114/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9544 - mae: 0.7630 - mse: 0.9544 - val_loss: 1.1189 - val_mae: 0.8223 - val_mse: 1.1189\n",
      "Epoch 115/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8508 - mae: 0.7230 - mse: 0.8508 - val_loss: 1.1534 - val_mae: 0.8330 - val_mse: 1.1534\n",
      "Epoch 116/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7587 - mae: 0.6711 - mse: 0.7587 - val_loss: 1.4171 - val_mae: 0.9521 - val_mse: 1.4171\n",
      "Epoch 117/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8152 - mae: 0.7183 - mse: 0.8152 - val_loss: 1.2730 - val_mae: 0.9167 - val_mse: 1.2730\n",
      "Epoch 118/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7385 - mae: 0.6714 - mse: 0.7385 - val_loss: 1.7043 - val_mae: 1.0268 - val_mse: 1.7043\n",
      "Epoch 119/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7645 - mae: 0.6717 - mse: 0.7645 - val_loss: 1.8967 - val_mae: 1.1081 - val_mse: 1.8967\n",
      "Epoch 120/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6872 - mae: 0.6386 - mse: 0.6872 - val_loss: 0.9786 - val_mae: 0.7774 - val_mse: 0.9786\n",
      "Epoch 121/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7747 - mae: 0.6732 - mse: 0.7747 - val_loss: 3.2263 - val_mae: 1.5564 - val_mse: 3.2263\n",
      "Epoch 122/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8310 - mae: 0.7069 - mse: 0.8310 - val_loss: 1.0349 - val_mae: 0.7858 - val_mse: 1.0349\n",
      "Epoch 123/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5965 - mae: 0.5795 - mse: 0.5965 - val_loss: 1.6590 - val_mae: 1.0344 - val_mse: 1.6590\n",
      "Epoch 124/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7051 - mae: 0.6650 - mse: 0.7051 - val_loss: 1.5367 - val_mae: 0.9961 - val_mse: 1.5367\n",
      "Epoch 125/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8065 - mae: 0.7175 - mse: 0.8065 - val_loss: 0.9302 - val_mae: 0.7568 - val_mse: 0.9302\n",
      "Epoch 126/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7056 - mae: 0.6404 - mse: 0.7056 - val_loss: 1.0898 - val_mae: 0.8036 - val_mse: 1.0898\n",
      "Epoch 127/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8021 - mae: 0.6859 - mse: 0.8021 - val_loss: 1.0698 - val_mae: 0.7789 - val_mse: 1.0698\n",
      "Epoch 128/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6929 - mae: 0.6472 - mse: 0.6929 - val_loss: 0.9490 - val_mae: 0.7501 - val_mse: 0.9490\n",
      "Epoch 129/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6874 - mae: 0.6439 - mse: 0.6874 - val_loss: 1.2015 - val_mae: 0.8613 - val_mse: 1.2015\n",
      "Epoch 130/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7258 - mae: 0.6661 - mse: 0.7258 - val_loss: 1.0552 - val_mae: 0.7755 - val_mse: 1.0552\n",
      "Epoch 131/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7322 - mae: 0.6598 - mse: 0.7322 - val_loss: 1.2305 - val_mae: 0.8690 - val_mse: 1.2305\n",
      "Epoch 132/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8259 - mae: 0.6942 - mse: 0.8259 - val_loss: 1.4692 - val_mae: 0.9772 - val_mse: 1.4692\n",
      "Epoch 133/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5867 - mae: 0.6001 - mse: 0.5867 - val_loss: 1.7090 - val_mae: 1.0445 - val_mse: 1.7090\n",
      "Epoch 134/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7596 - mae: 0.7026 - mse: 0.7596 - val_loss: 1.0471 - val_mae: 0.7765 - val_mse: 1.0471\n",
      "Epoch 135/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8003 - mae: 0.6876 - mse: 0.8003 - val_loss: 0.9742 - val_mae: 0.7734 - val_mse: 0.9742\n",
      "Epoch 136/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7115 - mae: 0.6382 - mse: 0.7115 - val_loss: 1.3312 - val_mae: 0.9120 - val_mse: 1.3312\n",
      "Epoch 137/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5899 - mae: 0.5944 - mse: 0.5899 - val_loss: 1.0772 - val_mae: 0.7708 - val_mse: 1.0772\n",
      "Epoch 138/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6259 - mae: 0.5913 - mse: 0.6259 - val_loss: 1.1331 - val_mae: 0.8258 - val_mse: 1.1331\n",
      "Epoch 139/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7088 - mae: 0.6328 - mse: 0.7088 - val_loss: 1.2282 - val_mae: 0.8511 - val_mse: 1.2282\n",
      "Epoch 140/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7625 - mae: 0.6919 - mse: 0.7625 - val_loss: 1.7514 - val_mae: 1.0496 - val_mse: 1.7514\n",
      "Epoch 141/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7048 - mae: 0.6398 - mse: 0.7048 - val_loss: 1.0283 - val_mae: 0.8070 - val_mse: 1.0283\n",
      "Epoch 142/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7015 - mae: 0.6499 - mse: 0.7015 - val_loss: 1.0752 - val_mae: 0.8017 - val_mse: 1.0752\n",
      "Epoch 143/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5906 - mae: 0.5991 - mse: 0.5906 - val_loss: 0.9970 - val_mae: 0.7730 - val_mse: 0.9970\n",
      "Epoch 144/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7435 - mae: 0.6498 - mse: 0.7435 - val_loss: 1.2289 - val_mae: 0.8814 - val_mse: 1.2289\n",
      "Epoch 145/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7145 - mae: 0.6583 - mse: 0.7145 - val_loss: 1.0600 - val_mae: 0.7857 - val_mse: 1.0600\n",
      "Epoch 146/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7077 - mae: 0.6385 - mse: 0.7077 - val_loss: 1.8521 - val_mae: 1.1161 - val_mse: 1.8521\n",
      "Epoch 147/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5568 - mae: 0.5898 - mse: 0.5568 - val_loss: 0.9213 - val_mae: 0.7329 - val_mse: 0.9213\n",
      "Epoch 148/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6323 - mae: 0.6038 - mse: 0.6323 - val_loss: 1.2995 - val_mae: 0.8791 - val_mse: 1.2995\n",
      "Epoch 149/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6841 - mae: 0.6368 - mse: 0.6841 - val_loss: 0.9631 - val_mae: 0.7609 - val_mse: 0.9631\n",
      "Epoch 150/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6156 - mae: 0.6051 - mse: 0.6156 - val_loss: 1.5918 - val_mae: 1.0226 - val_mse: 1.5918\n",
      "Epoch 151/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6798 - mae: 0.6565 - mse: 0.6798 - val_loss: 0.9191 - val_mae: 0.7586 - val_mse: 0.9191\n",
      "Epoch 152/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6120 - mae: 0.5921 - mse: 0.6120 - val_loss: 1.1225 - val_mae: 0.8272 - val_mse: 1.1225\n",
      "Epoch 153/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7285 - mae: 0.6746 - mse: 0.7285 - val_loss: 1.1923 - val_mae: 0.8305 - val_mse: 1.1923\n",
      "Epoch 154/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6051 - mae: 0.6074 - mse: 0.6051 - val_loss: 1.1295 - val_mae: 0.8334 - val_mse: 1.1295\n",
      "Epoch 155/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5354 - mae: 0.5597 - mse: 0.5354 - val_loss: 1.0244 - val_mae: 0.7842 - val_mse: 1.0244\n",
      "Epoch 156/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6494 - mae: 0.6141 - mse: 0.6494 - val_loss: 1.1607 - val_mae: 0.8384 - val_mse: 1.1607\n",
      "Epoch 157/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6340 - mae: 0.6160 - mse: 0.6340 - val_loss: 1.3978 - val_mae: 0.9306 - val_mse: 1.3978\n",
      "Epoch 158/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6175 - mae: 0.6044 - mse: 0.6175 - val_loss: 0.9502 - val_mae: 0.7701 - val_mse: 0.9502\n",
      "Epoch 159/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5719 - mae: 0.5835 - mse: 0.5719 - val_loss: 1.2184 - val_mae: 0.8463 - val_mse: 1.2184\n",
      "Epoch 160/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6295 - mae: 0.6167 - mse: 0.6295 - val_loss: 1.1189 - val_mae: 0.8129 - val_mse: 1.1189\n",
      "Epoch 161/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6175 - mae: 0.6004 - mse: 0.6175 - val_loss: 1.3097 - val_mae: 0.8876 - val_mse: 1.3097\n",
      "Epoch 162/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4727 - mae: 0.5301 - mse: 0.4727 - val_loss: 1.0717 - val_mae: 0.8137 - val_mse: 1.0717\n",
      "Epoch 163/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6968 - mae: 0.6570 - mse: 0.6968 - val_loss: 1.1546 - val_mae: 0.8045 - val_mse: 1.1546\n",
      "Epoch 164/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6950 - mae: 0.6499 - mse: 0.6950 - val_loss: 1.1639 - val_mae: 0.8334 - val_mse: 1.1639\n",
      "Epoch 165/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5644 - mae: 0.5963 - mse: 0.5644 - val_loss: 2.3933 - val_mae: 1.2711 - val_mse: 2.3933\n",
      "Epoch 166/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5196 - mae: 0.5443 - mse: 0.5196 - val_loss: 2.2330 - val_mae: 1.2327 - val_mse: 2.2330\n",
      "Epoch 167/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5105 - mae: 0.5418 - mse: 0.5105 - val_loss: 1.6054 - val_mae: 1.0012 - val_mse: 1.6054\n",
      "Epoch 168/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5062 - mae: 0.5333 - mse: 0.5062 - val_loss: 2.5484 - val_mae: 1.3558 - val_mse: 2.5484\n",
      "Epoch 169/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6270 - mae: 0.6204 - mse: 0.6270 - val_loss: 1.8840 - val_mae: 1.1081 - val_mse: 1.8840\n",
      "Epoch 170/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6123 - mae: 0.6006 - mse: 0.6123 - val_loss: 2.0486 - val_mae: 1.1738 - val_mse: 2.0486\n",
      "Epoch 171/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4996 - mae: 0.5400 - mse: 0.4996 - val_loss: 0.9704 - val_mae: 0.7762 - val_mse: 0.9704\n",
      "Epoch 172/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6550 - mae: 0.6173 - mse: 0.6550 - val_loss: 1.1209 - val_mae: 0.8130 - val_mse: 1.1209\n",
      "Epoch 173/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5677 - mae: 0.5946 - mse: 0.5677 - val_loss: 1.0154 - val_mae: 0.7765 - val_mse: 1.0154\n",
      "Epoch 174/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5260 - mae: 0.5594 - mse: 0.5260 - val_loss: 1.1122 - val_mae: 0.7867 - val_mse: 1.1122\n",
      "Epoch 175/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6119 - mae: 0.6077 - mse: 0.6119 - val_loss: 1.0953 - val_mae: 0.7968 - val_mse: 1.0953\n",
      "Epoch 176/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5019 - mae: 0.5568 - mse: 0.5019 - val_loss: 1.3543 - val_mae: 0.9002 - val_mse: 1.3543\n",
      "Epoch 177/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6326 - mae: 0.6441 - mse: 0.6326 - val_loss: 1.0406 - val_mae: 0.7879 - val_mse: 1.0406\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5364 - mae: 0.5683 - mse: 0.5364 - val_loss: 1.7437 - val_mae: 1.0754 - val_mse: 1.7437\n",
      "Epoch 179/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5177 - mae: 0.5444 - mse: 0.5177 - val_loss: 2.1401 - val_mae: 1.1832 - val_mse: 2.1401\n",
      "Epoch 180/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5975 - mae: 0.5840 - mse: 0.5975 - val_loss: 1.1249 - val_mae: 0.8314 - val_mse: 1.1249\n",
      "Epoch 181/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4017 - mae: 0.4826 - mse: 0.4017 - val_loss: 1.1174 - val_mae: 0.8192 - val_mse: 1.1174\n",
      "Epoch 182/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5234 - mae: 0.5335 - mse: 0.5234 - val_loss: 1.1107 - val_mae: 0.8253 - val_mse: 1.1107\n",
      "Epoch 183/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6991 - mae: 0.6524 - mse: 0.6991 - val_loss: 1.3688 - val_mae: 0.9073 - val_mse: 1.3688\n",
      "Epoch 184/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4573 - mae: 0.5121 - mse: 0.4573 - val_loss: 1.2436 - val_mae: 0.8830 - val_mse: 1.2436\n",
      "Epoch 185/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5780 - mae: 0.5984 - mse: 0.5780 - val_loss: 1.1279 - val_mae: 0.8573 - val_mse: 1.1279\n",
      "Epoch 186/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4934 - mae: 0.5490 - mse: 0.4934 - val_loss: 1.1013 - val_mae: 0.7998 - val_mse: 1.1013\n",
      "Epoch 187/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4491 - mae: 0.5045 - mse: 0.4491 - val_loss: 1.0786 - val_mae: 0.8159 - val_mse: 1.0786\n",
      "Epoch 188/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5631 - mae: 0.5711 - mse: 0.5631 - val_loss: 1.0271 - val_mae: 0.7964 - val_mse: 1.0271\n",
      "Epoch 189/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4117 - mae: 0.4891 - mse: 0.4117 - val_loss: 1.2449 - val_mae: 0.8571 - val_mse: 1.2449\n",
      "Epoch 190/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6245 - mae: 0.6123 - mse: 0.6245 - val_loss: 0.9444 - val_mae: 0.7686 - val_mse: 0.9444\n",
      "Epoch 191/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4945 - mae: 0.5413 - mse: 0.4945 - val_loss: 1.5771 - val_mae: 0.9688 - val_mse: 1.5771\n",
      "Epoch 192/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4928 - mae: 0.5321 - mse: 0.4928 - val_loss: 1.8114 - val_mae: 1.0781 - val_mse: 1.8114\n",
      "Epoch 193/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5002 - mae: 0.5411 - mse: 0.5002 - val_loss: 1.2223 - val_mae: 0.8558 - val_mse: 1.2223\n",
      "Epoch 194/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4805 - mae: 0.5148 - mse: 0.4805 - val_loss: 1.1147 - val_mae: 0.8237 - val_mse: 1.1147\n",
      "Epoch 195/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4919 - mae: 0.5283 - mse: 0.4919 - val_loss: 1.2166 - val_mae: 0.8642 - val_mse: 1.2166\n",
      "Epoch 196/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5911 - mae: 0.6070 - mse: 0.5911 - val_loss: 1.5894 - val_mae: 0.9996 - val_mse: 1.5894\n",
      "Kappa Score: 0.5539468856715491\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Epoch 1/1000\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 161.1959 - mae: 6.1395 - mse: 161.1959 - val_loss: 5.1567 - val_mae: 1.6921 - val_mse: 5.1567\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 33.6333 - mae: 4.8052 - mse: 33.6333 - val_loss: 44.1960 - val_mae: 6.5158 - val_mse: 44.1960\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 18.1117 - mae: 3.2190 - mse: 18.1117 - val_loss: 82.4003 - val_mae: 8.1311 - val_mse: 82.4003\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 12.4214 - mae: 2.4456 - mse: 12.4214 - val_loss: 69.7264 - val_mae: 8.1367 - val_mse: 69.7264\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 21.5988 - mae: 3.1612 - mse: 21.5988 - val_loss: 6.1131 - val_mae: 2.2415 - val_mse: 6.1131\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 13.9669 - mae: 3.2233 - mse: 13.9669 - val_loss: 4.7657 - val_mae: 1.7634 - val_mse: 4.7657\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.5825 - mae: 2.5376 - mse: 8.5825 - val_loss: 12.9836 - val_mae: 3.4603 - val_mse: 12.9836\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.7595 - mae: 2.1438 - mse: 6.7595 - val_loss: 8.9986 - val_mae: 2.4978 - val_mse: 8.9986\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 6.0225 - mae: 2.1015 - mse: 6.0225 - val_loss: 8.5933 - val_mae: 2.6951 - val_mse: 8.5933\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 5.0371 - mae: 1.7960 - mse: 5.0371 - val_loss: 3.9994 - val_mae: 1.7505 - val_mse: 3.9994\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.1647 - mae: 1.3308 - mse: 3.1647 - val_loss: 8.4316 - val_mae: 2.4062 - val_mse: 8.4316\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 4.6351 - mae: 1.7575 - mse: 4.6351 - val_loss: 2.5346 - val_mae: 1.1920 - val_mse: 2.5346\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2841 - mae: 1.3651 - mse: 3.2841 - val_loss: 1.4888 - val_mae: 0.9267 - val_mse: 1.4888\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.8156 - mae: 1.3009 - mse: 2.8156 - val_loss: 1.5469 - val_mae: 0.9392 - val_mse: 1.5469\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.2386 - mae: 1.2088 - mse: 2.2386 - val_loss: 1.8190 - val_mae: 1.0431 - val_mse: 1.8190\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.2099 - mae: 1.3505 - mse: 3.2099 - val_loss: 2.1227 - val_mae: 1.1205 - val_mse: 2.1227\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.7069 - mae: 1.2958 - mse: 2.7069 - val_loss: 1.8492 - val_mae: 1.0542 - val_mse: 1.8492\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9801 - mae: 1.1028 - mse: 1.9801 - val_loss: 3.8598 - val_mae: 1.5841 - val_mse: 3.8598\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.7020 - mae: 1.3179 - mse: 2.7020 - val_loss: 3.3069 - val_mae: 1.3650 - val_mse: 3.3069\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7708 - mae: 1.0458 - mse: 1.7708 - val_loss: 1.8832 - val_mae: 1.0435 - val_mse: 1.8832\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.2609 - mae: 1.2010 - mse: 2.2609 - val_loss: 2.1767 - val_mae: 1.1973 - val_mse: 2.1767\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.0956 - mae: 1.0980 - mse: 2.0956 - val_loss: 1.2841 - val_mae: 0.8689 - val_mse: 1.2841\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0469 - mae: 1.1080 - mse: 2.0469 - val_loss: 1.4758 - val_mae: 0.9375 - val_mse: 1.4758\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9051 - mae: 1.1037 - mse: 1.9051 - val_loss: 3.0162 - val_mae: 1.4618 - val_mse: 3.0162\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7639 - mae: 1.0607 - mse: 1.7639 - val_loss: 3.6632 - val_mae: 1.6672 - val_mse: 3.6632\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.0332 - mae: 1.1318 - mse: 2.0332 - val_loss: 2.2312 - val_mae: 1.1890 - val_mse: 2.2312\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5041 - mae: 0.9499 - mse: 1.5041 - val_loss: 1.3962 - val_mae: 0.9066 - val_mse: 1.3962\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.8658 - mae: 1.0812 - mse: 1.8658 - val_loss: 2.2282 - val_mae: 1.2274 - val_mse: 2.2282\n",
      "Epoch 29/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.8607 - mae: 1.1008 - mse: 1.8607 - val_loss: 1.3787 - val_mae: 0.9077 - val_mse: 1.3787\n",
      "Epoch 30/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7461 - mae: 1.0381 - mse: 1.7461 - val_loss: 2.6058 - val_mae: 1.2200 - val_mse: 2.6058\n",
      "Epoch 31/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6740 - mae: 0.9908 - mse: 1.6740 - val_loss: 1.4871 - val_mae: 0.9287 - val_mse: 1.4871\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5654 - mae: 0.9858 - mse: 1.5654 - val_loss: 1.8624 - val_mae: 1.0820 - val_mse: 1.8624\n",
      "Epoch 33/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5084 - mae: 0.9514 - mse: 1.5084 - val_loss: 3.5528 - val_mae: 1.5455 - val_mse: 3.5528\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.8143 - mae: 1.0457 - mse: 1.8143 - val_loss: 1.3695 - val_mae: 0.9290 - val_mse: 1.3695\n",
      "Epoch 35/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3662 - mae: 0.9151 - mse: 1.3662 - val_loss: 1.9451 - val_mae: 1.1270 - val_mse: 1.9451\n",
      "Epoch 36/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5808 - mae: 0.9972 - mse: 1.5808 - val_loss: 3.5661 - val_mae: 1.5220 - val_mse: 3.5661\n",
      "Epoch 37/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6316 - mae: 0.9879 - mse: 1.6316 - val_loss: 2.7292 - val_mae: 1.3049 - val_mse: 2.7292\n",
      "Epoch 38/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6149 - mae: 1.0160 - mse: 1.6149 - val_loss: 3.6944 - val_mae: 1.6945 - val_mse: 3.6944\n",
      "Epoch 39/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3674 - mae: 0.9269 - mse: 1.3674 - val_loss: 2.4361 - val_mae: 1.2316 - val_mse: 2.4361\n",
      "Epoch 40/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5878 - mae: 0.9801 - mse: 1.5878 - val_loss: 1.3358 - val_mae: 0.8752 - val_mse: 1.3358\n",
      "Epoch 41/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6628 - mae: 1.0162 - mse: 1.6628 - val_loss: 1.1744 - val_mae: 0.8229 - val_mse: 1.1744\n",
      "Epoch 42/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3112 - mae: 0.8865 - mse: 1.3112 - val_loss: 1.7666 - val_mae: 1.0748 - val_mse: 1.7666\n",
      "Epoch 43/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2045 - mae: 0.8732 - mse: 1.2045 - val_loss: 1.6156 - val_mae: 1.0077 - val_mse: 1.6156\n",
      "Epoch 44/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6237 - mae: 1.0123 - mse: 1.6237 - val_loss: 1.3939 - val_mae: 0.9235 - val_mse: 1.3939\n",
      "Epoch 45/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2512 - mae: 0.8589 - mse: 1.2512 - val_loss: 1.6489 - val_mae: 1.0308 - val_mse: 1.6489\n",
      "Epoch 46/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2176 - mae: 0.8408 - mse: 1.2176 - val_loss: 1.2246 - val_mae: 0.8828 - val_mse: 1.2246\n",
      "Epoch 47/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1994 - mae: 0.8420 - mse: 1.1994 - val_loss: 3.0746 - val_mae: 1.5305 - val_mse: 3.0746\n",
      "Epoch 48/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3725 - mae: 0.9004 - mse: 1.3725 - val_loss: 1.5680 - val_mae: 0.9694 - val_mse: 1.5680\n",
      "Epoch 49/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1520 - mae: 0.8396 - mse: 1.1520 - val_loss: 1.0874 - val_mae: 0.8155 - val_mse: 1.0874\n",
      "Epoch 50/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3333 - mae: 0.9123 - mse: 1.3333 - val_loss: 1.6147 - val_mae: 1.0277 - val_mse: 1.6147\n",
      "Epoch 51/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1680 - mae: 0.8388 - mse: 1.1680 - val_loss: 1.6838 - val_mae: 1.0314 - val_mse: 1.6838\n",
      "Epoch 52/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4138 - mae: 0.9380 - mse: 1.4138 - val_loss: 1.3561 - val_mae: 0.9216 - val_mse: 1.3561\n",
      "Epoch 53/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1018 - mae: 0.8204 - mse: 1.1018 - val_loss: 1.9429 - val_mae: 1.1195 - val_mse: 1.9429\n",
      "Epoch 54/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1699 - mae: 0.8421 - mse: 1.1699 - val_loss: 1.0221 - val_mae: 0.7754 - val_mse: 1.0221\n",
      "Epoch 55/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3779 - mae: 0.9066 - mse: 1.3779 - val_loss: 1.9685 - val_mae: 1.1430 - val_mse: 1.9685\n",
      "Epoch 56/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5335 - mae: 0.9831 - mse: 1.5335 - val_loss: 1.1074 - val_mae: 0.8158 - val_mse: 1.1074\n",
      "Epoch 57/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2264 - mae: 0.8507 - mse: 1.2264 - val_loss: 1.2763 - val_mae: 0.8804 - val_mse: 1.2763\n",
      "Epoch 58/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2537 - mae: 0.8349 - mse: 1.2537 - val_loss: 1.7149 - val_mae: 1.0611 - val_mse: 1.7149\n",
      "Epoch 59/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2564 - mae: 0.8487 - mse: 1.2564 - val_loss: 1.5301 - val_mae: 1.0053 - val_mse: 1.5301\n",
      "Epoch 60/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2286 - mae: 0.8616 - mse: 1.2286 - val_loss: 1.6382 - val_mae: 1.0729 - val_mse: 1.6382\n",
      "Epoch 61/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2550 - mae: 0.8906 - mse: 1.2550 - val_loss: 1.7468 - val_mae: 1.0487 - val_mse: 1.7468\n",
      "Epoch 62/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9421 - mae: 0.7621 - mse: 0.9421 - val_loss: 1.9885 - val_mae: 1.1693 - val_mse: 1.9885\n",
      "Epoch 63/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2366 - mae: 0.8611 - mse: 1.2366 - val_loss: 1.1332 - val_mae: 0.8301 - val_mse: 1.1332\n",
      "Epoch 64/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2132 - mae: 0.8587 - mse: 1.2132 - val_loss: 1.2541 - val_mae: 0.8811 - val_mse: 1.2541\n",
      "Epoch 65/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2418 - mae: 0.8660 - mse: 1.2418 - val_loss: 1.0360 - val_mae: 0.7961 - val_mse: 1.0360\n",
      "Epoch 66/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1844 - mae: 0.8147 - mse: 1.1844 - val_loss: 1.1286 - val_mae: 0.8240 - val_mse: 1.1286\n",
      "Epoch 67/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2922 - mae: 0.8973 - mse: 1.2922 - val_loss: 1.3087 - val_mae: 0.9260 - val_mse: 1.3087\n",
      "Epoch 68/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2857 - mae: 0.8710 - mse: 1.2857 - val_loss: 1.8456 - val_mae: 1.1319 - val_mse: 1.8456\n",
      "Epoch 69/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0732 - mae: 0.8074 - mse: 1.0732 - val_loss: 2.3038 - val_mae: 1.2060 - val_mse: 2.3038\n",
      "Epoch 70/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3175 - mae: 0.8916 - mse: 1.3175 - val_loss: 1.0683 - val_mae: 0.8152 - val_mse: 1.0683\n",
      "Epoch 71/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9771 - mae: 0.7709 - mse: 0.9771 - val_loss: 0.9904 - val_mae: 0.7799 - val_mse: 0.9904\n",
      "Epoch 72/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1869 - mae: 0.8618 - mse: 1.1869 - val_loss: 1.1048 - val_mae: 0.8289 - val_mse: 1.1048\n",
      "Epoch 73/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1074 - mae: 0.7996 - mse: 1.1074 - val_loss: 1.4433 - val_mae: 0.9618 - val_mse: 1.4433\n",
      "Epoch 74/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2302 - mae: 0.8576 - mse: 1.2302 - val_loss: 1.4475 - val_mae: 0.9559 - val_mse: 1.4475\n",
      "Epoch 75/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0696 - mae: 0.8115 - mse: 1.0696 - val_loss: 1.1364 - val_mae: 0.8337 - val_mse: 1.1364\n",
      "Epoch 76/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0870 - mae: 0.8123 - mse: 1.0870 - val_loss: 1.5112 - val_mae: 1.0025 - val_mse: 1.5112\n",
      "Epoch 77/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2681 - mae: 0.8802 - mse: 1.2681 - val_loss: 1.3670 - val_mae: 0.9127 - val_mse: 1.3670\n",
      "Epoch 78/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0398 - mae: 0.7940 - mse: 1.0398 - val_loss: 1.2678 - val_mae: 0.8959 - val_mse: 1.2678\n",
      "Epoch 79/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0978 - mae: 0.8293 - mse: 1.0978 - val_loss: 1.2609 - val_mae: 0.8994 - val_mse: 1.2609\n",
      "Epoch 80/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1123 - mae: 0.8256 - mse: 1.1123 - val_loss: 1.2607 - val_mae: 0.8841 - val_mse: 1.2607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1913 - mae: 0.8510 - mse: 1.1913 - val_loss: 1.3478 - val_mae: 0.9297 - val_mse: 1.3478\n",
      "Epoch 82/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8715 - mae: 0.7297 - mse: 0.8715 - val_loss: 2.4919 - val_mae: 1.3622 - val_mse: 2.4919\n",
      "Epoch 83/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2259 - mae: 0.8729 - mse: 1.2259 - val_loss: 1.2775 - val_mae: 0.8934 - val_mse: 1.2775\n",
      "Epoch 84/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8440 - mae: 0.7027 - mse: 0.8440 - val_loss: 1.0399 - val_mae: 0.7897 - val_mse: 1.0399\n",
      "Epoch 85/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1865 - mae: 0.8366 - mse: 1.1865 - val_loss: 2.5990 - val_mae: 1.3066 - val_mse: 2.5990\n",
      "Epoch 86/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9618 - mae: 0.7452 - mse: 0.9618 - val_loss: 1.0712 - val_mae: 0.8039 - val_mse: 1.0712\n",
      "Epoch 87/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0066 - mae: 0.7907 - mse: 1.0066 - val_loss: 1.0076 - val_mae: 0.8039 - val_mse: 1.0076\n",
      "Epoch 88/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2973 - mae: 0.8889 - mse: 1.2973 - val_loss: 1.0853 - val_mae: 0.8331 - val_mse: 1.0853\n",
      "Epoch 89/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8809 - mae: 0.7149 - mse: 0.8809 - val_loss: 1.4153 - val_mae: 0.9459 - val_mse: 1.4153\n",
      "Epoch 90/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1042 - mae: 0.8254 - mse: 1.1042 - val_loss: 1.8779 - val_mae: 1.1347 - val_mse: 1.8779\n",
      "Epoch 91/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9571 - mae: 0.7483 - mse: 0.9571 - val_loss: 2.3217 - val_mae: 1.2728 - val_mse: 2.3217\n",
      "Epoch 92/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9942 - mae: 0.7881 - mse: 0.9942 - val_loss: 1.3506 - val_mae: 0.9189 - val_mse: 1.3506\n",
      "Epoch 93/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0901 - mae: 0.7974 - mse: 1.0901 - val_loss: 1.8568 - val_mae: 1.0835 - val_mse: 1.8568\n",
      "Epoch 94/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2012 - mae: 0.8444 - mse: 1.2012 - val_loss: 1.6063 - val_mae: 1.0327 - val_mse: 1.6063\n",
      "Epoch 95/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8683 - mae: 0.7223 - mse: 0.8683 - val_loss: 0.9701 - val_mae: 0.7705 - val_mse: 0.9701\n",
      "Epoch 96/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0610 - mae: 0.7946 - mse: 1.0610 - val_loss: 1.2983 - val_mae: 0.9031 - val_mse: 1.2983\n",
      "Epoch 97/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0493 - mae: 0.8134 - mse: 1.0493 - val_loss: 1.6509 - val_mae: 1.0270 - val_mse: 1.6509\n",
      "Epoch 98/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0842 - mae: 0.8030 - mse: 1.0842 - val_loss: 1.0096 - val_mae: 0.8146 - val_mse: 1.0096\n",
      "Epoch 99/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8617 - mae: 0.7127 - mse: 0.8617 - val_loss: 2.6343 - val_mae: 1.4131 - val_mse: 2.6343\n",
      "Epoch 100/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0730 - mae: 0.8090 - mse: 1.0730 - val_loss: 1.2826 - val_mae: 0.9089 - val_mse: 1.2826\n",
      "Epoch 101/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0096 - mae: 0.7768 - mse: 1.0096 - val_loss: 1.1613 - val_mae: 0.8300 - val_mse: 1.1613\n",
      "Epoch 102/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9266 - mae: 0.7453 - mse: 0.9266 - val_loss: 1.3864 - val_mae: 0.9415 - val_mse: 1.3864\n",
      "Epoch 103/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8118 - mae: 0.6975 - mse: 0.8118 - val_loss: 1.4921 - val_mae: 0.9800 - val_mse: 1.4921\n",
      "Epoch 104/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1295 - mae: 0.8275 - mse: 1.1295 - val_loss: 0.9598 - val_mae: 0.7954 - val_mse: 0.9598\n",
      "Epoch 105/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8459 - mae: 0.7144 - mse: 0.8459 - val_loss: 1.0542 - val_mae: 0.7970 - val_mse: 1.0542\n",
      "Epoch 106/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0661 - mae: 0.8018 - mse: 1.0661 - val_loss: 1.2996 - val_mae: 0.9068 - val_mse: 1.2996\n",
      "Epoch 107/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8548 - mae: 0.7040 - mse: 0.8548 - val_loss: 0.9828 - val_mae: 0.7685 - val_mse: 0.9828\n",
      "Epoch 108/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9507 - mae: 0.7401 - mse: 0.9507 - val_loss: 1.1304 - val_mae: 0.8489 - val_mse: 1.1304\n",
      "Epoch 109/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9706 - mae: 0.7632 - mse: 0.9706 - val_loss: 0.9327 - val_mae: 0.7659 - val_mse: 0.9327\n",
      "Epoch 110/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9606 - mae: 0.7686 - mse: 0.9606 - val_loss: 0.9611 - val_mae: 0.7845 - val_mse: 0.9611\n",
      "Epoch 111/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8559 - mae: 0.7129 - mse: 0.8559 - val_loss: 1.0300 - val_mae: 0.7958 - val_mse: 1.0300\n",
      "Epoch 112/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.1005 - mae: 0.7975 - mse: 1.1005 - val_loss: 1.4007 - val_mae: 0.9432 - val_mse: 1.4007\n",
      "Epoch 113/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6873 - mae: 0.6378 - mse: 0.6873 - val_loss: 1.2559 - val_mae: 0.8960 - val_mse: 1.2559\n",
      "Epoch 114/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9804 - mae: 0.7709 - mse: 0.9804 - val_loss: 1.3244 - val_mae: 0.9021 - val_mse: 1.3244\n",
      "Epoch 115/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0404 - mae: 0.7989 - mse: 1.0404 - val_loss: 1.4592 - val_mae: 0.9638 - val_mse: 1.4592\n",
      "Epoch 116/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8680 - mae: 0.7143 - mse: 0.8680 - val_loss: 1.8755 - val_mae: 1.0983 - val_mse: 1.8755\n",
      "Epoch 117/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7463 - mae: 0.6674 - mse: 0.7463 - val_loss: 1.2472 - val_mae: 0.9115 - val_mse: 1.2472\n",
      "Epoch 118/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8938 - mae: 0.7382 - mse: 0.8938 - val_loss: 1.1628 - val_mae: 0.8572 - val_mse: 1.1628\n",
      "Epoch 119/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8406 - mae: 0.7130 - mse: 0.8406 - val_loss: 0.9440 - val_mae: 0.7634 - val_mse: 0.9440\n",
      "Epoch 120/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9480 - mae: 0.7553 - mse: 0.9480 - val_loss: 1.8980 - val_mae: 1.1356 - val_mse: 1.8980\n",
      "Epoch 121/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8757 - mae: 0.7338 - mse: 0.8757 - val_loss: 1.4775 - val_mae: 0.9543 - val_mse: 1.4775\n",
      "Epoch 122/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8667 - mae: 0.7277 - mse: 0.8667 - val_loss: 1.8186 - val_mae: 1.1124 - val_mse: 1.8186\n",
      "Epoch 123/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8711 - mae: 0.7185 - mse: 0.8711 - val_loss: 1.1497 - val_mae: 0.8663 - val_mse: 1.1497\n",
      "Epoch 124/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8004 - mae: 0.7083 - mse: 0.8004 - val_loss: 1.5344 - val_mae: 0.9993 - val_mse: 1.5344\n",
      "Epoch 125/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9080 - mae: 0.7413 - mse: 0.9080 - val_loss: 0.9530 - val_mae: 0.7630 - val_mse: 0.9530\n",
      "Epoch 126/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9332 - mae: 0.7484 - mse: 0.9332 - val_loss: 0.9053 - val_mae: 0.7469 - val_mse: 0.9053\n",
      "Epoch 127/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7956 - mae: 0.6642 - mse: 0.7956 - val_loss: 0.9424 - val_mae: 0.7534 - val_mse: 0.9424\n",
      "Epoch 128/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8743 - mae: 0.7210 - mse: 0.8743 - val_loss: 0.9656 - val_mae: 0.7663 - val_mse: 0.9656\n",
      "Epoch 129/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6042 - mae: 0.6072 - mse: 0.6042 - val_loss: 1.8481 - val_mae: 1.1218 - val_mse: 1.8481\n",
      "Epoch 130/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9758 - mae: 0.7523 - mse: 0.9758 - val_loss: 1.0311 - val_mae: 0.7937 - val_mse: 1.0311\n",
      "Epoch 131/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8805 - mae: 0.7387 - mse: 0.8805 - val_loss: 1.8392 - val_mae: 1.1226 - val_mse: 1.8392\n",
      "Epoch 132/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7382 - mae: 0.6455 - mse: 0.7382 - val_loss: 1.1320 - val_mae: 0.8647 - val_mse: 1.1320\n",
      "Epoch 133/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9673 - mae: 0.7841 - mse: 0.9673 - val_loss: 1.2977 - val_mae: 0.9041 - val_mse: 1.2977\n",
      "Epoch 134/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9463 - mae: 0.7564 - mse: 0.9463 - val_loss: 0.8847 - val_mae: 0.7616 - val_mse: 0.8847\n",
      "Epoch 135/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7266 - mae: 0.6362 - mse: 0.7266 - val_loss: 0.9724 - val_mae: 0.7815 - val_mse: 0.9724\n",
      "Epoch 136/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9854 - mae: 0.7568 - mse: 0.9854 - val_loss: 1.5972 - val_mae: 1.0110 - val_mse: 1.5972\n",
      "Epoch 137/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7451 - mae: 0.6792 - mse: 0.7451 - val_loss: 1.4492 - val_mae: 0.9815 - val_mse: 1.4492\n",
      "Epoch 138/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7386 - mae: 0.6669 - mse: 0.7386 - val_loss: 1.0331 - val_mae: 0.8093 - val_mse: 1.0331\n",
      "Epoch 139/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7375 - mae: 0.6563 - mse: 0.7375 - val_loss: 0.9409 - val_mae: 0.7816 - val_mse: 0.9409\n",
      "Epoch 140/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8244 - mae: 0.7021 - mse: 0.8244 - val_loss: 0.9016 - val_mae: 0.7643 - val_mse: 0.9016\n",
      "Epoch 141/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7788 - mae: 0.6731 - mse: 0.7788 - val_loss: 0.9048 - val_mae: 0.7664 - val_mse: 0.9048\n",
      "Epoch 142/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8221 - mae: 0.6888 - mse: 0.8221 - val_loss: 0.9600 - val_mae: 0.7632 - val_mse: 0.9600\n",
      "Epoch 143/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6830 - mae: 0.6523 - mse: 0.6830 - val_loss: 1.6451 - val_mae: 1.0085 - val_mse: 1.6451\n",
      "Epoch 144/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8426 - mae: 0.7236 - mse: 0.8426 - val_loss: 0.8759 - val_mae: 0.7388 - val_mse: 0.8759\n",
      "Epoch 145/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8149 - mae: 0.6701 - mse: 0.8149 - val_loss: 0.9316 - val_mae: 0.7581 - val_mse: 0.9316\n",
      "Epoch 146/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6763 - mae: 0.6292 - mse: 0.6763 - val_loss: 1.3057 - val_mae: 0.8976 - val_mse: 1.3057\n",
      "Epoch 147/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7842 - mae: 0.6868 - mse: 0.7842 - val_loss: 1.2880 - val_mae: 0.9167 - val_mse: 1.2880\n",
      "Epoch 148/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6790 - mae: 0.6449 - mse: 0.6790 - val_loss: 1.5689 - val_mae: 1.0029 - val_mse: 1.5689\n",
      "Epoch 149/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8583 - mae: 0.7018 - mse: 0.8583 - val_loss: 2.0254 - val_mae: 1.1414 - val_mse: 2.0254\n",
      "Epoch 150/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7661 - mae: 0.6822 - mse: 0.7661 - val_loss: 1.2041 - val_mae: 0.8897 - val_mse: 1.2041\n",
      "Epoch 151/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7170 - mae: 0.6500 - mse: 0.7170 - val_loss: 1.0278 - val_mae: 0.8033 - val_mse: 1.0278\n",
      "Epoch 152/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7612 - mae: 0.6689 - mse: 0.7612 - val_loss: 1.5751 - val_mae: 1.0024 - val_mse: 1.5751\n",
      "Epoch 153/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6607 - mae: 0.6199 - mse: 0.6607 - val_loss: 1.0213 - val_mae: 0.7732 - val_mse: 1.0213\n",
      "Epoch 154/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6897 - mae: 0.6445 - mse: 0.6897 - val_loss: 1.5883 - val_mae: 1.0280 - val_mse: 1.5883\n",
      "Epoch 155/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6832 - mae: 0.6295 - mse: 0.6832 - val_loss: 1.0257 - val_mae: 0.8017 - val_mse: 1.0257\n",
      "Epoch 156/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8229 - mae: 0.7118 - mse: 0.8229 - val_loss: 1.1242 - val_mae: 0.8399 - val_mse: 1.1242\n",
      "Epoch 157/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6601 - mae: 0.6429 - mse: 0.6601 - val_loss: 1.0004 - val_mae: 0.7738 - val_mse: 1.0004\n",
      "Epoch 158/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7113 - mae: 0.6644 - mse: 0.7113 - val_loss: 0.9695 - val_mae: 0.7729 - val_mse: 0.9695\n",
      "Epoch 159/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7348 - mae: 0.6783 - mse: 0.7348 - val_loss: 0.9717 - val_mae: 0.7669 - val_mse: 0.9717\n",
      "Epoch 160/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7529 - mae: 0.6685 - mse: 0.7529 - val_loss: 0.9363 - val_mae: 0.7589 - val_mse: 0.9363\n",
      "Epoch 161/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6812 - mae: 0.6207 - mse: 0.6812 - val_loss: 1.8826 - val_mae: 1.1093 - val_mse: 1.8826\n",
      "Epoch 162/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6693 - mae: 0.6349 - mse: 0.6693 - val_loss: 0.9815 - val_mae: 0.7747 - val_mse: 0.9815\n",
      "Epoch 163/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7604 - mae: 0.6872 - mse: 0.7604 - val_loss: 1.4256 - val_mae: 0.9258 - val_mse: 1.4256\n",
      "Epoch 164/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6650 - mae: 0.6388 - mse: 0.6650 - val_loss: 1.3793 - val_mae: 0.9204 - val_mse: 1.3793\n",
      "Epoch 165/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7144 - mae: 0.6614 - mse: 0.7144 - val_loss: 1.6297 - val_mae: 1.0068 - val_mse: 1.6297\n",
      "Epoch 166/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7347 - mae: 0.6472 - mse: 0.7347 - val_loss: 1.1545 - val_mae: 0.8184 - val_mse: 1.1545\n",
      "Epoch 167/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5890 - mae: 0.6036 - mse: 0.5890 - val_loss: 0.9761 - val_mae: 0.7803 - val_mse: 0.9761\n",
      "Epoch 168/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6228 - mae: 0.6158 - mse: 0.6228 - val_loss: 1.0382 - val_mae: 0.7942 - val_mse: 1.0382\n",
      "Epoch 169/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7174 - mae: 0.6539 - mse: 0.7174 - val_loss: 1.1317 - val_mae: 0.8384 - val_mse: 1.1317\n",
      "Epoch 170/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7739 - mae: 0.6864 - mse: 0.7739 - val_loss: 1.1825 - val_mae: 0.8502 - val_mse: 1.1825\n",
      "Epoch 171/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6876 - mae: 0.6309 - mse: 0.6876 - val_loss: 1.0714 - val_mae: 0.8206 - val_mse: 1.0714\n",
      "Epoch 172/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6690 - mae: 0.6161 - mse: 0.6690 - val_loss: 1.0735 - val_mae: 0.8000 - val_mse: 1.0735\n",
      "Epoch 173/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6100 - mae: 0.6087 - mse: 0.6100 - val_loss: 1.0691 - val_mae: 0.8047 - val_mse: 1.0691\n",
      "Epoch 174/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6167 - mae: 0.5931 - mse: 0.6167 - val_loss: 1.2604 - val_mae: 0.8915 - val_mse: 1.2604\n",
      "Epoch 175/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7636 - mae: 0.6823 - mse: 0.7636 - val_loss: 1.0505 - val_mae: 0.8081 - val_mse: 1.0505\n",
      "Epoch 176/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6554 - mae: 0.6243 - mse: 0.6554 - val_loss: 1.1047 - val_mae: 0.8336 - val_mse: 1.1047\n",
      "Epoch 177/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6529 - mae: 0.6195 - mse: 0.6529 - val_loss: 1.0117 - val_mae: 0.7936 - val_mse: 1.0117\n",
      "Epoch 178/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5348 - mae: 0.5744 - mse: 0.5348 - val_loss: 2.1807 - val_mae: 1.2281 - val_mse: 2.1807\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7000 - mae: 0.6392 - mse: 0.7000 - val_loss: 1.3437 - val_mae: 0.9056 - val_mse: 1.3437\n",
      "Epoch 180/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6303 - mae: 0.6212 - mse: 0.6303 - val_loss: 0.9885 - val_mae: 0.7800 - val_mse: 0.9885\n",
      "Epoch 181/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7056 - mae: 0.6372 - mse: 0.7056 - val_loss: 1.0520 - val_mae: 0.8144 - val_mse: 1.0520\n",
      "Epoch 182/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6149 - mae: 0.6228 - mse: 0.6149 - val_loss: 1.0682 - val_mae: 0.7904 - val_mse: 1.0682\n",
      "Epoch 183/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5835 - mae: 0.6009 - mse: 0.5835 - val_loss: 0.9440 - val_mae: 0.7621 - val_mse: 0.9440\n",
      "Epoch 184/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6609 - mae: 0.6298 - mse: 0.6609 - val_loss: 0.9835 - val_mae: 0.7813 - val_mse: 0.9835\n",
      "Epoch 185/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7538 - mae: 0.6590 - mse: 0.7538 - val_loss: 1.4134 - val_mae: 0.9354 - val_mse: 1.4134\n",
      "Epoch 186/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5730 - mae: 0.5835 - mse: 0.5730 - val_loss: 0.9923 - val_mae: 0.7793 - val_mse: 0.9923\n",
      "Epoch 187/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6569 - mae: 0.6082 - mse: 0.6569 - val_loss: 1.0497 - val_mae: 0.7972 - val_mse: 1.0497\n",
      "Epoch 188/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5021 - mae: 0.5494 - mse: 0.5021 - val_loss: 1.5419 - val_mae: 0.9951 - val_mse: 1.5419\n",
      "Epoch 189/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5632 - mae: 0.5724 - mse: 0.5632 - val_loss: 2.2327 - val_mae: 1.2249 - val_mse: 2.2327\n",
      "Epoch 190/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5256 - mae: 0.5567 - mse: 0.5256 - val_loss: 1.2395 - val_mae: 0.8857 - val_mse: 1.2395\n",
      "Epoch 191/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7165 - mae: 0.6558 - mse: 0.7165 - val_loss: 1.4003 - val_mae: 0.9207 - val_mse: 1.4003\n",
      "Epoch 192/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7467 - mae: 0.6778 - mse: 0.7467 - val_loss: 1.1422 - val_mae: 0.8365 - val_mse: 1.1422\n",
      "Epoch 193/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6092 - mae: 0.5932 - mse: 0.6092 - val_loss: 0.9880 - val_mae: 0.7767 - val_mse: 0.9880\n",
      "Epoch 194/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4676 - mae: 0.5294 - mse: 0.4676 - val_loss: 1.7718 - val_mae: 1.0753 - val_mse: 1.7718\n",
      "Epoch 195/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6547 - mae: 0.6290 - mse: 0.6547 - val_loss: 1.2074 - val_mae: 0.8639 - val_mse: 1.2074\n",
      "Epoch 196/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7129 - mae: 0.6652 - mse: 0.7129 - val_loss: 1.1754 - val_mae: 0.8292 - val_mse: 1.1754\n",
      "Epoch 197/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5791 - mae: 0.5882 - mse: 0.5791 - val_loss: 2.0150 - val_mae: 1.1553 - val_mse: 2.0150\n",
      "Epoch 198/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5672 - mae: 0.5632 - mse: 0.5672 - val_loss: 2.4116 - val_mae: 1.2619 - val_mse: 2.4116\n",
      "Epoch 199/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6265 - mae: 0.5917 - mse: 0.6265 - val_loss: 1.0712 - val_mae: 0.8057 - val_mse: 1.0712\n",
      "Epoch 200/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6546 - mae: 0.6217 - mse: 0.6546 - val_loss: 1.1767 - val_mae: 0.8702 - val_mse: 1.1767\n",
      "Epoch 201/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4091 - mae: 0.4825 - mse: 0.4091 - val_loss: 1.3007 - val_mae: 0.9082 - val_mse: 1.3007\n",
      "Epoch 202/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5337 - mae: 0.5543 - mse: 0.5337 - val_loss: 1.0811 - val_mae: 0.8145 - val_mse: 1.0811\n",
      "Epoch 203/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6001 - mae: 0.5738 - mse: 0.6001 - val_loss: 1.3016 - val_mae: 0.9105 - val_mse: 1.3016\n",
      "Epoch 204/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6671 - mae: 0.6413 - mse: 0.6671 - val_loss: 1.5199 - val_mae: 0.9733 - val_mse: 1.5199\n",
      "Epoch 205/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6382 - mae: 0.6335 - mse: 0.6382 - val_loss: 1.0334 - val_mae: 0.8011 - val_mse: 1.0334\n",
      "Epoch 206/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5403 - mae: 0.5756 - mse: 0.5403 - val_loss: 1.1070 - val_mae: 0.8359 - val_mse: 1.1070\n",
      "Epoch 207/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5442 - mae: 0.5747 - mse: 0.5442 - val_loss: 1.4679 - val_mae: 0.9503 - val_mse: 1.4679\n",
      "Epoch 208/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4308 - mae: 0.4950 - mse: 0.4308 - val_loss: 1.1781 - val_mae: 0.8389 - val_mse: 1.1781\n",
      "Epoch 209/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5949 - mae: 0.5965 - mse: 0.5949 - val_loss: 1.0361 - val_mae: 0.7866 - val_mse: 1.0361\n",
      "Epoch 210/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5486 - mae: 0.5678 - mse: 0.5486 - val_loss: 1.2618 - val_mae: 0.8712 - val_mse: 1.2618\n",
      "Epoch 211/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6127 - mae: 0.6054 - mse: 0.6127 - val_loss: 1.8923 - val_mae: 1.1012 - val_mse: 1.8923\n",
      "Epoch 212/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4092 - mae: 0.4879 - mse: 0.4092 - val_loss: 1.6344 - val_mae: 1.0284 - val_mse: 1.6344\n",
      "Epoch 213/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5210 - mae: 0.5546 - mse: 0.5210 - val_loss: 1.4296 - val_mae: 0.9339 - val_mse: 1.4296\n",
      "Epoch 214/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6451 - mae: 0.6316 - mse: 0.6451 - val_loss: 1.2016 - val_mae: 0.8663 - val_mse: 1.2016\n",
      "Epoch 215/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5680 - mae: 0.5652 - mse: 0.5680 - val_loss: 1.0762 - val_mae: 0.8003 - val_mse: 1.0762\n",
      "Epoch 216/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4672 - mae: 0.5356 - mse: 0.4672 - val_loss: 1.0923 - val_mae: 0.8137 - val_mse: 1.0923\n",
      "Epoch 217/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6001 - mae: 0.5733 - mse: 0.6001 - val_loss: 1.1244 - val_mae: 0.8340 - val_mse: 1.1244\n",
      "Epoch 218/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6504 - mae: 0.5927 - mse: 0.6504 - val_loss: 1.0596 - val_mae: 0.7987 - val_mse: 1.0596\n",
      "Epoch 219/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5612 - mae: 0.5565 - mse: 0.5612 - val_loss: 1.1212 - val_mae: 0.8170 - val_mse: 1.1212\n",
      "Epoch 220/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5680 - mae: 0.5756 - mse: 0.5680 - val_loss: 1.1750 - val_mae: 0.8424 - val_mse: 1.1750\n",
      "Epoch 221/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4404 - mae: 0.5156 - mse: 0.4404 - val_loss: 1.3603 - val_mae: 0.9347 - val_mse: 1.3603\n",
      "Epoch 222/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5869 - mae: 0.5978 - mse: 0.5869 - val_loss: 1.1077 - val_mae: 0.8358 - val_mse: 1.1077\n",
      "Epoch 223/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5239 - mae: 0.5805 - mse: 0.5239 - val_loss: 2.2548 - val_mae: 1.2244 - val_mse: 2.2548\n",
      "Epoch 224/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5900 - mae: 0.5820 - mse: 0.5900 - val_loss: 1.0269 - val_mae: 0.7945 - val_mse: 1.0269\n",
      "Epoch 225/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5999 - mae: 0.5911 - mse: 0.5999 - val_loss: 1.2787 - val_mae: 0.8760 - val_mse: 1.2787\n",
      "Epoch 226/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5907 - mae: 0.5690 - mse: 0.5907 - val_loss: 1.0712 - val_mae: 0.7919 - val_mse: 1.0712\n",
      "Epoch 227/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5202 - mae: 0.5566 - mse: 0.5202 - val_loss: 1.1618 - val_mae: 0.8193 - val_mse: 1.1618\n",
      "Epoch 228/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5057 - mae: 0.5494 - mse: 0.5057 - val_loss: 1.0901 - val_mae: 0.8039 - val_mse: 1.0901\n",
      "Epoch 229/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4852 - mae: 0.5497 - mse: 0.4852 - val_loss: 1.0360 - val_mae: 0.7903 - val_mse: 1.0360\n",
      "Epoch 230/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5290 - mae: 0.5751 - mse: 0.5290 - val_loss: 1.3055 - val_mae: 0.9150 - val_mse: 1.3055\n",
      "Epoch 231/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5505 - mae: 0.5790 - mse: 0.5505 - val_loss: 1.5831 - val_mae: 0.9787 - val_mse: 1.5831\n",
      "Epoch 232/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4339 - mae: 0.5003 - mse: 0.4339 - val_loss: 1.0587 - val_mae: 0.8081 - val_mse: 1.0587\n",
      "Epoch 233/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5479 - mae: 0.5775 - mse: 0.5479 - val_loss: 1.4335 - val_mae: 0.9392 - val_mse: 1.4335\n",
      "Epoch 234/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5766 - mae: 0.5955 - mse: 0.5766 - val_loss: 1.5306 - val_mae: 0.9982 - val_mse: 1.5306\n",
      "Epoch 235/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4208 - mae: 0.5073 - mse: 0.4208 - val_loss: 1.7431 - val_mae: 1.0507 - val_mse: 1.7431\n",
      "Epoch 236/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5097 - mae: 0.5596 - mse: 0.5097 - val_loss: 1.2361 - val_mae: 0.8849 - val_mse: 1.2361\n",
      "Epoch 237/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5839 - mae: 0.6126 - mse: 0.5839 - val_loss: 1.1296 - val_mae: 0.8254 - val_mse: 1.1296\n",
      "Epoch 238/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4979 - mae: 0.5368 - mse: 0.4979 - val_loss: 1.3109 - val_mae: 0.9091 - val_mse: 1.3109\n",
      "Epoch 239/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5348 - mae: 0.5680 - mse: 0.5348 - val_loss: 1.2367 - val_mae: 0.8803 - val_mse: 1.2367\n",
      "Epoch 240/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4049 - mae: 0.4896 - mse: 0.4049 - val_loss: 1.1373 - val_mae: 0.8310 - val_mse: 1.1373\n",
      "Epoch 241/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6662 - mae: 0.6514 - mse: 0.6662 - val_loss: 1.4212 - val_mae: 0.9495 - val_mse: 1.4212\n",
      "Epoch 242/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4445 - mae: 0.5268 - mse: 0.4445 - val_loss: 1.1718 - val_mae: 0.8557 - val_mse: 1.1718\n",
      "Epoch 243/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5178 - mae: 0.5591 - mse: 0.5178 - val_loss: 1.3817 - val_mae: 0.9321 - val_mse: 1.3817\n",
      "Epoch 244/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3639 - mae: 0.4613 - mse: 0.3639 - val_loss: 1.4864 - val_mae: 0.9742 - val_mse: 1.4864\n",
      "Kappa Score: 0.685589519650655\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Epoch 1/1000\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 279.1853 - mae: 7.4613 - mse: 279.1853 - val_loss: 3.4853 - val_mae: 1.4396 - val_mse: 3.4853\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 68.1521 - mae: 5.3540 - mse: 68.1521 - val_loss: 1.7927 - val_mae: 1.0445 - val_mse: 1.7927\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 58.7855 - mae: 5.3348 - mse: 58.7855 - val_loss: 3.4454 - val_mae: 1.5471 - val_mse: 3.4454\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 20.4598 - mae: 3.7925 - mse: 20.4598 - val_loss: 39.3397 - val_mae: 5.6759 - val_mse: 39.3397\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 23.9136 - mae: 4.1060 - mse: 23.9136 - val_loss: 47.6408 - val_mae: 6.5537 - val_mse: 47.6408\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 33.4599 - mae: 3.8548 - mse: 33.4599 - val_loss: 1.5226 - val_mae: 0.9492 - val_mse: 1.5226\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 20.8461 - mae: 3.2836 - mse: 20.8461 - val_loss: 2.9515 - val_mae: 1.4117 - val_mse: 2.9515\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 20.0176 - mae: 3.6117 - mse: 20.0176 - val_loss: 15.4701 - val_mae: 3.3353 - val_mse: 15.4701\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.1168 - mae: 1.3554 - mse: 3.1168 - val_loss: 10.0630 - val_mae: 2.9574 - val_mse: 10.0630\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 14.8703 - mae: 2.6961 - mse: 14.8703 - val_loss: 8.0488 - val_mae: 2.6636 - val_mse: 8.0488\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 11.7526 - mae: 2.6583 - mse: 11.7526 - val_loss: 5.1414 - val_mae: 1.7263 - val_mse: 5.1414\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.3028 - mae: 1.4442 - mse: 3.3028 - val_loss: 5.4114 - val_mae: 1.7908 - val_mse: 5.4114\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 5.8823 - mae: 1.8714 - mse: 5.8823 - val_loss: 2.4085 - val_mae: 1.1776 - val_mse: 2.4085\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 4.4655 - mae: 1.7015 - mse: 4.4655 - val_loss: 4.4505 - val_mae: 1.7011 - val_mse: 4.4505\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 5.5412 - mae: 1.8578 - mse: 5.5412 - val_loss: 2.3079 - val_mae: 1.1905 - val_mse: 2.3079\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 4.3214 - mae: 1.7229 - mse: 4.3214 - val_loss: 2.0214 - val_mae: 1.1221 - val_mse: 2.0214\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3187 - mae: 1.5103 - mse: 3.3187 - val_loss: 5.2859 - val_mae: 1.8547 - val_mse: 5.2859\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3358 - mae: 1.5009 - mse: 3.3358 - val_loss: 8.0907 - val_mae: 2.2427 - val_mse: 8.0907\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.8826 - mae: 1.2847 - mse: 2.8826 - val_loss: 2.1114 - val_mae: 1.1587 - val_mse: 2.1114\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.8884 - mae: 1.3340 - mse: 2.8884 - val_loss: 1.9317 - val_mae: 1.0951 - val_mse: 1.9317\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.3692 - mae: 1.2295 - mse: 2.3692 - val_loss: 3.0347 - val_mae: 1.4494 - val_mse: 3.0347\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.5292 - mae: 1.2553 - mse: 2.5292 - val_loss: 1.5792 - val_mae: 0.9741 - val_mse: 1.5792\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.3443 - mae: 1.4251 - mse: 3.3443 - val_loss: 2.8298 - val_mae: 1.3046 - val_mse: 2.8298\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0224 - mae: 1.1302 - mse: 2.0224 - val_loss: 6.1593 - val_mae: 2.2522 - val_mse: 6.1593\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.3810 - mae: 1.2216 - mse: 2.3810 - val_loss: 2.6170 - val_mae: 1.2613 - val_mse: 2.6170\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.5959 - mae: 1.2913 - mse: 2.5959 - val_loss: 1.3917 - val_mae: 0.9198 - val_mse: 1.3917\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7959 - mae: 1.0103 - mse: 1.7959 - val_loss: 4.3841 - val_mae: 1.6671 - val_mse: 4.3841\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.3212 - mae: 1.1901 - mse: 2.3212 - val_loss: 4.1026 - val_mae: 1.7826 - val_mse: 4.1026\n",
      "Epoch 29/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.9422 - mae: 1.1044 - mse: 1.9422 - val_loss: 2.5487 - val_mae: 1.2605 - val_mse: 2.5487\n",
      "Epoch 30/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 3.0810 - mae: 1.3894 - mse: 3.0810 - val_loss: 2.1286 - val_mae: 1.1486 - val_mse: 2.1286\n",
      "Epoch 31/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.1654 - mae: 1.1008 - mse: 2.1654 - val_loss: 2.2029 - val_mae: 1.1825 - val_mse: 2.2029\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7169 - mae: 1.0277 - mse: 1.7169 - val_loss: 3.1508 - val_mae: 1.4391 - val_mse: 3.1508\n",
      "Epoch 33/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0899 - mae: 1.1124 - mse: 2.0899 - val_loss: 1.7186 - val_mae: 1.0162 - val_mse: 1.7186\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8085 - mae: 1.0603 - mse: 1.8085 - val_loss: 2.4240 - val_mae: 1.2285 - val_mse: 2.4240\n",
      "Epoch 35/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8127 - mae: 1.0624 - mse: 1.8127 - val_loss: 2.4435 - val_mae: 1.2454 - val_mse: 2.4435\n",
      "Epoch 36/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.0892 - mae: 1.1253 - mse: 2.0892 - val_loss: 1.4192 - val_mae: 0.9097 - val_mse: 1.4192\n",
      "Epoch 37/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7479 - mae: 1.0382 - mse: 1.7479 - val_loss: 3.4216 - val_mae: 1.5789 - val_mse: 3.4216\n",
      "Epoch 38/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.3310 - mae: 0.8977 - mse: 1.3310 - val_loss: 4.5858 - val_mae: 1.8925 - val_mse: 4.5858\n",
      "Epoch 39/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 2.4129 - mae: 1.2263 - mse: 2.4129 - val_loss: 1.4261 - val_mae: 0.9218 - val_mse: 1.4261\n",
      "Epoch 40/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5110 - mae: 0.9693 - mse: 1.5110 - val_loss: 1.3731 - val_mae: 0.8924 - val_mse: 1.3731\n",
      "Epoch 41/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6507 - mae: 1.0142 - mse: 1.6507 - val_loss: 2.9136 - val_mae: 1.3627 - val_mse: 2.9136\n",
      "Epoch 42/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5763 - mae: 0.9973 - mse: 1.5763 - val_loss: 1.6219 - val_mae: 0.9852 - val_mse: 1.6219\n",
      "Epoch 43/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3660 - mae: 0.9098 - mse: 1.3660 - val_loss: 2.0705 - val_mae: 1.1379 - val_mse: 2.0705\n",
      "Epoch 44/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6431 - mae: 0.9984 - mse: 1.6431 - val_loss: 1.8562 - val_mae: 1.0765 - val_mse: 1.8562\n",
      "Epoch 45/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2892 - mae: 0.8925 - mse: 1.2892 - val_loss: 3.3785 - val_mae: 1.4594 - val_mse: 3.3785\n",
      "Epoch 46/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6698 - mae: 1.0188 - mse: 1.6698 - val_loss: 2.1836 - val_mae: 1.1856 - val_mse: 2.1836\n",
      "Epoch 47/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3274 - mae: 0.9067 - mse: 1.3274 - val_loss: 1.2758 - val_mae: 0.8760 - val_mse: 1.2758\n",
      "Epoch 48/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3119 - mae: 0.9171 - mse: 1.3119 - val_loss: 1.3139 - val_mae: 0.8628 - val_mse: 1.3139\n",
      "Epoch 49/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3360 - mae: 0.8894 - mse: 1.3360 - val_loss: 2.0836 - val_mae: 1.1508 - val_mse: 2.0836\n",
      "Epoch 50/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5735 - mae: 0.9867 - mse: 1.5735 - val_loss: 1.3917 - val_mae: 0.8926 - val_mse: 1.3917\n",
      "Epoch 51/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2872 - mae: 0.8891 - mse: 1.2872 - val_loss: 1.6802 - val_mae: 1.0005 - val_mse: 1.6802\n",
      "Epoch 52/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5139 - mae: 0.9796 - mse: 1.5139 - val_loss: 4.1171 - val_mae: 1.8053 - val_mse: 4.1171\n",
      "Epoch 53/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6039 - mae: 1.0020 - mse: 1.6039 - val_loss: 1.2951 - val_mae: 0.8820 - val_mse: 1.2951\n",
      "Epoch 54/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2537 - mae: 0.8882 - mse: 1.2537 - val_loss: 1.7083 - val_mae: 1.0276 - val_mse: 1.7083\n",
      "Epoch 55/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2162 - mae: 0.8606 - mse: 1.2162 - val_loss: 1.3086 - val_mae: 0.8774 - val_mse: 1.3086\n",
      "Epoch 56/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.7428 - mae: 1.0168 - mse: 1.7428 - val_loss: 1.3253 - val_mae: 0.8723 - val_mse: 1.3253\n",
      "Epoch 57/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3299 - mae: 0.9134 - mse: 1.3299 - val_loss: 1.1267 - val_mae: 0.8011 - val_mse: 1.1267\n",
      "Epoch 58/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2689 - mae: 0.8607 - mse: 1.2689 - val_loss: 1.5810 - val_mae: 0.9670 - val_mse: 1.5810\n",
      "Epoch 59/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.5107 - mae: 0.9441 - mse: 1.5107 - val_loss: 2.1762 - val_mae: 1.2022 - val_mse: 2.1762\n",
      "Epoch 60/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2018 - mae: 0.8632 - mse: 1.2018 - val_loss: 1.1991 - val_mae: 0.8289 - val_mse: 1.1991\n",
      "Epoch 61/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6165 - mae: 0.9938 - mse: 1.6165 - val_loss: 1.5741 - val_mae: 0.9724 - val_mse: 1.5741\n",
      "Epoch 62/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0088 - mae: 0.7883 - mse: 1.0088 - val_loss: 1.6825 - val_mae: 1.0347 - val_mse: 1.6825\n",
      "Epoch 63/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2928 - mae: 0.8776 - mse: 1.2928 - val_loss: 1.1496 - val_mae: 0.8103 - val_mse: 1.1496\n",
      "Epoch 64/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.6162 - mae: 0.9813 - mse: 1.6162 - val_loss: 1.0809 - val_mae: 0.8067 - val_mse: 1.0809\n",
      "Epoch 65/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1374 - mae: 0.8404 - mse: 1.1374 - val_loss: 1.2246 - val_mae: 0.8710 - val_mse: 1.2246\n",
      "Epoch 66/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3750 - mae: 0.9227 - mse: 1.3750 - val_loss: 1.3591 - val_mae: 0.8867 - val_mse: 1.3591\n",
      "Epoch 67/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2379 - mae: 0.8587 - mse: 1.2379 - val_loss: 2.1336 - val_mae: 1.2091 - val_mse: 2.1336\n",
      "Epoch 68/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1715 - mae: 0.8347 - mse: 1.1715 - val_loss: 1.1435 - val_mae: 0.8030 - val_mse: 1.1435\n",
      "Epoch 69/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2937 - mae: 0.9108 - mse: 1.2937 - val_loss: 1.1537 - val_mae: 0.8192 - val_mse: 1.1537\n",
      "Epoch 70/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1138 - mae: 0.8271 - mse: 1.1138 - val_loss: 1.1290 - val_mae: 0.8095 - val_mse: 1.1290\n",
      "Epoch 71/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2712 - mae: 0.8692 - mse: 1.2712 - val_loss: 1.2779 - val_mae: 0.8504 - val_mse: 1.2779\n",
      "Epoch 72/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2443 - mae: 0.8757 - mse: 1.2443 - val_loss: 1.4547 - val_mae: 0.9319 - val_mse: 1.4547\n",
      "Epoch 73/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0458 - mae: 0.8047 - mse: 1.0458 - val_loss: 2.6834 - val_mae: 1.3810 - val_mse: 2.6834\n",
      "Epoch 74/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1339 - mae: 0.8262 - mse: 1.1339 - val_loss: 2.0517 - val_mae: 1.1655 - val_mse: 2.0517\n",
      "Epoch 75/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3122 - mae: 0.8884 - mse: 1.3122 - val_loss: 1.0718 - val_mae: 0.7794 - val_mse: 1.0718\n",
      "Epoch 76/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0956 - mae: 0.8102 - mse: 1.0956 - val_loss: 1.0537 - val_mae: 0.7726 - val_mse: 1.0537\n",
      "Epoch 77/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3876 - mae: 0.9092 - mse: 1.3876 - val_loss: 1.4585 - val_mae: 0.9396 - val_mse: 1.4585\n",
      "Epoch 78/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4425 - mae: 0.9228 - mse: 1.4425 - val_loss: 1.3586 - val_mae: 0.8904 - val_mse: 1.3586\n",
      "Epoch 79/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8884 - mae: 0.7365 - mse: 0.8884 - val_loss: 1.0806 - val_mae: 0.7847 - val_mse: 1.0806\n",
      "Epoch 80/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2696 - mae: 0.8681 - mse: 1.2696 - val_loss: 1.1868 - val_mae: 0.8283 - val_mse: 1.1868\n",
      "Epoch 81/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0615 - mae: 0.7935 - mse: 1.0615 - val_loss: 2.0746 - val_mae: 1.1307 - val_mse: 2.0746\n",
      "Epoch 82/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1164 - mae: 0.8267 - mse: 1.1164 - val_loss: 1.0266 - val_mae: 0.7756 - val_mse: 1.0266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4215 - mae: 0.9081 - mse: 1.4215 - val_loss: 1.4897 - val_mae: 0.9407 - val_mse: 1.4897\n",
      "Epoch 84/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0235 - mae: 0.7808 - mse: 1.0235 - val_loss: 1.7610 - val_mae: 1.0679 - val_mse: 1.7610\n",
      "Epoch 85/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.3794 - mae: 0.9133 - mse: 1.3794 - val_loss: 1.1057 - val_mae: 0.8197 - val_mse: 1.1057\n",
      "Epoch 86/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9457 - mae: 0.7513 - mse: 0.9457 - val_loss: 1.2547 - val_mae: 0.8760 - val_mse: 1.2547\n",
      "Epoch 87/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1993 - mae: 0.8656 - mse: 1.1993 - val_loss: 2.4144 - val_mae: 1.2372 - val_mse: 2.4144\n",
      "Epoch 88/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2134 - mae: 0.8500 - mse: 1.2134 - val_loss: 1.0845 - val_mae: 0.7833 - val_mse: 1.0845\n",
      "Epoch 89/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9924 - mae: 0.7839 - mse: 0.9924 - val_loss: 2.6157 - val_mae: 1.2857 - val_mse: 2.6157\n",
      "Epoch 90/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2281 - mae: 0.8537 - mse: 1.2281 - val_loss: 1.2216 - val_mae: 0.8679 - val_mse: 1.2216\n",
      "Epoch 91/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0485 - mae: 0.8034 - mse: 1.0485 - val_loss: 1.1095 - val_mae: 0.7917 - val_mse: 1.1095\n",
      "Epoch 92/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0850 - mae: 0.8158 - mse: 1.0850 - val_loss: 1.2235 - val_mae: 0.8443 - val_mse: 1.2235\n",
      "Epoch 93/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2898 - mae: 0.8993 - mse: 1.2898 - val_loss: 1.0543 - val_mae: 0.7798 - val_mse: 1.0543\n",
      "Epoch 94/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9887 - mae: 0.7754 - mse: 0.9887 - val_loss: 2.2051 - val_mae: 1.2133 - val_mse: 2.2051\n",
      "Epoch 95/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1308 - mae: 0.8148 - mse: 1.1308 - val_loss: 1.0422 - val_mae: 0.7753 - val_mse: 1.0422\n",
      "Epoch 96/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1459 - mae: 0.8179 - mse: 1.1459 - val_loss: 1.2708 - val_mae: 0.8636 - val_mse: 1.2708\n",
      "Epoch 97/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9689 - mae: 0.7584 - mse: 0.9689 - val_loss: 1.3178 - val_mae: 0.9029 - val_mse: 1.3178\n",
      "Epoch 98/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9980 - mae: 0.7866 - mse: 0.9980 - val_loss: 1.1802 - val_mae: 0.8329 - val_mse: 1.1802\n",
      "Epoch 99/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2758 - mae: 0.8921 - mse: 1.2758 - val_loss: 1.2403 - val_mae: 0.8409 - val_mse: 1.2403\n",
      "Epoch 100/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0208 - mae: 0.7989 - mse: 1.0208 - val_loss: 1.6118 - val_mae: 0.9930 - val_mse: 1.6118\n",
      "Epoch 101/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1161 - mae: 0.8309 - mse: 1.1161 - val_loss: 1.4972 - val_mae: 0.9475 - val_mse: 1.4972\n",
      "Epoch 102/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9873 - mae: 0.7678 - mse: 0.9873 - val_loss: 1.4354 - val_mae: 0.9395 - val_mse: 1.4354\n",
      "Epoch 103/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2218 - mae: 0.8475 - mse: 1.2218 - val_loss: 1.4068 - val_mae: 0.9165 - val_mse: 1.4068\n",
      "Epoch 104/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9893 - mae: 0.7685 - mse: 0.9893 - val_loss: 0.9783 - val_mae: 0.7559 - val_mse: 0.9783\n",
      "Epoch 105/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9294 - mae: 0.7414 - mse: 0.9294 - val_loss: 1.0949 - val_mae: 0.8212 - val_mse: 1.0949\n",
      "Epoch 106/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0270 - mae: 0.7924 - mse: 1.0270 - val_loss: 1.0335 - val_mae: 0.7589 - val_mse: 1.0335\n",
      "Epoch 107/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0141 - mae: 0.7863 - mse: 1.0141 - val_loss: 1.6533 - val_mae: 1.0516 - val_mse: 1.6533\n",
      "Epoch 108/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.2467 - mae: 0.8930 - mse: 1.2467 - val_loss: 1.6334 - val_mae: 1.0252 - val_mse: 1.6334\n",
      "Epoch 109/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1833 - mae: 0.8549 - mse: 1.1833 - val_loss: 0.9785 - val_mae: 0.7561 - val_mse: 0.9785\n",
      "Epoch 110/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9829 - mae: 0.7680 - mse: 0.9829 - val_loss: 1.0281 - val_mae: 0.7779 - val_mse: 1.0281\n",
      "Epoch 111/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8525 - mae: 0.7067 - mse: 0.8525 - val_loss: 0.9992 - val_mae: 0.7652 - val_mse: 0.9992\n",
      "Epoch 112/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.1798 - mae: 0.8599 - mse: 1.1798 - val_loss: 1.1761 - val_mae: 0.8500 - val_mse: 1.1761\n",
      "Epoch 113/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0166 - mae: 0.7735 - mse: 1.0166 - val_loss: 1.1783 - val_mae: 0.8251 - val_mse: 1.1783\n",
      "Epoch 114/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8347 - mae: 0.7052 - mse: 0.8347 - val_loss: 1.0270 - val_mae: 0.7759 - val_mse: 1.0270\n",
      "Epoch 115/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9353 - mae: 0.7431 - mse: 0.9353 - val_loss: 1.5343 - val_mae: 1.0143 - val_mse: 1.5343\n",
      "Epoch 116/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0372 - mae: 0.8162 - mse: 1.0372 - val_loss: 0.9849 - val_mae: 0.7532 - val_mse: 0.9849\n",
      "Epoch 117/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0775 - mae: 0.8109 - mse: 1.0775 - val_loss: 1.9070 - val_mae: 1.1060 - val_mse: 1.9070\n",
      "Epoch 118/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0844 - mae: 0.7927 - mse: 1.0844 - val_loss: 1.2994 - val_mae: 0.8700 - val_mse: 1.2994\n",
      "Epoch 119/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9964 - mae: 0.7630 - mse: 0.9964 - val_loss: 1.0628 - val_mae: 0.7653 - val_mse: 1.0628\n",
      "Epoch 120/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9570 - mae: 0.7647 - mse: 0.9570 - val_loss: 1.3469 - val_mae: 0.9115 - val_mse: 1.3469\n",
      "Epoch 121/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0539 - mae: 0.7998 - mse: 1.0539 - val_loss: 1.1671 - val_mae: 0.8145 - val_mse: 1.1671\n",
      "Epoch 122/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9256 - mae: 0.7189 - mse: 0.9256 - val_loss: 1.3757 - val_mae: 0.9398 - val_mse: 1.3757\n",
      "Epoch 123/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8797 - mae: 0.7302 - mse: 0.8797 - val_loss: 1.1485 - val_mae: 0.8040 - val_mse: 1.1485\n",
      "Epoch 124/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0207 - mae: 0.7722 - mse: 1.0207 - val_loss: 1.2242 - val_mae: 0.8359 - val_mse: 1.2242\n",
      "Epoch 125/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7192 - mae: 0.6646 - mse: 0.7192 - val_loss: 1.0436 - val_mae: 0.7612 - val_mse: 1.0436\n",
      "Epoch 126/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0927 - mae: 0.8127 - mse: 1.0927 - val_loss: 1.8605 - val_mae: 1.1025 - val_mse: 1.8605\n",
      "Epoch 127/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9400 - mae: 0.7376 - mse: 0.9400 - val_loss: 1.4850 - val_mae: 1.0054 - val_mse: 1.4850\n",
      "Epoch 128/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8261 - mae: 0.7092 - mse: 0.8261 - val_loss: 1.2670 - val_mae: 0.8585 - val_mse: 1.2670\n",
      "Epoch 129/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8372 - mae: 0.6960 - mse: 0.8372 - val_loss: 1.9011 - val_mae: 1.1405 - val_mse: 1.9011\n",
      "Epoch 130/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8816 - mae: 0.7344 - mse: 0.8816 - val_loss: 1.1880 - val_mae: 0.8489 - val_mse: 1.1880\n",
      "Epoch 131/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0566 - mae: 0.7901 - mse: 1.0566 - val_loss: 1.6519 - val_mae: 1.0142 - val_mse: 1.6519\n",
      "Epoch 132/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8520 - mae: 0.7013 - mse: 0.8520 - val_loss: 0.9580 - val_mae: 0.7629 - val_mse: 0.9580\n",
      "Epoch 133/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8751 - mae: 0.7375 - mse: 0.8751 - val_loss: 1.0054 - val_mae: 0.7637 - val_mse: 1.0054\n",
      "Epoch 134/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8553 - mae: 0.6986 - mse: 0.8553 - val_loss: 1.0074 - val_mae: 0.7629 - val_mse: 1.0074\n",
      "Epoch 135/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9574 - mae: 0.7565 - mse: 0.9574 - val_loss: 1.3344 - val_mae: 0.8916 - val_mse: 1.3344\n",
      "Epoch 136/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8375 - mae: 0.7225 - mse: 0.8375 - val_loss: 0.9828 - val_mae: 0.7390 - val_mse: 0.9828\n",
      "Epoch 137/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8282 - mae: 0.7047 - mse: 0.8282 - val_loss: 1.3756 - val_mae: 0.9241 - val_mse: 1.3756\n",
      "Epoch 138/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8769 - mae: 0.7194 - mse: 0.8769 - val_loss: 1.1311 - val_mae: 0.8348 - val_mse: 1.1311\n",
      "Epoch 139/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8528 - mae: 0.7206 - mse: 0.8528 - val_loss: 1.6819 - val_mae: 1.0272 - val_mse: 1.6819\n",
      "Epoch 140/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8883 - mae: 0.7306 - mse: 0.8883 - val_loss: 1.8063 - val_mae: 1.0842 - val_mse: 1.8063\n",
      "Epoch 141/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8110 - mae: 0.6960 - mse: 0.8110 - val_loss: 1.6289 - val_mae: 0.9992 - val_mse: 1.6289\n",
      "Epoch 142/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8316 - mae: 0.7006 - mse: 0.8316 - val_loss: 1.1557 - val_mae: 0.8115 - val_mse: 1.1557\n",
      "Epoch 143/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9636 - mae: 0.7473 - mse: 0.9636 - val_loss: 1.0893 - val_mae: 0.7886 - val_mse: 1.0893\n",
      "Epoch 144/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8309 - mae: 0.6820 - mse: 0.8309 - val_loss: 1.2957 - val_mae: 0.8830 - val_mse: 1.2957\n",
      "Epoch 145/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8654 - mae: 0.7225 - mse: 0.8654 - val_loss: 1.3943 - val_mae: 0.9071 - val_mse: 1.3943\n",
      "Epoch 146/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0972 - mae: 0.8270 - mse: 1.0972 - val_loss: 1.3287 - val_mae: 0.9244 - val_mse: 1.3287\n",
      "Epoch 147/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7286 - mae: 0.6403 - mse: 0.7286 - val_loss: 1.0846 - val_mae: 0.8129 - val_mse: 1.0846\n",
      "Epoch 148/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.0153 - mae: 0.7707 - mse: 1.0153 - val_loss: 1.0414 - val_mae: 0.7689 - val_mse: 1.0414\n",
      "Epoch 149/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8241 - mae: 0.6908 - mse: 0.8241 - val_loss: 1.7623 - val_mae: 1.0390 - val_mse: 1.7623\n",
      "Epoch 150/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7271 - mae: 0.6376 - mse: 0.7271 - val_loss: 1.1310 - val_mae: 0.7956 - val_mse: 1.1310\n",
      "Epoch 151/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8889 - mae: 0.7152 - mse: 0.8889 - val_loss: 1.1802 - val_mae: 0.8315 - val_mse: 1.1802\n",
      "Epoch 152/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9673 - mae: 0.7333 - mse: 0.9673 - val_loss: 1.2891 - val_mae: 0.8560 - val_mse: 1.2891\n",
      "Epoch 153/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7195 - mae: 0.6706 - mse: 0.7195 - val_loss: 1.2576 - val_mae: 0.8795 - val_mse: 1.2576\n",
      "Epoch 154/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9754 - mae: 0.7801 - mse: 0.9754 - val_loss: 0.9253 - val_mae: 0.7514 - val_mse: 0.9253\n",
      "Epoch 155/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7210 - mae: 0.6281 - mse: 0.7210 - val_loss: 1.7760 - val_mae: 1.0809 - val_mse: 1.7760\n",
      "Epoch 156/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6973 - mae: 0.6290 - mse: 0.6973 - val_loss: 1.2182 - val_mae: 0.8251 - val_mse: 1.2182\n",
      "Epoch 157/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8627 - mae: 0.6994 - mse: 0.8627 - val_loss: 1.3457 - val_mae: 0.8754 - val_mse: 1.3457\n",
      "Epoch 158/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7502 - mae: 0.6488 - mse: 0.7502 - val_loss: 2.0989 - val_mae: 1.1602 - val_mse: 2.0989\n",
      "Epoch 159/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8050 - mae: 0.6955 - mse: 0.8050 - val_loss: 1.3039 - val_mae: 0.9033 - val_mse: 1.3039\n",
      "Epoch 160/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8630 - mae: 0.7122 - mse: 0.8630 - val_loss: 1.3944 - val_mae: 0.9595 - val_mse: 1.3944\n",
      "Epoch 161/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8890 - mae: 0.7154 - mse: 0.8890 - val_loss: 1.6629 - val_mae: 1.0481 - val_mse: 1.6629\n",
      "Epoch 162/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7379 - mae: 0.6716 - mse: 0.7379 - val_loss: 1.0940 - val_mae: 0.8305 - val_mse: 1.0940\n",
      "Epoch 163/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9640 - mae: 0.7589 - mse: 0.9640 - val_loss: 1.3439 - val_mae: 0.8841 - val_mse: 1.3439\n",
      "Epoch 164/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7199 - mae: 0.6536 - mse: 0.7199 - val_loss: 1.4281 - val_mae: 0.9883 - val_mse: 1.4281\n",
      "Epoch 165/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8542 - mae: 0.7089 - mse: 0.8542 - val_loss: 0.9415 - val_mae: 0.7451 - val_mse: 0.9415\n",
      "Epoch 166/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9737 - mae: 0.7720 - mse: 0.9737 - val_loss: 1.3630 - val_mae: 0.9105 - val_mse: 1.3630\n",
      "Epoch 167/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6688 - mae: 0.6175 - mse: 0.6688 - val_loss: 1.7090 - val_mae: 1.0618 - val_mse: 1.7090\n",
      "Epoch 168/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9947 - mae: 0.7735 - mse: 0.9947 - val_loss: 1.1294 - val_mae: 0.8097 - val_mse: 1.1294\n",
      "Epoch 169/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7971 - mae: 0.6899 - mse: 0.7971 - val_loss: 1.0335 - val_mae: 0.8107 - val_mse: 1.0335\n",
      "Epoch 170/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7371 - mae: 0.6501 - mse: 0.7371 - val_loss: 1.0054 - val_mae: 0.7762 - val_mse: 1.0054\n",
      "Epoch 171/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8745 - mae: 0.7233 - mse: 0.8745 - val_loss: 0.9397 - val_mae: 0.7411 - val_mse: 0.9397\n",
      "Epoch 172/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8366 - mae: 0.7019 - mse: 0.8366 - val_loss: 1.4184 - val_mae: 0.9364 - val_mse: 1.4184\n",
      "Epoch 173/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8155 - mae: 0.6878 - mse: 0.8155 - val_loss: 1.1127 - val_mae: 0.7991 - val_mse: 1.1127\n",
      "Epoch 174/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7606 - mae: 0.6809 - mse: 0.7606 - val_loss: 1.4367 - val_mae: 0.9689 - val_mse: 1.4367\n",
      "Epoch 175/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8192 - mae: 0.6873 - mse: 0.8192 - val_loss: 1.0916 - val_mae: 0.7925 - val_mse: 1.0916\n",
      "Epoch 176/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8036 - mae: 0.6903 - mse: 0.8036 - val_loss: 1.1959 - val_mae: 0.8514 - val_mse: 1.1959\n",
      "Epoch 177/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6376 - mae: 0.6051 - mse: 0.6376 - val_loss: 1.5387 - val_mae: 0.9847 - val_mse: 1.5387\n",
      "Epoch 178/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8757 - mae: 0.7170 - mse: 0.8757 - val_loss: 0.9454 - val_mae: 0.7651 - val_mse: 0.9454\n",
      "Epoch 179/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7787 - mae: 0.6700 - mse: 0.7787 - val_loss: 1.2603 - val_mae: 0.8639 - val_mse: 1.2603\n",
      "Epoch 180/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6999 - mae: 0.6347 - mse: 0.6999 - val_loss: 1.8097 - val_mae: 1.0636 - val_mse: 1.8097\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9410 - mae: 0.7305 - mse: 0.9410 - val_loss: 1.0099 - val_mae: 0.7644 - val_mse: 1.0099\n",
      "Epoch 182/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7171 - mae: 0.6359 - mse: 0.7171 - val_loss: 1.0045 - val_mae: 0.7724 - val_mse: 1.0045\n",
      "Epoch 183/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7212 - mae: 0.6525 - mse: 0.7212 - val_loss: 1.0558 - val_mae: 0.7800 - val_mse: 1.0558\n",
      "Epoch 184/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7338 - mae: 0.6503 - mse: 0.7338 - val_loss: 0.9798 - val_mae: 0.7686 - val_mse: 0.9798\n",
      "Epoch 185/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7566 - mae: 0.6694 - mse: 0.7566 - val_loss: 1.3661 - val_mae: 0.9085 - val_mse: 1.3661\n",
      "Epoch 186/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8114 - mae: 0.7007 - mse: 0.8114 - val_loss: 0.9712 - val_mae: 0.7535 - val_mse: 0.9712\n",
      "Epoch 187/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7332 - mae: 0.6501 - mse: 0.7332 - val_loss: 1.1160 - val_mae: 0.8495 - val_mse: 1.1160\n",
      "Epoch 188/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8487 - mae: 0.7103 - mse: 0.8487 - val_loss: 1.0183 - val_mae: 0.7818 - val_mse: 1.0183\n",
      "Epoch 189/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6761 - mae: 0.6211 - mse: 0.6761 - val_loss: 1.0644 - val_mae: 0.7832 - val_mse: 1.0644\n",
      "Epoch 190/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8026 - mae: 0.6806 - mse: 0.8026 - val_loss: 1.1835 - val_mae: 0.8763 - val_mse: 1.1835\n",
      "Epoch 191/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6780 - mae: 0.6319 - mse: 0.6780 - val_loss: 1.6397 - val_mae: 1.0054 - val_mse: 1.6397\n",
      "Epoch 192/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7261 - mae: 0.6560 - mse: 0.7261 - val_loss: 1.2914 - val_mae: 0.8852 - val_mse: 1.2914\n",
      "Epoch 193/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7152 - mae: 0.6336 - mse: 0.7152 - val_loss: 1.4777 - val_mae: 0.9975 - val_mse: 1.4777\n",
      "Epoch 194/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5969 - mae: 0.5978 - mse: 0.5969 - val_loss: 1.1780 - val_mae: 0.8161 - val_mse: 1.1780\n",
      "Epoch 195/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8700 - mae: 0.7126 - mse: 0.8700 - val_loss: 1.3738 - val_mae: 0.9345 - val_mse: 1.3738\n",
      "Epoch 196/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7463 - mae: 0.6634 - mse: 0.7463 - val_loss: 0.9871 - val_mae: 0.7567 - val_mse: 0.9871\n",
      "Epoch 197/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6736 - mae: 0.6140 - mse: 0.6736 - val_loss: 1.2532 - val_mae: 0.8835 - val_mse: 1.2532\n",
      "Epoch 198/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6650 - mae: 0.6030 - mse: 0.6650 - val_loss: 0.9863 - val_mae: 0.7556 - val_mse: 0.9863\n",
      "Epoch 199/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8055 - mae: 0.6847 - mse: 0.8055 - val_loss: 0.9931 - val_mae: 0.7686 - val_mse: 0.9931\n",
      "Epoch 200/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5611 - mae: 0.5710 - mse: 0.5611 - val_loss: 1.2427 - val_mae: 0.8538 - val_mse: 1.2427\n",
      "Epoch 201/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9141 - mae: 0.7377 - mse: 0.9141 - val_loss: 0.9841 - val_mae: 0.7787 - val_mse: 0.9841\n",
      "Epoch 202/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5430 - mae: 0.5540 - mse: 0.5430 - val_loss: 1.6311 - val_mae: 1.0066 - val_mse: 1.6311\n",
      "Epoch 203/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6302 - mae: 0.6143 - mse: 0.6302 - val_loss: 1.6148 - val_mae: 1.0195 - val_mse: 1.6148\n",
      "Epoch 204/1000\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.3784 - mae: 0.9528 - mse: 1.378 - 0s 2ms/step - loss: 0.8946 - mae: 0.7281 - mse: 0.8946 - val_loss: 1.0192 - val_mae: 0.7627 - val_mse: 1.0192\n",
      "Epoch 205/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7130 - mae: 0.6462 - mse: 0.7130 - val_loss: 1.4254 - val_mae: 0.9195 - val_mse: 1.4254\n",
      "Epoch 206/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5962 - mae: 0.5983 - mse: 0.5962 - val_loss: 2.0840 - val_mae: 1.1986 - val_mse: 2.0840\n",
      "Epoch 207/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7468 - mae: 0.6540 - mse: 0.7468 - val_loss: 1.0757 - val_mae: 0.8314 - val_mse: 1.0757\n",
      "Epoch 208/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8259 - mae: 0.7033 - mse: 0.8259 - val_loss: 1.0379 - val_mae: 0.7838 - val_mse: 1.0379\n",
      "Epoch 209/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6037 - mae: 0.5980 - mse: 0.6037 - val_loss: 1.1798 - val_mae: 0.8652 - val_mse: 1.1798\n",
      "Epoch 210/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7346 - mae: 0.6572 - mse: 0.7346 - val_loss: 0.9955 - val_mae: 0.8103 - val_mse: 0.9955\n",
      "Epoch 211/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6408 - mae: 0.5915 - mse: 0.6408 - val_loss: 1.4920 - val_mae: 0.9540 - val_mse: 1.4920\n",
      "Epoch 212/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6883 - mae: 0.6419 - mse: 0.6883 - val_loss: 1.7691 - val_mae: 1.0504 - val_mse: 1.7691\n",
      "Epoch 213/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5569 - mae: 0.5682 - mse: 0.5569 - val_loss: 1.3702 - val_mae: 0.9162 - val_mse: 1.3702\n",
      "Epoch 214/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.8342 - mae: 0.6786 - mse: 0.8342 - val_loss: 0.9464 - val_mae: 0.7602 - val_mse: 0.9464\n",
      "Epoch 215/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6785 - mae: 0.6409 - mse: 0.6785 - val_loss: 1.1102 - val_mae: 0.7929 - val_mse: 1.1102\n",
      "Epoch 216/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5529 - mae: 0.5667 - mse: 0.5529 - val_loss: 1.0993 - val_mae: 0.7957 - val_mse: 1.0993\n",
      "Epoch 217/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6152 - mae: 0.6033 - mse: 0.6152 - val_loss: 1.0931 - val_mae: 0.8045 - val_mse: 1.0931\n",
      "Epoch 218/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7672 - mae: 0.6687 - mse: 0.7672 - val_loss: 1.0131 - val_mae: 0.7789 - val_mse: 1.0131\n",
      "Epoch 219/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6134 - mae: 0.6191 - mse: 0.6134 - val_loss: 1.5708 - val_mae: 0.9861 - val_mse: 1.5708\n",
      "Epoch 220/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7589 - mae: 0.6566 - mse: 0.7589 - val_loss: 1.5085 - val_mae: 0.9985 - val_mse: 1.5085\n",
      "Epoch 221/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6196 - mae: 0.5991 - mse: 0.6196 - val_loss: 1.0655 - val_mae: 0.8329 - val_mse: 1.0655\n",
      "Epoch 222/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6671 - mae: 0.6139 - mse: 0.6671 - val_loss: 1.2224 - val_mae: 0.8590 - val_mse: 1.2224\n",
      "Epoch 223/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6726 - mae: 0.6223 - mse: 0.6726 - val_loss: 1.1659 - val_mae: 0.8293 - val_mse: 1.1659\n",
      "Epoch 224/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6866 - mae: 0.6314 - mse: 0.6866 - val_loss: 1.4368 - val_mae: 0.9307 - val_mse: 1.4368\n",
      "Epoch 225/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7653 - mae: 0.6612 - mse: 0.7653 - val_loss: 1.1107 - val_mae: 0.8018 - val_mse: 1.1107\n",
      "Epoch 226/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6383 - mae: 0.6180 - mse: 0.6383 - val_loss: 1.2732 - val_mae: 0.8609 - val_mse: 1.2732\n",
      "Epoch 227/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7316 - mae: 0.6443 - mse: 0.7316 - val_loss: 1.1246 - val_mae: 0.8155 - val_mse: 1.1246\n",
      "Epoch 228/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6366 - mae: 0.5825 - mse: 0.6366 - val_loss: 1.1254 - val_mae: 0.8666 - val_mse: 1.1254\n",
      "Epoch 229/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6321 - mae: 0.6128 - mse: 0.6321 - val_loss: 1.5880 - val_mae: 1.0062 - val_mse: 1.5880\n",
      "Epoch 230/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6663 - mae: 0.6268 - mse: 0.6663 - val_loss: 1.1393 - val_mae: 0.7965 - val_mse: 1.1393\n",
      "Epoch 231/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6405 - mae: 0.6115 - mse: 0.6405 - val_loss: 1.5198 - val_mae: 0.9536 - val_mse: 1.5198\n",
      "Epoch 232/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6245 - mae: 0.5989 - mse: 0.6245 - val_loss: 1.2770 - val_mae: 0.8839 - val_mse: 1.2770\n",
      "Epoch 233/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6724 - mae: 0.6425 - mse: 0.6724 - val_loss: 1.6821 - val_mae: 1.0060 - val_mse: 1.6821\n",
      "Epoch 234/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7297 - mae: 0.6430 - mse: 0.7297 - val_loss: 1.1371 - val_mae: 0.8266 - val_mse: 1.1371\n",
      "Epoch 235/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5300 - mae: 0.5432 - mse: 0.5300 - val_loss: 1.3125 - val_mae: 0.8963 - val_mse: 1.3125\n",
      "Epoch 236/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6140 - mae: 0.6189 - mse: 0.6140 - val_loss: 1.2697 - val_mae: 0.8652 - val_mse: 1.2697\n",
      "Epoch 237/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6968 - mae: 0.6254 - mse: 0.6968 - val_loss: 1.2139 - val_mae: 0.8477 - val_mse: 1.2139\n",
      "Epoch 238/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6620 - mae: 0.6030 - mse: 0.6620 - val_loss: 1.0531 - val_mae: 0.7792 - val_mse: 1.0531\n",
      "Epoch 239/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5569 - mae: 0.5758 - mse: 0.5569 - val_loss: 1.0245 - val_mae: 0.7851 - val_mse: 1.0245\n",
      "Epoch 240/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7059 - mae: 0.6235 - mse: 0.7059 - val_loss: 1.1635 - val_mae: 0.8312 - val_mse: 1.1635\n",
      "Epoch 241/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5968 - mae: 0.5893 - mse: 0.5968 - val_loss: 1.8063 - val_mae: 1.0662 - val_mse: 1.8063\n",
      "Epoch 242/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6144 - mae: 0.5989 - mse: 0.6144 - val_loss: 1.0602 - val_mae: 0.7899 - val_mse: 1.0602\n",
      "Epoch 243/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5759 - mae: 0.5658 - mse: 0.5759 - val_loss: 1.2676 - val_mae: 0.8594 - val_mse: 1.2676\n",
      "Epoch 244/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5994 - mae: 0.5923 - mse: 0.5994 - val_loss: 0.9662 - val_mae: 0.7955 - val_mse: 0.9662\n",
      "Epoch 245/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6482 - mae: 0.6091 - mse: 0.6482 - val_loss: 1.2421 - val_mae: 0.8658 - val_mse: 1.2421\n",
      "Epoch 246/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6428 - mae: 0.5949 - mse: 0.6428 - val_loss: 1.1520 - val_mae: 0.8052 - val_mse: 1.1520\n",
      "Epoch 247/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6445 - mae: 0.6101 - mse: 0.6445 - val_loss: 1.7750 - val_mae: 1.0531 - val_mse: 1.7750\n",
      "Epoch 248/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6178 - mae: 0.5720 - mse: 0.6178 - val_loss: 1.8105 - val_mae: 1.0702 - val_mse: 1.8105\n",
      "Epoch 249/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6885 - mae: 0.6213 - mse: 0.6885 - val_loss: 1.0656 - val_mae: 0.7969 - val_mse: 1.0656\n",
      "Epoch 250/1000\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6558 - mae: 0.6031 - mse: 0.6558 - val_loss: 1.0713 - val_mae: 0.8103 - val_mse: 1.0713\n",
      "Epoch 251/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5425 - mae: 0.5583 - mse: 0.5425 - val_loss: 1.1150 - val_mae: 0.8339 - val_mse: 1.1150\n",
      "Epoch 252/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5734 - mae: 0.5685 - mse: 0.5734 - val_loss: 1.1143 - val_mae: 0.7948 - val_mse: 1.1143\n",
      "Epoch 253/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6248 - mae: 0.5900 - mse: 0.6248 - val_loss: 1.6733 - val_mae: 1.0112 - val_mse: 1.6733\n",
      "Epoch 254/1000\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5664 - mae: 0.5680 - mse: 0.5664 - val_loss: 1.1853 - val_mae: 0.8777 - val_mse: 1.1853\n",
      "Kappa Score: 0.7402451838879159\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 5, shuffle = True)\n",
    "results = []\n",
    "r2s = []\n",
    "mses = []\n",
    "y_pred_list = []\n",
    "count = 1\n",
    "\n",
    "for num in range(1,9):\n",
    "    essay_set = pd.read_csv(\"../dataset/cleandata_set_{}.csv\".format(num))\n",
    "    train_corpus = essay_set['essay']\n",
    "    test_corpus = train_corpus.copy()\n",
    "    vocab = CountVectorizer(stop_words='english', lowercase= True).fit(train_corpus)\n",
    "\n",
    "    # generate counts for a new set of documents\n",
    "    doc_emb = vocab.transform(train_corpus)\n",
    "    \n",
    "    vec_size = 50\n",
    "    window=2\n",
    "    min_count=1\n",
    "    workers=8\n",
    "    epochs=40\n",
    "    essays = [TaggedDocument(gensim.utils.simple_preprocess(doc), [i]) for i, doc in enumerate(train_corpus)]\n",
    "    \n",
    "    model = Doc2Vec(essays, vector_size=vec_size, window=window, min_count=min_count, workers=workers, epochs=epochs)\n",
    "    #might not need this line\n",
    "    model.train(essays, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    doc = [gensim.utils.simple_preprocess(doc) for i, doc in enumerate(test_corpus)]\n",
    "\n",
    "    doc_emb = np.zeros((len(doc), vec_size))\n",
    "    for i in range(len(doc)):\n",
    "        doc_emb[i,:] = model.infer_vector(doc[i])\n",
    "        \n",
    "    df_train = pd.DataFrame(doc_emb)\n",
    "    df_train = pd.concat([df_train, df[[\"essay_set\", \"word_count\",\"Mistakes\",\"reading_ease\"]]], axis = 1, join = \"inner\")\n",
    "    \n",
    "    y = df[\"total_score\"]\n",
    "    X = df_train\n",
    "    print(\"\\n###########Set-{}###########\\n\".format(num))\n",
    "    count = 1\n",
    "    result_for_set = []\n",
    "    for traincv, testcv in cv.split(X):\n",
    "        print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "        \n",
    "        X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "        X_train = X_train.to_numpy()\n",
    "        X_test = X_test.to_numpy()\n",
    "\n",
    "        #X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "        #X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor=\"val_loss\", patience=100)\n",
    "        \n",
    "        lstm_model = build_model(len(X_train[0]))\n",
    "        lstm_model.fit(X_train, y_train, validation_split=0.2, epochs=1000, batch_size=32,callbacks=[early_stop])\n",
    "        \n",
    "        y_pred_temp = lstm_model.predict(X_test)\n",
    "\n",
    "        y_pred = []\n",
    "        for i in y_pred_temp:\n",
    "            y_pred.append(int(round(i[0])))\n",
    "        y_pred_temp = np.around(y_pred_temp)\n",
    "        if count == 5:\n",
    "             lstm_model.save_weights('final_lstm.h5')\n",
    "        y_test_new = []\n",
    "        for  i in list(y_test.array):\n",
    "            y_test_new.append(int(i))\n",
    "        result = cohen_kappa_score(y_test_new,y_pred,weights='quadratic')\n",
    "        print(\"Kappa Score: {}\".format(result))\n",
    "        result_for_set.append(result)\n",
    "        count += 1\n",
    "    results.append(result_for_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essay_set.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
